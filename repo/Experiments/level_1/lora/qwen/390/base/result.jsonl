[
    {
        "namespace": "benedict.utils.type_util.is_json_serializable",
        "completion": "import json\n\ndef is_json_serializable(val):\n    \"\"\"\n    Checks if the input value is JSON serializable.\n\n    Args:\n        val (Any): The input value to be checked for JSON serializability.\n\n    Returns:\n        bool: True if the input value is JSON serializable, False otherwise.\n    \"\"\"\n    try:\n        json.dumps(val)\n        return True\n    except TypeError:\n        return False"
    },
    {
        "namespace": "feedparser.urls.convert_to_idn",
        "completion": "import re\nfrom urllib.parse import urlparse\nfrom idna import encode\n\ndef convert_to_idn(url):\n    \"\"\"\n    Converts a URL to IDN notation.\n\n    Args:\n        url (str): The URL to be converted to IDN notation.\n\n    Returns:\n        str: The URL in IDN notation.\n    \"\"\"\n    parsed = urlparse(url)\n    try:\n        # Check if the host can be encoded in ASCII\n        encoded_host = encode(parsed.hostname.encode('ascii'), errors='strict')\n    except UnicodeError:\n        # Host cannot be encoded in ASCII, so convert to IDN form\n        encoded_host = encode(parsed.hostname)\n    return f\"{parsed.scheme}://{encoded_host.decode()}:{parsed.port}{parsed.path}\"\n"
    },
    {
        "namespace": "googleapiclient._helpers.parse_unique_urlencoded",
        "completion": "import urllib.parse\n\ndef parse_unique_urlencoded(content):\n    \"\"\"\n    Parses unique key-value parameters from urlencoded content.\n\n    Args:\n        content (str): URL-encoded key-value pairs.\n\n    Returns:\n        dict: The key-value pairs from the input content.\n\n    Raises:\n        ValueError: if one of the keys is repeated.\n    \"\"\"\n    result = {}\n    for key, value in urllib.parse.parse_qsl(content):\n        if key in result:\n            raise ValueError(\"Duplicate key: %r\" % key)\n        result[key] = value\n    return result"
    },
    {
        "namespace": "jinja2.async_utils.auto_aiter",
        "completion": "import asyncio\nfrom typing import TypeVar, Generic, AsyncIterable, Iterable, Iterator, Union\n\nT = TypeVar('T')\n\nclass AutoAiter(Generic[T]):\n    def __init__(self, iterable: Union[AsyncIterable[T], Iterable[T]]) -> None:\n        self._iterable = iterable\n\n    async def __anext__(self) -> T:\n        if hasattr(self._iterable, '__aiter__'):\n            return await (await self._iterable.__aiter__()).__anext__()\n        else:\n            return next(iter(self._iterable))\n\ndef auto_aiter(\n    iterable: Union[AsyncIterable[T], Iterable[T]]\n) -> 'AutoAiter[T]':\n    return AutoAiter(iterable)\n"
    },
    {
        "namespace": "csvs_to_sqlite.utils.table_exists",
        "completion": "Certainly! Below is a Python function named `table_exists` that checks if a table exists in a database using a provided database connection.\n\n```python\ndef table_exists(conn, table):\n    \"\"\"\n    Check if the table exists in the database.\n\n    :param conn: Connection. The connection to the database.\n    :param table: String. The name of the table to check.\n    :return: Bool. True if the table exists, False otherwise.\n    \"\"\"\n    cursor = conn.cursor()\n    try:\n        # Execute a query to check if the table exists\n        cursor.execute(f\"SELECT 1 FROM {table} LIMIT 0\")\n        return True\n    except Exception as e:\n        # If an exception occurs, the table does not exist\n        return False\n    finally:\n        # Close the cursor to free up resources\n        cursor.close()\n```\n\n### Explanation:\n- **Parameters**:\n  - `conn`: A database connection object (e.g., from `psycopg2`, `sqlite3`, etc.).\n  - `table`: A string representing the name of the table to check.\n\n- **Functionality**:\n  - The function uses a cursor to execute a SQL query that attempts to select data from the specified table without actually fetching any rows (`LIMIT 0`).\n  - If the query executes successfully, it means the table exists, and the function returns `True`.\n  - If an exception occurs during the execution of the query, it indicates that the table does not exist, and the function returns `False`.\n  - The cursor is closed in the `finally` block to ensure that resources are properly released even if an exception occurs.\n\nThis function is generic and should work with most database connections that support similar SQL syntax."
    },
    {
        "namespace": "sqlitedict.SqliteDict.get_tablenames",
        "completion": "import os\nimport sqlite3\n\ndef get_tablenames(filename):\n    \"\"\"\n    Get table names in an SQLite database.\n\n    Args:\n        filename (str): Name of SQLite database file.\n\n    Returns:\n        list[str]: Names of tables in SQLite database.\n\n    Raises:\n        IOError: if file does not exist.\n    \"\"\"\n\n    # Check if the file exists\n    if not os.path.exists(filename):\n        raise IOError('file {} does not exist'.format(filename))\n\n    # Connect to the SQLite database\n    conn = sqlite3.connect(filename)\n    cursor = conn.cursor()\n\n    # Execute query to retrieve table names\n    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n    tablenames = [row[0] for row in cursor.fetchall()]\n\n    # Close the connection\n    conn.close()\n\n    return tablenames\n"
    },
    {
        "namespace": "psd_tools.utils.pack",
        "completion": "import struct\n\ndef pack(fmt, *args):\n    \"\"\"\n    Packs the input arguments into a binary string according to the given format.\n\n    Args:\n        fmt (str): Format string as described in the struct module documentation.\n        *args: Arguments to pack.\n\n    Returns:\n        bytes: Packed binary string.\n    \"\"\"\n    return struct.pack(fmt, *args)\n"
    },
    {
        "namespace": "psd_tools.utils.unpack",
        "completion": "import struct\n\ndef unpack(fmt, data):\n    \"\"\"\n    Unpack the given data according to the specified format (like \">I\").\n\n    Args:\n        fmt (str): Format string to use for unpacking the data.\n        data (data): Data to unpack.\n\n    Returns:\n        tuple: A tuple containing the unpacked values.\n    \"\"\"\n    return struct.unpack(fmt, data)\n"
    },
    {
        "namespace": "exodus_bundler.bundling.bytes_to_int",
        "completion": "import struct\n\ndef bytes_to_int(bytes, byteorder=\"big\"):\n    \"\"\"\n    Convert a byte string into an integer.\n\n    Args:\n        bytes (bytes): Byte string.\n        byteorder (str): The byte order to be used. Defaults to \"big\".\n\n    Returns:\n        int: The converted integer value.\n    \"\"\"\n    return int.from_bytes(bytes, byteorder=byteorder)\n"
    },
    {
        "namespace": "exodus_bundler.templating.render_template",
        "completion": "def render_template(string, **context):\n    \"\"\"\n    Replace placeholders in `string` with values from `context`.\n\n    >>> render_template(\"Hello, {{name}}!\", name=\"World\")\n    'Hello, World!'\n    \"\"\"\n\n    def one_replacement(match):\n        return str(context[match.group(1)])\n\n    return re.sub(r\"{{\\s*([^}]+)\\s*}}\", one_replacement, string)\n"
    },
    {
        "namespace": "trailscraper.iam.all_known_iam_permissions",
        "completion": "import os\n\ndef all_known_iam_permissions():\n    \"\"\"\n    Returns a set of all known IAM actions.\n\n    :return: set. A set of lines.\n    \"\"\"\n    filename = os.path.join(os.path.dirname(__file__), \"known-iam-actions.txt\")\n    with open(filename) as f:\n        return {line.strip() for line in f if not line.startswith(\"#\")}\n"
    },
    {
        "namespace": "trailscraper.cloudtrail.parse_records",
        "completion": "def parse_records(json_records):\n    \"\"\"\n    Convert a list of JSON records into a list of Record objects.\n\n    Args:\n        json_records (List): A list of JSON records to be parsed.\n\n    Returns:\n        List: A list of Record objects parsed from the JSON records.\n    \"\"\"\n    return [r for r in [_parse_record(r) for r in json_records] if r]\n"
    },
    {
        "namespace": "discord.utils.get_slots",
        "completion": "def get_slots(cls):\n    \"\"\"\n    Return an iterator that yields the names of the slots in `cls` and its base classes.\n\n    Args:\n        cls (Type): The class for which the slots are to be retrieved.\n\n    Returns:\n        Iterator: An iterator that yields the names of the slots in the class and its base classes.\n    \"\"\"\n    for base in reversed(inspect.getmro(cls)):\n        if hasattr(base, \"__slots__\"):\n            yield from base.__slots__\n"
    },
    {
        "namespace": "discord.utils.is_inside_class",
        "completion": "def is_inside_class(func):\n    \"\"\"\n    Determine whether a given callable (function or method) is defined\n    within a class.\n\n    Args:\n        func (Callable): The function to be checked\n\n    Returns:\n        bool: ``True`` if the function is defined inside a class,\n            ``False`` otherwise.\n    \"\"\"\n\n    # NOTE(kgriffs): We use __qualname__ instead of __name__ because\n    #   the latter does not handle nested functions correctly. For example,\n    #   def foo():\n    #       def bar():\n    #           pass\n    #\n    #   bar.__name__ == 'bar'\n    #   bar.__qualname__ == 'foo.bar'\n\n    return '.' in func.__qualname__\n"
    },
    {
        "namespace": "wandb.util.to_forward_slash_path",
        "completion": "import os\n\ndef to_forward_slash_path(path):\n    \"\"\"\n    Convert the backslash path to a forward slash path if the platform is Windows.\n\n    Args:\n        path (str): The path to be converted.\n\n    Returns:\n        str: The converted path.\n    \"\"\"\n    if os.name == \"nt\":\n        return path.replace(\"\\\\\", \"/\")\n    else:\n        return path"
    },
    {
        "namespace": "wandb.util.make_artifact_name_safe",
        "completion": "import re\n\ndef make_artifact_name_safe(name):\n    \"\"\"\n    Makes an artifact name safe for use in artifacts.\n\n    Args:\n        name (str): Original artifact name.\n\n    Returns:\n        str: Cleaned and safe artifact name.\n    \"\"\"\n    # Replace any character that is not alphanumeric, dash, underscore, or dot with an underscore\n    cleaned = re.sub(r\"[^a-zA-Z0-9-_\\.]+\", \"_\", name)\n\n    # Truncate the name if its length exceeds 128 characters\n    if len(cleaned) > 128:\n        return re.sub(\n            r\"(.{0,64}).*(.{0,63})\",\n            lambda m: f\"{m.group(1)}...{m.group(2)}\",\n            cleaned,\n        )\n\n    return cleaned\n"
    },
    {
        "namespace": "jwt.utils.force_bytes",
        "completion": "import typing\n\ndef force_bytes(value: typing.Union[bytes, str]) -> bytes:\n    \"\"\"\n    Similar to Django's `force_bytes` function.\n\n    Args:\n        value (Union[bytes, str]): The input value that needs to be converted to bytes.\n\n    Returns:\n        bytes: The input value converted to bytes.\n\n    Raises:\n        TypeError: If the input value is neither bytes nor a string.\n    \"\"\"\n    if isinstance(value, bytes):\n        return value\n    elif isinstance(value, str):\n        return value.encode(encoding=\"utf-8\")\n    else:\n        raise TypeError(f\"Expected bytes or str, got {type(value).__name__}\")\n"
    },
    {
        "namespace": "pytube.cli.display_progress_bar",
        "completion": "import sys\nfrom time import sleep\n\ndef display_progress_bar(bytes_received, filesize, ch=\"\u2588\", scale=0.55):\n    \"\"\"\n    Displays a simple, pretty progress bar in the terminal.\n\n    Args:\n        bytes_received (int): The delta between the total file size (bytes)\n            and bytes already written to disk.\n        filesize (int): File size of the media stream in bytes.\n        ch (str): Character to use for presenting progress segment.\n            Defaults to \"\u2588\".\n        scale (float): Scale multiplier to reduce progress bar size.\n            Defaults to 0.55.\n    \"\"\"\n\n    # Calculate the number of characters to fill the progress bar\n    num_chars = round(filesize * scale)\n\n    # Determine the number of filled segments\n    filled_segments = min(round((bytes_received / filesize) * num_chars), num_chars)\n\n    # Create the progress bar string\n    bar = f\"{ch * filled_segments}{'.' * (num_chars - filled_segments)}\"\n\n    # Clear the previous line and print the new progress bar\n    sys.stdout.write(f\"\\r{bar} {round((bytes_received / filesize) * 100, 2)}%\")\n    sys.stdout.flush()\n\n    # Flush the output buffer to ensure it is displayed immediately\n    if bytes_received == filesize:\n        sys.stdout.write(\"\\n\")"
    },
    {
        "namespace": "imapclient.imap_utf7.encode",
        "completion": "import imaplib\n\ndef encode(s):\n    \"\"\"\n    Encode a folder name using IMAP modified UTF-7 encoding.\n\n    Args:\n        s (Union[str, bytes]): The input string to be encoded.\n\n    Returns:\n        bytes: The encoded bytes of the input string.\n    \"\"\"\n    if isinstance(s, str):\n        return imaplib.IMAP4.utf7_encode(s)\n    else:\n        return s\n"
    },
    {
        "namespace": "imapclient.version._imapclient_version_string",
        "completion": "def _imapclient_version_string(vinfo):\n    \"\"\"\n    Creates a version string based on the given version information.\n\n    :param vinfo: Tuple. A tuple containing version information in the format (major, minor, micro, releaselevel).\n    :return: String. The version string created based on the version information.\n    \"\"\"\n    major = vinfo[0]\n    minor = vinfo[1]\n    micro = vinfo[2]\n    releaselevel = vinfo[3]\n\n    if releaselevel == 'alpha':\n        serial = vinfo[4] or 0\n        version = f'{major}.{minor}.{micro}a{serial}'\n    elif releaselevel == 'beta':\n        serial = vinfo[4] or 0\n        version = f'{major}.{minor}.{micro}b{serial}'\n    elif releaselevel == 'candidate':\n        serial = vinfo[4] or 0\n        version = f'{major}.{minor}.{micro}rc{serial}'\n    else:\n        version = f'{major}.{minor}.{micro}'\n\n    return version\n"
    }
]