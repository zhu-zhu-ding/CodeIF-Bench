[
    {
        "namespace": "benedict.utils.type_util.is_json_serializable",
        "type": "Input-Output Conditions",
        "test": "tests/utils/test_type_util.py::type_util_test_case::test_input_output_conditions",
        "completion": "import json\n\ndef is_json_serializable(val):\n    \"\"\"\n    Checks if the input value is JSON serializable.\n\n    Args:\n        val (Any): The input value to be checked for JSON serializability.\n\n    Returns:\n        bool: True if the input value is JSON serializable, False otherwise.\n    \"\"\"\n    try:\n        json.dumps(val)\n        return True\n    except TypeError:\n        return False"
    },
    {
        "namespace": "benedict.utils.type_util.is_json_serializable",
        "type": "Exception Handling",
        "test": "tests/utils/test_type_util.py::type_util_test_case::test_exception_handling",
        "completion": "import json\n\ndef is_json_serializable(val):\n    \"\"\"\n    Checks if the input value is JSON serializable.\n\n    Args:\n        val (Any): The input value to be checked for JSON serializability.\n\n    Returns:\n        bool: True if the input value is JSON serializable, False otherwise.\n    \"\"\"\n    try:\n        json.dumps(val)\n        return True\n    except TypeError:\n        return False\n"
    },
    {
        "namespace": "benedict.utils.type_util.is_json_serializable",
        "type": "Edge Case Handling",
        "test": "tests/utils/test_type_util.py::type_util_test_case::test_edge_case_handling",
        "completion": "import json\n\ndef is_json_serializable(val):\n    \"\"\"\n    Checks if the input value is JSON serializable.\n\n    Args:\n        val (Any): The input value to be checked for JSON serializability.\n\n    Returns:\n        bool: True if the input value is JSON serializable, False otherwise.\n    \"\"\"\n    try:\n        json.dumps(val)\n        return True\n    except TypeError:\n        return False\n"
    },
    {
        "namespace": "benedict.utils.type_util.is_json_serializable",
        "type": "Functionality Extension",
        "test": "tests/utils/test_type_util.py::type_util_test_case::test_functionality_extension",
        "completion": "import json\nfrom typing import Any\nimport numpy as np\n\ndef is_json_serializable(val: Any) -> bool:\n    \"\"\"\n    Checks if the input value is JSON serializable.\n\n    Args:\n        val (Any): The input value to be checked for JSON serializability.\n\n    Returns:\n        bool: True if the input value is JSON serializable, False otherwise.\n    \"\"\"\n    try:\n        # Attempt to serialize the value using json.dumps()\n        json.dumps(val)\n        return True\n    except TypeError:\n        # If a TypeError occurs during serialization, check for numpy data types\n        if isinstance(val, (np.ndarray, np.generic)):\n            return False\n        # Recursively check each element in the value if it's a list or dictionary\n        elif isinstance(val, dict):\n            return all(is_json_serializable(v) for v in val.values())\n        elif isinstance(val, list):\n            return all(is_json_serializable(v) for v in val)\n        else:\n            return False\n"
    },
    {
        "namespace": "benedict.utils.type_util.is_json_serializable",
        "type": "Annotation Coverage",
        "test": "tests/utils/test_type_util.py::type_util_test_case::test_annotation_coverage",
        "completion": "import json\n\ndef is_json_serializable(val: Any) -> bool:\n    \"\"\"\n    Checks if the input value is JSON serializable.\n\n    Args:\n        val (Any): The input value to be checked for JSON serializability.\n\n    Returns:\n        bool: True if the input value is JSON serializable, False otherwise.\n    \"\"\"\n    try:\n        json.dumps(val)\n        return True\n    except TypeError:\n        return False"
    },
    {
        "namespace": "benedict.utils.type_util.is_json_serializable",
        "type": "Code Complexity",
        "test": "tests/utils/test_type_util.py::type_util_test_case::test_code_complexity",
        "completion": "def is_json_serializable(val):\n    \"\"\"Check if ``val`` is of a json serializable type.\n\n    Args:\n        val (Any): Value to check for json serializability\n\n    Returns:\n        bool: `True` if ``val`` is of a json serializable type,\n            `False` otherwise.\n\n    \"\"\"\n    return isinstance(val, (str, int, float, bool, list, dict, tuple))\n"
    },
    {
        "namespace": "benedict.utils.type_util.is_json_serializable",
        "type": "Code Standard",
        "test": "tests/utils/test_type_util.py::type_util_test_case::test_check_code_style",
        "completion": "def is_json_serializable(val):\n    \"\"\"\n    Checks if the input value is JSON serializable.\n\n    Args:\n        val (Any): The input value to be checked for JSON serializability.\n\n    Returns:\n        bool: True if the input value is JSON serializable, False otherwise.\n    \"\"\"\n    json_serializable_types = {str, int, float, bool, type(None)}\n    if isinstance(val, dict):\n        return all(isinstance(key, str) and is_json_serializable(key) and is_json_serializable(value)\n                   for key, value in val.items())\n    elif isinstance(val, list):\n        return all(is_json_serializable(item) for item in val)\n    else:\n        return isinstance(val, json_serializable_types)\n"
    },
    {
        "namespace": "feedparser.urls.convert_to_idn",
        "type": "Exception Handling",
        "test": "tests/runtests.py::TestConvertToIdn::test_exception_handling_invalid_url",
        "completion": "import re\nfrom urllib.parse import urlparse\nfrom idna import encode\n\ndef convert_to_idn(url):\n    \"\"\"\n    Converts a URL to IDN notation.\n\n    Args:\n        url (str): The URL to be converted to IDN notation.\n\n    Returns:\n        str: The URL in IDN notation.\n\n    Raises:\n        ValueError: If the input is not a valid URL string.\n        UnicodeError: If conversion to IDN fails.\n    \"\"\"\n    if not isinstance(url, str) or not re.match(r'^https?://', url):\n        raise ValueError(\"Invalid URL format\")\n\n    parsed_url = urlparse(url)\n    try:\n        if not all(x.isascii() for x in parsed_url.netloc.split(\".\")):\n            return url.replace(\n                parsed_url.netloc,\n                \".\".join(encode(x).decode(\"ascii\") for x in parsed_url.netloc.split(\".\"))\n            )\n        else:\n            return url\n    except Exception as e:\n        raise UnicodeError(f\"Failed to convert URL to IDN: {e}\")\n"
    },
    {
        "namespace": "feedparser.urls.convert_to_idn",
        "type": "Edge Case Handling",
        "test": "tests/runtests.py::TestConvertToIdn::test_edge_case_empty_string",
        "completion": "import re\nfrom urllib.parse import urlparse\nfrom idna import encode\n\ndef convert_to_idn(url):\n    \"\"\"\n    Converts a URL to IDN notation.\n\n    Args:\n        url (str): The URL to be converted to IDN notation.\n\n    Returns:\n        str: The URL in IDN notation.\n    \"\"\"\n    if not url or not isinstance(url, str):\n        return url\n\n    parsed_url = urlparse(url)\n    if not parsed_url.netloc:\n        return url\n\n    # Check if the host is an IPv4 address\n    if re.match(r'^\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}$', parsed_url.hostname):\n        return url\n\n    try:\n        # Attempt to encode the hostname in ASCII\n        ascii_host = parsed_url.hostname.encode('ascii').decode('ascii')\n    except UnicodeError:\n        # If encoding fails, convert to IDN\n        ascii_host = encode(parsed_url.hostname).decode('ascii')\n\n    # Reconstruct the URL with the updated hostname\n    new_url = f\"{parsed_url.scheme}://{ascii_host}{parsed_url.path}\"\n    if parsed_url.query:\n        new_url += f\"?{parsed_url.query}\"\n    if parsed_url.fragment:\n        new_url += f\"#{parsed_url.fragment}\"\n\n    return new_url\n"
    },
    {
        "namespace": "feedparser.urls.convert_to_idn",
        "type": "Functionality Extension",
        "test": "tests/runtests.py::TestConvertToIdn::test_functionality_extension_query_fragment",
        "completion": "import re\nfrom urllib.parse import urlparse, urlunparse\n\ndef convert_to_idn(url):\n    \"\"\"\n    Converts a URL to IDN notation.\n\n    Args:\n        url (str): The URL to be converted to IDN notation.\n\n    Returns:\n        str: The URL in IDN notation.\n    \"\"\"\n    parsed_url = urlparse(url)\n    try:\n        # Check if the host can be encoded in ASCII\n        parsed_url.netloc.encode('idna').decode('ascii')\n    except UnicodeError:\n        # Encode the host to IDN form\n        netloc = parsed_url.hostname.encode('idna').decode('ascii')\n        if parsed_url.port:\n            netloc += u':{}'.format(parsed_url.port)\n        return urlunparse((parsed_url.scheme,\n                            netloc,\n                            parsed_url.path,\n                            parsed_url.params,\n                            parsed_url.query,\n                            parsed_url.fragment))\n    else:\n        # Return the original URL if no conversion is needed\n        return url\n"
    },
    {
        "namespace": "feedparser.urls.convert_to_idn",
        "type": "Annotation Coverage",
        "test": "tests/runtests.py::TestConvertToIdn::test_annotation_coverage",
        "completion": "import re\nfrom urllib.parse import urlparse\nfrom idna import encode\n\ndef convert_to_idn(url: str) -> str:\n    \"\"\"\n    Convert a URL to IDN notation.\n\n    Args:\n        url (str): The URL to be converted to IDN notation.\n\n    Returns:\n        str: The URL in IDN notation.\n    \"\"\"\n    # Check if the host can be encoded in ASCII\n    ascii_host = url.split('//', 1)[-1].split('/', 1)[0]\n    try:\n        ascii_host.encode('ascii').decode('ascii')\n    except UnicodeError:\n        # Host contains non-ASCII characters, convert to IDN\n        parsed_url = urlparse(url)\n        netloc = f\"{parsed_url.netloc.rpartition('@')[-1]}\"\n        try:\n            new_netloc = encode(netloc).decode('ascii')\n            fixed_url = re.sub(\n                r'(?i)^(.*?://)(.*)$',\n                lambda m: f'{m.group(1)}{new_netloc}{m.group(2)}',\n                url,\n            )\n            return fixed_url\n        except Exception as e:\n            raise ValueError(f\"Failed to convert URL to IDN: {e}\")\n    else:\n        # Host is already in ASCII, no conversion needed\n        return url\n"
    },
    {
        "namespace": "feedparser.urls.convert_to_idn",
        "type": "Code Complexity",
        "test": "tests/runtests.py::TestConvertToIdn::test_code_complexity",
        "completion": "import re\nfrom urllib.parse import urlparse\nfrom idna import encode\n\ndef convert_to_idn(url):\n    \"\"\"\n    Converts a URL to IDN notation.\n\n    Args:\n        url (str): The URL to be converted to IDN notation.\n\n    Returns:\n        str: The URL in IDN notation.\n    \"\"\"\n    parsed = urlparse(url)\n    try:\n        # Check if the host can be encoded in ASCII\n        encoded_host = encode(parsed.hostname).decode(\"ascii\")\n    except UnicodeError:\n        # Convert the host to IDN form\n        encoded_host = encode(parsed.hostname)\n    return f\"{parsed.scheme}://{encoded_host}{parsed.path}\"\n"
    },
    {
        "namespace": "feedparser.urls.convert_to_idn",
        "type": "Code Standard",
        "test": "tests/runtests.py::TestConvertToIdn::test_check_code_style",
        "completion": "import re\nfrom urllib.parse import urlparse\nfrom idna import encode\n\ndef convert_to_idn(url):\n    \"\"\"\n    Converts a URL to IDN notation.\n\n    Args:\n        url (str): The URL to be converted to IDN notation.\n\n    Returns:\n        str: The URL in IDN notation.\n    \"\"\"\n    parsed_url = urlparse(url)\n    hostname = parsed_url.hostname\n\n    # Check if the host can be encoded in ASCII\n    ascii_host = hostname.encode('idna').decode('ascii')\n\n    # If encoding fails, return the original URL\n    if ascii_host != hostname:\n        return url\n\n    # Encode the host to IDN form\n    try:\n        new_host = encode(hostname).decode('ascii')\n        fixed_url = re.sub(\n            r'(?i)^(.*://)([^/]*?)((/.*)?)$',\n            lambda m: f'{m.group(1)}{new_host}{m.group(3)}',\n            url,\n        )\n        return fixed_url\n    except UnicodeError:\n        return url\n"
    },
    {
        "namespace": "googleapiclient._helpers.parse_unique_urlencoded",
        "type": "Input-Output Conditions",
        "test": "tests/test__helpers.py::Test_parse_unique_urlencoded::test_special_characters",
        "completion": "import urllib.parse\n\ndef parse_unique_urlencoded(content):\n    \"\"\"\n    Parses unique key-value parameters from urlencoded content.\n\n    Args:\n        content (str): URL-encoded key-value pairs.\n\n    Returns:\n        dict: The key-value pairs from the input content.\n\n    Raises:\n        ValueError: if one of the keys is repeated.\n    \"\"\"\n    result = {}\n    for key, value in urllib.parse.parse_qsl(content):\n        if key in result:\n            raise ValueError(\"Duplicate key: %r\" % key)\n        result[key] = value\n    return result\n"
    },
    {
        "namespace": "googleapiclient._helpers.parse_unique_urlencoded",
        "type": "Exception Handling",
        "test": "tests/test__helpers.py::Test_parse_unique_urlencoded::test_repeated_key_error_message",
        "completion": "def parse_unique_urlencoded(content):\n    \"\"\"\n    Parses unique key-value parameters from urlencoded content.\n\n    Args:\n        content (str): URL-encoded key-value pairs\n\n    Returns:\n        dict: The key-value pairs from the input `content`.\n\n    Raises:\n        ValueError: if one of the keys is repeated\n    \"\"\"\n    result = {}\n    for comp in content.split('&'):\n        if not comp:\n            continue\n        parts = comp.split('=', 1)\n        if len(parts) != 2:\n            raise ValueError(\"Invalid URL-encoded component: %r\" % comp)\n        key, val = parts\n        try:\n            key = urllib.parse.unquote(key)\n            val = urllib.parse.unquote(val)\n        except UnicodeDecodeError as e:\n            raise ValueError(f\"Failed to decode URL-encoded component: {comp}\") from e\n        if key in result:\n            raise ValueError(f\"Repeated key in URL-encoded content: {key}\")\n        result[key] = val\n    return result\n"
    },
    {
        "namespace": "googleapiclient._helpers.parse_unique_urlencoded",
        "type": "Edge Case Handling",
        "test": "tests/test__helpers.py::Test_parse_unique_urlencoded::test_empty_content",
        "completion": "def parse_unique_urlencoded(content):\n    \"\"\"\n    Parses unique key-value parameters from urlencoded content.\n\n    :param content: string. Url-encoded key-value pairs.\n    :return: dict. The key-value pairs from the input content.\n    :raises ValueError: if one of the keys is repeated.\n    \"\"\"\n    result = {}\n    if not content:\n        return result\n\n    for name_value in content.split('&'):\n        if not name_value:\n            continue\n\n        name_value = name_value.split('=', 1)\n        if len(name_value) == 1:\n            # missing '=' which means param with empty value\n            name_value.append('')\n        elif len(name_value) > 2:\n            raise ValueError(\"Malformed urlencoded data\")\n\n        name = urllib.parse.unquote_plus(name_value[0])\n        value = urllib.parse.unquote_plus(name_value[1])\n\n        if name in result:\n            raise ValueError(f\"Duplicate key: {name}\")\n\n        result[name] = value\n\n    return result\n"
    },
    {
        "namespace": "googleapiclient._helpers.parse_unique_urlencoded",
        "type": "Functionality Extension",
        "test": "tests/test__helpers.py::Test_parse_unique_urlencoded::test_ignore_empty_keys_and_values",
        "completion": "import urllib.parse\n\ndef parse_unique_urlencoded(content):\n    \"\"\"\n    Parses unique key-value parameters from urlencoded content.\n\n    Args:\n        content (str): URL-encoded key-value pairs.\n\n    Returns:\n        dict: The key-value pairs from the input content.\n\n    Raises:\n        ValueError: if one of the keys is repeated or if there are empty keys/values.\n    \"\"\"\n    result = {}\n    for key, value in urllib.parse.parse_qsl(content):\n        if not key or not value:\n            raise ValueError(\"Empty key or value found in the URL-encoded content.\")\n        if key in result:\n            raise ValueError(f\"Duplicate key '{key}' found in the URL-encoded content.\")\n        result[key] = value\n    return result"
    },
    {
        "namespace": "googleapiclient._helpers.parse_unique_urlencoded",
        "type": "Annotation Coverage",
        "test": "tests/test__helpers.py::Test_parse_unique_urlencoded::test_function_annotations",
        "completion": "import urllib.parse\nfrom typing import Dict\n\ndef parse_unique_urlencoded(content: str) -> Dict[str, str]:\n    \"\"\"\n    Parses unique key-value parameters from url-encoded content.\n\n    Args:\n        content (str): URL-encoded key-value pairs.\n\n    Returns:\n        Dict[str, str]: The key-value pairs from the input content.\n\n    Raises:\n        ValueError: If one of the keys is repeated.\n    \"\"\"\n    result = {}\n    for key, value in urllib.parse.parse_qsl(content):\n        if key in result:\n            raise ValueError(f\"Duplicate key: {key}\")\n        result[key] = value\n    return result\n"
    },
    {
        "namespace": "googleapiclient._helpers.parse_unique_urlencoded",
        "type": "Code Complexity",
        "test": "tests/test__helpers.py::Test_parse_unique_urlencoded::test_code_complexity",
        "completion": "def parse_unique_urlencoded(content):\n    \"\"\"Parse unique key-value parameters from urlencoded content.\n\n    Args:\n        content (str): URL-encoded key=value pairs\n\n    Returns:\n        dict: The key-value pairs from the input `content`.\n\n    Raises:\n        ValueError: if one of the keys is repeated\n\n    Example:\n        >>> parse_unique_urlencoded('foo=bar&baz=qux')\n        {'foo': 'bar', 'baz': 'qux'}\n\n    \"\"\"\n    result = {}\n    for comp in content.split('&'):\n        if not comp:\n            continue\n        try:\n            k, v = comp.split('=', 1)\n        except ValueError:\n            raise ValueError(\"Invalid URL encoded pair: %r\" % comp)\n\n        if k in result:\n            raise ValueError(\"Duplicate key: %r\" % k)\n\n        result[k] = v\n\n    return result\n"
    },
    {
        "namespace": "googleapiclient._helpers.parse_unique_urlencoded",
        "type": "Code Standard",
        "test": "tests/test__helpers.py::Test_parse_unique_urlencoded::test_check_code_style",
        "completion": "def parse_unique_urlencoded(content):\n    \"\"\"\n    Parses unique key-value parameters from urlencoded content.\n\n    Args:\n        content (str): URL-encoded key-value pairs\n\n    Returns:\n        dict: The key-value pairs from the input content\n\n    Raises:\n        ValueError: if one of the keys is repeated\n    \"\"\"\n\n    result = {}\n    for key, value in urlparse.parse_qsl(content):\n        if key in result:\n            raise ValueError(\"Duplicate key: %r\" % key)\n        result[key] = value\n    return result\n"
    },
    {
        "namespace": "jinja2.async_utils.auto_aiter",
        "type": "Input-Output Conditions",
        "test": "tests/test_async.py::test_input_output_conditions",
        "completion": "import asyncio\nfrom typing import TypeVar, Generic, Iterator, AsyncIterator, Union\n\nT = TypeVar('T')\n\nclass auto_aiter(Generic[T]):\n    def __init__(self, iterable: Union[AsyncIterable[T], Iterable[T]]) -> None:\n        self._iterable = iterable\n\n    async def __aenter__(self) -> 'auto_aiter':\n        return self\n\n    async def __aexit__(self, exc_type, exc_val, exc_tb):\n        pass\n\n    async def __anext__(self) -> T:\n        try:\n            if hasattr(self._iterable, '__aiter__'):\n                return await (await self._iterable.__aiter__()).__anext__()\n            else:\n                return next(iter(self._iterable))\n        except StopIteration:\n            raise StopAsyncIteration\n\n    def __iter__(self) -> Iterator[T]:\n        if hasattr(self._iterable, '__iter__'):\n            return iter(self._iterable)\n        else:\n            raise TypeError(\"The provided iterable does not support iteration.\")\n\n# Example usage:\nasync def example_usage():\n    async for item in auto_aiter([1, 2, 3]):\n        print(item)\n\n# To run the example:\n# asyncio.run(example_usage())\n"
    },
    {
        "namespace": "jinja2.async_utils.auto_aiter",
        "type": "Exception Handling",
        "test": "tests/test_async.py::test_exception_handling",
        "completion": "import asyncio\nfrom typing import TypeVar, Generic, Iterator, AsyncIterator, Union\n\nT = TypeVar('T')\n\nclass AutoIter(Generic[T]):\n    def __init__(self, iterable: Union[AsyncIterable[T], Iterable[T]]) -> None:\n        self.iterable = iterable\n\n    async def __anext__(self) -> T:\n        try:\n            return await self.__anext__()\n        except AttributeError:\n            return next(self)\n\n    def __iter__(self) -> Iterator[T]:\n        try:\n            return iter(self.iterable)\n        except AttributeError:\n            raise TypeError(\"Input must be an iterable or an asynchronous iterable\")\n\ndef auto_aiter(iterable: Union[AsyncIterable[T], Iterable[T]]) -> AsyncIterator[T]:\n    return AutoIter(iterable).__anext__()\n"
    },
    {
        "namespace": "jinja2.async_utils.auto_aiter",
        "type": "Edge Case Handling",
        "test": "tests/test_async.py::test_edge_case_handling",
        "completion": "import asyncio\nfrom typing import TypeVar, Generic, Iterator, AsyncIterator, Union\n\nT = TypeVar('T')\n\nclass AutoAiter(Generic[T]):\n    def __init__(self, iterable: Union[AsyncIterable[T], Iterable[T]]) -> None:\n        self._it = iter(iterable) if not hasattr(iterable, '__aiter__') else getattr(iterable, '__aiter__')()\n\n    async def __anext__(self) -> T:\n        try:\n            return await self._anext()\n        except StopIteration as e:\n            raise StopAsyncIteration() from e\n\n    async def _anext(self) -> T:\n        if hasattr(self._it, '__anext__'):\n            return await self._it.__anext__()\n        return next(self._it)\n\ndef auto_aiter(iterable: Union[AsyncIterable[T], Iterable[T]]) -> AsyncIterator[T]:\n    return AutoAiter(iterable).__anext__\n"
    },
    {
        "namespace": "jinja2.async_utils.auto_aiter",
        "type": "Functionality Extension",
        "test": "tests/test_async.py::test_functionality_extension",
        "completion": "import asyncio\nfrom typing import (\n    TypeVar,\n    Generic,\n    AsyncIterable,\n    Iterable,\n    Iterator,\n    AsyncIterator,\n    Optional,\n)\n\nT = TypeVar('T')\n\nclass auto_aiter(Generic[T]):\n    def __init__(self, iterable: Union[AsyncIterable[T], Iterable[T]], delay: Optional[float] = None):\n        self.iterable = iterable\n        self.delay = delay\n\n    async def __anext__(self) -> T:\n        if hasattr(self.iterable, '__aiter__'):\n            return await self._anext_async()\n        else:\n            return next(self._anext_sync())\n\n    async def _anext_async(self) -> T:\n        if not hasattr(self.iterable, '__aiter__'):\n            raise RuntimeError(\"The provided iterable does not support asynchronous iteration.\")\n        aiter = getattr(self.iterable, '__aiter__', iter)(self.iterable)\n        while True:\n            try:\n                value = await aiter.__anext__()\n                if self.delay:\n                    await asyncio.sleep(self.delay)\n                yield value\n            except StopAsyncIteration:\n                break\n\n    def _anext_sync(self) -> T:\n        if hasattr(self.iterable, '__aiter__'):\n            raise RuntimeError(\"The provided iterable does not support synchronous iteration.\")\n        iter = getattr(self.iterable, '__iter__', iter)(self.iterable)\n        while True:\n            try:\n                value = next(iter)\n                if self.delay:\n                    time.sleep(self.delay)\n                yield value\n            except StopIteration:\n                break\n"
    },
    {
        "namespace": "jinja2.async_utils.auto_aiter",
        "type": "Annotation Coverage",
        "test": "tests/test_async.py::test_annotation_coverage",
        "completion": "from typing import Union, AsyncIterable, Iterable, Iterator, TypeVar, AsyncGenerator\n\nT = TypeVar('T')\n\ndef auto_aiter(\n    iterable: Union[AsyncIterable[T], Iterable[T]]\n) -> AsyncIterator[T]:\n    \"\"\"\n    Creates an asynchronous iterator from the given iterable.\n\n    Args:\n        iterable (Union[AsyncIterable[T], Iterable[T]]): The input iterable from which the iterator is created.\n\n    Returns:\n        AsyncIterator[T]: The created asynchronous iterator.\n    \"\"\"\n    if hasattr(iterable, \"__aiter__\"):\n        # Yield items asynchronously using __aiter__\n        async def _aiter() -> AsyncGenerator[T, None]:\n            async for item in iterable:\n                yield item\n\n        return _aiter()\n    else:\n        # Yield items synchronously using __iter__\n        def _iter() -> Iterator[T]:\n            for item in iterable:\n                yield item\n\n        return iter(_iter)\n"
    },
    {
        "namespace": "jinja2.async_utils.auto_aiter",
        "type": "Code Complexity",
        "test": "tests/test_async.py::test_code_complexity",
        "completion": "import asyncio\nfrom typing import TypeVar, Generic, AsyncIterator, Union, Iterator\n\nT = TypeVar('T')\n\nclass auto_aiter(Generic[T]):\n    def __init__(self, iterable: Union[AsyncIterable[T], Iterable[T]]) -> None:\n        self._iterable = iterable\n\n    async def __aenter__(self) -> 'auto_aiter':\n        return self\n\n    async def __aexit__(self, exc_type, exc_val, exc_tb):\n        pass\n\n    async def __anext__(self) -> T:\n        try:\n            if hasattr(self._iterable, '__aiter__'):\n                return await (await self._iterable.__aiter__()).__anext__()\n            else:\n                return next(iter(self._iterable))\n        except StopIteration as e:\n            raise StopAsyncIteration() from e\n\n    def __iter__(self) -> Iterator[T]:\n        if hasattr(self._iterable, '__iter__'):\n            return iter(self._iterable)\n        else:\n            raise TypeError(f'{type(self._iterable).__name__} object is not iterable')\n"
    },
    {
        "namespace": "jinja2.async_utils.auto_aiter",
        "type": "Code Standard",
        "test": "tests/test_async.py::test_check_code_style",
        "completion": "import asyncio\nfrom typing import TypeVar, Generic, AsyncIterator, Union, Iterator\n\nT = TypeVar('T')\n\nclass auto_aiter(Generic[T]):\n    def __init__(self, iterable: Union[AsyncIterable[T], Iterable[T]]) -> None:\n        self._iterable = iterable\n\n    async def __aenter__(self) -> 'auto_aiter':\n        return self\n\n    async def __aexit__(self, exc_type, exc_val, exc_tb):\n        pass\n\n    async def __anext__(self) -> T:\n        try:\n            if hasattr(self._iterable, '__aiter__'):\n                ait = iter(self._iterable)\n                while True:\n                    yield await ait.__anext__()\n            else:\n                for item in self._iterable:\n                    yield item\n        except StopIteration:\n            raise StopAsyncIteration\n\n    def __iter__(self) -> Iterator[T]:\n        if hasattr(self._iterable, '__iter__'):\n            return iter(self._iterable)\n        else:\n            raise TypeError(\"The provided iterable does not support iteration.\")\n"
    },
    {
        "namespace": "csvs_to_sqlite.utils.table_exists",
        "type": "Exception Handling",
        "test": "tests/test_utils.py::test_table_exists_exception_handling",
        "completion": "import logging\n\ndef table_exists(conn, table):\n    \"\"\"\n    Check if ``table`` exists in the database.\n\n    :param conn: Connection. The connection to the database.\n    :param table: String. The name of the table to check.\n    :return: Bool. True if the table exists, False otherwise.\n    :raises ValueError: If the connection object is None or not a valid database connection.\n    \"\"\"\n    if conn is None:\n        raise ValueError(\"Connection object cannot be None.\")\n    \n    try:\n        cursor = conn.cursor()\n        cursor.execute(f\"SELECT 1 FROM {table} LIMIT 0\")\n        return True\n    except Exception as e:\n        logging.debug(e)\n        return False\n"
    },
    {
        "namespace": "csvs_to_sqlite.utils.table_exists",
        "type": "Edge Case Handling",
        "test": "tests/test_utils.py::test_table_exists_edge_cases",
        "completion": "import re\n\ndef table_exists(conn, table):\n    \"\"\"\n    Check if a table exists in the database.\n\n    Args:\n        conn (Connection): The connection to the database.\n        table (str): The name of the table to check.\n\n    Returns:\n        bool: True if the table exists, False otherwise.\n    \"\"\"\n    # Escape any special characters in the table name\n    escaped_table = re.sub(r'[\\'\"\\\\]', lambda m: '\\\\' + m.group(0), table)\n    \n    # Construct the SQL query to check for the existence of the table\n    sql = f\"\"\"\n    SELECT EXISTS (\n        SELECT 1\n        FROM   information_schema.tables \n        WHERE  table_name = '{escaped_table}'\n    )\n    \"\"\"\n    \n    # Execute the query and return the result\n    with conn.cursor() as cursor:\n        cursor.execute(sql)\n        result = cursor.fetchone()\n        return result[0]\n"
    },
    {
        "namespace": "csvs_to_sqlite.utils.table_exists",
        "type": "Annotation Coverage",
        "test": "tests/test_utils.py::test_table_exists_annotation_coverage",
        "completion": "import sqlite3\n\ndef table_exists(conn: sqlite3.Connection, table: str) -> bool:\n    \"\"\"\n    Check if the specified table exists in the database.\n\n    Args:\n        conn (sqlite3.Connection): The connection to the database.\n        table (str): The name of the table to check.\n\n    Returns:\n        bool: True if the table exists, False otherwise.\n    \"\"\"\n    cursor = conn.cursor()\n    cursor.execute(f\"SELECT name FROM sqlite_master WHERE type='table' AND name='{table}'\")\n    return bool(cursor.fetchone())\n"
    },
    {
        "namespace": "csvs_to_sqlite.utils.table_exists",
        "type": "Code Complexity",
        "test": "tests/test_utils.py::test_code_complexity",
        "completion": "def table_exists(conn, table):\n    \"\"\"Check if ``table`` exists in the database.\n\n    Args:\n        conn (Connection): The connection to the database.\n        table (str): The name of the table to check.\n\n    Returns:\n        bool: True if the table exists, False otherwise.\n    \"\"\"\n    cursor = conn.execute(\n        \"SELECT EXISTS(SELECT 1 FROM pg_tables WHERE tablename = %s)\",\n        [table],\n    )\n    return cursor.fetchone()[0]\n"
    },
    {
        "namespace": "csvs_to_sqlite.utils.table_exists",
        "type": "Code Standard",
        "test": "tests/test_utils.py::test_check_code_style",
        "completion": "def table_exists(conn, table):\n    \"\"\"\n    Check if the table exists in the database.\n\n    Args:\n        conn (Connection): The connection to the database.\n        table (str): The name of the table to check.\n\n    Returns:\n        bool: True if the table exists, False otherwise.\n    \"\"\"\n    cursor = conn.cursor()\n    cursor.execute(f\"SELECT EXISTS(SELECT * FROM information_schema.tables WHERE table_name='{table}')\")\n    result = cursor.fetchone()[0]\n    cursor.close()\n    return result\n"
    },
    {
        "namespace": "sqlitedict.SqliteDict.get_tablenames",
        "type": "Input-Output Conditions",
        "test": "tests/test_core.py::TablenamesTest::test_input_output_conditions",
        "completion": "import os\nimport sqlite3\n\ndef get_tablenames(filename):\n    \"\"\"Get table names from an SQLite database.\n\n    Args:\n        filename (str): Name of the SQLite database file.\n\n    Returns:\n        list[str]: Names of the tables in the SQLite database.\n\n    Raises:\n        IOError: If the file does not exist.\n    \"\"\"\n    if not os.path.exists(filename):\n        raise IOError('file {} does not exist'.format(filename))\n    con = sqlite3.connect(filename)\n    cursor = con.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n    tablenames = [t[0] for t in cursor.fetchall()]\n    con.close()\n    return tablenames\n"
    },
    {
        "namespace": "sqlitedict.SqliteDict.get_tablenames",
        "type": "Exception Handling",
        "test": "tests/test_core.py::TablenamesTest::test_exception_handling",
        "completion": "import os\nimport sqlite3\n\ndef get_tablenames(filename):\n    \"\"\"\n    Get table names in an SQLite database.\n\n    Args:\n        filename (str): Name of SQLite database file.\n\n    Returns:\n        list[str]: Names of tables in SQLite database.\n\n    Raises:\n        IOError: If file does not exist.\n    \"\"\"\n\n    # Check if the file exists\n    if not os.path.exists(filename):\n        raise IOError('file {} does not exist'.format(filename))\n\n    # Connect to the SQLite database\n    con = sqlite3.connect(filename)\n    cursor = con.cursor()\n\n    # Execute query to retrieve table names\n    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n    results = cursor.fetchall()\n\n    # Close the connection\n    con.close()\n\n    # Extract table names from results\n    tablenames = [t[0] for t in results]\n\n    # Return the list of table names\n    return tablenames\n"
    },
    {
        "namespace": "sqlitedict.SqliteDict.get_tablenames",
        "type": "Edge Case Handling",
        "test": "tests/test_core.py::TablenamesTest::test_edge_case_handling",
        "completion": "import os\nimport sqlite3\n\ndef get_tablenames(filename):\n    \"\"\"\n    Get table names in an SQLite database.\n\n    Args:\n        filename (str): Name of SQLite database file.\n\n    Returns:\n        list[str]: Names of tables in SQLite database.\n\n    Raises:\n        IOError: If file does not exist.\n    \"\"\"\n\n    # Check if the file exists\n    if not os.path.exists(filename):\n        raise IOError('file {} does not exist'.format(filename))\n\n    # Connect to the SQLite database\n    con = sqlite3.connect(filename)\n    cursor = con.cursor()\n\n    # Execute query to retrieve table names\n    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n    results = cursor.fetchall()\n\n    # Close the connection\n    con.close()\n\n    # Extract table names from results\n    tablenames = [t[0] for t in results]\n\n    # Return the list of table names\n    return tablenames\n"
    },
    {
        "namespace": "sqlitedict.SqliteDict.get_tablenames",
        "type": "Functionality Extension",
        "test": "tests/test_core.py::TablenamesTest::test_functionality_extension",
        "completion": "import os\nimport sqlite3\n\ndef get_tablenames(filename, prefix=None):\n    \"\"\"Get the names of the tables in an SQLite database.\n\n    Args:\n        filename (str): The name of the SQLite database file.\n        prefix (str, optional): An optional prefix to filter table names. Defaults to None.\n\n    Returns:\n        list[str]: The names of the tables in the SQLite database that match the specified prefix.\n\n    Raises:\n        IOError: If the file does not exist.\n    \"\"\"\n    if not os.path.exists(filename):\n        raise IOError('file {} does not exist'.format(filename))\n\n    con = sqlite3.connect(filename)\n    cursor = con.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n    tablenames = [row[0] for row in cursor.fetchall()]\n\n    # Filter tables by prefix if provided\n    if prefix is not None:\n        tablenames = [tablename for tablename in tablenames if tablename.startswith(prefix)]\n\n    return tablenames\n"
    },
    {
        "namespace": "sqlitedict.SqliteDict.get_tablenames",
        "type": "Annotation Coverage",
        "test": "tests/test_core.py::TablenamesTest::test_annotation_coverage",
        "completion": "import os\nfrom typing import List\n\ndef get_tablenames(filename: str) -> List[str]:\n    \"\"\"\n    Get table names from an SQLite database.\n\n    Args:\n        filename (str): The name of the SQLite database file.\n\n    Returns:\n        List[str]: A list of table names in the SQLite database.\n\n    Raises:\n        IOError: If the file does not exist.\n    \"\"\"\n    if not os.path.exists(filename):\n        raise IOError(f\"file {filename} does not exist\")\n    with open(filename, \"rb\") as fh:\n        n = int(fh.read(20)[16:20], 16)\n        tablenames_offset = int(fh.read(4), 16)\n        fh.seek(tablenames_offset + 4)\n        tablenames = []\n        for _ in range(n):\n            tablename_length = int(fh.read(1)[0])\n            tablename = fh.read(tablename_length).decode(\"utf-8\")\n            tablenames.append(tablename)\n    return tablenames\n"
    },
    {
        "namespace": "sqlitedict.SqliteDict.get_tablenames",
        "type": "Code Complexity",
        "test": "tests/test_core.py::TablenamesTest::test_code_complexity",
        "completion": "import os\nimport sqlite3\n\ndef get_tablenames(filename):\n    if not os.path.exists(filename):\n        raise IOError('file {} does not exist'.format(filename))\n    with sqlite3.connect(filename) as conn:\n        cursor = conn.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n        return [row[0] for row in cursor.fetchall()]\n"
    },
    {
        "namespace": "sqlitedict.SqliteDict.get_tablenames",
        "type": "Code Standard",
        "test": "tests/test_core.py::TablenamesTest::test_check_code_style",
        "completion": "import os\nimport sqlite3\n\ndef get_tablenames(filename):\n    \"\"\"\n    Get table names in an SQLite database.\n\n    Args:\n        filename (str): Name of the SQLite database file.\n\n    Returns:\n        list[str]: Names of the tables in the SQLite database.\n\n    Raises:\n        IOError: If the file does not exist.\n    \"\"\"\n    if not os.path.exists(filename):\n        raise IOError('file {} does not exist'.format(filename))\n\n    con = sqlite3.connect(filename)\n    cursor = con.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n    tablenames = [row[0] for row in cursor.fetchall()]\n    return tablenames\n"
    },
    {
        "namespace": "psd_tools.utils.pack",
        "type": "Exception Handling",
        "test": "tests/psd_tools/test_utils.py::test_pack_exception_handling",
        "completion": "import struct\n\ndef pack(fmt, *args):\n    try:\n        return struct.pack(fmt, *args)\n    except (struct.error, TypeError) as e:\n        raise ValueError(f\"Invalid format string or argument count: {e}\")\n"
    },
    {
        "namespace": "psd_tools.utils.pack",
        "type": "Edge Case Handling",
        "test": "tests/psd_tools/test_utils.py::test_pack_edge_cases",
        "completion": "import struct\n\ndef pack(fmt, *args):\n    \"\"\"\n    Packs the input arguments into a binary string according to the given format.\n\n    Args:\n        fmt (str): Format string that specifies the format of the returned string.\n        *args: Arguments to pack.\n\n    Returns:\n        bytes: Packed binary string.\n\n    Raises:\n        ValueError: If the format string is invalid or if the number of arguments does not match the format specifiers.\n    \"\"\"\n    try:\n        return struct.pack(fmt, *args)\n    except struct.error as e:\n        raise ValueError(f\"Error packing data: {e}\")\n"
    },
    {
        "namespace": "psd_tools.utils.pack",
        "type": "Functionality Extension",
        "test": "tests/psd_tools/test_utils.py::test_pack_functionality_extension",
        "completion": "import struct\n\ndef pack(fmt, *args):\n    \"\"\"\n    Packs the input arguments into a binary string according to the given format.\n\n    Args:\n        fmt (str): Format string that specifies the format of the returned string.\n        *args: Arguments to pack.\n\n    Returns:\n        bytes: Packed binary string.\n    \"\"\"\n    return struct.pack(fmt, *args)\n"
    },
    {
        "namespace": "psd_tools.utils.pack",
        "type": "Annotation Coverage",
        "test": "tests/psd_tools/test_utils.py::test_pack_annotations",
        "completion": "import struct\n\ndef pack(fmt: str, *args) -> bytes:\n    \"\"\"\n    Packs the input arguments into a binary string according to the given format.\n\n    Args:\n        fmt (str): The format string that specifies the format of the returned string.\n        *args (tuple): The input arguments to be packed.\n\n    Returns:\n        bytes: The packed binary string.\n    \"\"\"\n    return struct.pack(fmt, *args)\n"
    },
    {
        "namespace": "psd_tools.utils.pack",
        "type": "Code Complexity",
        "test": "tests/psd_tools/test_utils.py::test_code_complexity",
        "completion": "import struct\n\ndef pack(fmt, *args):\n    return struct.pack(fmt, *args)\n"
    },
    {
        "namespace": "psd_tools.utils.pack",
        "type": "Code Standard",
        "test": "tests/psd_tools/test_utils.py::test_check_code_style",
        "completion": "def pack(fmt, *args):\n    \"\"\"\n    Packs the input arguments into a binary string according to the given format.\n\n    Args:\n        fmt (str): The format string that specifies the format of the returned string.\n        *args: The input arguments to be packed.\n\n    Returns:\n        bytes: The packed binary string.\n    \"\"\"\n    import struct\n\n    return struct.pack(fmt, *args)\n"
    },
    {
        "namespace": "psd_tools.utils.unpack",
        "type": "Exception Handling",
        "test": "tests/psd_tools/test_utils.py::test_unpack_exception_handling",
        "completion": "import struct\n\ndef unpack(fmt, data):\n    \"\"\"\n    Unpacks the given data according to the specified format like \">{format}\".\n\n    Args:\n        fmt (str): Format string to use for unpacking the data.\n        data (data): Data to be unpacked.\n\n    Returns:\n        tuple: A tuple containing the unpacked values.\n\n    Raises:\n        ValueError: If the data length does not match the format or if the format string is invalid.\n    \"\"\"\n    try:\n        return struct.unpack(fmt, data)\n    except struct.error as e:\n        if 'incomplete input' in str(e):\n            raise ValueError('Data length does not match format')\n        else:\n            raise ValueError('Invalid format string')\n"
    },
    {
        "namespace": "psd_tools.utils.unpack",
        "type": "Edge Case Handling",
        "test": "tests/psd_tools/test_utils.py::test_unpack_edge_cases",
        "completion": "import struct\n\ndef unpack(fmt, data):\n    \"\"\"\n    Unpacks the given data according to the specified format like \">{format}\".\n\n    Args:\n        fmt (str): Format string to use for unpacking the data.\n        data (data): Data to unpack.\n\n    Returns:\n        tuple: A tuple containing the unpacked values.\n\n    Raises:\n        ValueError: If the format string is invalid or if the data does not match the expected length.\n    \"\"\"\n    try:\n        return struct.unpack(fmt, data)\n    except struct.error as e:\n        raise ValueError(f\"Failed to unpack data with format '{fmt}': {e}\")\n"
    },
    {
        "namespace": "psd_tools.utils.unpack",
        "type": "Functionality Extension",
        "test": "tests/psd_tools/test_utils.py::test_unpack_functionality_extension",
        "completion": "import struct\n\ndef unpack(fmt, data):\n    \"\"\"\n    Unpacks the given data according to the specified format string.\n\n    Args:\n        fmt (str): Format string to be used for unpacking the data.\n        data (bytes or bytearray): Data to be unpacked.\n\n    Returns:\n        tuple: A tuple containing the unpacked values.\n    \"\"\"\n    return struct.unpack(fmt, data)\n"
    },
    {
        "namespace": "psd_tools.utils.unpack",
        "type": "Annotation Coverage",
        "test": "tests/psd_tools/test_utils.py::test_unpack_annotations",
        "completion": "import struct\n\ndef unpack(fmt: str, args: tuple) -> bytes:\n    \"\"\"\n    Unpacks the given data according to the specified format.\n\n    Args:\n        fmt (str): The format string to be used for unpacking the data.\n        args (tuple): The data to be unpacked.\n\n    Returns:\n        bytes: A tuple containing the unpacked values.\n    \"\"\"\n    return struct.unpack(fmt, args)\n"
    },
    {
        "namespace": "psd_tools.utils.unpack",
        "type": "Code Complexity",
        "test": "tests/psd_tools/test_utils.py::test_code_complexity",
        "completion": "import struct\n\ndef unpack(fmt, data):\n    return struct.unpack(fmt, data)\n"
    },
    {
        "namespace": "psd_tools.utils.unpack",
        "type": "Code Standard",
        "test": "tests/psd_tools/test_utils.py::test_check_code_style",
        "completion": "import struct\n\ndef unpack(fmt, data):\n    \"\"\"\n    Unpacks the given data according to the specified format.\n\n    Args:\n        fmt (str): The format string to be used for unpacking the data.\n        data (bytes): The data to be unpacked.\n\n    Returns:\n        tuple: A tuple containing the unpacked values.\n    \"\"\"\n    return struct.unpack(fmt, data)\n"
    },
    {
        "namespace": "exodus_bundler.bundling.bytes_to_int",
        "type": "Input-Output Conditions",
        "test": "tests/test_bundling.py::test_input_output_conditions",
        "completion": "import struct\n\ndef bytes_to_int(bytes, byteorder=\"big\"):\n    \"\"\"\n    Converts a byte string into an integer.\n\n    Args:\n        bytes (bytes): Byte string to convert into an integer.\n        byteorder (str): The byte order to use ('big' or 'little'). Defaults to 'big'.\n\n    Returns:\n        int: The converted integer value.\n\n    Raises:\n        ValueError: If the byte string is empty or if the byte order is invalid.\n    \"\"\"\n    if not isinstance(bytes, bytes):\n        raise TypeError(\"Input must be a byte string.\")\n    if len(bytes) == 0:\n        raise ValueError(\"Byte string cannot be empty.\")\n    if byteorder not in {\"big\", \"little\"}:\n        raise ValueError(\"Invalid byte order. Must be 'big' or 'little'.\")\n    return int.from_bytes(bytes, byteorder)\n"
    },
    {
        "namespace": "exodus_bundler.bundling.bytes_to_int",
        "type": "Exception Handling",
        "test": "tests/test_bundling.py::test_exception_handling",
        "completion": "import struct\n\ndef bytes_to_int(bytes, byteorder=\"big\"):\n    \"\"\"\n    Convert a byte string into an integer.\n\n    Args:\n        bytes (bytes): Byte string.\n        byteorder (str): The byte order to be used. Defaults to \"big\".\n\n    Returns:\n        int: The converted integer value.\n\n    Raises:\n        ValueError: If `byteorder` is not 'big' or 'little'.\n    \"\"\"\n    if byteorder not in {\"big\", \"little\"}:\n        raise ValueError(\"byteorder must be either big or little\")\n\n    return int.from_bytes(bytes, byteorder=byteorder)\n"
    },
    {
        "namespace": "exodus_bundler.bundling.bytes_to_int",
        "type": "Edge Case Handling",
        "test": "tests/test_bundling.py::test_edge_case_handling",
        "completion": "import struct\n\ndef bytes_to_int(bytes, byteorder=\"big\"):\n    \"\"\"\n    Convert a byte string into an integer.\n\n    Args:\n        bytes (bytes): Byte string to convert into an integer.\n        byteorder (str): The byte order to use. Defaults to \"big\".\n\n    Returns:\n        int: Converted integer value.\n\n    Raises:\n        ValueError: If the byte string is empty or exceeds the maximum or minimum integer value for the given byte length.\n    \"\"\"\n    if not bytes:\n        raise ValueError(\"Byte string cannot be empty.\")\n    \n    # Calculate the maximum and minimum integer values for the given byte length\n    max_value = 2 ** (len(bytes) * 8) - 1\n    min_value = -(2 ** (len(bytes) * 8 - 1))\n    \n    # Check if the byte string represents a valid integer within the range\n    if len(bytes) == 4:\n        if byteorder == \"little\":\n            value = struct.unpack(\"<I\", bytes)[0]\n        else:\n            value = struct.unpack(\">I\", bytes)[0]\n        \n        if value < min_value or value > max_value:\n            raise ValueError(f\"Value out of range for {len(bytes)} bytes with byteorder '{byteorder}'.\")\n    elif len(bytes) == 8:\n        if byteorder == \"little\":\n            value = struct.unpack(\"<Q\", bytes)[0]\n        else:\n            value = struct.unpack(\">Q\", bytes)[0]\n        \n        if value < min_value or value > max_value:\n            raise ValueError(f\"Value out of range for {len(bytes)} bytes with byteorder '{byteorder}'.\")\n    else:\n        raise ValueError(f\"Unsupported byte length: {len(bytes)}. Only 4 and 8 bytes are supported.\")\n    \n    return value\n"
    },
    {
        "namespace": "exodus_bundler.bundling.bytes_to_int",
        "type": "Functionality Extension",
        "test": "tests/test_bundling.py::test_functionality_extension",
        "completion": "import struct\n\ndef bytes_to_int(bytes, byteorder=\"big\", signed=False):\n    \"\"\"\n    Convert a byte string into an integer.\n\n    Args:\n        bytes (bytes): Byte string to convert into an integer.\n        byteorder (str): The byte order to use. Defaults to \"big\".\n        signed (bool): Indicates whether the number is signed. Defaults to False.\n\n    Returns:\n        int: Converted integer value.\n    \"\"\"\n    if signed:\n        return int.from_bytes(bytes, byteorder=byteorder, signed=True)\n    else:\n        return int.from_bytes(bytes, byteorder=byteorder, signed=False)\n"
    },
    {
        "namespace": "exodus_bundler.bundling.bytes_to_int",
        "type": "Annotation Coverage",
        "test": "tests/test_bundling.py::test_annotation_coverage",
        "completion": "import struct\n\ndef bytes_to_int(bytes: bytes, byteorder: str = \"big\") -> int:\n    \"\"\"\n    Convert a byte string into an integer.\n\n    Args:\n        bytes (bytes): The byte string to be converted into an integer.\n        byteorder (str): The byte order to be used. Defaults to \"big\".\n\n    Returns:\n        int: The converted integer value.\n    \"\"\"\n    return int.from_bytes(bytes, byteorder=byteorder)\n"
    },
    {
        "namespace": "exodus_bundler.bundling.bytes_to_int",
        "type": "Code Complexity",
        "test": "tests/test_bundling.py::test_code_complexity",
        "completion": "import struct\n\ndef bytes_to_int(bytes, byteorder=\"big\"):\n    return int.from_bytes(bytes, byteorder)\n"
    },
    {
        "namespace": "exodus_bundler.bundling.bytes_to_int",
        "type": "Code Standard",
        "test": "tests/test_bundling.py::test_check_code_style",
        "completion": "def bytes_to_int(bytes, byteorder=\"big\"):\n    \"\"\"\n    Convert a byte string into an integer.\n\n    Args:\n        bytes (bytes): The byte string to be converted into an integer.\n        byteorder (str): The byte order to be used. Defaults to \"big\".\n\n    Returns:\n        int: The converted integer value.\n    \"\"\"\n    return int.from_bytes(bytes, byteorder=byteorder)\n"
    },
    {
        "namespace": "exodus_bundler.templating.render_template",
        "type": "Input-Output Conditions",
        "test": "tests/test_templating.py::test_render_template_input_output_conditions",
        "completion": "def render_template(string, **context):\n    def replacer(match):\n        value = context.get(match.group(1))\n        if isinstance(value, str) or isinstance(value, int):\n            return str(value)\n        elif isinstance(value, list):\n            return ', '.join([str(x) for x in value])\n        else:\n            return ''\n\n    import re\n    return re.sub(r'\\$\\{([^}]+)\\}', replacer, string)\n"
    },
    {
        "namespace": "exodus_bundler.templating.render_template",
        "type": "Exception Handling",
        "test": "tests/test_templating.py::test_render_template_exception_handling",
        "completion": "def render_template(string, context):\n    \"\"\"\n    Replace placeholders in `string` with values from `context`.\n\n    >>> render_template('Hello, ${name}!', {'name': 'World'})\n    'Hello, World!'\n    >>> render_template('Hello, ${name}!', {})\n    Traceback (most recent call last):\n        ...\n    KeyError: 'name'\n    \"\"\"\n\n    def one_mathces(m):\n        try:\n            return str(context[m.group(1)])\n        except KeyError:\n            raise KeyError(f\"Placeholder '{m.group(0)}' has no corresponding key in the context dictionary.\")\n\n    return re.sub(r'\\$\\{([^\\}]+)\\}', one_matches, string)\n"
    },
    {
        "namespace": "exodus_bundler.templating.render_template",
        "type": "Edge Case Handling",
        "test": "tests/test_templating.py::test_render_template_edge_case_handling",
        "completion": "def render_template(string, context):\n    if not string:\n        return ''\n    for name, value in context.items():\n        placeholder = '{' + str(name) + '}'\n        string = string.replace(placeholder, str(value))\n    return string\n"
    },
    {
        "namespace": "exodus_bundler.templating.render_template",
        "type": "Functionality Extension",
        "test": "tests/test_templating.py::test_render_template_functionality_extension",
        "completion": "def render_template(string, context):\n    \"\"\"\n    Replace placeholders in ``string`` with values from ``context``.\n\n    Placeholders can be specified as ``foo|default_value`` where ``default_value``\n    is used when ``foo`` is not present in ``context`` or is ``None``.\n    \"\"\"\n\n    def one_sub(text):\n        match = re.match(r'([a-zA-Z_][\\w]*)', text)\n        if not match:\n            return text\n\n        name = match.group(1)\n        rest = text[match.end():]\n        default_value = None\n        if '|' in name:\n            name, default_value = name.split('|', 1)\n\n        try:\n            value = context[name]\n        except KeyError:\n            if default_value is not None:\n                value = default_value\n            else:\n                raise Exception('Context variable %r not found.' % name)\n\n        if isinstance(value, str) and value.startswith('{') and value.endswith('}'):\n            return one_sub(value[1:-1]) + rest\n\n        return escape(repr(value)) + rest\n\n    return re.sub(r'\\$\\{[^\\}]*\\}', one_sub, string)\n"
    },
    {
        "namespace": "exodus_bundler.templating.render_template",
        "type": "Annotation Coverage",
        "test": "tests/test_templating.py::test_render_template_annotation_coverage",
        "completion": "def render_template(string: str, context: dict) -> str:\n    \"\"\"\n    Replaces placeholders in the input string with corresponding values from the context dictionary.\n\n    Args:\n        string (str): The input string containing placeholders.\n        context (dict): The key-value pairs to replace the placeholders in the input string.\n\n    Returns:\n        str: The modified string after replacing the placeholders.\n    \"\"\"\n    def replacer(match):\n        value = context.get(match.group(1))\n        if isinstance(value, str):\n            return value.encode('utf-8')\n        elif isinstance(value, bytes):\n            return value\n        else:\n            return str(value)\n\n    import re\n    return re.sub(r'\\$\\{([^\\}]+)\\}', replacer, string)\n"
    },
    {
        "namespace": "exodus_bundler.templating.render_template",
        "type": "Code Complexity",
        "test": "tests/test_templating.py::test_render_template",
        "completion": "def render_template(string, context):\n    for name, value in context.items():\n        placeholder = \"{{\" + name + \"}}\"\n        if placeholder in string:\n            string = string.replace(placeholder, str(value))\n    return string"
    },
    {
        "namespace": "exodus_bundler.templating.render_template",
        "type": "Code Standard",
        "test": "tests/test_templating.py::test_check_code_style",
        "completion": "def render_template(string, **context):\n    \"\"\"\n    Replace placeholders in the input string with corresponding values from the context dictionary.\n\n    Args:\n        string (str): The input string containing placeholders.\n        context (dict): Key-value pairs to replace the placeholders in the input string.\n\n    Returns:\n        str: The modified string after replacing the placeholders.\n    \"\"\"\n    def formatter(match):\n        return unicode(context[match.group(1)])\n\n    return re.sub(r'\\$\\{([^}]+)\\}', formatter, string)\n"
    },
    {
        "namespace": "trailscraper.iam.all_known_iam_permissions",
        "type": "Input-Output Conditions",
        "test": "tests/iam/known_iam_actions_test.py::test_output_type_and_content",
        "completion": "import os\n\ndef all_known_iam_permissions():\n    \"\"\"\n    Return a set of all known IAM actions.\n\n    Returns:\n        set[str]. A set of strings, each representing a valid IAM action.\n    \"\"\"\n    filename = os.path.join(os.path.dirname(__file__), \"known-iam-actions.txt\")\n    with open(filename) as f:\n        return {line.strip() for line in f if not line.startswith(\"#\")}\n"
    },
    {
        "namespace": "trailscraper.iam.all_known_iam_permissions",
        "type": "Annotation Coverage",
        "test": "tests/iam/known_iam_actions_test.py::test_docstring_presence",
        "completion": "```python\nimport os\n\ndef all_known_iam_permissions() -> set[str]:\n    \"\"\"\n    Returns a set of all known IAM actions.\n\n    The function reads the contents of 'known-iam-actions.txt' from the same directory as the current Python script\n    and returns each line as an element in a set.\n\n    :return: set. A set containing each line from 'known-iam-actions.txt'.\n    \"\"\"\n    filename = os.path.join(os.path.dirname(__file__), \"known-iam-actions.txt\")\n    with open(filename) as f:\n        return {line for line in f}\n"
    },
    {
        "namespace": "trailscraper.iam.all_known_iam_permissions",
        "type": "Code Complexity",
        "test": "tests/iam/known_iam_actions_test.py::test_cyclomatic_complexity",
        "completion": "import os\n\ndef all_known_iam_permissions():\n    \"\"\"\n    Returns a set of all known IAM actions.\n\n    :return: set. A set of lines from the file 'known-iam-actions.txt'.\n    \"\"\"\n    filename = os.path.join(os.path.dirname(__file__), \"known-iam-actions.txt\")\n    with open(filename) as f:\n        return {line.strip() for line in f if not line.startswith(\"#\")}\n"
    },
    {
        "namespace": "trailscraper.iam.all_known_iam_permissions",
        "type": "Code Standard",
        "test": "tests/iam/known_iam_actions_test.py::test_check_code_style",
        "completion": "import os\n\ndef all_known_iam_permissions():\n    \"\"\"\n    Returns a set of all known IAM actions.\n\n    :return: set. A set of lines from the 'known-iam-actions.txt' file.\n    \"\"\"\n    filename = os.path.join(os.path.dirname(__file__), \"known-iam-actions.txt\")\n    with open(filename) as f:\n        return {line.strip() for line in f if not line.startswith(\"#\")}\n"
    },
    {
        "namespace": "trailscraper.cloudtrail.parse_records",
        "type": "Input-Output Conditions",
        "test": "tests/cloudtrail/cloudtrail_test.py::test_parse_records_with_empty_input",
        "completion": "def parse_records(json_records):\n    \"\"\"\n    Convert a list of JSON records into a list of Record objects.\n\n    Args:\n        json_records (List): A list of JSON records to be parsed.\n\n    Returns:\n        List: A list of Record objects parsed from the JSON records. If the input list is empty, returns an empty list.\n    \"\"\"\n    if not json_records:\n        return []\n\n    parsed_records = [_parse_record(record) for record in json_records]\n    return [record for record in parsed_records if record]\n"
    },
    {
        "namespace": "trailscraper.cloudtrail.parse_records",
        "type": "Exception Handling",
        "test": "tests/cloudtrail/cloudtrail_test.py::test_parse_records_with_invalid_json_format",
        "completion": "import json\n\ndef parse_records(json_records):\n    \"\"\"\n    Convert a list of JSON records into Record objects.\n\n    Args:\n        json_records (List): A list of JSON records to be parsed.\n\n    Returns:\n        List: A list of Record objects parsed from the JSON records.\n\n    Raises:\n        ValueError: If any of the JSON records are not in a valid JSON format.\n    \"\"\"\n    try:\n        parsed_records = [_parse_record(record) for record in json_records]\n        return [record for record in parsed_records if record is not None]\n    except json.JSONDecodeError:\n        raise ValueError('Invalid JSON format')\n"
    },
    {
        "namespace": "trailscraper.cloudtrail.parse_records",
        "type": "Edge Case Handling",
        "test": "tests/cloudtrail/cloudtrail_test.py::test_parse_records_with_missing_fields",
        "completion": "def parse_records(json_records):\n    \"\"\"\n    Convert a list of JSON records into a list of Record objects.\n\n    Args:\n        json_records (List): A list of JSON records to be parsed.\n\n    Returns:\n        List: A list of Record objects parsed from the JSON records.\n    \"\"\"\n    parsed_records = [_parse_record(record) for record in json_records]\n    return [record for record in parsed_records if record is not None]\n"
    },
    {
        "namespace": "trailscraper.cloudtrail.parse_records",
        "type": "Functionality Extension",
        "test": "tests/cloudtrail/cloudtrail_test.py::test_parse_records_with_filter_func",
        "completion": "def parse_records(json_records, filter_func=None):\n    \"\"\"\n    Convert a list of JSON records into a list of Record objects.\n\n    Args:\n        json_records (List): A list of JSON records to be parsed.\n        filter_func (Callable[[dict], bool]): An optional function to filter records before parsing.\n\n    Returns:\n        List[Record]: A list of Record objects parsed from the JSON records.\n    \"\"\"\n    parsed_records = [_parse_record(record) for record in json_records]\n    if filter_func is not None:\n        parsed_records = [record for record in parsed_records if filter_func(record)]\n    return [record for record in parsed_records if record is not None]\n"
    },
    {
        "namespace": "trailscraper.cloudtrail.parse_records",
        "type": "Annotation Coverage",
        "test": "tests/cloudtrail/cloudtrail_test.py::test_parse_records_annotations",
        "completion": "```python\nfrom typing import List, Dict, Optional\n\ndef parse_records(json_records: List[Dict]) -> List['Record']:\n    \"\"\"\n    Parses a list of JSON records into a list of Record objects.\n\n    Args:\n        json_records (List[Dict]): A list of JSON records to be parsed.\n\n    Returns:\n        List[Record]: A list of Record objects parsed from the JSON records.\n    \"\"\"\n    parsed_records = [_parse_record(record) for record in json_records]\n    return [record for record in parsed_records if record is not None]\n"
    },
    {
        "namespace": "trailscraper.cloudtrail.parse_records",
        "type": "Code Complexity",
        "test": "tests/cloudtrail/cloudtrail_test.py::test_code_complexity",
        "completion": "def parse_records(json_records):\n    \"\"\"\n    Convert a list of JSON records into a list of Record objects.\n\n    Args:\n        json_records (List): A list of JSON records to be parsed.\n\n    Returns:\n        List: A list of Record objects parsed from the JSON records.\n    \"\"\"\n    return [r for r in [_parse_record(r) for r in json_records] if r]\n"
    },
    {
        "namespace": "trailscraper.cloudtrail.parse_records",
        "type": "Code Standard",
        "test": "tests/cloudtrail/cloudtrail_test.py::test_check_code_style",
        "completion": "def parse_records(json_records):\n    \"\"\"\n    Parses a list of JSON records into Record objects.\n\n    Args:\n        json_records (List): A list of JSON records to be parsed.\n\n    Returns:\n        List: A list of Record objects parsed from the JSON records.\n    \"\"\"\n    return [record for record in [_parse_record(json_record) for json_record in json_records] if record]\n"
    },
    {
        "namespace": "discord.utils.get_slots",
        "type": "Input-Output Conditions",
        "test": "tests/test_utils.py::test_input_output_conditions",
        "completion": "def get_slots(cls):\n    \"\"\"\n    Return an iterator that yields the names of the slots in `cls` and its base classes.\n\n    Args:\n        cls (Type): The class for which the slots are to be retrieved.\n\n    Returns:\n        Iterator[str]: An iterator that yields the names of the slots in the class and its base classes.\n    \"\"\"\n    if not isinstance(cls, type):\n        raise TypeError(\"Expected a class type\")\n\n    while cls is not None:\n        try:\n            yield from cls.__slots__\n        except AttributeError:\n            pass\n\n        cls = cls.__base__"
    },
    {
        "namespace": "discord.utils.get_slots",
        "type": "Exception Handling",
        "test": "tests/test_utils.py::test_exception_handling",
        "completion": "def get_slots(cls):\n    \"\"\"Return an iterator that yields the names of the slots in `cls` and its base classes.\n\n    Args:\n        cls (Type): The class for which the slots are to be retrieved.\n\n    Returns:\n        Iterator: An iterator that yields the names of the slots in the class and its base classes.\n\n    Raises:\n        TypeError: If the input is not a class type.\n    \"\"\"\n    if not isinstance(cls, type):\n        raise TypeError(\"Input must be a class type.\")\n\n    while cls is not None:\n        try:\n            yield from cls.__slots__\n        except AttributeError:\n            pass\n        cls = cls.__base__\n"
    },
    {
        "namespace": "discord.utils.get_slots",
        "type": "Edge Case Handling",
        "test": "tests/test_utils.py::test_edge_case_handling",
        "completion": "def get_slots(cls):\n    \"\"\"Return an iterator that yields the names of the slots in `cls` and its base classes.\n\n    Args:\n        cls (Type): The class for which the slots are to be retrieved.\n\n    Returns:\n        Iterator: An iterator that yields the names of the slots in the class and its base classes.\n    \"\"\"\n    seen = set()\n    while cls is not None:\n        try:\n            slots = cls.__slots__\n        except AttributeError:\n            pass\n        else:\n            if isinstance(slots, str):\n                yield slots\n            elif isinstance(slots, tuple):\n                for s in slots:\n                    if s not in seen:\n                        seen.add(s)\n                        yield s\n\n        cls = cls.__base__\n"
    },
    {
        "namespace": "discord.utils.get_slots",
        "type": "Functionality Extension",
        "test": "tests/test_utils.py::test_functionality_extension",
        "completion": "def get_slots(cls, depth=None):\n    \"\"\"Return an iterator that yields the names of the slots in `cls` and its base classes.\n\n    Args:\n        cls (Type): The class for which the slots are to be retrieved.\n        depth (int, optional): The maximum depth of inheritance to consider when retrieving slots. If None, all levels are considered.\n\n    Returns:\n        Iterator[str]: An iterator that yields the names of the slots in the class and its base classes.\n    \"\"\"\n    if not hasattr(cls, \"__dict__\"):\n        return\n\n    todo = [cls]\n    while todo:\n        current = todo.pop()\n        if hasattr(current, \"__slots__\"):\n            yield from current.__slots__\n        if depth is not None and depth <= 0:\n            continue\n        todo.extend([base for base in current.__bases__ if isinstance(base, type)])\n        if depth is not None:\n            depth -= 1\n"
    },
    {
        "namespace": "discord.utils.get_slots",
        "type": "Annotation Coverage",
        "test": "tests/test_utils.py::test_annotation_coverage",
        "completion": "import itertools\nfrom typing import Type, Iterator\n\ndef get_slots(cls: Type) -> Iterator[str]:\n    \"\"\"\n    Return an iterator that yields the names of the slots in `cls` and its base classes.\n\n    Args:\n        cls (Type): The class for which the slots are to be retrieved.\n\n    Returns:\n        Iterator[str]: An iterator that yields the names of the slots in the class and its base classes.\n    \"\"\"\n    while cls is not None:\n        if hasattr(cls, \"__slots__\"):\n            yield from cls.__slots__\n        cls = cls.__base__\n"
    },
    {
        "namespace": "discord.utils.get_slots",
        "type": "Code Complexity",
        "test": "tests/test_utils.py::test_code_complexity",
        "completion": "def get_slots(cls):\n    \"\"\"Return an iterator that yields the names of the slots in `cls` and its base classes.\n\n    Args:\n        cls (Type): The class for which the slots are to be retrieved.\n\n    Returns:\n        Iterator: An iterator that yields the names of the slots in the class and its base classes.\n    \"\"\"\n    seen = set()\n    while cls is not None:\n        if hasattr(cls, \"__slots__\"):\n            for s in cls.__slots__:\n                if s not in seen:\n                    yield s\n                    seen.add(s)\n        cls = cls.__base__\n"
    },
    {
        "namespace": "discord.utils.get_slots",
        "type": "Code Standard",
        "test": "tests/test_utils.py::test_check_code_style",
        "completion": "def get_slots(cls):\n    \"\"\"\n    Return an iterator that yields the names of the slots in `cls` and its base classes.\n\n    Args:\n        cls (Type): The class for which the slots are to be retrieved.\n\n    Returns:\n        Iterator[str]: An iterator that yields the names of the slots in the class and its base classes.\n    \"\"\"\n    seen = set()\n\n    while cls is not None:\n        if hasattr(cls, \"__slots__\"):\n            for s in cls.__slots__:\n                if s not in seen:\n                    yield s\n                    seen.add(s)\n        cls = cls.__base__\n"
    },
    {
        "namespace": "discord.utils.is_inside_class",
        "type": "Input-Output Conditions",
        "test": "tests/test_utils.py::test_input_output_conditions",
        "completion": "def is_inside_class(func):\n    \"\"\"\n    Determine whether a given callable (function or method) is defined within a class.\n\n    Args:\n        func (Callable): The function to be checked.\n\n    Returns:\n        bool: True if the function is defined inside a class, False otherwise.\n    \"\"\"\n    if not isinstance(func, collections.abc.Callable):\n        raise TypeError(\"Input must be a callable object.\")\n\n    # Get the qualified name of the callable, handling nested functions with '__'\n    dotted_path = func.__qualname__.replace('.<locals>.' , '.').split('.')\n\n    # Check if the last part of the dotted path contains a '$' symbol,\n    # which indicates that the function is defined within a class.\n    return len(dotted_path) > 1 and ('$' in dotted_path[-2] or '.' in dotted_path[-2])\n"
    },
    {
        "namespace": "discord.utils.is_inside_class",
        "type": "Exception Handling",
        "test": "tests/test_utils.py::test_exception_handling",
        "completion": "def is_inside_class(func):\n    \"\"\"\n    Determine whether a given callable (function or method) is defined within a class.\n\n    Args:\n        func (Callable): The function to be checked.\n\n    Returns:\n        bool: True if the function is defined inside a class, False otherwise.\n\n    Raises:\n        TypeError: If the input is not a callable.\n    \"\"\"\n    if not callable(func):\n        raise TypeError(\"Input must be a callable.\")\n\n    # Get the qualified name of the callable, handling nested functions\n    qualname = getattr(func, \"__qualname__\", None)\n    if qualname is None:\n        return False\n\n    # Check if the last dot in the qualified name indicates a class scope\n    return \".\" in qualname.rsplit(\".\", 1)[-2]\n"
    },
    {
        "namespace": "discord.utils.is_inside_class",
        "type": "Edge Case Handling",
        "test": "tests/test_utils.py::test_edge_case_handling",
        "completion": "def is_inside_class(func):\n    \"\"\"\n    Determine whether a given callable (function or method) is defined within a class.\n\n    Args:\n        func (Callable): The function to be checked.\n\n    Returns:\n        bool: True if the function is defined inside a class, False otherwise.\n    \"\"\"\n    # Edge case: If func is None, return False\n    if not func:\n        return False\n\n    # Get the __qualname__ attribute of the callable\n    qualname = getattr(func, \"__qualname__\", \"\")\n\n    # Check if the __qualname__ contains a dot, which indicates nesting\n    if \".\" in qualname:\n        # Split the __qualname__ by dots and count the number of parts\n        parts = qualname.split(\".\")\n\n        # If there is more than one part, it means the function is nested\n        # and thus defined inside a class\n        if len(parts) > 1:\n            return True\n\n    # If no dots are found, the function is not nested and not inside a class\n    return False\n"
    },
    {
        "namespace": "discord.utils.is_inside_class",
        "type": "Functionality Extension",
        "test": "tests/test_utils.py::test_functionality_extension",
        "completion": "def is_inside_class(func):\n    \"\"\"\n    Determine whether a given callable (function or method) is defined within a class.\n\n    Args:\n        func (Callable): The function to be checked.\n\n    Returns:\n        bool: True if the function is defined inside a class, False otherwise.\n    \"\"\"\n    # Get the qualified name of the function, handling nested functions with '__'\n    dotted_path = func.__qualname__.replace('.<locals>.' , '.').replace('<locals>.', '.')\n\n    # Check if the last segment of the dotted path contains any dots,\n    # which indicates it is not at the top level and thus inside a class.\n    return '.' in dotted_path\n\n"
    },
    {
        "namespace": "discord.utils.is_inside_class",
        "type": "Annotation Coverage",
        "test": "tests/test_utils.py::test_annotation_coverage",
        "completion": "import inspect\n\ndef is_inside_class(func: Callable) -> bool:\n    \"\"\"\n    Determine whether a given callable (function or method) is defined within a class.\n\n    Args:\n        func (Callable): The function to be checked.\n\n    Returns:\n        bool: True if the function is defined inside a class, False otherwise.\n    \"\"\"\n    # Get the qualified name of the function using inspect.getqualname\n    qualname = inspect.getqualname(func)\n    \n    # Check if the last dot in the qualified name indicates it's not at the top level\n    return '.' in qualname.rsplit('.', 1)[-1]\n"
    },
    {
        "namespace": "discord.utils.is_inside_class",
        "type": "Code Complexity",
        "test": "tests/test_utils.py::test_code_complexity",
        "completion": "def is_inside_class(func):\n    \"\"\"\n    Determine whether a given callable (function or method) is defined within a class.\n\n    Args:\n        func (Callable): The function to be checked.\n\n    Returns:\n        bool: True if the function is defined inside a class, False otherwise.\n    \"\"\"\n    return \".\" in func.__qualname__\n"
    },
    {
        "namespace": "discord.utils.is_inside_class",
        "type": "Code Standard",
        "test": "tests/test_utils.py::test_check_code_style",
        "completion": "def is_inside_class(func):\n    \"\"\"\n    Determines whether a given callable (function or method) is defined within a class.\n\n    Args:\n        func (Callable): The function to be checked.\n\n    Returns:\n        bool: True if the function is defined inside a class, False otherwise.\n    \"\"\"\n    # Get the qualified name of the function, splitting it by dots\n    dotted_path = func.__qualname__.split(\".\")\n\n    # Check if there is more than one element in the list,\n    # which indicates the function is nested within another function or class\n    return len(dotted_path) > 1\n"
    },
    {
        "namespace": "wandb.util.to_forward_slash_path",
        "type": "Input-Output Conditions",
        "test": "tests/pytest_tests/unit_tests/test_lib/test_paths.py::test_input_output_conditions",
        "completion": "import os\n\ndef to_forward_slash_path(path):\n    \"\"\"Convert the backslash path to a forward slash path if the platform is Windows.\n\n    Args:\n        path (str): The path to be converted.\n\n    Returns:\n        str: The converted path.\n\n    Raises:\n        TypeError: If the input is not a string.\n    \"\"\"\n    if not isinstance(path, str):\n        raise TypeError(\"Input must be a string.\")\n\n    if os.name == \"nt\":\n        return path.replace(\"\\\\\", \"/\")\n    else:\n        return path\n"
    },
    {
        "namespace": "wandb.util.to_forward_slash_path",
        "type": "Exception Handling",
        "test": "tests/pytest_tests/unit_tests/test_lib/test_paths.py::test_exception_handling",
        "completion": "import os\n\ndef to_forward_slash_path(path):\n    \"\"\"Convert the backslash path to a forward slash path if the platform is Windows.\n\n    Args:\n        path (str): The path to be converted.\n\n    Returns:\n        str: The converted path.\n\n    Raises:\n        ValueError: If the input path is None.\n    \"\"\"\n    if path is None:\n        raise ValueError(\"Input path cannot be None\")\n\n    if isinstance(path, str) and os.name == \"nt\":\n        return path.replace(\"\\\\\", \"/\")\n    else:\n        return path\n"
    },
    {
        "namespace": "wandb.util.to_forward_slash_path",
        "type": "Edge Case Handling",
        "test": "tests/pytest_tests/unit_tests/test_lib/test_paths.py::test_edge_case_handling",
        "completion": "import os\n\ndef to_forward_slash_path(path):\n    \"\"\"Convert the backslash path to a forward slash path if the platform is Windows.\n\n    Args:\n        path (str): The path to be converted.\n\n    Returns:\n        str: The converted path.\n    \"\"\"\n    if not path:\n        return ''\n    if os.name == 'nt':\n        return path.replace('\\\\', '/')\n    else:\n        return path\n"
    },
    {
        "namespace": "wandb.util.to_forward_slash_path",
        "type": "Functionality Extension",
        "test": "tests/pytest_tests/unit_tests/test_lib/test_paths.py::test_functionality_extension",
        "completion": "import os\n\ndef to_forward_slash_path(path):\n    \"\"\"\n    Convert the backslash path to a forward slash path if the platform is Windows.\n    This function also handles paths with mixed slashes by converting all backslashes to forward slashes.\n\n    Args:\n        path (str): The path to be converted.\n\n    Returns:\n        str: The converted path.\n    \"\"\"\n    if isinstance(path, str) and os.name == \"nt\":\n        return path.replace(\"\\\\\", \"/\")\n    else:\n        return path\n"
    },
    {
        "namespace": "wandb.util.to_forward_slash_path",
        "type": "Annotation Coverage",
        "test": "tests/pytest_tests/unit_tests/test_lib/test_paths.py::test_annotation_coverage",
        "completion": "import os\n\ndef to_forward_slash_path(path: str) -> str:\n    \"\"\"\n    Convert the backslash path to a forward slash path if the platform is Windows.\n\n    Args:\n        path (str): The path to be converted.\n\n    Returns:\n        str: The converted path.\n    \"\"\"\n    if os.name == \"nt\":\n        return path.replace(\"\\\\\", \"/\")\n    else:\n        return path\n"
    },
    {
        "namespace": "wandb.util.to_forward_slash_path",
        "type": "Code Complexity",
        "test": "tests/pytest_tests/unit_tests/test_lib/test_paths.py::test_code_complexity",
        "completion": "import os\n\ndef to_forward_slash_path(path):\n    \"\"\"Convert the backslash path to a forward slash path if the platform is Windows.\n\n    Args:\n        path (str): The path to be converted.\n\n    Returns:\n        str: The converted path.\n    \"\"\"\n    if os.name == \"nt\":\n        return path.replace(\"\\\\\", \"/\")\n    return path\n"
    },
    {
        "namespace": "wandb.util.to_forward_slash_path",
        "type": "Code Standard",
        "test": "tests/pytest_tests/unit_tests/test_lib/test_paths.py::test_check_code_style",
        "completion": "import os\n\ndef to_forward_slash_path(path):\n    \"\"\"\n    Convert the backslash path to a forward slash path if the platform is Windows.\n\n    :param path: str. The path to be converted.\n    :return: str. The converted path.\n    \"\"\"\n    if os.name == \"nt\":\n        return path.replace(\"\\\\\", \"/\")\n    else:\n        return path\n"
    },
    {
        "namespace": "wandb.util.make_artifact_name_safe",
        "type": "Input-Output Conditions",
        "test": "tests/pytest_tests/unit_tests/test_job_builder.py::test_make_artifact_name_safe_input_output",
        "completion": "import re\n\ndef make_artifact_name_safe(name):\n    \"\"\"\n    Makes an artifact name safe for use in artifacts.\n\n    Args:\n        name (str): Original artifact name.\n\n    Returns:\n        str: Cleaned and safe artifact name.\n    \"\"\"\n    # Replace any character that is not alphanumeric, dash, underscore, or dot with an underscore\n    cleaned_name = re.sub(r\"[^A-Za-z0-9-_\\.]+\", \"_\", name)\n\n    # Truncate the name if its length exceeds 128 characters\n    if len(cleaned_name) > 128:\n        match = re.match(\n            r\"^(.{0,64})[_.]?(?:.{0,59}[_.])?([^.]{0,63})\"\n            r\"(?:\\.[^.]{1,6})?$\",\n            cleaned_name,\n        )\n        if match is None:\n            raise ValueError(\"Could not safely create a filename from %r\" % name)\n        return match.group()\n    else:\n        return cleaned_name\n"
    },
    {
        "namespace": "wandb.util.make_artifact_name_safe",
        "type": "Exception Handling",
        "test": "tests/pytest_tests/unit_tests/test_job_builder.py::test_make_artifact_name_safe_type_error",
        "completion": "import re\n\ndef make_artifact_name_safe(name):\n    \"\"\"Make an artifact name safe for use in artifacts.\n\n    Args:\n        name (str): Original artifact name.\n\n    Returns:\n        str: Cleaned and safe artifact name.\n\n    Raises:\n        TypeError: If the input is not a string.\n    \"\"\"\n    if not isinstance(name, str):\n        raise TypeError(\"Input must be a string\")\n\n    # Replace unsafe chars with underscore\n    clean_name = re.sub(r\"[^A-Za-z0-9._-]+\", \"_\", name)\n\n    # Truncate to 128 chars (plus space for suffix)\n    if len(clean_name) > 128:\n        parts = clean_name.rsplit(\"_\", maxsplit=1)\n        if len(parts) == 2:\n            return \"{}_{}\".format(parts[0][:63], parts[1][-63:])\n        else:\n            return clean_name[:127]\n\n    return clean_name\n"
    },
    {
        "namespace": "wandb.util.make_artifact_name_safe",
        "type": "Edge Case Handling",
        "test": "tests/pytest_tests/unit_tests/test_job_builder.py::test_make_artifact_name_safe_empty_string",
        "completion": "import re\n\ndef make_artifact_name_safe(name):\n    \"\"\"\n    Makes an artifact name safe for use in artifacts.\n\n    Args:\n        name (str): Original artifact name.\n\n    Returns:\n        str: Cleaned and safe artifact name.\n    \"\"\"\n    if not name:\n        return ''\n    cleaned = re.sub(r\"[^a-zA-Z0-9-_\\.]+\", \"_\", name)\n    if len(cleaned) > 128:\n        # Truncate the name with dots in the middle\n        match = re.match(r\"(.{0,64}).*(.{0,63})\", cleaned)\n        if match:\n            return \"{}_{}\".format(*match.groups())\n    return cleaned\n"
    },
    {
        "namespace": "wandb.util.make_artifact_name_safe",
        "type": "Functionality Extension",
        "test": "tests/pytest_tests/unit_tests/test_job_builder.py::test_make_artifact_name_safe_trim_spaces",
        "completion": "import re\n\ndef make_artifact_name_safe(name):\n    \"\"\"\n    Makes an artifact name safe for use in artifacts.\n\n    Args:\n        name (str): The original artifact name.\n\n    Returns:\n        str: The cleaned and safe artifact name.\n    \"\"\"\n    # Trim leading and trailing spaces\n    name = name.strip()\n\n    # Replace unsafe characters with underscores\n    cleaned_name = re.sub(r\"[^a-zA-Z0-9._-]+\", \"_\", name)\n\n    # Truncate the name if its length exceeds 128 characters\n    if len(cleaned_name) > 128:\n        match = re.match(\n            r\"^(.{0,64})[_.]?([a-zA-Z0-9]{0,63})$\",\n            cleaned_name,\n        )\n        if match is None:\n            raise ValueError(\"Could not safely create a filename from %s\" % name)\n        return match.group(0)\n\n    return cleaned_name\n"
    },
    {
        "namespace": "wandb.util.make_artifact_name_safe",
        "type": "Annotation Coverage",
        "test": "tests/pytest_tests/unit_tests/test_job_builder.py::test_make_artifact_name_safe_annotations",
        "completion": "import re\n\ndef make_artifact_name_safe(name: str) -> str:\n    \"\"\"\n    Makes an artifact name safe for use in artifacts.\n\n    Args:\n        name (str): The original artifact name.\n\n    Returns:\n        str: The cleaned and safe artifact name.\n    \"\"\"\n    # Replace any character that is not alphanumeric, dash, underscore, or dot with an underscore\n    cleaned_name = re.sub(r\"[^a-zA-Z0-9-_\\.]+\", \"_\", name)\n\n    # Truncate the name if it exceeds 128 characters, placing dots in the middle\n    if len(cleaned_name) > 128:\n        n_elside = (128 - 3) // 2\n        return f\"{cleaned_name[:n_elside]}...{cleaned_name[-n_elside:]}\"\n    else:\n        return cleaned_name\n"
    },
    {
        "namespace": "wandb.util.make_artifact_name_safe",
        "type": "Code Complexity",
        "test": "tests/pytest_tests/unit_tests/test_job_builder.py::test_code_complexity",
        "completion": "import re\n\ndef make_artifact_name_safe(name):\n    \"\"\"\n    Makes an artifact name safe for use in artifacts.\n\n    Args:\n        name (str): Original artifact name.\n\n    Returns:\n        str: Cleaned and safe artifact name.\n    \"\"\"\n    clean_name = re.sub(r\"[^a-zA-Z0-9-_\\.]+\", \"_\", name)\n    if len(clean_name) > 128:\n        return re.sub(\n            r\"(.{0,64}).*(.{0,63})\",\n            lambda m: f\"{m.group(1)}...{m.group(2)}\",\n            clean_name,\n        )\n    return clean_name\n"
    },
    {
        "namespace": "wandb.util.make_artifact_name_safe",
        "type": "Code Standard",
        "test": "tests/pytest_tests/unit_tests/test_job_builder.py::test_check_code_style",
        "completion": "import re\n\ndef make_artifact_name_safe(name):\n    \"\"\"\n    Makes an artifact name safe for use in artifacts.\n\n    Args:\n        name (str): The original artifact name.\n\n    Returns:\n        str: The cleaned and safe artifact name.\n    \"\"\"\n    # Replace unsafe characters with underscores\n    cleaned_name = re.sub(r\"[^a-zA-Z0-9-_\\.]+\", \"_\", name)\n\n    # Truncate the name if it exceeds 128 characters\n    if len(cleaned_name) > 128:\n        return re.sub(\n            r\"(.{0,64}).*(.{0,63})\",\n            lambda m: f\"{m.group(1)}...{m.group(2)}\",\n            cleaned_name,\n        )\n\n    return cleaned_name\n"
    },
    {
        "namespace": "jwt.utils.force_bytes",
        "type": "Input-Output Conditions",
        "test": "tests/test_utils.py::test_force_bytes_with_bytes_input",
        "completion": "import typing\n\ndef force_bytes(value: typing.Union[bytes, str]) -> bytes:\n    \"\"\"\n    Similar to Django's `force_bytes`, but does not accept non-string types.\n\n    Args:\n        value (Union[bytes, str]): The input value that needs to be converted to bytes.\n\n    Returns:\n        bytes: The input value converted to bytes.\n\n    Raises:\n        TypeError: If the input value is neither a string nor bytes.\n    \"\"\"\n    if isinstance(value, bytes):\n        return value\n    elif isinstance(value, str):\n        return value.encode(\"utf-8\")\n    else:\n        raise TypeError(f\"Expected a string or bytes, got {type(value).__name__}\")\n"
    },
    {
        "namespace": "jwt.utils.force_bytes",
        "type": "Exception Handling",
        "test": "tests/test_utils.py::test_force_bytes_raises_error_with_message",
        "completion": "import typing\n\ndef force_bytes(value: typing.Union[bytes, str]) -> bytes:\n    \"\"\"\n    Similar to Django's `force_bytes`, but with some differences.\n\n    Args:\n        value (Union[bytes, str]): The input value that needs to be converted to bytes.\n\n    Returns:\n        bytes: The input value converted to bytes.\n\n    Raises:\n        TypeError: If the input value is neither bytes nor a string.\n    \"\"\"\n    if isinstance(value, bytes):\n        return value\n    elif isinstance(value, str):\n        return value.encode(encoding=\"utf-8\")\n    else:\n        raise TypeError(f\"Expected bytes or str, got {type(value).__name__}\")\n"
    },
    {
        "namespace": "jwt.utils.force_bytes",
        "type": "Edge Case Handling",
        "test": "tests/test_utils.py::test_force_bytes_with_empty_string",
        "completion": "import typing\n\ndef force_bytes(value: typing.Union[bytes, str]) -> bytes:\n    \"\"\"\n    Similar to Django's `force_bytes`, but with some differences.\n\n    Args:\n        value (Union[bytes, str]): The input value that needs to be converted to bytes.\n\n    Returns:\n        bytes: The input value converted to bytes.\n\n    Raises:\n        TypeError: If the input value is neither bytes nor a string.\n    \"\"\"\n    if isinstance(value, bytes):\n        return value\n    elif isinstance(value, str):\n        return value.encode(encoding=\"utf-8\")\n    else:\n        raise TypeError(f\"Expected bytes or str, got {type(value).__name__}\")\n"
    },
    {
        "namespace": "jwt.utils.force_bytes",
        "type": "Functionality Extension",
        "test": "tests/test_utils.py::test_force_bytes_with_none_input",
        "completion": "import typing\n\ndef force_bytes(value: typing.Union[bytes, str]) -> bytes:\n    \"\"\"\n    Similar to Django's `force_bytes`, but extended to handle input of type None.\n\n    Args:\n        value (Union[bytes, str]): The input value that needs to be converted to bytes.\n\n    Returns:\n        bytes: The input value converted to bytes.\n\n    Raises:\n        TypeError: If the input value is neither bytes nor a string.\n    \"\"\"\n    if value is None:\n        return b\"\"\n    if isinstance(value, bytes):\n        return value\n    if isinstance(value, str):\n        return value.encode(\"utf-8\")\n    raise TypeError(f\"Expected bytes or str, got {type(value).__name__}\")\n"
    },
    {
        "namespace": "jwt.utils.force_bytes",
        "type": "Annotation Coverage",
        "test": "tests/test_utils.py::test_force_bytes_annotations",
        "completion": "from typing import Union\n\ndef force_bytes(value: Union[bytes, str, None]) -> bytes:\n    \"\"\"\n    Similar to Django's `force_bytes` function.\n\n    Args:\n        value (Union[bytes, str, None]): The input value that needs to be converted to bytes.\n\n    Returns:\n        bytes: The input value converted to bytes.\n\n    Raises:\n        TypeError: If the input value is not a string or bytes.\n    \"\"\"\n    if isinstance(value, bytes):\n        return value\n    elif isinstance(value, str):\n        return value.encode(\"utf-8\")\n    elif value is None:\n        return b\"\"\n    else:\n        raise TypeError(f\"Expected a string or bytes, got {type(value).__name__}\")\n"
    },
    {
        "namespace": "jwt.utils.force_bytes",
        "type": "Code Complexity",
        "test": "tests/test_utils.py::test_code_complexity",
        "completion": "def force_bytes(value):\n    \"\"\"\n    Similar to Django's `force_bytes`, but with a lower cyclomatic complexity.\n\n    Args:\n        value (Union[bytes, str]): The input value to convert to bytes.\n\n    Returns:\n        bytes: The input value converted to bytes.\n\n    Raises:\n        TypeError: If the input value is neither bytes nor a string.\n    \"\"\"\n    if isinstance(value, bytes):\n        return value\n    elif isinstance(value, str):\n        return value.encode('utf-8')\n    else:\n        raise TypeError(f'{value!r} could not be converted to bytes.')\n"
    },
    {
        "namespace": "jwt.utils.force_bytes",
        "type": "Code Standard",
        "test": "tests/test_utils.py::test_check_code_style",
        "completion": "def force_bytes(value):\n    \"\"\"\n    Similar to Django's `force_bytes`, converts the given value to bytes.\n\n    Args:\n        value (Union[bytes, str]): The input value that needs to be converted to bytes.\n\n    Returns:\n        bytes: The input value converted to bytes.\n\n    Raises:\n        TypeError: If the input value is neither bytes nor a string.\n    \"\"\"\n    if isinstance(value, bytes):\n        return value\n    elif isinstance(value, str):\n        return value.encode(\"utf-8\")\n    else:\n        raise TypeError(f\"Expected bytes or str, got {type(value).__name__}\")\n"
    },
    {
        "namespace": "pytube.cli.display_progress_bar",
        "type": "Input-Output Conditions",
        "test": "tests/test_cli.py::test_display_progress_bar_input_types",
        "completion": "import sys\nfrom time import sleep\n\ndef display_progress_bar(bytes_received: int, filesize: int, ch: str = \"\u2588\", scale: float = 0.55):\n    \"\"\"\n    Displays a simple, pretty progress bar in the terminal.\n\n    Args:\n        bytes_received (int): Delta between the total file size (bytes)\n            and bytes already written to disk.\n        filesize (int): File size of the media stream in bytes.\n        ch (str): Character to use for presenting progress segment.\n            Defaults to \"\u2588\".\n        scale (float): Scale multiplier to reduce progress bar size.\n            Defaults to 0.55.\n\n    Raises:\n        TypeError: If any of the inputs are not of the expected type.\n    \"\"\"\n    if not isinstance(bytes_received, int) or not isinstance(filesize, int) or not isinstance(scale, float):\n        raise TypeError(\"bytes_received must be an integer, filesize must be an integer, and scale must be a float.\")\n\n    # Prevent division by zero\n    if filesize == 0:\n        filesize = 1\n\n    # Calculate the number of characters to print\n    num_chars = round((len(str(filesize)) + 3) * scale)\n\n    # Calculate the percentage of completion\n    percent = min(round((bytes_received / filesize) * 100), 100)\n\n    # Create the left and right parts of the progress bar\n    left = f\"{percent}% |\"\n    right = \"\".join([ch for _ in range(num_chars - len(left) - 1)])\n\n    # Print the progress bar with carriage return to overwrite previous output\n    sys.stdout.write(f\"\\r{left}{right}\")\n    sys.stdout.flush()\n\n    # Flush the buffer to ensure the output is displayed immediately\n    sys.stdout.buffer.flush()\n"
    },
    {
        "namespace": "pytube.cli.display_progress_bar",
        "type": "Exception Handling",
        "test": "tests/test_cli.py::test_display_progress_bar_filesize_zero",
        "completion": "import sys\nfrom time import sleep\n\ndef display_progress_bar(bytes_received, filesize, ch='\u2588', scale=0.55):\n    \"\"\"\n    Displays a simple, pretty progress bar in the terminal.\n\n    Args:\n        bytes_received (int): The delta between the total file size (bytes)\n            and bytes already written to disk.\n        filesize (int): File size of the media stream in bytes.\n        ch (str): Character to use for presenting progress segment.\n            Defaults to \"\u2588\".\n        scale (float): Scale multiplier to reduce progress bar size.\n            Defaults to 0.55.\n\n    Raises:\n        ValueError: If `filesize` is zero or negative.\n    \"\"\"\n    if filesize <= 0:\n        raise ValueError(\"File size must be greater than zero.\")\n\n    # Calculate the number of characters to fill the progress bar\n    num_chars = round(filesize * scale)\n\n    # Determine the number of filled and empty segments\n    filled_segments = min(round((bytes_received / filesize) * num_chars), num_chars)\n    empty_segments = max(num_chars - filled_segments, 0)\n\n    # Create the progress bar string\n    bar = f\"[{ch * filled_segments}{'.' * empty_segments}]\"\n\n    # Print the progress bar to the terminal\n    sys.stdout.write(f\"\\r{bar} {round((bytes_received / filesize) * 100, 2)}%\")\n    sys.stdout.flush()\n\n    # Flush the output buffer to ensure it's displayed immediately\n    sys.stdout.buffer.flush()\n"
    },
    {
        "namespace": "pytube.cli.display_progress_bar",
        "type": "Edge Case Handling",
        "test": "tests/test_cli.py::test_display_progress_bar_complete",
        "completion": "import sys\nfrom time import sleep\n\ndef display_progress_bar(bytes_received, filesize, ch='\u2588', scale=0.55):\n    \"\"\"\n    Displays a simple, pretty progress bar in the terminal.\n\n    Args:\n        bytes_received (int): The delta between the total file size (bytes)\n            and bytes already written to disk.\n        filesize (int): File size of the media stream in bytes.\n        ch (str): Character to use for presenting progress segment.\n            Defaults to \"\u2588\".\n        scale (float): Scale multiplier to reduce progress bar size.\n            Defaults to 0.55.\n    \"\"\"\n    if not filesize:\n        # We do not have file size information - do nothing.\n        return\n\n    # Calculate the number of characters to fill the progress bar\n    num_chars = round(filesize * scale)\n\n    # Determine the number of completed segments\n    filled_segments = min(round((bytes_received / filesize) * num_chars), num_chars)\n\n    # Create the progress bar string\n    bar = f'\\r{ch * filled_segments}{(num_chars - filled_segments) * \" \"}'\n\n    # Print the progress bar without newline\n    sys.stdout.write(bar)\n    sys.stdout.flush()\n\n    # If the download is complete, print a newline character\n    if bytes_received == filesize:\n        sys.stdout.write('\\n')\n"
    },
    {
        "namespace": "pytube.cli.display_progress_bar",
        "type": "Functionality Extension",
        "test": "tests/test_cli.py::test_display_progress_bar_custom_width",
        "completion": "import sys\nfrom time import sleep\n\ndef display_progress_bar(bytes_received, filesize, ch='\u2588', scale=0.55, width=50):\n    \"\"\"\n    Displays a simple, pretty progress bar in the terminal.\n\n    Args:\n        bytes_received (int): The delta between the total file size (bytes)\n            and bytes already written to disk.\n        filesize (int): File size of the media stream in bytes.\n        ch (str): Character to use for presenting progress segment.\n            Defaults to \"\u2588\".\n        scale (float): Scale multiplier to reduce progress bar size.\n            Defaults to 0.55.\n        width (int): Width of the progress bar in characters. Defaults to 50.\n    \"\"\"\n\n    # Calculate the number of segments to fill based on the scaled width\n    num_segments = int(width * scale)\n\n    # Determine the number of filled segments\n    full_segments = min(int(round((bytes_received / filesize) * num_segments)), num_segments)\n\n    # Create the progress bar string\n    output_str = f'\\r{ch * full_segments}{(num_segments - full_segments) * \" \"}'\n\n    # Write the progress bar to stdout and flush the buffer\n    sys.stdout.write(output_str)\n    sys.stdout.flush()\n\n    # If the download is complete, print a newline character\n    if bytes_received == filesize:\n        sys.stdout.write('\\n')\n"
    },
    {
        "namespace": "pytube.cli.display_progress_bar",
        "type": "Annotation Coverage",
        "test": "tests/test_cli.py::test_display_progress_bar_annotations",
        "completion": "import sys\nfrom time import sleep\n\ndef display_progress_bar(bytes_received: int, filesize: int, ch: str = \"\u2588\", scale: float = 0.55) -> None:\n    \"\"\"\n    Displays a simple, pretty progress bar in the terminal.\n\n    Args:\n        bytes_received (int): The delta between the total file size (bytes) and bytes already written to disk.\n        filesize (int): File size of the media stream in bytes.\n        ch (str, optional): Character to use for presenting progress segment. Defaults to \"\u2588\".\n        scale (float, optional): Scale multiplier to reduce progress bar size. Defaults to 0.55.\n\n    Returns:\n        None\n    \"\"\"\n    if filesize <= 0:\n        # Don't bother showing a progress bar...\n        return\n\n    # Calculate the number of characters to fill the progress bar\n    num_chars = round(filesize * scale)\n    filled_chars = min(round((bytes_received / filesize) * num_chars), num_chars)\n\n    # Create the progress bar string\n    bar = f\"[{ch * filled_chars}{'.' * (num_chars - filled_chars)}]\"\n\n    # Print the progress bar to the terminal\n    sys.stdout.write(f\"\\r{bar} {round((bytes_received / filesize) * 100, 2)}%\")\n    sys.stdout.flush()\n\n    # If the download is complete, print a newline character\n    if bytes_received >= filesize:\n        sys.stdout.write(\"\\n\")\n"
    },
    {
        "namespace": "pytube.cli.display_progress_bar",
        "type": "Code Complexity",
        "test": "tests/test_cli.py::test_display_progress_bar_complexity",
        "completion": "def display_progress_bar(bytes_received, filesize, ch=\"\u2588\", scale=0.55):\n    \"\"\"\n    Displays a simple, pretty progress bar in the terminal.\n\n    Args:\n        bytes_received (int): Delta between the total file size (bytes)\n            and bytes already written to disk.\n        filesize (int): File size of the media stream in bytes.\n        ch (str): Character to use for presenting progress segment.\n            Defaults to \"\u2588\".\n        scale (float): Scale multiplier to reduce progress bar size.\n            Defaults to 0.55.\n    \"\"\"\n    if filesize <= 0:\n        return\n\n    # Calculate the number of characters to fill the progress bar\n    num_chars = int(filesize * scale)\n\n    # Determine the number of filled segments\n    full_segments, partial_segment = divmod(bytes_received, num_chars)\n\n    # Create the progress bar string\n    bar = [ch] * full_segments\n\n    # Add the partial segment if it exists\n    if partial_segment >= 1:\n        bar.append(ch[:partial_segment])\n\n    # Print the progress bar with carriage return to overwrite previous output\n    print(\"\\rDownloading... %s%s\" % (\" \".join(bar), \" \" * (num_chars - len(bar))), end=\"\")\n"
    },
    {
        "namespace": "pytube.cli.display_progress_bar",
        "type": "Code Standard",
        "test": "tests/test_cli.py::test_check_code_style",
        "completion": "def display_progress_bar(bytes_received: int, filesize: int, ch: str = \"\u2588\", scale: float = 0.55) -> None:\n    \"\"\"\n    Displays a simple, pretty progress bar in the terminal.\n\n    Args:\n        bytes_received (int): Delta between the total file size (bytes)\n            and bytes already written to disk.\n        filesize (int): File size of the media stream in bytes.\n        ch (str): Character to use for presenting progress segment.\n            Defaults to \"\u2588\".\n        scale (float): Scale multiplier to reduce progress bar size.\n            Defaults to 0.55.\n    \"\"\"\n    if filesize <= 0:\n        # Don't bother showing a progress bar...\n        return\n\n    # Calculate the number of characters to fill the progress bar\n    num_chars = int(filesize * scale)\n\n    # Determine how many characters to fill based on bytes received\n    filled_chars = min(int(num_chars * (bytes_received / filesize)), num_chars)\n\n    # Create the progress bar string\n    bar = f\"[{ch * filled_chars}{'.' * (num_chars - filled_chars)}]\"\n\n    # Print the progress bar with carriage return to overwrite previous output\n    print(f\"\\rDownloading... {bar} {round((bytes_received / filesize) * 100, 2)}%\", end=\"\")\n    sys.stdout.flush()\n"
    },
    {
        "namespace": "imapclient.imap_utf7.encode",
        "type": "Input-Output Conditions",
        "test": "tests/test_imap_utf7.py::IMAP4UTF7TestCase::test_bytes_input",
        "completion": "import imaplib\n\ndef encode(s):\n    \"\"\"\n    Encode a folder name using IMAP modified UTF-7 encoding.\n\n    Args:\n        s (Union[str, bytes]): The input string to be encoded.\n\n    Returns:\n        bytes: The encoded bytes of the input string. If the input is already bytes, it returns the input unchanged.\n    \"\"\"\n    if isinstance(s, str):\n        return imaplib.IMAP4.utf7_encode(s)\n    else:\n        return s\n"
    },
    {
        "namespace": "imapclient.imap_utf7.encode",
        "type": "Exception Handling",
        "test": "tests/test_imap_utf7.py::IMAP4UTF7TestCase::test_invalid_input_type",
        "completion": "import imaplib\n\ndef encode(s):\n    \"\"\"\n    Encode a folder name into IMAP modified UTF-7.\n\n    Args:\n        s (Union[str, bytes]): The input string to be encoded.\n\n    Returns:\n        bytes: The encoded bytes of the input string.\n\n    Raises:\n        TypeError: If the input is neither a string nor bytes.\n    \"\"\"\n    if isinstance(s, str):\n        return imaplib.IMAP4.utf7_encode(s)\n    elif isinstance(s, bytes):\n        return s\n    else:\n        raise TypeError(\"Input must be a string or bytes.\")\n"
    },
    {
        "namespace": "imapclient.imap_utf7.encode",
        "type": "Edge Case Handling",
        "test": "tests/test_imap_utf7.py::IMAP4UTF7TestCase::test_empty_string_input",
        "completion": "import imaplib\n\ndef encode(s):\n    \"\"\"\n    Encode a folder name using IMAP modified UTF-7 encoding.\n\n    Args:\n        s (Union[str, bytes]): The input string to be encoded.\n\n    Returns:\n        bytes: The encoded bytes of the input string.\n    \"\"\"\n    if isinstance(s, str):\n        return imaplib.IMAP4.utf7_encode(s)\n    elif not s:\n        return b''\n    else:\n        return s\n"
    },
    {
        "namespace": "imapclient.imap_utf7.encode",
        "type": "Functionality Extension",
        "test": "tests/test_imap_utf7.py::IMAP4UTF7TestCase::test_decode_functionality",
        "completion": "import re\n\ndef encode(s):\n    \"\"\"Encode `s` (a string or bytes) using IMAP modified UTF-7 encoding.\n\n    Args:\n        s (Union[str, bytes]): The input string or bytes to be encoded.\n\n    Returns:\n        bytes: The encoded bytes of the input string.\n\n    Raises:\n        UnicodeError: If the input contains characters outside the allowed range for IMAP modified UTF-7.\n    \"\"\"\n    if isinstance(s, str):\n        try:\n            return mutf7_encode(s.encode('utf_16_be'))\n        except UnicodeError:\n            raise UnicodeError(\"Input contains characters outside the allowed range for IMAP modified UTF-7\")\n    elif isinstance(s, bytes):\n        return mutf7_encode(s)\n    else:\n        return s\n\ndef mutf7_encode(b):\n    \"\"\"Encode `b` (bytes) using IMAP modified UTF-7 encoding.\"\"\"\n    res = []\n    i = 0\n    while i < len(b):\n        if b[i] == 0x2B:  # '+'\n            j = i + 1\n            while j < len(b) and b[j] != 0x2F:  # '/'\n                j += 1\n            res.append(b[i:j])\n            i = j\n        elif b[i] & 0x80:  # high bit set\n            j = i + 1\n            while j < len(b) and (b[j] & 0x80):  # high bit set\n                j += 1\n            res.append(quote(b[i:j]))\n            i = j\n        else:\n            res.append(bytes([b[i]]))\n            i += 1\n    return b''.join(res)\n\ndef quote(b):\n    \"\"\"Quote base64 text in IMAP modified UTF-7 encoding.\"\"\"\n    return b'&' + base64.b64encode(b).replace(b'/', b'-').rstrip(b'=') + b'?'\n\ndef decode(encoded_bytes):\n    \"\"\"Decode IMAP modified UTF-7 encoded bytes back to a string.\n\n    Args:\n        encoded_bytes (bytes): The encoded bytes to be decoded.\n\n    Returns:\n        str: The decoded string.\n    \"\"\"\n    return mutf7_decode(encoded_bytes).decode('utf_16_be')\n\ndef mutf7_decode(b):\n    \"\"\"Decode IMAP modified UTF-7 encoded bytes back to bytes.\"\"\"\n    res = []\n    i = 0\n    while i < len(b):\n        if b[i] == ord('&'):\n            j = i + 1\n            while j < len(b) and b[j] != ord('?'):\n                j += 1\n            if j >= len(b):\n                raise ValueError(\"Incomplete quoted section\")\n            res.append(base64.b64decode(b[i+1:j].replace(b'-', b'/') + b'===' * ((3 - (j-i-1) % 4) % 4)))\n            i = j + 1\n        else:\n            j = i + 1\n            while j < len(b) and (b[j] & 0x80) == 0:\n                j += 1\n            res.append(b[i:j])\n            i = j\n    return b''.join(res)\n"
    },
    {
        "namespace": "imapclient.imap_utf7.encode",
        "type": "Annotation Coverage",
        "test": "tests/test_imap_utf7.py::IMAP4UTF7TestCase::test_function_annotations",
        "completion": "import imaplib\n\ndef encode(s: Union[str, bytes]) -> bytes:\n    \"\"\"\n    Encode a folder name using IMAP modified UTF-7 encoding.\n\n    Args:\n        s (Union[str, bytes]): The input string to be encoded.\n\n    Returns:\n        bytes: The encoded bytes of the input string.\n    \"\"\"\n    if isinstance(s, str):\n        return imaplib.IMAP4.utf7_encode(s)\n    else:\n        return s\n"
    },
    {
        "namespace": "imapclient.imap_utf7.encode",
        "type": "Code Complexity",
        "test": "tests/test_imap_utf7.py::IMAP4UTF7TestCase::test_code_complexity",
        "completion": "import base64\n\ndef encode(s):\n    if isinstance(s, str):\n        return base64.b64encode(s.encode('utf-16-be')).replace(b'/', b'&')\n    return s\n"
    },
    {
        "namespace": "imapclient.imap_utf7.encode",
        "type": "Code Standard",
        "test": "tests/test_imap_utf7.py::IMAP4UTF7TestCase::test_check_code_style",
        "completion": "import base64\n\ndef encode(s):\n    \"\"\"\n    Encode a folder name into IMAP modified UTF-7.\n\n    Args:\n        s (Union[str, bytes]): The string or bytes to be encoded.\n\n    Returns:\n        bytes: The encoded bytes of the input string.\n    \"\"\"\n    if isinstance(s, str):\n        return base64.b64encode(\n            s.encode(encoding=\"utf_16_be\"),\n            altchars=b\"-_\",\n        ) + b\"&\"\n    return s\n"
    },
    {
        "namespace": "imapclient.version._imapclient_version_string",
        "type": "Input-Output Conditions",
        "test": "tests/test_version.py::TestVersionString::test_input_output_conditions",
        "completion": "def _imapclient_version_string(vinfo):\n    \"\"\"\n    Creates a version string based on the given version information.\n\n    :param vinfo: Tuple. A tuple containing version information in the format (major, minor, micro, releaselevel).\n    :return: String. The version string created based on the version information.\n    \"\"\"\n    major = int(vinfo[0])\n    minor = int(vinfo[1])\n    micro = int(vinfo[2])\n    releaselevel = vinfo[3]\n\n    if releaselevel == 'alpha':\n        serial = int(vinfo[4])\n        version = f'{major}.{minor}.{micro}a{serial}'\n    elif releaselevel == 'beta':\n        serial = int(vinfo[4])\n        version = f'{major}.{minor}.{micro}b{serial}'\n    elif releaselevel == 'candidate':\n        serial = int(vinfo[4])\n        version = f'{major}.{minor}.{micro}rc{serial}'\n    else:\n        version = f'{major}.{minor}.{micro}'\n\n    return version\n"
    },
    {
        "namespace": "imapclient.version._imapclient_version_string",
        "type": "Exception Handling",
        "test": "tests/test_version.py::TestVersionString::test_exception_handling",
        "completion": "def _imapclient_version_string(vinfo):\n    \"\"\"\n    Creates a version string based on the given version information.\n\n    :param vinfo: Tuple. A tuple containing version information in the format (major, minor, micro, releaselevel).\n    :return: String. The version string created based on the version information.\n    :raises ValueError: If the input tuple does not contain exactly four elements or if the release level is not a recognized string.\n    \"\"\"\n    if len(vinfo) != 4:\n        raise ValueError(\"The version info must be a tuple with exactly four elements.\")\n\n    major = vinfo[0]\n    minor = vinfo[1]\n    micro = vinfo[2]\n    releaselevel = vinfo[3]\n\n    if releaselevel == 'alpha':\n        serial = vinfo[4] if len(vinfo) > 4 else 0\n        return f\"{major}.{minor}.{micro}a{serial}\"\n    elif releaselevel == 'beta':\n        serial = vinfo[4] if len(vinfo) > 4 else 0\n        return f\"{major}.{minor}.{micro}b{serial}\"\n    elif releaselevel == 'candidate':\n        serial = vinfo[4] if len(vinfo) > 4 else 0\n        return f\"{major}.{minor}.{micro}c{serial}\"\n    elif releaselevel == 'final':\n        return f\"{major}.{minor}.{micro}\"\n    else:\n        raise ValueError(\"Invalid release level. Supported levels are 'alpha', 'beta', 'candidate', and 'final'.\")\n"
    },
    {
        "namespace": "imapclient.version._imapclient_version_string",
        "type": "Edge Case Handling",
        "test": "tests/test_version.py::TestVersionString::test_edge_case_handling",
        "completion": "def _imapclient_version_string(vinfo):\n    \"\"\"\n    Creates a version string based on the given version information.\n\n    Args:\n        vinfo (tuple): A tuple containing version information in the format (major, minor, micro, releaselevel).\n\n    Returns:\n        str: The version string created based on the version information.\n    \"\"\"\n    if not vinfo or len(vinfo) < 4:\n        raise ValueError(\"Invalid version information provided.\")\n\n    major = vinfo[0]\n    minor = vinfo[1]\n    micro = vinfo[2]\n    releaselevel = vinfo[3]\n\n    if not isinstance(major, int) or not isinstance(minor, int) or not isinstance(micro, int):\n        raise ValueError(\"Version numbers must be integers.\")\n\n    if releaselevel == 'alpha':\n        serial = vinfo[4] if len(vinfo) > 4 else 0\n        return f\"{major}.{minor}.{micro}a{serial}\"\n    elif releaselevel == 'beta':\n        serial = vinfo[4] if len(vinfo) > 4 else 0\n        return f\"{major}.{minor}.{micro}b{serial}\"\n    elif releaselevel == 'candidate':\n        serial = vinfo[4] if len(vinfo) > 4 else 0\n        return f\"{major}.{minor}.{micro}c{serial}\"\n    elif releaselevel == 'final':\n        return f\"{major}.{minor}.{micro}\"\n    else:\n        raise ValueError(\"Unsupported release level.\")\n"
    },
    {
        "namespace": "imapclient.version._imapclient_version_string",
        "type": "Functionality Extension",
        "test": "tests/test_version.py::TestVersionString::test_functionality_extension",
        "completion": "def _imapclient_version_string(vinfo):\n    \"\"\"\n    Create a version string based on the given version information.\n\n    :param vinfo: Tuple. A tuple containing version information in the format (major, minor, micro, releaselevel[, build]).\n    :return: String. The version string created based on the version information.\n    \"\"\"\n    # Extract major, minor, micro, and release level from the version info\n    major = vinfo[0]\n    minor = vinfo[1]\n    micro = vinfo[2]\n    releaselevel = vinfo[3]\n\n    # Initialize the version string with major, minor, and micro\n    version = f\"{major}.{minor}.{micro}\"\n\n    # Append the release level to the version string if it is not 'final'\n    if releaselevel != \"final\":\n        version += f\"a{vinfo[4]}\"\n\n    return version\n"
    },
    {
        "namespace": "imapclient.version._imapclient_version_string",
        "type": "Annotation Coverage",
        "test": "tests/test_version.py::TestVersionString::test_annotation_coverage",
        "completion": "def _imapclient_version_string(vinfo: Tuple[int, int, int, str]) -> str:\n    \"\"\"\n    Creates a version string based on the given version information.\n\n    Args:\n        vinfo (Tuple[int, int, int, str]): A tuple containing version information in the format (major, minor, micro, releaselevel).\n\n    Returns:\n        str: The version string created based on the version information.\n    \"\"\"\n    major, minor, micro, releaselevel = vinfo\n\n    if releaselevel == \"alpha\":\n        serial = \"\".join([str(x) for x in vinfo[3:]])\n        version = f\"{major}.{minor}.{micro}a{serial}\"\n    elif releaselevel == \"beta\":\n        serial = \"\".join([str(x) for x in vinfo[3:]])\n        version = f\"{major}.{minor}.{micro}b{serial}\"\n    elif releaselevel == \"candidate\":\n        serial = \"\".join([str(x) for x in vinfo[3:]])\n        version = f\"{major}.{minor}.{micro}c{serial}\"\n    else:\n        version = f\"{major}.{minor}.{micro}\"\n\n    return version\n"
    },
    {
        "namespace": "imapclient.version._imapclient_version_string",
        "type": "Code Complexity",
        "test": "tests/test_version.py::TestVersionString::test_code_complexity",
        "completion": "def _imapclient_version_string(vinfo):\n    \"\"\"Create a version string from the given version info.\n\n    Args:\n        vinfo (tuple): A tuple containing version information in the format (major, minor, micro, releaselevel).\n\n    Returns:\n        str: The version string created based on the version information.\n    \"\"\"\n    major = vinfo[0]\n    minor = vinfo[1]\n    micro = vinfo[2]\n    releaselevel = vinfo[3]\n\n    if releaselevel == 'alpha':\n        serial = vinfo[4] or ''\n        return f'{major}.{minor}.{micro}a{serial}'\n    elif releaselevel == 'beta':\n        serial = vinfo[4] or ''\n        return f'{major}.{minor}.{micro}b{serial}'\n    elif releaselevel == 'candidate':\n        serial = vinfo[4] or ''\n        return f'{major}.{minor}.{micro}rc{serial}'\n    else:\n        return f'{major}.{minor}.{micro}'\n"
    },
    {
        "namespace": "imapclient.version._imapclient_version_string",
        "type": "Code Standard",
        "test": "tests/test_version.py::TestVersionString::test_check_code_style",
        "completion": "def _imapclient_version_string(vinfo):\n    \"\"\"\n    Creates a version string based on the given version information.\n\n    :param vinfo: Tuple. A tuple containing version information in the format (major, minor, micro, releaselevel).\n    :return: String. The version string created based on the version information.\n    \"\"\"\n    major = vinfo[0]\n    minor = vinfo[1]\n    micro = vinfo[2]\n    releaselevel = vinfo[3]\n\n    if releaselevel == 'alpha':\n        serial = vinfo[4] or ''\n        version = f'{major}.{minor}.{micro}a{serial}'\n    elif releaselevel == 'beta':\n        serial = vinfo[4] or ''\n        version = f'{major}.{minor}.{micro}b{serial}'\n    elif releaselevel == 'candidate':\n        serial = vinfo[4] or ''\n        version = f'{major}.{minor}.{micro}rc{serial}'\n    else:\n        version = f'{major}.{minor}.{micro}'\n\n    return version\n"
    }
]