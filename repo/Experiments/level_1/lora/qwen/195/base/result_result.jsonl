{"namespace": "benedict.utils.type_util.is_json_serializable", "completion": "\nimport json\n\ndef is_json_serializable(val):\n    \"\"\"\n    Checks if the input value is JSON serializable.\n\n    Args:\n        val (Any): The input value to be checked for JSON serializability.\n\n    Returns:\n        bool: True if the input value is JSON serializable, False otherwise.\n    \"\"\"\n    try:\n        json.dumps(val)\n        return True\n    except TypeError:\n        return False\n", "Result": "Pass"}
{"namespace": "feedparser.urls.convert_to_idn", "completion": "\nimport re\nfrom urllib.parse import urlparse\nimport idna\n\ndef convert_to_idn(url):\n    \"\"\"\n    Converts a URL to IDN notation.\n\n    Args:\n        url (str): The URL to be converted to IDN notation.\n\n    Returns:\n        str: The URL in IDN notation.\n    \"\"\"\n    parsed_url = urlparse(url)\n    if not parsed_url.hostname:\n        return url\n    try:\n        # Check if the hostname can be encoded in ASCII\n        ascii_hostname = parsed_url.hostname.encode('ascii')\n        # If encoding fails, it means the hostname contains non-ASCII characters\n        return url\n    except UnicodeEncodeError:\n        # Convert the hostname to IDN form\n        new_host = idna.encode(parsed_url.hostname).decode('utf-8')\n        # Replace the original hostname with the IDN version in the URL\n        return re.sub(r'(?i)^(?:https?://)?(?:www\\.)?(.*?)(?:/|$)',\n                      r'https://{0}\\1'.format(new_host),\n                      url,\n                      flags=re.IGNORECASE)\n", "Result": "Error"}
{"namespace": "googleapiclient._helpers.parse_unique_urlencoded", "completion": "\nfrom urllib.parse import parse_qs\n\ndef parse_unique_urlencoded(content):\n    \"\"\"\n    Parses unique key-value parameters from URL-encoded content.\n\n    Args:\n        content (str): URL-encoded key-value pairs.\n\n    Returns:\n        dict: The key-value pairs from the input content.\n\n    Raises:\n        ValueError: If one of the keys is repeated.\n    \"\"\"\n    parsed_params = parse_qs(content)\n    \n    # Check for repeated keys\n    for key in parsed_params:\n        if len(parsed_params[key]) > 1:\n            raise ValueError(f\"Repeated key found: {key}\")\n    \n    # Convert lists to single values if there's only one value\n    result = {}\n    for key, values in parsed_params.items():\n        if len(values) == 1:\n            result[key] = values[0]\n        else:\n            result[key] = values\n    \n    return result\n", "Result": "Pass"}
{"namespace": "jinja2.async_utils.auto_aiter", "completion": "\nfrom typing import AsyncIterable, Iterable, TypeVar, AsyncIterator\n\nT = TypeVar('T')\n\nasync def auto_aiter(iterable: AsyncIterable[T] | Iterable[T]) -> AsyncIterator[T]:\n    \"\"\"\n    Creates an async iterator from the given iterable.\n\n    Args:\n        iterable (Union[AsyncIterable[T], Iterable[T]]): The input iterable from which the iterator is created.\n\n    Returns:\n        AsyncIterator[T]: The created asynchronous iterator.\n    \"\"\"\n    try:\n        # Attempt to get an asynchronous iterator using __aiter__\n        return iter(iterable)  # type: ignore\n    except AttributeError:\n        # If __aiter__ is not available, yield items synchronously\n        for item in iterable:\n            yield item\n", "Result": "Error"}
{"namespace": "csvs_to_sqlite.utils.table_exists", "completion": "\nimport sqlite3\n\ndef table_exists(conn, table):\n    \"\"\"\n    Check if the table exists in the database.\n\n    :param conn: Connection. The connection to the database.\n    :param table: String. The name of the table to check.\n    :return: Bool. True if the table exists, False otherwise.\n    \"\"\"\n    cursor = conn.cursor()\n    cursor.execute(f\"SELECT name FROM sqlite_master WHERE type='table' AND name='{table}'\")\n    return bool(cursor.fetchone())\n", "Result": "Pass"}
{"namespace": "sqlitedict.SqliteDict.get_tablenames", "completion": "\nimport sqlite3\n\ndef get_tablenames(filename):\n    \"\"\"\n    Retrieves the names of the tables in an SQLite database.\n\n    Args:\n        filename (str): The name of the SQLite database file.\n\n    Returns:\n        list: A list of table names in the SQLite database.\n\n    Raises:\n        IOError: If the file does not exist.\n    \"\"\"\n    if not os.path.exists(filename):\n        raise IOError('file {} does not exist'.format(filename))\n    \n    conn = sqlite3.connect(filename)\n    cursor = conn.cursor()\n    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n    tablenames = [row[0] for row in cursor.fetchall()]\n    cursor.close()\n    conn.close()\n    return tablenames\n", "Result": "Error"}
{"namespace": "psd_tools.utils.pack", "completion": "\nimport struct\n\ndef pack(fmt, *args):\n    \"\"\"\n    Packs the input arguments into a binary string according to the given format.\n\n    :param fmt: String. The format string that specifies the format of the returned string.\n    :param args: Tuple. The input arguments to be packed.\n    :return: Binary string. The packed binary string.\n    \"\"\"\n    return struct.pack(fmt, *args)\n", "Result": "Error"}
{"namespace": "psd_tools.utils.unpack", "completion": "\nimport struct\n\ndef unpack(fmt, data):\n    \"\"\"\n    Unpacks the given data according to the specified format.\n\n    :param fmt: String. The format string to be used for unpacking the data.\n    :param data: Bytes or bytearray. The data to be unpacked.\n    :return: Tuple. A tuple containing the unpacked values.\n    \"\"\"\n    return struct.unpack(fmt, data)\n", "Result": "Error"}
{"namespace": "exodus_bundler.bundling.bytes_to_int", "completion": "\nimport struct\n\ndef bytes_to_int(bytes, byteorder=\"big\"):\n    \"\"\"\n    Convert a byte string into an integer.\n\n    :param bytes: Byte string to be converted into an integer.\n    :type bytes: bytes\n    :param byteorder: Byte order to be used (\"big\" or \"little\"). Defaults to \"big\".\n    :type byteorder: str\n    :return: Converted integer value.\n    :rtype: int\n    \"\"\"\n    return int.from_bytes(bytes, byteorder=byteorder)\n", "Result": "Pass"}
{"namespace": "exodus_bundler.templating.render_template", "completion": "\ndef render_template(string, **context):\n    \"\"\"\n    Replaces placeholders in the input string with corresponding values from the context dictionary.\n\n    Args:\n        string (str): The input string containing placeholders.\n        context (dict): Key-value pairs to replace the placeholders in the input string.\n\n    Returns:\n        str: The modified string after replacing the placeholders.\n    \"\"\"\n    for key, value in context.items():\n        placeholder = f'{{{key}}}'\n        if placeholder in string:\n            string = string.replace(placeholder, str(value))\n    return string\n", "Result": "Error"}
{"namespace": "trailscraper.iam.all_known_iam_permissions", "completion": "\nimport os\n\ndef all_known_iam_permissions():\n    \"\"\"\n    Returns a set of all known IAM actions.\n\n    :return: set. A set of lines.\n    \"\"\"\n    filename = os.path.join(os.path.dirname(__file__), 'known-iam-actions.txt')\n    with open(filename) as f:\n        return {line.strip() for line in f}\n", "Result": "Pass"}
{"namespace": "trailscraper.cloudtrail.parse_records", "completion": "\ndef parse_records(json_records):\n    \"\"\"\n    Parses a list of JSON records into Record objects.\n\n    Args:\n        json_records (List): A list of JSON records to be parsed.\n\n    Returns:\n        List: A list of Record objects parsed from the JSON records.\n    \"\"\"\n    parsed_records = [_parse_record(record) for record in json_records]\n    return [record for record in parsed_records if record is not None]\n", "Result": "Pass"}
{"namespace": "discord.utils.get_slots", "completion": "\ndef get_slots(cls):\n    \"\"\"\n    Returns an iterator that yields the names of the slots in the class and its base classes.\n\n    :param cls: Type. The class for which the slots are to be retrieved.\n    :return: Iterator. An iterator that yields the names of the slots in the class and its base classes.\n    \"\"\"\n    while cls:\n        if hasattr(cls, '__slots__'):\n            for slot in cls.__slots__:\n                yield slot\n        cls = cls.__base__\n", "Result": "Pass"}
{"namespace": "discord.utils.is_inside_class", "completion": "\ndef is_inside_class(func):\n    \"\"\"\n    Determine whether a given callable (function or method) is defined within a class.\n\n    Args:\n        func (Callable): The function to be checked.\n\n    Returns:\n        bool: True if the function is defined inside a class, False otherwise.\n    \"\"\"\n    # Check if the function's __qualname__ contains a dot, which indicates it's nested\n    return '.' in getattr(func, '__qualname__', '')\n", "Result": "Error"}
{"namespace": "wandb.util.to_forward_slash_path", "completion": "\nimport os\n\ndef to_forward_slash_path(path):\n    \"\"\"\n    Convert the backslash path to a forward slash path if the platform is Windows.\n\n    Args:\n        path (str): The path to be converted.\n\n    Returns:\n        str: The converted path.\n    \"\"\"\n    if os.name == \"nt\":\n        return path.replace(\"\\\\\", \"/\")\n    else:\n        return path\n", "Result": "Pass"}
{"namespace": "wandb.util.make_artifact_name_safe", "completion": "\nimport re\n\ndef make_artifact_name_safe(name):\n    \"\"\"\n    Makes an artifact name safe for use in artifacts.\n\n    Args:\n        name (str): The original artifact name.\n\n    Returns:\n        str: The cleaned and safe artifact name.\n    \"\"\"\n    # Replace any character that is not alphanumeric, dash, underscore, or dot with an underscore\n    cleaned = re.sub(r\"[^a-zA-Z0-9-_\\.]\", \"_\", name)\n    \n    # Truncate the name if its length exceeds 128 characters\n    if len(cleaned) > 128:\n        return re.sub(\n            r\"(.{0,64}).*(.{0,63})\",\n            lambda m: f\"{m.group(1)}...{m.group(2)}\",\n            cleaned,\n        )\n    else:\n        return cleaned\n", "Result": "Pass"}
{"namespace": "jwt.utils.force_bytes", "completion": "\nfrom typing import Union\n\ndef force_bytes(value: Union[bytes, str]) -> bytes:\n    \"\"\"\n    Convert the input value to bytes.\n\n    Args:\n        value (Union[bytes, str]): The input value that needs to be converted to bytes.\n\n    Returns:\n        bytes: The input value converted to bytes.\n\n    Raises:\n        TypeError: If the input value is neither a bytes nor a string.\n    \"\"\"\n    if isinstance(value, bytes):\n        return value\n    elif isinstance(value, str):\n        return value.encode('utf-8')\n    else:\n        raise TypeError(f'Expected bytes or str, got {type(value).__name__}')\n", "Result": "Pass"}
{"namespace": "pytube.cli.display_progress_bar", "completion": "\nimport sys\n\ndef display_progress_bar(bytes_received, filesize, ch='\u2588', scale=0.55):\n    \"\"\"\n    Displays a simple, pretty progress bar in the terminal.\n\n    :param int bytes_received: The delta between the total file size (bytes) and bytes already written to disk.\n    :param int filesize: File size of the media stream in bytes.\n    :param str ch: Character to use for presenting progress segment. Defaults to \"\u2588\".\n    :param float scale: Scale multiplier to reduce progress bar size. Defaults to 0.55.\n    \"\"\"\n    if filesize <= 0:\n        # Avoid division by zero\n        sys.stdout.write(\"[{}] 100%\\r\".format(ch * 40))\n        sys.stdout.flush()\n        return\n\n    # Calculate the number of characters to fill the progress bar\n    num_chars = int(filesize * scale)\n    filled_chars = int((bytes_received / filesize) * num_chars)\n\n    # Create the progress bar string\n    progress_bar = \"[\" + (ch * filled_chars).ljust(num_chars) + \"]\"\n\n    # Calculate the percentage complete\n    percent_complete = min(int((bytes_received / filesize) * 100), 100)\n\n    # Print the progress bar and percentage\n    sys.stdout.write(\"{} {}%\\r\".format(progress_bar, percent_complete))\n    sys.stdout.flush()\n\n# Example usage:\n# import time\n# filesize = 1024 * 1024  # 1 MB\n# for i in range(0, filesize, 1024):\n#     display_progress_bar(i, filesize)\n#     time.sleep(0.1)\n", "Result": "Error"}
{"namespace": "imapclient.imap_utf7.encode", "completion": "\nfrom typing import Union\n\ndef encode(s: Union[str, bytes]) -> bytes:\n    \"\"\"\n    Encode a folder name using IMAP modified UTF-7 encoding.\n\n    Args:\n        s (Union[str, bytes]): The input string to be encoded.\n\n    Returns:\n        bytes: The encoded bytes of the input string.\n    \"\"\"\n    if isinstance(s, str):\n        return s.encode('imap4-modified-utf-7')\n    else:\n        return s\n", "Result": "Error"}
{"namespace": "imapclient.version._imapclient_version_string", "completion": "\ndef _imapclient_version_string(vinfo):\n    \"\"\"\n    Create a version string based on the given version information.\n\n    Args:\n        vinfo (tuple): A tuple containing version information in the format (major, minor, micro, releaselevel).\n\n    Returns:\n        str: The version string created based on the version information.\n    \"\"\"\n    major = vinfo[0]\n    minor = vinfo[1]\n    micro = vinfo[2]\n    releaselevel = vinfo[3]\n\n    if releaselevel == 'alpha':\n        serial = vinfo[4] or ''\n        version = f'{major}.{minor}.{micro}a{serial}'\n    elif releaselevel == 'beta':\n        serial = vinfo[4] or ''\n        version = f'{major}.{minor}.{micro}b{serial}'\n    elif releaselevel == 'candidate':\n        serial = vinfo[4] or ''\n        version = f'{major}.{minor}.{micro}rc{serial}'\n    else:\n        version = f'{major}.{minor}.{micro}'\n\n    return version\n", "Result": "Error"}
