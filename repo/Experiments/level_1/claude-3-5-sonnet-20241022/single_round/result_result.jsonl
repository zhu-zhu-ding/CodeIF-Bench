{"namespace": "benedict.utils.type_util.is_json_serializable", "type": "Input-Output Conditions", "test": "tests/utils/test_type_util.py::type_util_test_case::test_input_output_conditions", "completion": "\ndef is_json_serializable(val: Any) -> bool:\n    \"\"\"\n    Check if the input value is JSON serializable.\n    \n    :param val: Any. The input value to be checked for JSON serializability\n    :return: Bool. True if the input value is JSON serializable, False otherwise\n    \"\"\"\n    # Handle None case\n    if val is None:\n        return True\n    \n    # Basic JSON serializable types\n    if isinstance(val, (bool, int, float, str)):\n        return True\n    \n    # Handle lists and tuples\n    if isinstance(val, (list, tuple)):\n        return all(is_json_serializable(item) for item in val)\n    \n    # Handle dictionaries\n    if isinstance(val, dict):\n        return all(isinstance(k, str) and is_json_serializable(v) for k, v in val.items())\n    \n    # All other types are not JSON serializable\n    return False\n", "Result": "Error"}
{"namespace": "benedict.utils.type_util.is_json_serializable", "type": "Exception Handling", "test": "tests/utils/test_type_util.py::type_util_test_case::test_exception_handling", "completion": "\nimport json\nfrom typing import Any\n\ndef is_json_serializable(val: Any) -> bool:\n    \"\"\"\n    Check if the input value is JSON serializable.\n    \n    :param val: Any - The input value to be checked for JSON serializability\n    :return: Bool - True if the input value is JSON serializable, False otherwise\n    \"\"\"\n    try:\n        json.dumps(val)\n        return True\n    except (TypeError, OverflowError, ValueError):\n        return False\n", "Result": "Pass"}
{"namespace": "benedict.utils.type_util.is_json_serializable", "type": "Edge Case Handling", "test": "tests/utils/test_type_util.py::type_util_test_case::test_edge_case_handling", "completion": "\ndef is_json_serializable(val: Any) -> bool:\n    \"\"\"\n    Check if the input value is JSON serializable.\n    \n    :param val: Any. The input value to be checked for JSON serializability.\n    :return: Bool. True if the input value is JSON serializable, False otherwise.\n    \"\"\"\n    # Handle None case\n    if val is None:\n        return True\n    \n    # Handle basic JSON serializable types\n    if isinstance(val, (bool, int, float, str)):\n        return True\n    \n    # Handle collections\n    if isinstance(val, (list, tuple)):\n        return all(is_json_serializable(item) for item in val)\n    \n    if isinstance(val, dict):\n        # Check if all keys are strings (JSON requirement)\n        if not all(isinstance(key, str) for key in val.keys()):\n            return False\n        # Check if all values are serializable\n        return all(is_json_serializable(value) for value in val.values())\n    \n    # Handle non-serializable types\n    return False\n", "Result": "Error"}
{"namespace": "benedict.utils.type_util.is_json_serializable", "type": "Functionality Extension", "test": "tests/utils/test_type_util.py::type_util_test_case::test_functionality_extension", "completion": "\ndef is_json_serializable(val: Any) -> bool:\n    \"\"\"\n    Check if the input value is JSON serializable.\n    \n    :param val: Any. The input value to be checked for JSON serializability\n    :return: Bool. True if the input value is JSON serializable, False otherwise\n    \"\"\"\n    # Handle None, which is JSON serializable\n    if val is None:\n        return True\n    \n    # Basic JSON serializable types\n    json_types = (bool, int, float, str)\n    \n    # Check if value is of basic JSON serializable type\n    if isinstance(val, json_types):\n        return True\n    \n    # Check for numpy types if numpy is available\n    try:\n        import numpy as np\n        if isinstance(val, (np.ndarray, np.generic)):\n            return False\n    except ImportError:\n        pass\n    \n    # Handle lists and dictionaries by checking their contents\n    if isinstance(val, (list, tuple)):\n        return all(is_json_serializable(item) for item in val)\n    \n    if isinstance(val, dict):\n        return all(isinstance(k, str) and is_json_serializable(v) \n                  for k, v in val.items())\n    \n    # If none of the above conditions are met, the value is not JSON serializable\n    return False\n", "Result": "Error"}
{"namespace": "benedict.utils.type_util.is_json_serializable", "type": "Annotation Coverage", "test": "tests/utils/test_type_util.py::type_util_test_case::test_annotation_coverage", "completion": "\nfrom typing import Any\nimport json\n\ndef is_json_serializable(val: Any) -> bool:\n    \"\"\"\n    Check if the input value is JSON serializable.\n    \n    Args:\n        val (Any): The input value to be checked for JSON serializability\n        \n    Returns:\n        bool: True if the input value is JSON serializable, False otherwise\n    \"\"\"\n    try:\n        json.dumps(val)\n        return True\n    except (TypeError, OverflowError):\n        return False\n", "Result": "Pass"}
{"namespace": "benedict.utils.type_util.is_json_serializable", "type": "Code Complexity", "test": "tests/utils/test_type_util.py::type_util_test_case::test_code_complexity", "completion": "\ndef is_json_serializable(val: Any) -> bool:\n    \"\"\"\n    Check if the input value is JSON serializable.\n    \n    :param val: Any - The input value to be checked for JSON serializability\n    :return: Bool - True if the input value is JSON serializable, False otherwise\n    \"\"\"\n    try:\n        json.dumps(val)\n        return True\n    except (TypeError, OverflowError):\n        return False\n", "Result": "Error"}
{"namespace": "benedict.utils.type_util.is_json_serializable", "type": "Code Standard", "test": "tests/utils/test_type_util.py::type_util_test_case::test_check_code_style", "completion": "\ndef is_json_serializable(val: Any) -> bool:\n    \"\"\"\n    Check if the input value is JSON serializable.\n\n    :param val: Any\n        The input value to be checked for JSON serializability\n    :return: bool\n        True if the input value is JSON serializable, False otherwise\n    \"\"\"\n    try:\n        json.dumps(val)\n        return True\n    except (TypeError, OverflowError):\n        return False\n", "Result": "Error"}
{"namespace": "feedparser.urls.convert_to_idn", "type": "Exception Handling", "test": "tests/runtests.py::TestConvertToIdn::test_exception_handling_invalid_url", "completion": "\nfrom urllib.parse import urlparse, urlunparse\nimport idna\n\ndef convert_to_idn(url: str) -> str:\n    \"\"\"\n    Convert a URL to IDN notation.\n    \n    Args:\n        url (str): The URL to be converted to IDN notation\n        \n    Returns:\n        str: The URL in IDN notation\n        \n    Raises:\n        ValueError: If the input is not a valid URL string\n        UnicodeError: If conversion to IDN fails\n    \"\"\"\n    if not isinstance(url, str):\n        raise ValueError(\"URL must be a string\")\n    \n    try:\n        # Parse the URL into components\n        parsed = urlparse(url)\n        \n        if not parsed.netloc:\n            raise ValueError(\"Invalid URL: no host found\")\n        \n        # Split host into parts (handling potential subdomains)\n        host_parts = parsed.hostname.split('.')\n        \n        # Convert each part to IDN if necessary\n        idn_parts = []\n        for part in host_parts:\n            # Check if part needs conversion (contains non-ASCII characters)\n            if not part.isascii():\n                try:\n                    idn_parts.append(idna.encode(part).decode('ascii'))\n                except idna.IDNAError as e:\n                    raise UnicodeError(f\"IDN conversion failed: {str(e)}\")\n            else:\n                idn_parts.append(part)\n        \n        # Reconstruct the host\n        new_host = '.'.join(idn_parts)\n        \n        # Reconstruct the URL with the new host\n        new_components = parsed._replace(netloc=new_host)\n        if parsed.port:\n            new_components = new_components._replace(netloc=f\"{new_host}:{parsed.port}\")\n        \n        return urlunparse(new_components)\n        \n    except Exception as e:\n        if isinstance(e, UnicodeError):\n            raise\n        raise ValueError(f\"Invalid URL: {str(e)}\")\n", "Result": "Pass"}
{"namespace": "feedparser.urls.convert_to_idn", "type": "Edge Case Handling", "test": "tests/runtests.py::TestConvertToIdn::test_edge_case_empty_string", "completion": "\nfrom urllib.parse import urlparse, urlunparse\nimport re\n\ndef convert_to_idn(url):\n    \"\"\"\n    Convert a URL to IDN notation.\n    \n    Args:\n        url (str): The URL to be converted to IDN notation\n        \n    Returns:\n        str: The URL in IDN notation\n        \n    Examples:\n        >>> convert_to_idn(\"https://\u4f8b\u5b50.com/path\")\n        'https://xn--fsq.com/path'\n        >>> convert_to_idn(\"https://example.com\")\n        'https://example.com'\n    \"\"\"\n    if not url:\n        return url\n        \n    # Try to parse the URL\n    try:\n        parsed = urlparse(url)\n    except ValueError:\n        return url\n        \n    # If there's no netloc (host), return original URL\n    if not parsed.netloc:\n        return url\n        \n    # Check if the host is an IP address\n    ip_pattern = r'^(?:[0-9]{1,3}\\.){3}[0-9]{1,3}$'\n    if re.match(ip_pattern, parsed.netloc):\n        return url\n        \n    try:\n        # Convert the host to IDN notation\n        idn_host = parsed.netloc.encode('idna').decode('ascii')\n        \n        # Create a new parsed result with the IDN host\n        idn_parts = parsed._replace(netloc=idn_host)\n        \n        # Convert back to URL string\n        return urlunparse(idn_parts)\n    except UnicodeError:\n        # If conversion fails, return original URL\n        return url\n", "Result": "Error"}
{"namespace": "feedparser.urls.convert_to_idn", "type": "Functionality Extension", "test": "tests/runtests.py::TestConvertToIdn::test_functionality_extension_query_fragment", "completion": "\nfrom urllib.parse import urlparse, urlunparse\nimport idna\n\ndef convert_to_idn(url: str) -> str:\n    \"\"\"\n    Convert a URL to IDN notation. Checks if the host can be encoded in ASCII.\n    If not, converts the host to IDN form while preserving query parameters and fragments.\n    \n    :param url: String. The URL to be converted to IDN notation\n    :return: String. The URL in IDN notation\n    \n    Example:\n        >>> convert_to_idn('https://\u4f8b\u5b50.com/path?param=value#fragment')\n        'https://xn--fsq.com/path?param=value#fragment'\n    \"\"\"\n    # Parse the URL into components\n    parsed = urlparse(url)\n    \n    # If there's no hostname, return the original URL\n    if not parsed.hostname:\n        return url\n    \n    try:\n        # Try to encode the hostname as ASCII to check if conversion is needed\n        parsed.hostname.encode('ascii')\n        return url\n    except UnicodeEncodeError:\n        # Convert hostname to IDN notation\n        idn_hostname = idna.encode(parsed.hostname).decode('ascii')\n        \n        # Reconstruct the netloc (username:password@hostname:port)\n        netloc_parts = []\n        if parsed.username:\n            netloc_parts.append(parsed.username)\n            if parsed.password:\n                netloc_parts.append(':' + parsed.password)\n            netloc_parts.append('@')\n        netloc_parts.append(idn_hostname)\n        if parsed.port:\n            netloc_parts.append(':' + str(parsed.port))\n        \n        # Create new parsed components with the IDN hostname\n        new_components = parsed._replace(netloc=''.join(netloc_parts))\n        \n        # Reconstruct the URL while preserving all components\n        return urlunparse(new_components)\n", "Result": "Pass"}
{"namespace": "feedparser.urls.convert_to_idn", "type": "Annotation Coverage", "test": "tests/runtests.py::TestConvertToIdn::test_annotation_coverage", "completion": "\nfrom typing import str\nfrom urllib.parse import urlparse, urlunparse\n\ndef convert_to_idn(url: str) -> str:\n    \"\"\"\n    Convert a URL to IDN notation. Checks if the host can be encoded in ASCII.\n    If not, converts the host to IDN form.\n\n    Args:\n        url (str): The URL to be converted to IDN notation\n\n    Returns:\n        str: The URL in IDN notation\n\n    Example:\n        >>> convert_to_idn(\"https://m\u00fcnchen.de\")\n        'https://xn--mnchen-3ya.de'\n    \"\"\"\n    # Parse the URL into components\n    parsed = urlparse(url)\n    \n    # Convert the hostname to IDN notation if needed\n    if parsed.hostname:\n        try:\n            # Try encoding the hostname to ASCII to check if conversion is needed\n            parsed.hostname.encode('ascii')\n        except UnicodeEncodeError:\n            # Convert to IDN notation if ASCII encoding fails\n            idn_hostname = parsed.hostname.encode('idna').decode('ascii')\n            # Reconstruct the netloc (may include port, username, password)\n            netloc_parts = parsed.netloc.split(parsed.hostname)\n            new_netloc = idn_hostname.join(netloc_parts)\n            # Create a new parsed result with the IDN hostname\n            parsed = parsed._replace(netloc=new_netloc)\n    \n    # Convert back to URL string\n    return urlunparse(parsed)\n", "Result": "Error"}
{"namespace": "feedparser.urls.convert_to_idn", "type": "Code Complexity", "test": "tests/runtests.py::TestConvertToIdn::test_code_complexity", "completion": "\nfrom urllib.parse import urlparse, urlunparse\nimport idna\n\ndef convert_to_idn(url: str) -> str:\n    \"\"\"\n    Convert a URL to IDN notation.\n    \n    Args:\n        url (str): The URL to be converted to IDN notation\n        \n    Returns:\n        str: The URL in IDN notation\n        \n    Example:\n        >>> convert_to_idn('https://m\u00fcnchen.de')\n        'https://xn--mnchen-3ya.de'\n    \"\"\"\n    # Parse the URL into components\n    parsed = urlparse(url)\n    \n    # If there's no hostname, return the original URL\n    if not parsed.hostname:\n        return url\n    \n    try:\n        # Convert the hostname to IDN notation\n        idn_hostname = idna.encode(parsed.hostname).decode('ascii')\n        \n        # Create a new named tuple with the converted hostname\n        converted = parsed._replace(netloc=parsed.netloc.replace(\n            parsed.hostname, idn_hostname))\n        \n        # Reconstruct the URL\n        return urlunparse(converted)\n        \n    except (UnicodeError, idna.IDNAError):\n        # Return original URL if conversion fails\n        return url\n", "Result": "Pass"}
{"namespace": "feedparser.urls.convert_to_idn", "type": "Code Standard", "test": "tests/runtests.py::TestConvertToIdn::test_check_code_style", "completion": "\nfrom urllib.parse import urlparse, urlunparse\nimport idna\n\n\ndef convert_to_idn(url: str) -> str:\n    \"\"\"\n    Convert a URL to IDN notation.\n\n    This function checks if the host can be encoded in ASCII. If not,\n    it converts the host to IDN form.\n\n    Args:\n        url (str): The URL to be converted to IDN notation.\n\n    Returns:\n        str: The URL in IDN notation.\n\n    Example:\n        >>> convert_to_idn('https://m\u00fcnchen.de')\n        'https://xn--mnchen-3ya.de'\n    \"\"\"\n    # Parse the URL into components\n    parsed = urlparse(url)\n    \n    # If there's no hostname, return the original URL\n    if not parsed.netloc:\n        return url\n    \n    try:\n        # Try to encode the hostname as ASCII\n        parsed.netloc.encode('ascii')\n        return url\n    except UnicodeEncodeError:\n        # Convert the hostname to IDN notation\n        idn_hostname = idna.encode(parsed.netloc).decode('ascii')\n        \n        # Create a new parsed result with the IDN hostname\n        idn_parts = parsed._replace(netloc=idn_hostname)\n        \n        # Reconstruct the URL with the IDN hostname\n        return urlunparse(idn_parts)\n", "Result": "Error"}
{"namespace": "googleapiclient._helpers.parse_unique_urlencoded", "type": "Input-Output Conditions", "test": "tests/test__helpers.py::Test_parse_unique_urlencoded::test_special_characters", "completion": "\ndef parse_unique_urlencoded(content: str) -> dict:\n    \"\"\"\n    Parse URL-encoded content into a dictionary, ensuring unique keys.\n    \n    Args:\n        content (str): URL-encoded key-value pairs (e.g. 'key1=value1&key2=value2')\n        \n    Returns:\n        dict: Dictionary containing the parsed key-value pairs\n        \n    Raises:\n        ValueError: If a duplicate key is found in the content\n    \"\"\"\n    from urllib.parse import parse_qs, unquote\n    \n    # Parse the URL-encoded content\n    parsed_content = parse_qs(content, keep_blank_values=True)\n    \n    # Check for duplicate keys\n    for key, value_list in parsed_content.items():\n        if len(value_list) > 1:\n            raise ValueError(f\"Duplicate key found: {key}\")\n    \n    # Convert the parsed content to a simple key-value dictionary\n    result = {key: unquote(value_list[0]) for key, value_list in parsed_content.items()}\n    \n    return result\n", "Result": "Pass"}
{"namespace": "googleapiclient._helpers.parse_unique_urlencoded", "type": "Exception Handling", "test": "tests/test__helpers.py::Test_parse_unique_urlencoded::test_repeated_key_error_message", "completion": "\ndef parse_unique_urlencoded(content: str) -> dict:\n    \"\"\"\n    Parse URL-encoded content and ensure unique keys.\n    \n    Args:\n        content (str): URL-encoded key-value pairs\n        \n    Returns:\n        dict: Parsed key-value pairs\n        \n    Raises:\n        ValueError: If a duplicate key is encountered\n    \"\"\"\n    if not content:\n        return {}\n    \n    result = {}\n    pairs = content.split('&')\n    \n    for pair in pairs:\n        if not pair:\n            continue\n            \n        try:\n            key, value = pair.split('=', 1)\n        except ValueError:\n            # Handle cases where there's no '=' in the pair\n            key = pair\n            value = ''\n            \n        from urllib.parse import unquote\n        decoded_key = unquote(key)\n        decoded_value = unquote(value)\n        \n        if decoded_key in result:\n            raise ValueError(f\"Duplicate key found: '{decoded_key}'\")\n            \n        result[decoded_key] = decoded_value\n        \n    return result\n", "Result": "Error"}
{"namespace": "googleapiclient._helpers.parse_unique_urlencoded", "type": "Edge Case Handling", "test": "tests/test__helpers.py::Test_parse_unique_urlencoded::test_empty_content", "completion": "\ndef parse_unique_urlencoded(content: str) -> dict:\n    \"\"\"\n    Parse unique key-value parameters from URL-encoded content.\n    \n    Args:\n        content (str): URL-encoded key-value pairs\n        \n    Returns:\n        dict: The key-value pairs from the input content\n        \n    Raises:\n        ValueError: If one of the keys is repeated\n    \"\"\"\n    if not content:\n        return {}\n    \n    result = {}\n    pairs = content.split('&')\n    \n    for pair in pairs:\n        if not pair:\n            continue\n            \n        key_value = pair.split('=', 1)\n        if len(key_value) != 2:\n            continue\n            \n        key, value = key_value\n        if key in result:\n            raise ValueError(f\"Duplicate key found: {key}\")\n            \n        result[key] = value\n        \n    return result\n", "Result": "Pass"}
{"namespace": "googleapiclient._helpers.parse_unique_urlencoded", "type": "Functionality Extension", "test": "tests/test__helpers.py::Test_parse_unique_urlencoded::test_ignore_empty_keys_and_values", "completion": "\ndef parse_unique_urlencoded(content: str) -> dict:\n    \"\"\"\n    Parse unique key-value parameters from URL-encoded content.\n    Empty keys and values are ignored.\n    \n    Args:\n        content (str): URL-encoded key-value pairs\n        \n    Returns:\n        dict: The key-value pairs from the input content\n        \n    Raises:\n        ValueError: If one of the keys is repeated\n    \"\"\"\n    if not content:\n        return {}\n    \n    result = {}\n    # Split the content by '&' and process each pair\n    pairs = content.split('&')\n    \n    for pair in pairs:\n        # Skip empty pairs\n        if not pair:\n            continue\n            \n        # Split into key and value\n        parts = pair.split('=', 1)\n        \n        # Handle cases where there's no '=' or value\n        if len(parts) == 1:\n            key = parts[0]\n            value = ''\n        else:\n            key, value = parts\n            \n        # Skip if key is empty\n        if not key:\n            continue\n            \n        # Check for duplicate keys\n        if key in result:\n            raise ValueError(f\"Duplicate key found: {key}\")\n            \n        # Add to result if value is not empty\n        if value:\n            from urllib.parse import unquote\n            result[unquote(key)] = unquote(value)\n    \n    return result\n", "Result": "Pass"}
{"namespace": "googleapiclient._helpers.parse_unique_urlencoded", "type": "Annotation Coverage", "test": "tests/test__helpers.py::Test_parse_unique_urlencoded::test_function_annotations", "completion": "\nfrom typing import Dict\nfrom urllib.parse import parse_qs\n\ndef parse_unique_urlencoded(content: str) -> Dict[str, str]:\n    \"\"\"\n    Parse unique key-value parameters from URL-encoded content.\n    \n    Args:\n        content: URL-encoded key-value pairs\n        \n    Returns:\n        A dictionary containing the key-value pairs from the input content\n        \n    Raises:\n        ValueError: If one of the keys is repeated\n    \"\"\"\n    # Parse the URL-encoded content into a dictionary\n    # parse_qs returns a dict with values as lists\n    parsed_dict = parse_qs(content, keep_blank_values=True)\n    \n    # Check for repeated keys by comparing the length of values\n    for key, values in parsed_dict.items():\n        if len(values) > 1:\n            raise ValueError(f\"Repeated key found: {key}\")\n    \n    # Convert the dictionary values from lists to single strings\n    result = {key: values[0] for key, values in parsed_dict.items()}\n    \n    return result\n", "Result": "Pass"}
{"namespace": "googleapiclient._helpers.parse_unique_urlencoded", "type": "Code Complexity", "test": "tests/test__helpers.py::Test_parse_unique_urlencoded::test_code_complexity", "completion": "\nfrom urllib.parse import parse_qs\n\ndef parse_unique_urlencoded(content: str) -> dict:\n    \"\"\"\n    Parse unique key-value parameters from URL-encoded content.\n    \n    Args:\n        content: URL-encoded key-value pairs\n        \n    Returns:\n        dict: The key-value pairs from the input content\n        \n    Raises:\n        ValueError: If one of the keys is repeated\n    \"\"\"\n    # Parse the URL-encoded content into a dictionary\n    parsed_dict = parse_qs(content, keep_blank_values=True)\n    \n    # Check for repeated keys by comparing lengths\n    for key, values in parsed_dict.items():\n        if len(values) > 1:\n            raise ValueError(f\"Repeated key found: {key}\")\n    \n    # Convert the parsed dictionary to the desired format\n    # parse_qs returns values as lists, so we take the first item\n    return {key: values[0] for key, values in parsed_dict.items()}\n", "Result": "Pass"}
{"namespace": "googleapiclient._helpers.parse_unique_urlencoded", "type": "Code Standard", "test": "tests/test__helpers.py::Test_parse_unique_urlencoded::test_check_code_style", "completion": "\ndef parse_unique_urlencoded(content: str) -> dict:\n    \"\"\"\n    Parse unique key-value parameters from URL-encoded content.\n    \n    Args:\n        content (str): URL-encoded key-value pairs\n        \n    Returns:\n        dict: The key-value pairs from the input content\n        \n    Raises:\n        ValueError: If one of the keys is repeated\n    \"\"\"\n    if not content:\n        return {}\n    \n    result = {}\n    pairs = content.split('&')\n    \n    for pair in pairs:\n        if not pair:\n            continue\n            \n        try:\n            key, value = pair.split('=', 1)\n        except ValueError:\n            # Handle cases where there's no '=' in the pair\n            key, value = pair, ''\n        \n        # Check for duplicate keys\n        if key in result:\n            raise ValueError(f\"Duplicate key found: {key}\")\n            \n        result[key] = value\n        \n    return result\n", "Result": "Pass"}
{"namespace": "jinja2.async_utils.auto_aiter", "type": "Input-Output Conditions", "test": "tests/test_async.py::test_input_output_conditions", "completion": "\nfrom typing import Union, AsyncIterator, AsyncIterable, Iterable, TypeVar\n\nT = TypeVar('T')\n\nasync def auto_aiter(iterable: Union[AsyncIterable[T], Iterable[T]]) -> AsyncIterator[T]:\n    \"\"\"\n    Creates an asynchronous iterator from the given iterable.\n    \n    Args:\n        iterable: An iterable that can be either synchronous or asynchronous.\n        \n    Returns:\n        An asynchronous iterator that yields elements from the input iterable.\n        \n    Examples:\n        # With a synchronous iterable\n        async for item in auto_aiter([1, 2, 3]):\n            print(item)\n            \n        # With an asynchronous iterable\n        async for item in auto_aiter(some_async_iterable):\n            print(item)\n    \"\"\"\n    if hasattr(iterable, '__aiter__'):\n        async for item in iterable:\n            yield item\n    else:\n        for item in iterable:\n            yield item\n", "Result": "Pass"}
{"namespace": "jinja2.async_utils.auto_aiter", "type": "Exception Handling", "test": "tests/test_async.py::test_exception_handling", "completion": "\nfrom typing import Union, AsyncIterator, Iterable, AsyncIterable\nimport inspect\n\nasync def auto_aiter(iterable: Union[AsyncIterable, Iterable]) -> AsyncIterator:\n    \"\"\"\n    Creates an asynchronous iterator from the given iterable.\n    \n    Args:\n        iterable: Union[AsyncIterable, Iterable]\n            The input iterable from which the iterator is created.\n            \n    Returns:\n        AsyncIterator: The created asynchronous iterator.\n        \n    Raises:\n        TypeError: If the input is neither an iterable nor an asynchronous iterable.\n    \"\"\"\n    # Check if input has __aiter__ (async iterable)\n    if hasattr(iterable, '__aiter__'):\n        async for item in iterable:\n            yield item\n    # Check if input has __iter__ (sync iterable)\n    elif hasattr(iterable, '__iter__'):\n        for item in iterable:\n            yield item\n    else:\n        raise TypeError('Input must be an iterable or an asynchronous iterable')\n", "Result": "Pass"}
{"namespace": "jinja2.async_utils.auto_aiter", "type": "Edge Case Handling", "test": "tests/test_async.py::test_edge_case_handling", "completion": "\nfrom typing import Union, AsyncIterator, Iterable, AsyncIterable\n\nasync def auto_aiter(iterable: Union[AsyncIterable, Iterable]) -> AsyncIterator:\n    \"\"\"\n    Creates an asynchronous iterator from the given iterable.\n    \n    Args:\n        iterable: An iterable that can be either synchronous or asynchronous.\n        \n    Returns:\n        An asynchronous iterator that yields elements from the input iterable.\n    \"\"\"\n    # Check if the iterable has __aiter__ (is async iterable)\n    if hasattr(iterable, '__aiter__'):\n        async for item in iterable:\n            yield item\n    else:\n        # Handle synchronous iterable\n        for item in iterable:\n            yield item\n", "Result": "Pass"}
{"namespace": "jinja2.async_utils.auto_aiter", "type": "Functionality Extension", "test": "tests/test_async.py::test_functionality_extension", "completion": "\nfrom typing import Union, AsyncIterator, Iterable, AsyncIterable\nimport asyncio\nfrom inspect import isawaitable\n\nasync def auto_aiter(\n    iterable: Union[AsyncIterable, Iterable], \n    delay: float = 0\n) -> AsyncIterator:\n    \"\"\"\n    Creates an asynchronous iterator from the given iterable.\n    \n    Args:\n        iterable: The input iterable (can be sync or async)\n        delay: Optional delay in seconds between yielding elements (default: 0)\n    \n    Returns:\n        AsyncIterator: An async iterator that yields elements from the input iterable\n    \"\"\"\n    if hasattr(iterable, '__aiter__'):\n        # Handle async iterable\n        async for item in iterable:\n            if delay > 0:\n                await asyncio.sleep(delay)\n            yield item\n    else:\n        # Handle sync iterable\n        for item in iterable:\n            if delay > 0:\n                await asyncio.sleep(delay)\n            # If the item is awaitable, await it before yielding\n            if isawaitable(item):\n                yield await item\n            else:\n                yield item\n", "Result": "Pass"}
{"namespace": "jinja2.async_utils.auto_aiter", "type": "Annotation Coverage", "test": "tests/test_async.py::test_annotation_coverage", "completion": "\nfrom typing import Any, AsyncIterator, AsyncIterable, Iterable, Union\n\nasync def auto_aiter(iterable: Union[AsyncIterable[Any], Iterable[Any]]) -> AsyncIterator[Any]:\n    if hasattr(iterable, '__aiter__'):\n        async for item in iterable:\n            yield item\n    else:\n        for item in iterable:\n            yield item\n", "Result": "Pass"}
{"namespace": "jinja2.async_utils.auto_aiter", "type": "Code Complexity", "test": "tests/test_async.py::test_code_complexity", "completion": "\nfrom typing import Union, AsyncIterator, AsyncIterable, Iterable\nfrom collections.abc import AsyncIterable as ABCAsyncIterable\n\nasync def auto_aiter(iterable: Union[AsyncIterable, Iterable]) -> AsyncIterator:\n    \"\"\"\n    Creates an asynchronous iterator from the given iterable.\n    \n    Args:\n        iterable: The input iterable (can be either async or sync) from which \n                 the iterator is created.\n    \n    Returns:\n        An asynchronous iterator that yields items from the input iterable.\n    \"\"\"\n    if isinstance(iterable, ABCAsyncIterable):\n        async for item in iterable:\n            yield item\n    else:\n        for item in iterable:\n            yield item\n", "Result": "Pass"}
{"namespace": "jinja2.async_utils.auto_aiter", "type": "Code Standard", "test": "tests/test_async.py::test_check_code_style", "completion": "\nfrom typing import Union, AsyncIterator, AsyncIterable, Iterable\nfrom collections.abc import AsyncIterator as AsyncIteratorABC\n\n\nasync def auto_aiter(iterable: Union[AsyncIterable, Iterable]) -> AsyncIterator:\n    \"\"\"\n    Create an asynchronous iterator from the given iterable.\n\n    This function checks if the iterable has an __aiter__ attribute and if so,\n    yields items asynchronously, otherwise, yields items synchronously.\n\n    Args:\n        iterable: The input iterable from which the iterator is created.\n                 Can be either an AsyncIterable or a regular Iterable.\n\n    Returns:\n        AsyncIterator: An asynchronous iterator that yields items from the input iterable.\n\n    Examples:\n        async for item in auto_aiter(some_iterable):\n            print(item)\n    \"\"\"\n    if hasattr(iterable, '__aiter__'):\n        async for item in iterable:\n            yield item\n    else:\n        for item in iterable:\n            yield item\n", "Result": "Error"}
{"namespace": "csvs_to_sqlite.utils.table_exists", "type": "Exception Handling", "test": "tests/test_utils.py::test_table_exists_exception_handling", "completion": "\ndef table_exists(conn, table):\n    \"\"\"\n    Check if the table exists in the database.\n    \n    Args:\n        conn: Connection object for the database\n        table: String representing the table name to check\n        \n    Returns:\n        bool: True if table exists, False otherwise\n        \n    Raises:\n        ValueError: If conn is None or not a valid database connection\n    \"\"\"\n    if conn is None:\n        raise ValueError(\"Database connection cannot be None\")\n    \n    try:\n        # Try to execute a simple query to check if table exists\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"\n            SELECT name \n            FROM sqlite_master \n            WHERE type='table' AND name=?;\n        \"\"\", (table,))\n        \n        result = cursor.fetchone()\n        cursor.close()\n        \n        return result is not None\n        \n    except AttributeError:\n        raise ValueError(\"Invalid database connection object\")\n    except Exception as e:\n        raise ValueError(f\"Error checking table existence: {str(e)}\")\n", "Result": "Pass"}
{"namespace": "csvs_to_sqlite.utils.table_exists", "type": "Edge Case Handling", "test": "tests/test_utils.py::test_table_exists_edge_cases", "completion": "\ndef table_exists(conn, table: str) -> bool:\n    \"\"\"\n    Check if a table exists in the database.\n    \n    Args:\n        conn: Connection object to the database\n        table: String representing the name of the table to check\n        \n    Returns:\n        bool: True if the table exists, False otherwise\n        \n    Raises:\n        ValueError: If table name is empty or None\n        TypeError: If table name is not a string\n    \"\"\"\n    if not isinstance(table, str):\n        raise TypeError(\"Table name must be a string\")\n    \n    if not table or table.isspace():\n        raise ValueError(\"Table name cannot be empty\")\n    \n    try:\n        cursor = conn.cursor()\n        \n        # Use parameterized query to safely handle special characters\n        # This query works for SQLite, PostgreSQL, and MySQL\n        cursor.execute(\"\"\"\n            SELECT COUNT(*) \n            FROM information_schema.tables \n            WHERE table_name = %s\n        \"\"\", (table,))\n        \n        if cursor.fetchone()[0] > 0:\n            return True\n            \n        return False\n        \n    except Exception as e:\n        # Log the error if needed\n        # logger.error(f\"Error checking table existence: {str(e)}\")\n        return False\n    \n    finally:\n        if cursor:\n            cursor.close()\n", "Result": "Error"}
{"namespace": "csvs_to_sqlite.utils.table_exists", "type": "Annotation Coverage", "test": "tests/test_utils.py::test_table_exists_annotation_coverage", "completion": "\nfrom sqlite3 import Connection\n\ndef table_exists(conn: Connection, table: str) -> bool:\n    \"\"\"\n    Check if the table exists in the database.\n\n    Args:\n        conn: Connection to the database\n        table: Name of the table to check\n\n    Returns:\n        True if the table exists, False otherwise\n    \"\"\"\n    cursor = conn.cursor()\n    cursor.execute(\"\"\"\n        SELECT name \n        FROM sqlite_master \n        WHERE type='table' AND name=?;\n    \"\"\", (table,))\n    \n    return cursor.fetchone() is not None\n", "Result": "Pass"}
{"namespace": "csvs_to_sqlite.utils.table_exists", "type": "Code Complexity", "test": "tests/test_utils.py::test_code_complexity", "completion": "\ndef table_exists(conn: object, table: str) -> bool:\n    \"\"\"\n    Check if the table exists in the database.\n    \n    Args:\n        conn: Connection object to the database\n        table: String name of the table to check\n        \n    Returns:\n        bool: True if the table exists, False otherwise\n    \"\"\"\n    cursor = conn.cursor()\n    cursor.execute(\"\"\"\n        SELECT name \n        FROM sqlite_master \n        WHERE type='table' AND name=?;\n    \"\"\", (table,))\n    \n    return cursor.fetchone() is not None\n", "Result": "Pass"}
{"namespace": "csvs_to_sqlite.utils.table_exists", "type": "Code Standard", "test": "tests/test_utils.py::test_check_code_style", "completion": "\ndef table_exists(conn, table):\n    \"\"\"\n    Check if the table exists in the database.\n\n    Args:\n        conn: Connection object\n            The connection to the database\n        table: str\n            The name of the table to check\n\n    Returns:\n        bool: True if the table exists, False otherwise\n    \"\"\"\n    try:\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"\n            SELECT name \n            FROM sqlite_master \n            WHERE type='table' AND name=?;\n        \"\"\", (table,))\n        return cursor.fetchone() is not None\n    except Exception as e:\n        print(f\"Error checking if table exists: {e}\")\n        return False\n    finally:\n        cursor.close()\n", "Result": "Error"}
{"namespace": "sqlitedict.SqliteDict.get_tablenames", "type": "Input-Output Conditions", "test": "tests/test_core.py::TablenamesTest::test_input_output_conditions", "completion": "\nimport sqlite3\nimport os\n\ndef get_tablenames(filename: str) -> list[str]:\n    \"\"\"\n    Retrieves the names of tables in an SQLite database.\n    \n    Args:\n        filename (str): The name of the SQLite database file.\n        \n    Returns:\n        list[str]: A list of table names in the database.\n        \n    Raises:\n        IOError: If the specified database file does not exist.\n    \"\"\"\n    if not os.path.exists(filename):\n        raise IOError(f\"file {filename} does not exist\")\n    \n    with sqlite3.connect(filename) as conn:\n        cursor = conn.cursor()\n        # Query sqlite_master table to get all table names\n        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n        # Extract table names from query result and return as list\n        return [table[0] for table in cursor.fetchall()]\n", "Result": "Error"}
{"namespace": "sqlitedict.SqliteDict.get_tablenames", "type": "Exception Handling", "test": "tests/test_core.py::TablenamesTest::test_exception_handling", "completion": "\ndef get_tablenames(filename: str) -> list[str]:\n    \"\"\"\n    Retrieves the names of tables in an SQLite database.\n    \n    Args:\n        filename (str): The name of the SQLite database file\n        \n    Returns:\n        list[str]: List of table names in the database\n        \n    Raises:\n        IOError: If the database file does not exist\n    \"\"\"\n    import os\n    import sqlite3\n    \n    if not os.path.exists(filename):\n        raise IOError(f\"file {filename} does not exist\")\n        \n    with sqlite3.connect(filename) as conn:\n        cursor = conn.cursor()\n        # Query to get all table names from sqlite_master\n        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n        tables = cursor.fetchall()\n        \n    # Convert list of tuples to list of strings and return\n    return [table[0] for table in tables]\n", "Result": "Pass"}
{"namespace": "sqlitedict.SqliteDict.get_tablenames", "type": "Edge Case Handling", "test": "tests/test_core.py::TablenamesTest::test_edge_case_handling", "completion": "\nimport sqlite3\nimport os\n\ndef get_tablenames(filename: str) -> list[str]:\n    \"\"\"\n    Retrieves the names of tables in an SQLite database.\n    \n    Args:\n        filename (str): The name of the SQLite database file\n        \n    Returns:\n        list[str]: List of table names in the database\n        \n    Raises:\n        IOError: If the specified database file does not exist\n    \"\"\"\n    if not os.path.exists(filename):\n        raise IOError(f\"file {filename} does not exist\")\n    \n    with sqlite3.connect(filename) as conn:\n        cursor = conn.cursor()\n        # Query to get all table names from sqlite_master\n        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n        tables = cursor.fetchall()\n        \n        # Extract table names from query results and return as list\n        return [table[0] for table in tables]\n", "Result": "Error"}
{"namespace": "sqlitedict.SqliteDict.get_tablenames", "type": "Functionality Extension", "test": "tests/test_core.py::TablenamesTest::test_functionality_extension", "completion": "\ndef get_tablenames(filename: str, prefix: str = None) -> list[str]:\n    \"\"\"\n    Retrieve the names of tables in an SQLite database.\n    \n    Args:\n        filename (str): The name of the SQLite database file\n        prefix (str, optional): Filter tables by this prefix. Defaults to None.\n    \n    Returns:\n        list[str]: List of table names in the database\n        \n    Raises:\n        IOError: If the database file does not exist\n    \"\"\"\n    import sqlite3\n    import os\n    \n    if not os.path.exists(filename):\n        raise IOError(f\"file {filename} does not exist\")\n        \n    with sqlite3.connect(filename) as conn:\n        cursor = conn.cursor()\n        # Query to get all table names\n        cursor.execute(\"\"\"\n            SELECT name FROM sqlite_master \n            WHERE type='table'\n        \"\"\")\n        \n        tables = [row[0] for row in cursor.fetchall()]\n        \n        # Filter tables by prefix if specified\n        if prefix:\n            tables = [table for table in tables if table.startswith(prefix)]\n            \n        return tables\n", "Result": "Pass"}
{"namespace": "sqlitedict.SqliteDict.get_tablenames", "type": "Annotation Coverage", "test": "tests/test_core.py::TablenamesTest::test_annotation_coverage", "completion": "\nimport sqlite3\nfrom typing import List\nimport os\n\ndef get_tablenames(filename: str) -> List[str]:\n    \"\"\"\n    Retrieves the names of tables in an SQLite database.\n    \n    Args:\n        filename: String. The name of the SQLite database file.\n        \n    Returns:\n        List of strings. The names of the tables in the SQLite database.\n        \n    Raises:\n        IOError: If the specified database file does not exist.\n    \"\"\"\n    if not os.path.exists(filename):\n        raise IOError(f\"file {filename} does not exist\")\n    \n    with sqlite3.connect(filename) as conn:\n        cursor = conn.cursor()\n        # Query to get all table names from sqlite_master\n        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n        tables = cursor.fetchall()\n        \n        # Extract table names from the query results and return as list\n        return [table[0] for table in tables]\n", "Result": "Error"}
{"namespace": "sqlitedict.SqliteDict.get_tablenames", "type": "Code Complexity", "test": "tests/test_core.py::TablenamesTest::test_code_complexity", "completion": "\ndef get_tablenames(filename: str) -> list[str]:\n    \"\"\"\n    Retrieves the names of tables in an SQLite database.\n    \n    Args:\n        filename (str): The name of the SQLite database file.\n        \n    Returns:\n        list[str]: The names of the tables in the SQLite database.\n        \n    Raises:\n        IOError: If the specified database file does not exist.\n    \"\"\"\n    import sqlite3\n    import os\n    \n    if not os.path.exists(filename):\n        raise IOError(f\"file {filename} does not exist\")\n        \n    with sqlite3.connect(filename) as conn:\n        cursor = conn.cursor()\n        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n        return [table[0] for table in cursor.fetchall()]\n", "Result": "Pass"}
{"namespace": "sqlitedict.SqliteDict.get_tablenames", "type": "Code Standard", "test": "tests/test_core.py::TablenamesTest::test_check_code_style", "completion": "\nimport os\nimport sqlite3\n\n\ndef get_tablenames(filename: str) -> list[str]:\n    \"\"\"\n    Retrieve the names of tables in an SQLite database.\n\n    Args:\n        filename: String. The name of the SQLite database file.\n\n    Returns:\n        List of strings. The names of the tables in the SQLite database.\n\n    Raises:\n        IOError: If the specified database file does not exist.\n    \"\"\"\n    if not os.path.exists(filename):\n        raise IOError(f\"file {filename} does not exist\")\n\n    with sqlite3.connect(filename) as conn:\n        cursor = conn.cursor()\n        # Query sqlite_master table to get all table names\n        cursor.execute(\"\"\"\n            SELECT name \n            FROM sqlite_master \n            WHERE type='table'\n        \"\"\")\n        tables = cursor.fetchall()\n        \n    # Extract table names from query results and return as list\n    return [table[0] for table in tables]\n", "Result": "Error"}
{"namespace": "psd_tools.utils.pack", "type": "Exception Handling", "test": "tests/psd_tools/test_utils.py::test_pack_exception_handling", "completion": "\ndef pack(fmt: str, *args) -> bytes:\n    \"\"\"\n    Pack the input arguments into a binary string according to the given format.\n    \n    :param fmt: String. The format string that specifies the format of the returned string.\n        Format should start with '>' followed by format specifiers:\n        'i' for 32-bit integer\n        'h' for 16-bit integer\n        'b' for 8-bit integer\n        'f' for 32-bit float\n        'd' for 64-bit double\n    :param args: Tuple. The input arguments to be packed.\n    :return: Binary string. The packed binary string.\n    :raises ValueError: If format string is invalid or number of arguments doesn't match.\n    \"\"\"\n    import struct\n    \n    # Validate format string\n    if not fmt.startswith('>'):\n        raise ValueError(\"Format string must start with '>'\")\n    \n    # Remove '>' from format string for processing\n    format_specs = fmt[1:]\n    \n    # Check if number of arguments matches format specifiers\n    if len(format_specs) != len(args):\n        raise ValueError(f\"Number of arguments ({len(args)}) does not match format string ({len(format_specs)})\")\n    \n    # Valid format specifiers\n    valid_formats = {'i', 'h', 'b', 'f', 'd'}\n    \n    # Check for invalid format specifiers\n    invalid_specs = set(format_specs) - valid_formats\n    if invalid_specs:\n        raise ValueError(f\"Invalid format specifier(s): {invalid_specs}\")\n    \n    try:\n        # Pack the arguments according to the format string\n        return struct.pack(fmt, *args)\n    except struct.error as e:\n        raise ValueError(f\"Packing failed: {str(e)}\")\n", "Result": "Error"}
{"namespace": "psd_tools.utils.pack", "type": "Edge Case Handling", "test": "tests/psd_tools/test_utils.py::test_pack_edge_cases", "completion": "\ndef pack(fmt: str, *args) -> bytes:\n    \"\"\"\n    Pack the input arguments into a binary string according to the given format.\n    \n    Format specifiers:\n    >   - big-endian\n    B   - unsigned char (1 byte)\n    H   - unsigned short (2 bytes)\n    I   - unsigned int (4 bytes)\n    b   - signed char (1 byte)\n    h   - signed short (2 bytes)\n    i   - signed int (4 bytes)\n    \n    :param fmt: Format string specifying the format of the returned string\n    :param args: Input arguments to be packed\n    :return: Packed binary string\n    \n    Examples:\n        pack('>B', 255)  # Returns: b'\\xff'\n        pack('>H', 65535)  # Returns: b'\\xff\\xff'\n        pack('>I', 4294967295)  # Returns: b'\\xff\\xff\\xff\\xff'\n        pack('>bhi', -128, -32768, -2147483648)  # Handles negative numbers\n    \"\"\"\n    if not fmt.startswith('>'):\n        raise ValueError(\"Only big-endian ('>') format is supported\")\n    \n    result = bytearray()\n    format_chars = fmt[1:]  # Remove the '>' prefix\n    \n    if len(format_chars) != len(args):\n        raise ValueError(f\"Format string requires {len(format_chars)} arguments, but {len(args)} were provided\")\n    \n    for format_char, value in zip(format_chars, args):\n        if format_char in 'BHI':  # Unsigned integers\n            if value < 0:\n                raise ValueError(f\"Cannot pack negative value {value} into unsigned format '{format_char}'\")\n            \n            max_values = {'B': 255, 'H': 65535, 'I': 4294967295}\n            if value > max_values[format_char]:\n                raise ValueError(f\"Value {value} is too large for format '{format_char}'\")\n            \n            bytes_count = {'B': 1, 'H': 2, 'I': 4}[format_char]\n            result.extend(value.to_bytes(bytes_count, 'big'))\n            \n        elif format_char in 'bhi':  # Signed integers\n            min_values = {'b': -128, 'h': -32768, 'i': -2147483648}\n            max_values = {'b': 127, 'h': 32767, 'i': 2147483647}\n            \n            if value < min_values[format_char] or value > max_values[format_char]:\n                raise ValueError(f\"Value {value} is out of range for format '{format_char}'\")\n            \n            bytes_count = {'b': 1, 'h': 2, 'i': 4}[format_char]\n            result.extend(value.to_bytes(bytes_count, 'big', signed=True))\n            \n        else:\n            raise ValueError(f\"Unsupported format character: '{format_char}'\")\n    \n    return bytes(result)\n", "Result": "Error"}
{"namespace": "psd_tools.utils.pack", "type": "Functionality Extension", "test": "tests/psd_tools/test_utils.py::test_pack_functionality_extension", "completion": "\nimport struct\nfrom typing import Any, Tuple\n\ndef pack(fmt: str, *args: Any) -> bytes:\n    \"\"\"\n    Pack the input arguments into a binary string according to the given format.\n    \n    The format string follows the pattern '>{format}' where:\n    - '>' indicates big-endian byte order\n    - format specifies the data type (e.g., 'i' for integer, 'f' for float)\n    \n    :param fmt: Format string that specifies the format of the returned string\n    :param args: Input arguments to be packed\n    :return: Packed binary string\n    \n    Examples:\n        >>> pack('>i', 42)  # Pack integer\n        b'\\\\x00\\\\x00\\\\x00*'\n        >>> pack('>f', 3.14)  # Pack float\n        b'@I\\\\x0f\\\\xd0'\n        >>> pack('>if', 42, 3.14)  # Pack integer and float\n        b'\\\\x00\\\\x00\\\\x00*@I\\\\x0f\\\\xd0'\n    \"\"\"\n    try:\n        return struct.pack(fmt, *args)\n    except struct.error as e:\n        raise ValueError(f\"Packing failed: {str(e)}\")\n", "Result": "Error"}
{"namespace": "psd_tools.utils.pack", "type": "Annotation Coverage", "test": "tests/psd_tools/test_utils.py::test_pack_annotations", "completion": "\ndef pack(fmt: str, *args: tuple) -> bytes:\n    \"\"\"\n    Packs the input arguments into a binary string according to the given format.\n    \n    :param fmt: String. The format string that specifies the format of the returned string.\n    :param *args: Tuple. The input arguments to be packed.\n    :return: Binary string. The packed binary string.\n    \"\"\"\n    import struct\n    \n    # Ensure format string starts with '>'\n    if not fmt.startswith('>'):\n        fmt = '>' + fmt\n        \n    try:\n        # Pack the arguments according to the format string\n        return struct.pack(fmt, *args)\n    except struct.error as e:\n        raise ValueError(f\"Packing failed: {str(e)}\")\n", "Result": "Pass"}
{"namespace": "psd_tools.utils.pack", "type": "Code Complexity", "test": "tests/psd_tools/test_utils.py::test_code_complexity", "completion": "\ndef pack(fmt: str, *args) -> bytes:\n    \"\"\"\n    Pack the input arguments into a binary string according to the given format.\n    \n    :param fmt: String. The format string that specifies the format of the returned string.\n        Format should be in the form \">{format}\" where format can be:\n        - 'B' for unsigned char (1 byte)\n        - 'H' for unsigned short (2 bytes)\n        - 'I' for unsigned int (4 bytes)\n        - 'Q' for unsigned long long (8 bytes)\n    :param args: Tuple. The input arguments to be packed.\n    :return: Binary string. The packed binary string.\n    \n    Example:\n        pack(\">BHI\", 1, 2, 3) -> b'\\x01\\x00\\x02\\x00\\x00\\x00\\x03'\n    \"\"\"\n    import struct\n    \n    try:\n        return struct.pack(fmt, *args)\n    except struct.error as e:\n        raise ValueError(f\"Packing failed: {str(e)}\")\n", "Result": "Error"}
{"namespace": "psd_tools.utils.pack", "type": "Code Standard", "test": "tests/psd_tools/test_utils.py::test_check_code_style", "completion": "\nimport struct\nfrom typing import Any, Tuple\n\n\ndef pack(fmt: str, *args: Any) -> bytes:\n    \"\"\"\n    Pack the input arguments into a binary string according to the given format.\n    \n    The format string follows the struct module format, prefixed with '>'.\n    For example: '>I' for big-endian unsigned int, '>f' for big-endian float.\n    \n    Args:\n        fmt: String specifying the format of the returned binary string.\n        *args: Variable length argument list containing values to be packed.\n    \n    Returns:\n        A bytes object containing the packed values.\n    \n    Raises:\n        struct.error: If the format string is invalid or if the number of \n                     arguments doesn't match the format string.\n    \n    Examples:\n        >>> pack('>I', 1234)\n        b'\\x00\\x00\\x04\\xd2'\n        >>> pack('>If', 1234, 3.14)\n        b'\\x00\\x00\\x04\\xd2@H\\xf5\\xc3'\n    \"\"\"\n    if not fmt.startswith('>'):\n        fmt = '>' + fmt\n    \n    try:\n        return struct.pack(fmt, *args)\n    except struct.error as e:\n        raise struct.error(f\"Packing failed: {str(e)}\")\n", "Result": "Pass"}
{"namespace": "psd_tools.utils.unpack", "type": "Exception Handling", "test": "tests/psd_tools/test_utils.py::test_unpack_exception_handling", "completion": "\ndef unpack(fmt: str, data: bytes) -> tuple:\n    \"\"\"\n    Unpacks the given data according to the specified format.\n    \n    :param fmt: String. The format string to be used for unpacking the data.\n    :param data: Data. The data to be unpacked.\n    :return: Tuple. A tuple containing the unpacked values.\n    \n    Format specifications:\n    >: Big-endian\n    h: 16-bit integer (2 bytes)\n    i: 32-bit integer (4 bytes)\n    q: 64-bit integer (8 bytes)\n    f: 32-bit float (4 bytes)\n    d: 64-bit float (8 bytes)\n    \"\"\"\n    import struct\n    \n    if not fmt.startswith('>'):\n        raise ValueError('Invalid format string')\n    \n    try:\n        # Calculate expected data length based on format\n        format_specs = fmt[1:]  # Remove the '>' prefix\n        expected_length = 0\n        \n        for spec in format_specs:\n            if spec in 'hi':\n                expected_length += 4\n            elif spec in 'qd':\n                expected_length += 8\n            elif spec == 'f':\n                expected_length += 4\n            else:\n                raise ValueError('Invalid format string')\n        \n        if len(data) != expected_length:\n            raise ValueError('Data length does not match format')\n            \n        # Unpack the data using struct\n        return struct.unpack(fmt, data)\n        \n    except struct.error:\n        raise ValueError('Data length does not match format')\n", "Result": "Error"}
{"namespace": "psd_tools.utils.unpack", "type": "Edge Case Handling", "test": "tests/psd_tools/test_utils.py::test_unpack_edge_cases", "completion": "\ndef unpack(fmt: str, data: bytes) -> tuple:\n    \"\"\"\n    Unpacks binary data according to the specified format string.\n    \n    Args:\n        fmt (str): Format string specifying how to unpack the data.\n                  Format should be in the form '>{format}' where:\n                  - '>' indicates big-endian byte order\n                  - format specifies the type (e.g., 'I' for unsigned int)\n        data (bytes): Binary data to be unpacked\n        \n    Returns:\n        tuple: Tuple containing the unpacked values\n        \n    Raises:\n        ValueError: If format string is invalid or data is empty when data is expected\n        TypeError: If data is not in bytes format\n    \"\"\"\n    import struct\n    \n    # Handle edge cases\n    if not fmt:\n        return tuple()\n    \n    if not isinstance(data, bytes):\n        raise TypeError(\"Data must be in bytes format\")\n        \n    if not data and fmt.strip('>'):\n        raise ValueError(\"Empty data provided for non-empty format string\")\n        \n    if not fmt.strip('>') and not data:\n        return tuple()\n    \n    try:\n        # Ensure format string starts with '>'\n        if not fmt.startswith('>'):\n            fmt = '>' + fmt\n            \n        # Unpack the data according to the format\n        result = struct.unpack(fmt, data)\n        return result\n        \n    except struct.error as e:\n        raise ValueError(f\"Failed to unpack data: {str(e)}\")\n", "Result": "Pass"}
{"namespace": "psd_tools.utils.unpack", "type": "Functionality Extension", "test": "tests/psd_tools/test_utils.py::test_unpack_functionality_extension", "completion": "\ndef unpack(fmt: str, data: bytes) -> tuple:\n    \"\"\"\n    Unpacks binary data according to the specified format string.\n    \n    Format string syntax: '>{format}'\n    where format can contain multiple type specifiers:\n    - 'i': 32-bit integer\n    - 'h': 16-bit integer\n    - 'f': 32-bit float\n    - 'd': 64-bit double\n    - 'c': single character\n    - 's': string (must be preceded by length, e.g., '5s' for 5 characters)\n    \n    :param fmt: String. The format string to be used for unpacking the data\n    :param data: bytes. The binary data to be unpacked\n    :return: Tuple containing the unpacked values\n    \n    Examples:\n        unpack('>ii', b'\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02')  # Returns (1, 2)\n        unpack('>if', b'\\x00\\x00\\x00\\x01\\x40\\x00\\x00\\x00')  # Returns (1, 2.0)\n    \"\"\"\n    import struct\n    \n    if not isinstance(data, bytes):\n        raise TypeError(\"Data must be bytes\")\n    \n    if not fmt.startswith('>'):\n        raise ValueError(\"Format string must start with '>'\")\n    \n    try:\n        # Use struct.unpack to decode the binary data according to the format string\n        result = struct.unpack(fmt, data)\n        return result\n    except struct.error as e:\n        raise ValueError(f\"Failed to unpack data: {str(e)}\")\n", "Result": "Error"}
{"namespace": "psd_tools.utils.unpack", "type": "Annotation Coverage", "test": "tests/psd_tools/test_utils.py::test_unpack_annotations", "completion": "\nfrom struct import unpack\nfrom typing import Any, Tuple\n\ndef unpack(fmt: str, data: bytes) -> Tuple[Any, ...]:\n    \"\"\"\n    Unpacks the given data according to the specified format.\n    \n    Args:\n        fmt (str): The format string to be used for unpacking the data.\n            Format should be specified like '>I' for big-endian unsigned int,\n            '>f' for big-endian float, etc.\n        data (bytes): The binary data to be unpacked.\n    \n    Returns:\n        Tuple[Any, ...]: A tuple containing the unpacked values.\n        \n    Examples:\n        >>> unpack('>I', b'\\x00\\x00\\x00\\x01')\n        (1,)\n        >>> unpack('>ff', b'\\x40\\x00\\x00\\x00\\x40\\x40\\x00\\x00')\n        (2.0, 3.0)\n    \"\"\"\n    try:\n        return unpack(fmt, data)\n    except struct.error as e:\n        raise ValueError(f\"Failed to unpack data: {str(e)}\")\n", "Result": "Error"}
{"namespace": "psd_tools.utils.unpack", "type": "Code Complexity", "test": "tests/psd_tools/test_utils.py::test_code_complexity", "completion": "\nfrom typing import Tuple, Any\nimport struct\n\ndef unpack(fmt: str, data: bytes) -> Tuple[Any, ...]:\n    \"\"\"\n    Unpacks binary data according to the specified format string.\n    \n    The function uses the struct module to unpack binary data into Python values\n    based on the given format string. The format string follows the struct module\n    format specification.\n    \n    Args:\n        fmt (str): Format string specifying how to interpret the bytes data.\n                  Example: '>I' for big-endian unsigned int\n        data (bytes): Binary data to be unpacked\n    \n    Returns:\n        Tuple[Any, ...]: A tuple containing the unpacked values\n        \n    Examples:\n        >>> unpack('>I', b'\\x00\\x00\\x00\\x01')\n        (1,)\n        >>> unpack('>hh', b'\\x00\\x01\\x00\\x02')\n        (1, 2)\n    \"\"\"\n    return struct.unpack(fmt, data)\n", "Result": "Error"}
{"namespace": "psd_tools.utils.unpack", "type": "Code Standard", "test": "tests/psd_tools/test_utils.py::test_check_code_style", "completion": "\nimport struct\nfrom typing import Tuple, Union, Any\n\ndef unpack(fmt: str, data: Union[bytes, bytearray]) -> Tuple[Any, ...]:\n    \"\"\"\n    Unpacks binary data according to the specified format string.\n    \n    The format string follows the struct module format, with '>' indicating\n    big-endian byte order.\n    \n    Args:\n        fmt (str): Format string specifying how to interpret the binary data.\n                  Example: '>I' for big-endian unsigned int.\n        data (Union[bytes, bytearray]): Binary data to be unpacked.\n    \n    Returns:\n        Tuple[Any, ...]: A tuple containing the unpacked values.\n    \n    Raises:\n        struct.error: If the format string is invalid or data size doesn't match.\n        TypeError: If data is not bytes or bytearray.\n    \"\"\"\n    if not isinstance(data, (bytes, bytearray)):\n        raise TypeError(\"Data must be bytes or bytearray\")\n    \n    try:\n        return struct.unpack(fmt, data)\n    except struct.error as e:\n        raise struct.error(f\"Failed to unpack data: {str(e)}\")\n", "Result": "Error"}
{"namespace": "exodus_bundler.bundling.bytes_to_int", "type": "Input-Output Conditions", "test": "tests/test_bundling.py::test_input_output_conditions", "completion": "\ndef bytes_to_int(bytes_str: bytes, byteorder: str = \"big\") -> int:\n    \"\"\"\n    Convert a byte string into an integer.\n    \n    Args:\n        bytes_str: Byte string to be converted into an integer\n        byteorder: String indicating byte order ('big' or 'little'), defaults to 'big'\n        \n    Returns:\n        Integer converted from the byte string\n        \n    Raises:\n        ValueError: If bytes_str is empty or byteorder is invalid\n    \"\"\"\n    if not bytes_str:\n        raise ValueError(\"Byte string cannot be empty\")\n        \n    if byteorder not in (\"big\", \"little\"):\n        raise ValueError(\"Byte order must be either 'big' or 'little'\")\n    \n    return int.from_bytes(bytes_str, byteorder=byteorder)\n", "Result": "Error"}
{"namespace": "exodus_bundler.bundling.bytes_to_int", "type": "Exception Handling", "test": "tests/test_bundling.py::test_exception_handling", "completion": "\ndef bytes_to_int(bytes_str: bytes, byteorder: str = \"big\") -> int:\n    \"\"\"\n    Convert a byte string into an integer.\n    \n    Args:\n        bytes_str: Byte string to be converted into an integer\n        byteorder: String indicating byte order ('big' or 'little'), defaults to 'big'\n        \n    Returns:\n        Integer converted from the byte string\n        \n    Raises:\n        ValueError: If byteorder is not 'big' or 'little'\n    \"\"\"\n    if byteorder not in [\"big\", \"little\"]:\n        raise ValueError(\"byteorder must be either 'big' or 'little'\")\n    \n    return int.from_bytes(bytes_str, byteorder=byteorder)\n", "Result": "Error"}
{"namespace": "exodus_bundler.bundling.bytes_to_int", "type": "Edge Case Handling", "test": "tests/test_bundling.py::test_edge_case_handling", "completion": "\ndef bytes_to_int(bytes_str: bytes, byteorder: str = \"big\") -> int:\n    \"\"\"\n    Convert a byte string into an integer.\n    \n    Args:\n        bytes_str: Byte string to be converted into an integer\n        byteorder: Byte order to use (\"big\" or \"little\"), defaults to \"big\"\n    \n    Returns:\n        Integer value represented by the byte string\n        \n    Raises:\n        ValueError: If byteorder is not \"big\" or \"little\"\n        TypeError: If bytes_str is not a bytes object\n    \"\"\"\n    if not isinstance(bytes_str, bytes):\n        raise TypeError(\"Input must be a bytes object\")\n        \n    if byteorder not in (\"big\", \"little\"):\n        raise ValueError(\"byteorder must be either 'big' or 'little'\")\n    \n    try:\n        return int.from_bytes(bytes_str, byteorder=byteorder)\n    except OverflowError:\n        raise OverflowError(\"Byte string too large to convert to integer\")\n", "Result": "Pass"}
{"namespace": "exodus_bundler.bundling.bytes_to_int", "type": "Functionality Extension", "test": "tests/test_bundling.py::test_functionality_extension", "completion": "\ndef bytes_to_int(bytes_str: bytes, byteorder: str = \"big\", signed: bool = False) -> int:\n    \"\"\"\n    Convert a byte string into an integer.\n    \n    Args:\n        bytes_str: Byte string to be converted into an integer\n        byteorder: Byte order to be used (\"big\" or \"little\"). Defaults to \"big\"\n        signed: Boolean indicating whether the number is signed. Defaults to False\n    \n    Returns:\n        Integer value converted from the byte string\n        \n    Examples:\n        >>> bytes_to_int(b'\\x00\\x0F')  # Returns 15\n        >>> bytes_to_int(b'\\xFF\\xFF', signed=True)  # Returns -1\n        >>> bytes_to_int(b'\\x0F\\x00', byteorder=\"little\")  # Returns 3840\n    \"\"\"\n    return int.from_bytes(bytes_str, byteorder=byteorder, signed=signed)\n", "Result": "Pass"}
{"namespace": "exodus_bundler.bundling.bytes_to_int", "type": "Annotation Coverage", "test": "tests/test_bundling.py::test_annotation_coverage", "completion": "\ndef bytes_to_int(bytes_str: bytes, byteorder: str = \"big\") -> int:\n    \"\"\"\n    Convert a byte string into an integer.\n    \n    The function unpacks the byte string into characters and converts them\n    into an integer using the specified byte order.\n    \n    Args:\n        bytes_str: Byte string to be converted into an integer\n        byteorder: The byte order to be used (\"big\" or \"little\")\n    \n    Returns:\n        The converted integer value\n    \n    Examples:\n        >>> bytes_to_int(b'\\x00\\x01')\n        1\n        >>> bytes_to_int(b'\\x01\\x00', byteorder=\"little\")\n        1\n    \"\"\"\n    return int.from_bytes(bytes_str, byteorder=byteorder)\n", "Result": "Error"}
{"namespace": "exodus_bundler.bundling.bytes_to_int", "type": "Code Complexity", "test": "tests/test_bundling.py::test_code_complexity", "completion": "\ndef bytes_to_int(bytes_str: bytes, byteorder: str = \"big\") -> int:\n    \"\"\"\n    Convert a byte string into an integer.\n    \n    Args:\n        bytes_str: Byte string to be converted into an integer\n        byteorder: String indicating byte order ('big' or 'little'), defaults to 'big'\n    \n    Returns:\n        Integer value converted from the byte string\n    \n    Examples:\n        >>> bytes_to_int(b'\\x00\\x01')\n        1\n        >>> bytes_to_int(b'\\x01\\x00', byteorder='little')\n        256\n    \"\"\"\n    return int.from_bytes(bytes_str, byteorder=byteorder)\n", "Result": "Pass"}
{"namespace": "exodus_bundler.bundling.bytes_to_int", "type": "Code Standard", "test": "tests/test_bundling.py::test_check_code_style", "completion": "\ndef bytes_to_int(bytes_string: bytes, byteorder: str = \"big\") -> int:\n    \"\"\"\n    Convert a byte string into an integer.\n\n    The function unpacks the byte string into characters and converts them\n    into an integer value using the specified byte order.\n\n    Args:\n        bytes_string: Byte string to be converted into an integer\n        byteorder: String indicating the byte order (\"big\" or \"little\")\n\n    Returns:\n        Integer value converted from the byte string\n\n    Raises:\n        ValueError: If an invalid byteorder is specified\n    \"\"\"\n    if byteorder not in (\"big\", \"little\"):\n        raise ValueError(\"byteorder must be either 'big' or 'little'\")\n    \n    return int.from_bytes(bytes_string, byteorder=byteorder)\n", "Result": "Pass"}
{"namespace": "exodus_bundler.templating.render_template", "type": "Input-Output Conditions", "test": "tests/test_templating.py::test_render_template_input_output_conditions", "completion": "\ndef render_template(string: str, context: dict) -> str:\n    \"\"\"\n    Replaces placeholders in the input string with values from the context dictionary.\n    \n    Args:\n        string: The input string containing placeholders in the format {{key}}\n        context: Dictionary containing key-value pairs to replace the placeholders\n        \n    Returns:\n        The modified string with all placeholders replaced by their corresponding values\n        \n    Example:\n        >>> template = \"Hello {{name}}, you are {{age}} years old\"\n        >>> context = {\"name\": \"John\", \"age\": 25}\n        >>> render_template(template, context)\n        'Hello John, you are 25 years old'\n    \"\"\"\n    result = string\n    \n    for key, value in context.items():\n        placeholder = \"{{\" + key + \"}}\"\n        result = result.replace(placeholder, str(value))\n        \n    return result\n", "Result": "Error"}
{"namespace": "exodus_bundler.templating.render_template", "type": "Exception Handling", "test": "tests/test_templating.py::test_render_template_exception_handling", "completion": "\ndef render_template(string: str, context: dict) -> str:\n    \"\"\"\n    Replaces placeholders in the input string with values from the context dictionary.\n    \n    Args:\n        string: The input string containing placeholders.\n        context: Dictionary containing key-value pairs to replace the placeholders.\n        \n    Returns:\n        The modified string after replacing the placeholders.\n        \n    Raises:\n        KeyError: If a placeholder in the string doesn't have a matching key in context.\n    \"\"\"\n    result = string\n    \n    # Find all placeholders in the format {{key}}\n    start = 0\n    while True:\n        # Find opening brackets\n        start = result.find(\"{{\", start)\n        if start == -1:\n            break\n            \n        # Find closing brackets\n        end = result.find(\"}}\", start)\n        if end == -1:\n            break\n            \n        # Extract the key (removing whitespace)\n        key = result[start + 2:end].strip()\n        \n        # Check if key exists in context\n        if key not in context:\n            raise KeyError(f\"Placeholder '{key}' not found in context\")\n            \n        # Replace the placeholder with the value from context\n        placeholder = result[start:end + 2]\n        result = result.replace(placeholder, str(context[key]))\n        \n        # Move start position forward\n        start = end + 2\n        \n    return result\n", "Result": "Error"}
{"namespace": "exodus_bundler.templating.render_template", "type": "Edge Case Handling", "test": "tests/test_templating.py::test_render_template_edge_case_handling", "completion": "\ndef render_template(string: str, context: dict) -> str:\n    \"\"\"\n    Replaces placeholders in the input string with values from the context dictionary.\n    \n    Args:\n        string: The input string containing placeholders\n        context: Dictionary containing key-value pairs to replace placeholders\n        \n    Returns:\n        The modified string after replacing the placeholders\n        \n    Examples:\n        >>> render_template(\"Hello {name}!\", {\"name\": \"John\"})\n        'Hello John!'\n        >>> render_template(\"\", {\"name\": \"John\"})\n        ''\n    \"\"\"\n    if not string:\n        return \"\"\n        \n    try:\n        return string.format(**context)\n    except KeyError as e:\n        raise KeyError(f\"Missing key in context dictionary: {e}\")\n", "Result": "Error"}
{"namespace": "exodus_bundler.templating.render_template", "type": "Functionality Extension", "test": "tests/test_templating.py::test_render_template_functionality_extension", "completion": "\ndef render_template(string: str, context: dict) -> str:\n    \"\"\"\n    Replaces placeholders in the input string with values from the context dictionary.\n    Supports default values using the '|' separator.\n    \n    Args:\n        string: The input string containing placeholders\n        context: Dictionary containing key-value pairs to replace placeholders\n        \n    Returns:\n        The modified string with all placeholders replaced\n        \n    Example:\n        string = \"Hello {{name|stranger}}, welcome to {{place|our site}}\"\n        context = {\"name\": \"John\"}\n        result = \"Hello John, welcome to our site\"\n    \"\"\"\n    result = string\n    \n    # Find all placeholders using basic string operations\n    start = 0\n    while True:\n        # Find opening brackets\n        start = result.find(\"{{\", start)\n        if start == -1:\n            break\n            \n        # Find closing brackets\n        end = result.find(\"}}\", start)\n        if end == -1:\n            break\n            \n        # Extract placeholder content\n        placeholder = result[start + 2:end].strip()\n        \n        # Check if default value exists\n        if \"|\" in placeholder:\n            key, default = placeholder.split(\"|\", 1)\n            key = key.strip()\n            default = default.strip()\n            # Use context value if exists, otherwise use default\n            value = context.get(key, default)\n        else:\n            key = placeholder.strip()\n            # Use context value if exists, otherwise keep placeholder\n            value = context.get(key, \"{{\" + key + \"}}\")\n            \n        # Replace placeholder with value\n        result = result[:start] + str(value) + result[end + 2:]\n        \n    return result\n", "Result": "Error"}
{"namespace": "exodus_bundler.templating.render_template", "type": "Annotation Coverage", "test": "tests/test_templating.py::test_render_template_annotation_coverage", "completion": "\ndef render_template(string: str, context: dict) -> str:\n    \"\"\"\n    Replaces placeholders in the input string with corresponding values from the context dictionary.\n    \n    Args:\n        string: The input string containing placeholders.\n        context: The key-value pairs to replace the placeholders in the input string.\n    \n    Returns:\n        The modified string after replacing the placeholders.\n    \n    Example:\n        >>> template = \"Hello, {name}! You are {age} years old.\"\n        >>> context = {\"name\": \"Alice\", \"age\": 25}\n        >>> render_template(template, context)\n        'Hello, Alice! You are 25 years old.'\n    \"\"\"\n    try:\n        return string.format(**context)\n    except KeyError as e:\n        raise KeyError(f\"Missing key in context dictionary: {e}\")\n    except ValueError as e:\n        raise ValueError(f\"Invalid placeholder format in template: {e}\")\n", "Result": "Error"}
{"namespace": "exodus_bundler.templating.render_template", "type": "Code Complexity", "test": "tests/test_templating.py::test_render_template", "completion": "\ndef render_template(string: str, context: dict) -> str:\n    \"\"\"\n    Replaces placeholders in the input string with values from the context dictionary.\n    \n    Args:\n        string: The input string containing placeholders.\n        context: Dictionary containing key-value pairs to replace the placeholders.\n    \n    Returns:\n        The modified string after replacing the placeholders.\n    \n    Example:\n        >>> template = \"Hello, {name}! You are {age} years old.\"\n        >>> context = {\"name\": \"Alice\", \"age\": 25}\n        >>> render_template(template, context)\n        'Hello, Alice! You are 25 years old.'\n    \"\"\"\n    try:\n        return string.format(**context)\n    except KeyError as e:\n        return string  # Return original string if placeholder not found in context\n", "Result": "Error"}
{"namespace": "exodus_bundler.templating.render_template", "type": "Code Standard", "test": "tests/test_templating.py::test_check_code_style", "completion": "\ndef render_template(string: str, context: dict) -> str:\n    \"\"\"\n    Replace placeholders in the input string with values from the context dictionary.\n\n    Args:\n        string: The input string containing placeholders.\n        context: Dictionary containing key-value pairs to replace the placeholders.\n\n    Returns:\n        The modified string after replacing the placeholders.\n\n    Example:\n        >>> template = \"Hello, {name}! You are {age} years old.\"\n        >>> context = {\"name\": \"Alice\", \"age\": 25}\n        >>> render_template(template, context)\n        'Hello, Alice! You are 25 years old.'\n    \"\"\"\n    try:\n        return string.format(**context)\n    except KeyError as e:\n        raise KeyError(f\"Missing key in context dictionary: {e}\")\n    except ValueError as e:\n        raise ValueError(f\"Invalid placeholder format in template: {e}\")\n", "Result": "Error"}
{"namespace": "trailscraper.iam.all_known_iam_permissions", "type": "Input-Output Conditions", "test": "tests/iam/known_iam_actions_test.py::test_output_type_and_content", "completion": "\nimport os\n\ndef all_known_iam_permissions() -> set:\n    \"\"\"\n    Returns a set of all known IAM actions by reading from a text file.\n    \n    The function reads from 'known-iam-actions.txt' located in the same directory\n    as the current script.\n    \n    Returns:\n        set: A set of strings, where each string represents a valid IAM action\n    \"\"\"\n    current_dir = os.path.dirname(os.path.abspath(__file__))\n    file_path = os.path.join(current_dir, 'known-iam-actions.txt')\n    \n    try:\n        with open(file_path, 'r') as f:\n            return set(line.strip() for line in f if line.strip())\n    except FileNotFoundError:\n        return set()\n", "Result": "Pass"}
{"namespace": "trailscraper.iam.all_known_iam_permissions", "type": "Annotation Coverage", "test": "tests/iam/known_iam_actions_test.py::test_docstring_presence", "completion": "\ndef all_known_iam_permissions() -> set:\n    \"\"\"\n    Returns a set of all known IAM actions by reading from a text file.\n    The file 'known-iam-actions.txt' should be located in the same directory\n    as this script.\n\n    Parameters:\n        None\n\n    Returns:\n        set: A set of strings where each string represents an IAM action\n    \"\"\"\n    import os\n\n    # Get the directory path of the current script\n    current_dir = os.path.dirname(os.path.abspath(__file__))\n    \n    # Construct the full path to the known-iam-actions.txt file\n    file_path = os.path.join(current_dir, 'known-iam-actions.txt')\n    \n    # Read and return the lines as a set\n    with open(file_path, 'r') as f:\n        return set(line.strip() for line in f)\n", "Result": "Pass"}
{"namespace": "trailscraper.iam.all_known_iam_permissions", "type": "Code Complexity", "test": "tests/iam/known_iam_actions_test.py::test_cyclomatic_complexity", "completion": "\nfrom pathlib import Path\nimport os\n\ndef all_known_iam_permissions() -> set:\n    \"\"\"\n    Returns a set of all known IAM actions by reading from known-iam-actions.txt file.\n    \n    :return: A set of lines containing IAM actions\n    :rtype: set\n    \"\"\"\n    file_path = Path(os.path.dirname(__file__)) / 'known-iam-actions.txt'\n    return set(file_path.read_text().splitlines())\n", "Result": "Pass"}
{"namespace": "trailscraper.iam.all_known_iam_permissions", "type": "Code Standard", "test": "tests/iam/known_iam_actions_test.py::test_check_code_style", "completion": "\nimport os\n\n\ndef all_known_iam_permissions() -> set:\n    \"\"\"\n    Returns a set of all known IAM actions from a text file.\n\n    The function reads from 'known-iam-actions.txt' located in the same\n    directory as the current script.\n\n    Returns:\n        set: A set of strings, where each string is an IAM action.\n    \"\"\"\n    current_dir = os.path.dirname(os.path.abspath(__file__))\n    permissions_file = os.path.join(current_dir, 'known-iam-actions.txt')\n    \n    with open(permissions_file, 'r') as file:\n        return set(line.strip() for line in file)\n", "Result": "Pass"}
{"namespace": "trailscraper.cloudtrail.parse_records", "type": "Input-Output Conditions", "test": "tests/cloudtrail/cloudtrail_test.py::test_parse_records_with_empty_input", "completion": "\ndef parse_records(json_records: list) -> list:\n    \"\"\"\n    Parse a list of JSON records into Record objects.\n    \n    Args:\n        json_records: List of JSON records to be parsed\n        \n    Returns:\n        List of Record objects, with None values filtered out\n    \"\"\"\n    if not json_records:\n        return []\n        \n    parsed_records = [_parse_record(record) for record in json_records]\n    return [record for record in parsed_records if record is not None]\n", "Result": "Pass"}
{"namespace": "trailscraper.cloudtrail.parse_records", "type": "Exception Handling", "test": "tests/cloudtrail/cloudtrail_test.py::test_parse_records_with_invalid_json_format", "completion": "\ndef parse_records(json_records):\n    \"\"\"\n    Parse a list of JSON records into Record objects.\n    \n    Args:\n        json_records (List): A list of JSON records to be parsed\n        \n    Returns:\n        List: A list of Record objects parsed from the JSON records\n        \n    Raises:\n        ValueError: If any of the JSON records are not in a valid JSON format\n    \"\"\"\n    if not isinstance(json_records, list):\n        raise ValueError(\"Invalid JSON format\")\n    \n    try:\n        # Parse each record and filter out None values\n        parsed_records = [\n            record for record in \n            (_parse_record(json_record) for json_record in json_records)\n            if record is not None\n        ]\n        return parsed_records\n        \n    except (TypeError, ValueError) as e:\n        raise ValueError(\"Invalid JSON format\") from e\n", "Result": "Pass"}
{"namespace": "trailscraper.cloudtrail.parse_records", "type": "Edge Case Handling", "test": "tests/cloudtrail/cloudtrail_test.py::test_parse_records_with_missing_fields", "completion": "\ndef parse_records(json_records: list) -> list:\n    \"\"\"\n    Parse a list of JSON records into Record objects.\n    \n    Args:\n        json_records (list): A list of JSON records to be parsed\n        \n    Returns:\n        list: A list of Record objects parsed from the JSON records\n        \n    Example:\n        >>> records = [{\"id\": 1, \"name\": \"Test\"}, {\"id\": 2, \"name\": \"Test2\"}]\n        >>> parsed = parse_records(records)\n    \"\"\"\n    # Use list comprehension with filter to process records and remove None values\n    parsed_records = [\n        record for record in map(_parse_record, json_records)\n        if record is not None\n    ]\n    \n    return parsed_records\n", "Result": "Error"}
{"namespace": "trailscraper.cloudtrail.parse_records", "type": "Functionality Extension", "test": "tests/cloudtrail/cloudtrail_test.py::test_parse_records_with_filter_func", "completion": "\ndef parse_records(json_records: list, filter_func=None) -> list:\n    \"\"\"\n    Parse a list of JSON records into Record objects and optionally filter them.\n    \n    Args:\n        json_records (list): A list of JSON records to be parsed\n        filter_func (callable, optional): A function that takes a Record object and returns\n            a boolean indicating whether to include the record\n    \n    Returns:\n        list: A list of parsed Record objects that meet the filter criteria\n    \"\"\"\n    # Parse all records and filter out None values\n    parsed_records = [\n        record for record in map(_parse_record, json_records)\n        if record is not None\n    ]\n    \n    # Apply additional filtering if filter_func is provided\n    if filter_func is not None:\n        parsed_records = [\n            record for record in parsed_records\n            if filter_func(record)\n        ]\n    \n    return parsed_records\n", "Result": "Error"}
{"namespace": "trailscraper.cloudtrail.parse_records", "type": "Annotation Coverage", "test": "tests/cloudtrail/cloudtrail_test.py::test_parse_records_annotations", "completion": "\nfrom typing import List, Optional\nfrom .models import Record  # Assuming Record class is defined in models.py\n\ndef parse_records(json_records: List[dict]) -> List[Record]:\n    \"\"\"\n    Parse a list of JSON records into Record objects.\n    \n    Args:\n        json_records: List of JSON records to be parsed\n        \n    Returns:\n        List of Record objects, with None values filtered out\n    \"\"\"\n    parsed_records = [_parse_record(record) for record in json_records]\n    return [record for record in parsed_records if record is not None]\n", "Result": "Error"}
{"namespace": "trailscraper.cloudtrail.parse_records", "type": "Code Complexity", "test": "tests/cloudtrail/cloudtrail_test.py::test_code_complexity", "completion": "\ndef parse_records(json_records: List[dict]) -> List[Record]:\n    \"\"\"\n    Parse a list of JSON records into Record objects.\n    \n    Args:\n        json_records: List of JSON records to be parsed\n        \n    Returns:\n        List of Record objects, with None values filtered out\n    \"\"\"\n    parsed_records = map(_parse_record, json_records)\n    return [record for record in parsed_records if record is not None]\n", "Result": "Error"}
{"namespace": "trailscraper.cloudtrail.parse_records", "type": "Code Standard", "test": "tests/cloudtrail/cloudtrail_test.py::test_check_code_style", "completion": "\ndef parse_records(json_records: list) -> list:\n    \"\"\"\n    Parse a list of JSON records into Record objects.\n    \n    Args:\n        json_records: List of JSON records to be parsed\n        \n    Returns:\n        List of Record objects, with None values filtered out\n    \"\"\"\n    parsed_records = [_parse_record(record) for record in json_records]\n    return [record for record in parsed_records if record is not None]\n", "Result": "Pass"}
{"namespace": "discord.utils.get_slots", "type": "Input-Output Conditions", "test": "tests/test_utils.py::test_input_output_conditions", "completion": "\ndef get_slots(cls):\n    \"\"\"\n    Returns an iterator that yields the names of the slots in the class and its base classes.\n    \n    Args:\n        cls (type): The class for which the slots are to be retrieved.\n        \n    Returns:\n        Iterator[str]: An iterator that yields the names of the slots in the class \n                      and its base classes.\n        \n    Raises:\n        TypeError: If the input is not a class type.\n    \"\"\"\n    if not isinstance(cls, type):\n        raise TypeError(\"Input must be a class type\")\n    \n    # Create a generator expression to iterate through the class hierarchy\n    # and yield slots from each class\n    return (\n        slot\n        for base in reversed(cls.__mro__)  # Traverse method resolution order\n        if hasattr(base, '__slots__')      # Check if class has slots\n        for slot in (base.__slots__ if isinstance(base.__slots__, (list, tuple))\n                    else (base.__slots__,)) # Handle both string and sequence slots\n    )\n", "Result": "Pass"}
{"namespace": "discord.utils.get_slots", "type": "Exception Handling", "test": "tests/test_utils.py::test_exception_handling", "completion": "\ndef get_slots(cls):\n    \"\"\"\n    Returns an iterator that yields the names of the slots in the class and its base classes.\n    \n    Args:\n        cls: Type. The class for which the slots are to be retrieved.\n        \n    Returns:\n        Iterator. An iterator that yields the names of the slots in the class and its base classes.\n        \n    Raises:\n        TypeError: If the input is not a class type.\n    \"\"\"\n    if not isinstance(cls, type):\n        raise TypeError('Input must be a class type.')\n    \n    # Create a generator expression to iterate through the class hierarchy\n    bases = (base for base in cls.__mro__)\n    \n    # Iterate through each class in the hierarchy\n    for base in bases:\n        # Check if the class has __slots__ defined\n        if hasattr(base, '__slots__'):\n            # If __slots__ is a string, yield it directly\n            if isinstance(base.__slots__, str):\n                yield base.__slots__\n            # If __slots__ is a sequence, yield each slot name\n            else:\n                yield from base.__slots__\n", "Result": "Error"}
{"namespace": "discord.utils.get_slots", "type": "Edge Case Handling", "test": "tests/test_utils.py::test_edge_case_handling", "completion": "\ndef get_slots(cls: type) -> iter:\n    \"\"\"\n    Returns an iterator that yields the names of the slots in the class and its base classes.\n    \n    Args:\n        cls (type): The class for which the slots are to be retrieved.\n        \n    Returns:\n        Iterator: An iterator that yields the names of the slots in the class and its base classes.\n        \n    Example:\n        >>> class A:\n        ...     __slots__ = ('x', 'y')\n        >>> class B(A):\n        ...     __slots__ = ('z',)\n        >>> list(get_slots(B))\n        ['z', 'x', 'y']\n    \"\"\"\n    # Handle the case where the class doesn't use slots\n    if not hasattr(cls, '__slots__'):\n        return iter(())\n    \n    # Get slots from current class\n    current_slots = getattr(cls, '__slots__', ())\n    \n    # Convert string to tuple if slots is defined as string\n    if isinstance(current_slots, str):\n        current_slots = (current_slots,)\n    \n    # Get slots from base classes\n    base_slots = (\n        slot\n        for base in cls.__bases__\n        for slot in get_slots(base)\n    )\n    \n    # Combine current slots with base slots\n    return iter(tuple(current_slots) + tuple(base_slots))\n", "Result": "Pass"}
{"namespace": "discord.utils.get_slots", "type": "Functionality Extension", "test": "tests/test_utils.py::test_functionality_extension", "completion": "\ndef get_slots(cls: type, depth: int = None) -> iter:\n    \"\"\"\n    Returns an iterator that yields the names of the slots in the class and its base classes.\n    \n    Args:\n        cls (type): The class for which the slots are to be retrieved\n        depth (int, optional): Maximum inheritance depth to traverse. None means no limit.\n    \n    Returns:\n        Iterator: An iterator that yields the names of the slots in the class and its base classes\n    \n    Example:\n        class A:\n            __slots__ = ('a', 'b')\n        \n        class B(A):\n            __slots__ = ('c',)\n        \n        list(get_slots(B))  # Returns: ['c', 'a', 'b']\n        list(get_slots(B, depth=0))  # Returns: ['c']\n    \"\"\"\n    current_depth = 0\n    current_cls = cls\n    \n    while current_cls is not None:\n        # Check if we've reached the maximum depth\n        if depth is not None and current_depth >= depth:\n            break\n            \n        # Get slots from current class if they exist\n        slots = getattr(current_cls, '__slots__', ())\n        if isinstance(slots, str):\n            yield slots\n        else:\n            yield from slots\n            \n        # Move up to the next base class\n        bases = current_cls.__bases__\n        current_cls = bases[0] if bases else None\n        current_depth += 1\n", "Result": "Pass"}
{"namespace": "discord.utils.get_slots", "type": "Annotation Coverage", "test": "tests/test_utils.py::test_annotation_coverage", "completion": "\nfrom typing import Type, Any, Iterator\n\ndef get_slots(cls: Type[Any]) -> Iterator[str]:\n    \"\"\"\n    Returns an iterator that yields the names of the slots in the class and its base classes.\n    \n    Args:\n        cls: The class for which the slots are to be retrieved.\n        \n    Returns:\n        An iterator that yields the names of the slots in the class and its base classes.\n    \"\"\"\n    # Get all base classes including the class itself\n    for class_ in cls.__mro__:\n        # Check if the class has __slots__ attribute\n        if hasattr(class_, '__slots__'):\n            # Get slots from the current class\n            slots = class_.__slots__\n            # If slots is a string, convert it to a tuple containing that string\n            if isinstance(slots, str):\n                yield slots\n            else:\n                # Yield each slot name from the slots sequence\n                yield from slots\n", "Result": "Pass"}
{"namespace": "discord.utils.get_slots", "type": "Code Complexity", "test": "tests/test_utils.py::test_code_complexity", "completion": "\ndef get_slots(cls: type) -> iter:\n    \"\"\"\n    Returns an iterator that yields the names of the slots in the class and its base classes.\n    \n    Args:\n        cls (type): The class for which the slots are to be retrieved.\n    \n    Returns:\n        iter: An iterator that yields the names of the slots in the class and its base classes.\n    \n    Example:\n        >>> class A:\n        ...     __slots__ = ('x', 'y')\n        >>> class B(A):\n        ...     __slots__ = ('z',)\n        >>> list(get_slots(B))\n        ['z', 'x', 'y']\n    \"\"\"\n    for c in cls.__mro__:\n        if hasattr(c, '__slots__'):\n            slots = c.__slots__\n            yield from slots if isinstance(slots, (list, tuple)) else (slots,)\n", "Result": "Pass"}
{"namespace": "discord.utils.get_slots", "type": "Code Standard", "test": "tests/test_utils.py::test_check_code_style", "completion": "\ndef get_slots(cls: type) -> iter:\n    \"\"\"\n    Returns an iterator that yields the names of the slots in the class and its base classes.\n    \n    This function iterates through the class hierarchy and yields the slots of each class.\n    If a class has no slots defined, it is skipped.\n    \n    Args:\n        cls: The class for which the slots are to be retrieved.\n        \n    Returns:\n        An iterator that yields the names of the slots in the class and its base classes.\n        \n    Example:\n        >>> class A:\n        ...     __slots__ = ('x', 'y')\n        >>> class B(A):\n        ...     __slots__ = ('z',)\n        >>> list(get_slots(B))\n        ['z', 'x', 'y']\n    \"\"\"\n    # Iterate through the class and its base classes\n    for class_ in cls.__mro__:\n        # Check if the class has __slots__ attribute\n        if hasattr(class_, '__slots__'):\n            # Get the slots from the class\n            slots = class_.__slots__\n            \n            # If slots is a string, convert it to a tuple containing that string\n            if isinstance(slots, str):\n                slots = (slots,)\n                \n            # Yield each slot name\n            for slot in slots:\n                yield slot\n", "Result": "Pass"}
{"namespace": "discord.utils.is_inside_class", "type": "Input-Output Conditions", "test": "tests/test_utils.py::test_input_output_conditions", "completion": "\ndef is_inside_class(func):\n    \"\"\"\n    Determine whether a given callable (function or method) is defined within a class.\n    \n    Args:\n        func: Callable object to be checked\n        \n    Returns:\n        bool: True if the function is defined inside a class, False otherwise\n        \n    Raises:\n        TypeError: If the input is not a callable object\n    \"\"\"\n    if not callable(func):\n        raise TypeError(\"Input must be a callable object\")\n    \n    # Get the qualified name of the callable\n    qualified_name = getattr(func, '__qualname__', '')\n    \n    # Split the qualified name into parts\n    name_parts = qualified_name.split('.')\n    \n    # If there's only one part, it's a module-level function\n    if len(name_parts) == 1:\n        return False\n        \n    # Check if any part represents a nested function (contains '<locals>')\n    for part in name_parts[:-1]:  # Exclude the last part (function name)\n        if '<locals>' in part:\n            return False\n            \n    return True\n", "Result": "Pass"}
{"namespace": "discord.utils.is_inside_class", "type": "Exception Handling", "test": "tests/test_utils.py::test_exception_handling", "completion": "\ndef is_inside_class(func):\n    \"\"\"\n    Determine whether a given callable (function or method) is defined within a class.\n    \n    Args:\n        func: Callable - The function to be checked\n        \n    Returns:\n        bool: True if the function is defined inside a class, False otherwise\n        \n    Raises:\n        TypeError: If the input is not a callable\n    \"\"\"\n    if not callable(func):\n        raise TypeError('Input must be a callable.')\n    \n    # Get the qualified name of the callable\n    qualified_name = getattr(func, '__qualname__', '')\n    \n    # Split the qualified name into parts\n    # For methods in classes, qualified_name will contain dots\n    # e.g., 'MyClass.my_method' or 'MyClass.NestedClass.my_method'\n    name_parts = qualified_name.split('.')\n    \n    # If there's only one part (no dots), it's a standalone function\n    # If there are multiple parts, check if any part is a function\n    # Functions within classes will have '<locals>' in their qualified name\n    return len(name_parts) > 1 and '<locals>' not in qualified_name\n", "Result": "Pass"}
{"namespace": "discord.utils.is_inside_class", "type": "Edge Case Handling", "test": "tests/test_utils.py::test_edge_case_handling", "completion": "\ndef is_inside_class(func):\n    \"\"\"\n    Determine whether a given callable (function or method) is defined within a class.\n    \n    Args:\n        func: Callable - The function or method to be checked\n        \n    Returns:\n        bool - True if the function is defined inside a class, False otherwise\n        \n    Examples:\n        >>> class MyClass:\n        ...     def method(self): pass\n        >>> def standalone(): pass\n        >>> is_inside_class(MyClass.method)  # Returns True\n        >>> is_inside_class(standalone)      # Returns False\n    \"\"\"\n    if not callable(func):\n        raise TypeError(\"Input must be a callable (function or method)\")\n        \n    # Get the qualified name of the callable\n    qualname = getattr(func, '__qualname__', '')\n    \n    # Split the qualified name into parts\n    parts = qualname.split('.')\n    \n    # If there's only one part, it's a standalone function\n    if len(parts) <= 1:\n        return False\n        \n    # Check if any part represents a function (ends with '<locals>')\n    # If all parts except the last one don't contain '<locals>', \n    # then the function is inside a class\n    for part in parts[:-1]:\n        if '<locals>' in part:\n            return False\n            \n    return True\n", "Result": "Error"}
{"namespace": "discord.utils.is_inside_class", "type": "Functionality Extension", "test": "tests/test_utils.py::test_functionality_extension", "completion": "\ndef is_inside_class(func):\n    \"\"\"\n    Determine whether a given callable is defined within a class and identify its method type.\n    \n    Args:\n        func: Callable - The function to be checked\n        \n    Returns:\n        bool - True if the function is defined inside a class, False otherwise\n        \n    Example:\n        class MyClass:\n            def method(self): pass\n            @classmethod\n            def class_method(cls): pass\n            @staticmethod\n            def static_method(): pass\n            \n        def standalone_function(): pass\n        \n        print(is_inside_class(MyClass.method))  # True\n        print(is_inside_class(standalone_function))  # False\n    \"\"\"\n    if not callable(func):\n        raise TypeError(\"Input must be a callable\")\n        \n    # Get the qualified name of the callable\n    qualname = getattr(func, '__qualname__', '')\n    \n    # Check if it's a method\n    if hasattr(func, '__self__'):\n        # Instance method bound to a class\n        if isinstance(func.__self__, type):\n            return True, 'classmethod'\n        # Instance method bound to an instance\n        return True, 'instance_method'\n    \n    # Check for static method\n    if isinstance(func, staticmethod):\n        return True, 'staticmethod'\n    \n    # Check if the qualified name contains a dot (indicating class membership)\n    # but exclude nested functions by checking if the first part is capitalized\n    # (following Python class naming convention)\n    if '.' in qualname:\n        first_part = qualname.split('.')[0]\n        if first_part[0].isupper():\n            # If we reach here, it's likely an unbound method\n            return True, 'unbound_method'\n    \n    return False, 'function'\n", "Result": "Error"}
{"namespace": "discord.utils.is_inside_class", "type": "Annotation Coverage", "test": "tests/test_utils.py::test_annotation_coverage", "completion": "\nfrom typing import Callable\n\ndef is_inside_class(func: Callable) -> bool:\n    \"\"\"\n    Determine whether a given callable (function or method) is defined within a class.\n    \n    The function checks the __qualname__ attribute of the callable to analyze the dotted\n    path that denotes its qualified name, considering the possibility of nested functions.\n    \n    Args:\n        func: Callable to be checked\n        \n    Returns:\n        bool: True if the function is defined inside a class, False otherwise\n    \"\"\"\n    # Get the qualified name of the callable\n    qualified_name = func.__qualname__\n    \n    # Split the qualified name into parts\n    name_parts = qualified_name.split('.')\n    \n    # If there's only one part, the function is not inside a class\n    if len(name_parts) == 1:\n        return False\n        \n    # Check if any part starts with '<' which indicates a nested function\n    # If all parts are nested functions, return False\n    for part in name_parts[:-1]:\n        if part.startswith('<'):\n            return False\n            \n    return True\n", "Result": "Error"}
{"namespace": "discord.utils.is_inside_class", "type": "Code Complexity", "test": "tests/test_utils.py::test_code_complexity", "completion": "\ndef is_inside_class(func: callable) -> bool:\n    \"\"\"\n    Determine whether a given callable is defined within a class.\n    \n    Args:\n        func: Callable to be checked.\n        \n    Returns:\n        bool: True if the function is defined inside a class, False otherwise.\n        \n    Example:\n        >>> class MyClass:\n        ...     def method(self):\n        ...         pass\n        >>> def standalone():\n        ...     pass\n        >>> is_inside_class(MyClass.method)  # Returns True\n        >>> is_inside_class(standalone)      # Returns False\n    \"\"\"\n    return '.' in getattr(func, '__qualname__', '')\n", "Result": "Error"}
{"namespace": "discord.utils.is_inside_class", "type": "Code Standard", "test": "tests/test_utils.py::test_check_code_style", "completion": "\ndef is_inside_class(func: callable) -> bool:\n    \"\"\"\n    Determine whether a given callable (function or method) is defined within a class.\n    \n    The function checks the __qualname__ attribute of the callable to analyze the dotted\n    path that denotes its qualified name, considering the possibility of nested functions.\n    \n    Args:\n        func: Callable to be checked.\n        \n    Returns:\n        bool: True if the function is defined inside a class, False otherwise.\n        \n    Examples:\n        >>> def standalone_function():\n        ...     pass\n        >>> class MyClass:\n        ...     def class_method(self):\n        ...         pass\n        >>> is_inside_class(standalone_function)\n        False\n        >>> is_inside_class(MyClass.class_method)\n        True\n    \"\"\"\n    if not callable(func):\n        raise TypeError(\"Input must be a callable (function or method)\")\n    \n    # Get the qualified name of the callable\n    qualified_name = getattr(func, '__qualname__', '')\n    \n    # Split the qualified name into parts\n    name_parts = qualified_name.split('.')\n    \n    # If there's only one part, it's a standalone function\n    if len(name_parts) <= 1:\n        return False\n        \n    # Check if any part represents a class (starts with uppercase)\n    # Exclude the last part as it's the function name itself\n    return any(part[0].isupper() for part in name_parts[:-1])\n", "Result": "Error"}
{"namespace": "wandb.util.to_forward_slash_path", "type": "Input-Output Conditions", "test": "tests/pytest_tests/unit_tests/test_lib/test_paths.py::test_input_output_conditions", "completion": "\ndef to_forward_slash_path(path):\n    \"\"\"\n    Convert backslash path to forward slash path if the platform is Windows.\n    \n    :param path: String. The path to be converted.\n    :return: String. The converted path.\n    :raises TypeError: If the input path is not a string.\n    \"\"\"\n    if not isinstance(path, str):\n        raise TypeError(\"Input path must be a string\")\n    \n    return path.replace('\\\\', '/')\n", "Result": "Error"}
{"namespace": "wandb.util.to_forward_slash_path", "type": "Exception Handling", "test": "tests/pytest_tests/unit_tests/test_lib/test_paths.py::test_exception_handling", "completion": "\ndef to_forward_slash_path(path: str) -> str:\n    \"\"\"\n    Convert backslash path to forward slash path if the platform is Windows.\n\n    Args:\n        path (str): The path to be converted.\n\n    Returns:\n        str: The converted path.\n\n    Raises:\n        ValueError: If the input path is None.\n    \"\"\"\n    if path is None:\n        raise ValueError(\"Input path cannot be None\")\n    \n    return path.replace('\\\\', '/')\n", "Result": "Error"}
{"namespace": "wandb.util.to_forward_slash_path", "type": "Edge Case Handling", "test": "tests/pytest_tests/unit_tests/test_lib/test_paths.py::test_edge_case_handling", "completion": "\ndef to_forward_slash_path(path: str) -> str:\n    \"\"\"\n    Convert backslash path to forward slash path if the platform is Windows.\n    \n    :param path: String. The path to be converted.\n    :return: String. The converted path.\n    \"\"\"\n    if not path:  # Handle empty string\n        return \"\"\n        \n    import platform\n    if platform.system() == \"Windows\":\n        return path.replace(\"\\\\\", \"/\")\n    \n    return path\n", "Result": "Pass"}
{"namespace": "wandb.util.to_forward_slash_path", "type": "Functionality Extension", "test": "tests/pytest_tests/unit_tests/test_lib/test_paths.py::test_functionality_extension", "completion": "\ndef to_forward_slash_path(path: str) -> str:\n    \"\"\"\n    Convert backslash path to forward slash path, handling mixed slashes.\n    \n    :param path: String. The path to be converted\n    :return: String. The converted path with forward slashes\n    \"\"\"\n    if path:\n        # Replace all backslashes with forward slashes\n        return path.replace('\\\\', '/')\n    return path\n", "Result": "Pass"}
{"namespace": "wandb.util.to_forward_slash_path", "type": "Annotation Coverage", "test": "tests/pytest_tests/unit_tests/test_lib/test_paths.py::test_annotation_coverage", "completion": "\ndef to_forward_slash_path(path: str) -> str:\n    \"\"\"\n    Convert backslash path to forward slash path if the platform is Windows.\n    \n    :param path: String. The path to be converted.\n    :return: String. The converted path.\n    \"\"\"\n    import platform\n    \n    if platform.system() == 'Windows':\n        return path.replace('\\\\', '/')\n    return path\n", "Result": "Pass"}
{"namespace": "wandb.util.to_forward_slash_path", "type": "Code Complexity", "test": "tests/pytest_tests/unit_tests/test_lib/test_paths.py::test_code_complexity", "completion": "\ndef to_forward_slash_path(path: str) -> str:\n    \"\"\"\n    Convert backslash path to forward slash path if the platform is Windows.\n    \n    :param path: String. The path to be converted.\n    :return: String. The converted path.\n    \"\"\"\n    return path.replace('\\\\', '/')\n", "Result": "Error"}
{"namespace": "wandb.util.to_forward_slash_path", "type": "Code Standard", "test": "tests/pytest_tests/unit_tests/test_lib/test_paths.py::test_check_code_style", "completion": "\nimport os\n\n\ndef to_forward_slash_path(path: str) -> str:\n    \"\"\"\n    Convert backslash path to forward slash path if the platform is Windows.\n\n    Args:\n        path (str): The path to be converted.\n\n    Returns:\n        str: The converted path with forward slashes.\n    \"\"\"\n    if os.name == 'nt':  # Check if platform is Windows\n        return path.replace('\\\\', '/')\n    return path\n", "Result": "Pass"}
{"namespace": "wandb.util.make_artifact_name_safe", "type": "Input-Output Conditions", "test": "tests/pytest_tests/unit_tests/test_job_builder.py::test_make_artifact_name_safe_input_output", "completion": "\nimport re\n\ndef make_artifact_name_safe(name: str) -> str:\n    \"\"\"\n    Makes an artifact name safe for use by replacing invalid characters and truncating if necessary.\n    \n    :param name: str. The original artifact name\n    :return: str. The cleaned and safe artifact name\n    \"\"\"\n    # Replace any characters that aren't alphanumeric, dash, underscore, or dot with underscore\n    safe_name = re.sub(r'[^a-zA-Z0-9\\-_\\.]', '_', name)\n    \n    # If the name is longer than 128 characters, truncate it with dots in the middle\n    if len(safe_name) > 128:\n        # Keep first 62 and last 62 characters, with '...' in between\n        safe_name = safe_name[:62] + '...' + safe_name[-62:]\n        \n    return safe_name\n", "Result": "Pass"}
{"namespace": "wandb.util.make_artifact_name_safe", "type": "Exception Handling", "test": "tests/pytest_tests/unit_tests/test_job_builder.py::test_make_artifact_name_safe_type_error", "completion": "\ndef make_artifact_name_safe(name: str) -> str:\n    \"\"\"\n    Makes an artifact name safe for use by replacing invalid characters and truncating if necessary.\n    \n    Args:\n        name: The original artifact name\n        \n    Returns:\n        The cleaned and safe artifact name\n        \n    Raises:\n        TypeError: If the input is not a string\n    \"\"\"\n    if not isinstance(name, str):\n        raise TypeError('Input must be a string')\n        \n    import re\n    \n    # Replace invalid characters with underscores\n    safe_name = re.sub(r'[^a-zA-Z0-9\\-_.]', '_', name)\n    \n    # If name is longer than 128 characters, truncate it with dots in the middle\n    if len(safe_name) > 128:\n        prefix = safe_name[:62]\n        suffix = safe_name[-62:]\n        safe_name = f\"{prefix}...{suffix}\"\n        \n    return safe_name\n", "Result": "Error"}
{"namespace": "wandb.util.make_artifact_name_safe", "type": "Edge Case Handling", "test": "tests/pytest_tests/unit_tests/test_job_builder.py::test_make_artifact_name_safe_empty_string", "completion": "\nimport re\n\ndef make_artifact_name_safe(name: str) -> str:\n    \"\"\"\n    Makes an artifact name safe for use by replacing invalid characters and truncating if necessary.\n    \n    Args:\n        name (str): The original artifact name\n        \n    Returns:\n        str: The cleaned and safe artifact name\n    \"\"\"\n    if not name:\n        return \"\"\n    \n    # Replace any characters that are not alphanumeric, dashes, underscores, or dots\n    safe_name = re.sub(r'[^a-zA-Z0-9\\-_\\.]', '_', name)\n    \n    # If the name is longer than 128 characters, truncate it with dots in the middle\n    if len(safe_name) > 128:\n        half_length = (128 - 3) // 2  # -3 for the dots\n        safe_name = f\"{safe_name[:half_length]}...{safe_name[-half_length:]}\"\n    \n    return safe_name\n", "Result": "Pass"}
{"namespace": "wandb.util.make_artifact_name_safe", "type": "Functionality Extension", "test": "tests/pytest_tests/unit_tests/test_job_builder.py::test_make_artifact_name_safe_trim_spaces", "completion": "\nimport re\n\ndef make_artifact_name_safe(name: str) -> str:\n    \"\"\"\n    Makes an artifact name safe for use by replacing invalid characters and handling length constraints.\n    \n    Args:\n        name (str): The original artifact name\n        \n    Returns:\n        str: The cleaned and safe artifact name\n        \n    Example:\n        >>> make_artifact_name_safe(\"My Artifact! (v2.0)\")\n        'My_Artifact_v2.0'\n    \"\"\"\n    # Trim leading and trailing spaces\n    name = name.strip()\n    \n    # Replace any characters that aren't alphanumeric, dash, underscore, or dot with underscore\n    cleaned_name = re.sub(r'[^a-zA-Z0-9\\-_\\.]', '_', name)\n    \n    # If the name is longer than 128 characters, truncate it with dots in the middle\n    if len(cleaned_name) > 128:\n        half_length = (128 - 3) // 2  # -3 for the dots\n        cleaned_name = f\"{cleaned_name[:half_length]}...{cleaned_name[-half_length:]}\"\n    \n    return cleaned_name\n", "Result": "Pass"}
{"namespace": "wandb.util.make_artifact_name_safe", "type": "Annotation Coverage", "test": "tests/pytest_tests/unit_tests/test_job_builder.py::test_make_artifact_name_safe_annotations", "completion": "\nimport re\n\ndef make_artifact_name_safe(name: str) -> str:\n    \"\"\"\n    Makes an artifact name safe for use by replacing invalid characters and truncating if necessary.\n    \n    :param name: The original artifact name\n    :return: The cleaned and safe artifact name\n    \"\"\"\n    # Replace any characters that are not alphanumeric, dashes, underscores, or dots with underscores\n    safe_name = re.sub(r'[^a-zA-Z0-9\\-_\\.]', '_', name)\n    \n    # If the name is longer than 128 characters, truncate it with dots in the middle\n    if len(safe_name) > 128:\n        # Keep 60 characters from start and enough characters from end to make total length 128\n        # Including the dots in the middle\n        return safe_name[:60] + '...' + safe_name[-(128-60-3):]\n    \n    return safe_name\n", "Result": "Pass"}
{"namespace": "wandb.util.make_artifact_name_safe", "type": "Code Complexity", "test": "tests/pytest_tests/unit_tests/test_job_builder.py::test_code_complexity", "completion": "\nimport re\n\ndef make_artifact_name_safe(name: str) -> str:\n    \"\"\"\n    Makes an artifact name safe for use by replacing invalid characters and truncating if needed.\n    \n    :param name: str. The original artifact name\n    :return: str. The cleaned and safe artifact name\n    \"\"\"\n    # Replace invalid characters with underscores\n    safe_name = re.sub(r'[^a-zA-Z0-9\\-_.]', '_', name)\n    \n    # If name length exceeds 128 characters, truncate with dots in middle\n    if len(safe_name) > 128:\n        half_length = (128 - 3) // 2  # -3 for the dots\n        safe_name = f\"{safe_name[:half_length]}...{safe_name[-half_length:]}\"\n        \n    return safe_name\n", "Result": "Pass"}
{"namespace": "wandb.util.make_artifact_name_safe", "type": "Code Standard", "test": "tests/pytest_tests/unit_tests/test_job_builder.py::test_check_code_style", "completion": "\nimport re\n\ndef make_artifact_name_safe(name: str) -> str:\n    \"\"\"\n    Makes an artifact name safe for use by replacing invalid characters and truncating if needed.\n    \n    This function:\n    1. Replaces non-alphanumeric/dash/underscore/dot characters with underscores\n    2. Truncates names longer than 128 characters, inserting dots in the middle\n    \n    Args:\n        name: The original artifact name\n        \n    Returns:\n        A cleaned and safe artifact name\n        \n    Examples:\n        >>> make_artifact_name_safe(\"my-artifact.1.0\")\n        'my-artifact.1.0'\n        >>> make_artifact_name_safe(\"my@artifact#2.0\")\n        'my_artifact_2.0'\n    \"\"\"\n    if not isinstance(name, str):\n        raise TypeError(\"Artifact name must be a string\")\n    \n    if not name:\n        raise ValueError(\"Artifact name cannot be empty\")\n    \n    # Replace invalid characters with underscores\n    safe_name = re.sub(r'[^a-zA-Z0-9\\-_.]', '_', name)\n    \n    # If name is longer than 128 characters, truncate it with dots in the middle\n    if len(safe_name) > 128:\n        half_length = (128 - 3) // 2  # -3 for the dots\n        safe_name = f\"{safe_name[:half_length]}...{safe_name[-half_length:]}\"\n    \n    return safe_name\n", "Result": "Error"}
{"namespace": "jwt.utils.force_bytes", "type": "Input-Output Conditions", "test": "tests/test_utils.py::test_force_bytes_with_bytes_input", "completion": "\ndef force_bytes(value: Union[bytes, str]) -> bytes:\n    \"\"\"\n    Convert the input value to bytes.\n    \n    Args:\n        value: Input value that needs to be converted to bytes.\n              Must be either bytes or str type.\n    \n    Returns:\n        bytes: The input value converted to bytes.\n    \n    Raises:\n        TypeError: If the input value is neither bytes nor str type.\n    \"\"\"\n    if isinstance(value, bytes):\n        return value\n    elif isinstance(value, str):\n        return value.encode('utf-8')\n    else:\n        raise TypeError(f\"Expected bytes or str, got {type(value).__name__}\")\n", "Result": "Pass"}
{"namespace": "jwt.utils.force_bytes", "type": "Exception Handling", "test": "tests/test_utils.py::test_force_bytes_raises_error_with_message", "completion": "\ndef force_bytes(value: Union[bytes, str]) -> bytes:\n    \"\"\"\n    Convert the input value to bytes.\n    \n    Args:\n        value: Union[bytes, str]\n            The input value that needs to be converted to bytes.\n            Can be either a string or bytes object.\n    \n    Returns:\n        bytes: The input value converted to bytes.\n        \n    Raises:\n        TypeError: If the input value is neither string nor bytes.\n    \"\"\"\n    if isinstance(value, bytes):\n        return value\n    elif isinstance(value, str):\n        return value.encode('utf-8')\n    else:\n        raise TypeError(f\"Expected string or bytes object, got {type(value).__name__}\")\n", "Result": "Error"}
{"namespace": "jwt.utils.force_bytes", "type": "Edge Case Handling", "test": "tests/test_utils.py::test_force_bytes_with_empty_string", "completion": "\ndef force_bytes(value: Union[bytes, str]) -> bytes:\n    \"\"\"\n    Convert the input value to bytes.\n    \n    Args:\n        value: Union[bytes, str]\n            The input value that needs to be converted to bytes.\n            Can be either a string or bytes object.\n    \n    Returns:\n        bytes: The input value converted to bytes.\n        \n    Raises:\n        TypeError: If the input value is neither string nor bytes.\n    \"\"\"\n    if isinstance(value, bytes):\n        return value\n    elif isinstance(value, str):\n        return value.encode('utf-8')\n    else:\n        raise TypeError(f\"Expected str or bytes, got {type(value).__name__}\")\n", "Result": "Pass"}
{"namespace": "jwt.utils.force_bytes", "type": "Functionality Extension", "test": "tests/test_utils.py::test_force_bytes_with_none_input", "completion": "\ndef force_bytes(value: Union[bytes, str, None]) -> bytes:\n    \"\"\"\n    Convert the input value to bytes.\n    \n    Args:\n        value: Input value that needs to be converted to bytes.\n              Can be bytes, str, or None.\n    \n    Returns:\n        bytes: The input value converted to bytes.\n              Returns empty bytes if input is None.\n    \n    Raises:\n        TypeError: If input is neither bytes, str, nor None.\n    \"\"\"\n    if value is None:\n        return b''\n    \n    if isinstance(value, bytes):\n        return value\n    \n    if isinstance(value, str):\n        return value.encode('utf-8')\n    \n    raise TypeError(f\"Expected bytes, str, or None. Got {type(value).__name__}\")\n", "Result": "Pass"}
{"namespace": "jwt.utils.force_bytes", "type": "Annotation Coverage", "test": "tests/test_utils.py::test_force_bytes_annotations", "completion": "\nfrom typing import Union\n\ndef force_bytes(value: Union[bytes, str, None]) -> bytes:\n    \"\"\"\n    Convert the input value to bytes.\n    \n    Args:\n        value: The input value that needs to be converted to bytes.\n              Can be bytes, str, or None.\n    \n    Returns:\n        bytes: The input value converted to bytes.\n    \n    Raises:\n        TypeError: If the input value is neither bytes nor str.\n    \"\"\"\n    if value is None:\n        return b''\n    if isinstance(value, bytes):\n        return value\n    if isinstance(value, str):\n        return value.encode('utf-8')\n    \n    raise TypeError(f\"Expected bytes or str, got {type(value).__name__}\")\n", "Result": "Error"}
{"namespace": "jwt.utils.force_bytes", "type": "Code Complexity", "test": "tests/test_utils.py::test_code_complexity", "completion": "\ndef force_bytes(value: Union[bytes, str]) -> bytes:\n    \"\"\"\n    Convert the input value to bytes.\n    \n    Args:\n        value: Input value that needs to be converted to bytes.\n              Must be either bytes or str type.\n    \n    Returns:\n        bytes: The input value converted to bytes.\n    \n    Raises:\n        TypeError: If the input value is neither bytes nor str.\n    \"\"\"\n    if isinstance(value, bytes):\n        return value\n    if isinstance(value, str):\n        return value.encode('utf-8')\n    raise TypeError(f\"Expected bytes or str, got {type(value).__name__}\")\n", "Result": "Pass"}
{"namespace": "jwt.utils.force_bytes", "type": "Code Standard", "test": "tests/test_utils.py::test_check_code_style", "completion": "\ndef force_bytes(value: Union[bytes, str]) -> bytes:\n    \"\"\"\n    Convert the input value to bytes.\n\n    Args:\n        value: Input value that needs to be converted to bytes.\n              Must be either bytes or str type.\n\n    Returns:\n        bytes: The input value converted to bytes.\n\n    Raises:\n        TypeError: If the input value is neither bytes nor str type.\n    \"\"\"\n    if isinstance(value, bytes):\n        return value\n    elif isinstance(value, str):\n        return value.encode('utf-8')\n    else:\n        raise TypeError(f\"Expected bytes or str, got {type(value).__name__}\")\n", "Result": "Pass"}
{"namespace": "pytube.cli.display_progress_bar", "type": "Input-Output Conditions", "test": "tests/test_cli.py::test_display_progress_bar_input_types", "completion": "\ndef display_progress_bar(bytes_received: int, filesize: int, ch: str = \"\u2588\", scale: float = 0.55) -> None:\n    \"\"\"\n    Display a simple progress bar in the terminal based on bytes received and total file size.\n    \n    Args:\n        bytes_received (int): The delta between total file size and bytes already written\n        filesize (int): File size of the media stream in bytes\n        ch (str): Character to use for presenting progress segment (default: \"\u2588\")\n        scale (float): Scale multiplier to reduce progress bar size (default: 0.55)\n        \n    Raises:\n        TypeError: If bytes_received or filesize are not integers, or if scale is not float\n    \"\"\"\n    # Type checking\n    if not isinstance(bytes_received, int):\n        raise TypeError(\"bytes_received must be an integer\")\n    if not isinstance(filesize, int):\n        raise TypeError(\"filesize must be an integer\")\n    if not isinstance(scale, float):\n        raise TypeError(\"scale must be a float\")\n    \n    # Calculate progress percentage\n    progress = min(1.0, bytes_received / filesize)\n    percent = progress * 100\n    \n    # Calculate bar width based on terminal size and scale\n    terminal_width = get_terminal_size().columns\n    bar_length = int(terminal_width * scale)\n    \n    # Calculate filled and empty portions of the bar\n    filled_length = int(bar_length * progress)\n    empty_length = bar_length - filled_length\n    \n    # Create the progress bar\n    bar = ch * filled_length + '-' * empty_length\n    \n    # Print the progress bar with percentage\n    print(f'\\r|{bar}| {percent:.1f}%', end='', flush=True)\n", "Result": "Error"}
{"namespace": "pytube.cli.display_progress_bar", "type": "Exception Handling", "test": "tests/test_cli.py::test_display_progress_bar_filesize_zero", "completion": "\ndef display_progress_bar(bytes_received: int, filesize: int, ch: str = \"\u2588\", scale: float = 0.55) -> None:\n    \"\"\"\n    Display a simple progress bar in the terminal based on the bytes received and total file size.\n    \n    Args:\n        bytes_received (int): The delta between the total file size (bytes) and bytes already written to disk\n        filesize (int): File size of the media stream in bytes\n        ch (str): Character to use for presenting progress segment. Defaults to \"\u2588\"\n        scale (float): Scale multiplier to reduce progress bar size. Defaults to 0.55\n    \n    Raises:\n        ValueError: If filesize is zero\n    \"\"\"\n    if filesize <= 0:\n        raise ValueError(\"File size must be greater than zero.\")\n    \n    # Calculate the progress percentage\n    percentage = (bytes_received / filesize) * 100\n    \n    # Calculate the width of the progress bar based on terminal size and scale\n    terminal_width = get_terminal_width()\n    bar_width = int(terminal_width * scale)\n    \n    # Calculate filled and empty portions of the progress bar\n    filled_length = int(bar_width * bytes_received // filesize)\n    empty_length = bar_width - filled_length\n    \n    # Create the progress bar\n    bar = ch * filled_length + '-' * empty_length\n    \n    # Print the progress bar with percentage\n    print(f'\\r|{bar}| {percentage:.1f}%', end='', flush=True)\n", "Result": "Error"}
{"namespace": "pytube.cli.display_progress_bar", "type": "Edge Case Handling", "test": "tests/test_cli.py::test_display_progress_bar_complete", "completion": "\ndef display_progress_bar(bytes_received: int, filesize: int, ch: str = \"\u2588\", scale: float = 0.55) -> None:\n    \"\"\"\n    Display a simple, pretty progress bar in the terminal based on the bytes received and total file size.\n    \n    Args:\n        bytes_received (int): The delta between the total file size (bytes) and bytes already written to disk\n        filesize (int): File size of the media stream in bytes\n        ch (str): Character to use for presenting progress segment. Defaults to \"\u2588\"\n        scale (float): Scale multiplier to reduce progress bar size. Defaults to 0.55\n    \"\"\"\n    # Calculate the progress percentage\n    progress = min(1.0, bytes_received / filesize)\n    percent = progress * 100\n    \n    # Calculate the width of the progress bar based on terminal size\n    columns = get_terminal_size().columns\n    max_width = int(columns * scale)\n    \n    # Calculate filled and empty segments\n    filled_length = int(max_width * progress)\n    empty_length = max_width - filled_length\n    \n    # Create the progress bar\n    bar = ch * filled_length + '-' * empty_length\n    \n    # Create the percentage display\n    percent_display = f' {percent:6.2f}%'\n    \n    # Print the progress bar and percentage\n    print(f'\\r|{bar}|{percent_display}', end='', flush=True)\n    \n    # Print a newline when download is complete\n    if bytes_received >= filesize:\n        print()\n", "Result": "Error"}
{"namespace": "pytube.cli.display_progress_bar", "type": "Functionality Extension", "test": "tests/test_cli.py::test_display_progress_bar_custom_width", "completion": "\ndef display_progress_bar(bytes_received: int, filesize: int, ch: str = \"\u2588\", scale: float = 0.55, width: int = 50) -> None:\n    \"\"\"\n    Display a customizable progress bar in the terminal based on download progress.\n    \n    Args:\n        bytes_received (int): The number of bytes received/processed\n        filesize (int): Total file size in bytes\n        ch (str): Character to use for progress segments (default: \"\u2588\")\n        scale (float): Scale multiplier to reduce progress bar size (default: 0.55)\n        width (int): Width of the progress bar in characters (default: 50)\n    \"\"\"\n    # Calculate percentage completed\n    percentage = (bytes_received / filesize) * 100\n    \n    # Calculate the number of segments to fill\n    filled_length = int(width * (bytes_received / float(filesize)))\n    \n    # Create the progress bar\n    bar = ch * filled_length + '-' * (width - filled_length)\n    \n    # Calculate file sizes for display\n    received_mb = bytes_received / 1024 / 1024\n    total_mb = filesize / 1024 / 1024\n    \n    # Create the progress line\n    progress_line = f'\\rProgress: |{bar}| {percentage:.1f}% ({received_mb:.1f}MB/{total_mb:.1f}MB)'\n    \n    # Print the progress bar (use end='' to stay on the same line)\n    print(progress_line, end='')\n    \n    # Print a newline when download is complete\n    if bytes_received == filesize:\n        print()\n", "Result": "Error"}
{"namespace": "pytube.cli.display_progress_bar", "type": "Annotation Coverage", "test": "tests/test_cli.py::test_display_progress_bar_annotations", "completion": "\ndef display_progress_bar(bytes_received: int, filesize: int, ch: str = \"\u2588\", scale: float = 0.55) -> None:\n    \"\"\"\n    Display a simple, pretty progress bar in the terminal based on the bytes received and total file size.\n    \n    Args:\n        bytes_received (int): The delta between the total file size (bytes) and bytes already written to disk\n        filesize (int): File size of the media stream in bytes\n        ch (str): Character to use for presenting progress segment. Defaults to \"\u2588\"\n        scale (float): Scale multiplier to reduce progress bar size. Defaults to 0.55\n    \"\"\"\n    # Get terminal width\n    columns = min(100, int(filesize * scale))\n    \n    # Calculate progress percentage\n    percent = bytes_received / filesize\n    \n    # Calculate number of filled progress segments\n    filled = int(columns * percent)\n    \n    # Create progress bar string\n    bar = ch * filled + '-' * (columns - filled)\n    \n    # Calculate percentage for display\n    percent_display = int(percent * 100)\n    \n    # Print progress bar with percentage\n    print(f'\\r|{bar}| {percent_display}%', end='', flush=True)\n    \n    # Print newline when download is complete\n    if bytes_received == filesize:\n        print()\n", "Result": "Error"}
{"namespace": "pytube.cli.display_progress_bar", "type": "Code Complexity", "test": "tests/test_cli.py::test_display_progress_bar_complexity", "completion": "\ndef display_progress_bar(bytes_received: int, filesize: int, ch: str = \"\u2588\", scale: float = 0.55) -> None:\n    \"\"\"\n    Display a simple progress bar in the terminal based on download progress.\n    \n    Args:\n        bytes_received (int): The number of bytes received/processed\n        filesize (int): Total file size in bytes\n        ch (str): Character to use for progress segments (default: \"\u2588\")\n        scale (float): Scale multiplier to reduce progress bar size (default: 0.55)\n    \"\"\"\n    # Calculate the terminal width and scale the progress bar\n    terminal_width = min(100, int(get_terminal_size().columns * scale))\n    \n    # Calculate progress percentage and number of filled segments\n    progress = bytes_received / filesize\n    filled_length = int(terminal_width * progress)\n    \n    # Create the progress bar string\n    bar = ch * filled_length + '-' * (terminal_width - filled_length)\n    \n    # Calculate percentage and format display string\n    percent = int(100 * progress)\n    display = f'\\rProgress: |{bar}| {percent}%'\n    \n    # Print the progress bar (use end='' to stay on same line)\n    print(display, end='' if percent < 100 else '\\n')\n", "Result": "Error"}
{"namespace": "pytube.cli.display_progress_bar", "type": "Code Standard", "test": "tests/test_cli.py::test_check_code_style", "completion": "\ndef display_progress_bar(bytes_received: int, filesize: int, ch: str = \"\u2588\", scale: float = 0.55) -> None:\n    \"\"\"\n    Display a simple, pretty progress bar in the terminal based on the bytes received\n    and the total file size.\n\n    Args:\n        bytes_received (int): The delta between the total file size (bytes) and\n            bytes already written to disk.\n        filesize (int): File size of the media stream in bytes.\n        ch (str, optional): Character to use for presenting progress segment.\n            Defaults to \"\u2588\".\n        scale (float, optional): Scale multiplier to reduce progress bar size.\n            Defaults to 0.55.\n\n    Returns:\n        None\n    \"\"\"\n    # Calculate terminal width and scale the progress bar\n    columns = min(80, int(get_terminal_size().columns * scale))\n    \n    # Calculate progress percentage\n    progress = bytes_received / filesize\n    filled_length = int(columns * progress)\n    \n    # Create the progress bar\n    bar = ch * filled_length + '-' * (columns - filled_length)\n    percentage = progress * 100\n    \n    # Print the progress bar with percentage\n    print(f'\\r|{bar}| {percentage:.1f}%', end='', flush=True)\n    \n    # Print newline when download is complete\n    if bytes_received == filesize:\n        print()\n", "Result": "Error"}
{"namespace": "imapclient.imap_utf7.encode", "type": "Input-Output Conditions", "test": "tests/test_imap_utf7.py::IMAP4UTF7TestCase::test_bytes_input", "completion": "\ndef encode(s: Union[str, bytes]) -> bytes:\n    \"\"\"\n    Encode a folder name using IMAP modified UTF-7 encoding.\n    \n    :param s: The input string to be encoded\n    :type s: Union[str, bytes]\n    :return: The encoded bytes of the input string\n    :rtype: bytes\n    \"\"\"\n    # Return input unchanged if it's already bytes\n    if isinstance(s, bytes):\n        return s\n    \n    # Convert string to bytes using IMAP modified UTF-7 encoding\n    if isinstance(s, str):\n        # Replace standard Base64 characters\n        s = s.encode('utf-16be').replace(b'+', b'+-)\n        \n        # Find non-ASCII sequences\n        result = bytearray()\n        start = 0\n        \n        for i in range(len(s)):\n            # Check for non-ASCII characters\n            if s[i] >= 0x80:\n                if start < i:\n                    result.extend(s[start:i])\n                start = i\n                while i < len(s) and s[i] >= 0x80:\n                    i += 1\n                # Encode non-ASCII sequence\n                base64_segment = base64.b64encode(s[start:i]).rstrip(b'=')\n                result.extend(b'+' + base64_segment + b'-')\n                start = i\n                \n        # Add remaining ASCII characters\n        if start < len(s):\n            result.extend(s[start:])\n            \n        return bytes(result)\n    \n    raise TypeError(f\"Expected str or bytes, got {type(s).__name__}\")\n", "Result": "Error"}
{"namespace": "imapclient.imap_utf7.encode", "type": "Exception Handling", "test": "tests/test_imap_utf7.py::IMAP4UTF7TestCase::test_invalid_input_type", "completion": "\ndef encode(s: Union[str, bytes]) -> bytes:\n    \"\"\"\n    Encode a folder name using IMAP modified UTF-7 encoding.\n    \n    :param s: The input string to be encoded\n    :type s: Union[str, bytes]\n    :return: The encoded bytes of the input string\n    :rtype: bytes\n    :raises TypeError: If the input is neither a string nor bytes\n    \"\"\"\n    if isinstance(s, bytes):\n        return s\n    \n    if not isinstance(s, str):\n        raise TypeError(f\"Expected str or bytes, got {type(s).__name__}\")\n    \n    # If the string only contains ASCII characters (except for '&'),\n    # we only need to escape '&' characters\n    if all(ord(c) < 128 for c in s):\n        return s.replace('&', '&-').encode('ascii')\n    \n    # Initialize result list to store encoded parts\n    result = []\n    buffer = []\n    \n    for char in s:\n        if ord(char) < 128 and char not in '&+,':\n            # ASCII chars except &+, can be used directly\n            if buffer:\n                # Flush any buffered non-ASCII chars first\n                result.append(f'&{base64.b64encode(bytes(buffer)).decode().rstrip(\"=\")}')\n                buffer = []\n            result.append(char)\n        else:\n            # Non-ASCII chars need to be encoded\n            buffer.append(ord(char) >> 8)\n            buffer.append(ord(char) & 0xFF)\n    \n    # Flush any remaining buffered chars\n    if buffer:\n        result.append(f'&{base64.b64encode(bytes(buffer)).decode().rstrip(\"=\")}')\n    \n    return ''.join(result).encode('ascii')\n", "Result": "Error"}
{"namespace": "imapclient.imap_utf7.encode", "type": "Edge Case Handling", "test": "tests/test_imap_utf7.py::IMAP4UTF7TestCase::test_empty_string_input", "completion": "\ndef encode(s: Union[str, bytes]) -> bytes:\n    \"\"\"\n    Encode a folder name using IMAP modified UTF-7 encoding.\n    \n    :param s: The input string to be encoded\n    :type s: Union[str, bytes]\n    :return: The encoded bytes of the input string\n    :rtype: bytes\n    \"\"\"\n    # Return empty bytes for empty string\n    if s == '':\n        return b''\n    \n    # Return unchanged if input is already bytes\n    if isinstance(s, bytes):\n        return s\n    \n    # Convert string to bytes using IMAP modified UTF-7\n    result = []\n    is_unicode = False\n    unicode_chars = []\n\n    for char in s:\n        # Handle ASCII characters (except &)\n        if 0x20 <= ord(char) <= 0x7e and char != '&':\n            if is_unicode:\n                # Encode accumulated unicode chars\n                if unicode_chars:\n                    result.append('&' + base64.b64encode(\n                        ''.join(unicode_chars).encode('utf-16be')\n                    ).decode('ascii').rstrip('=').replace('/', ',') + '-')\n                    unicode_chars = []\n                is_unicode = False\n            result.append(char)\n        else:\n            # Handle non-ASCII characters\n            is_unicode = True\n            unicode_chars.append(char)\n    \n    # Handle any remaining unicode chars\n    if unicode_chars:\n        result.append('&' + base64.b64encode(\n            ''.join(unicode_chars).encode('utf-16be')\n        ).decode('ascii').rstrip('=').replace('/', ',') + '-')\n    \n    # Handle special case of '&'\n    return ''.join(result).replace('&', '&-').encode('ascii')\n", "Result": "Error"}
{"namespace": "imapclient.imap_utf7.encode", "type": "Functionality Extension", "test": "tests/test_imap_utf7.py::IMAP4UTF7TestCase::test_decode_functionality", "completion": "\nfrom typing import Union\nimport base64\n\ndef encode(s: Union[str, bytes]) -> bytes:\n    \"\"\"\n    Encode a folder name using IMAP modified UTF-7 encoding.\n    \n    :param s: The input string to be encoded\n    :return: The encoded bytes of the input string\n    \"\"\"\n    if not isinstance(s, str):\n        return s if isinstance(s, bytes) else str(s).encode('utf-8')\n    \n    result = []\n    is_unicode = False\n    unicode_chars = []\n    \n    for char in s:\n        # Check if character needs encoding\n        if ord(char) < 0x20 or ord(char) > 0x7e:\n            if not is_unicode:\n                is_unicode = True\n                result.append('&')\n            unicode_chars.append(char)\n        else:\n            if is_unicode:\n                if unicode_chars:\n                    # Convert unicode chars to modified BASE64\n                    encoded = base64.b64encode(\n                        ''.join(unicode_chars).encode('utf-16be')\n                    ).decode('ascii')\n                    # Remove padding and append to result\n                    result.append(encoded.rstrip('='))\n                result.append('-')\n                unicode_chars = []\n                is_unicode = False\n            \n            # Handle special characters\n            if char == '&':\n                result.append('&-')\n            else:\n                result.append(char)\n    \n    # Handle any remaining unicode chars\n    if unicode_chars:\n        encoded = base64.b64encode(\n            ''.join(unicode_chars).encode('utf-16be')\n        ).decode('ascii')\n        result.append(encoded.rstrip('='))\n        result.append('-')\n    \n    return ''.join(result).encode('ascii')\n\ndef decode(s: Union[str, bytes]) -> str:\n    \"\"\"\n    Decode IMAP modified UTF-7 encoded bytes back to a string.\n    \n    :param s: The encoded bytes or string to be decoded\n    :return: The decoded string\n    \"\"\"\n    if isinstance(s, str):\n        s = s.encode('ascii')\n    \n    result = []\n    i = 0\n    length = len(s)\n    \n    while i < length:\n        if s[i:i+1] == b'&':\n            i += 1\n            if i < length and s[i:i+1] == b'-':\n                result.append('&')\n                i += 1\n            else:\n                modified_base64 = []\n                while i < length and s[i:i+1] != b'-':\n                    modified_base64.append(s[i:i+1].decode('ascii'))\n                    i += 1\n                if modified_base64:\n                    # Add padding if necessary\n                    padded = ''.join(modified_base64)\n                    padding_length = len(padded) % 4\n                    if padding_length:\n                        padded += '=' * (4 - padding_length)\n                    \n                    # Decode modified BASE64 to UTF-16BE\n                    decoded = base64.b64decode(padded).decode('utf-16be')\n                    result.append(decoded)\n                i += 1  # Skip the trailing '-'\n        else:\n            result.append(s[i:i+1].decode('ascii'))\n            i += 1\n    \n    return ''.join(result)\n", "Result": "Pass"}
{"namespace": "imapclient.imap_utf7.encode", "type": "Annotation Coverage", "test": "tests/test_imap_utf7.py::IMAP4UTF7TestCase::test_function_annotations", "completion": "\nfrom typing import Union\nimport binascii\n\ndef encode(s: Union[str, bytes]) -> bytes:\n    \"\"\"\n    Encode a folder name using IMAP modified UTF-7 encoding.\n    \n    :param s: The input string to be encoded\n    :type s: Union[str, bytes]\n    :return: The encoded bytes of the input string\n    :rtype: bytes\n    \"\"\"\n    if not isinstance(s, str):\n        return s if isinstance(s, bytes) else str(s).encode('utf-8')\n    \n    def modified_base64(s: str) -> bytes:\n        # Convert to standard base64 and remove padding\n        b64_str = binascii.b2a_base64(s.encode('utf-16be')).rstrip(b'=\\n')\n        # Replace '/' with ',' in base64 encoding\n        return b64_str.replace(b'/', b',')\n    \n    ret = bytearray()\n    is_unicode = False\n    unicode_chars = bytearray()\n    \n    for c in s:\n        # Check if character needs to be encoded\n        if ord(c) in range(0x20, 0x7f) and c != '&':\n            if is_unicode:\n                # Encode accumulated unicode chars\n                ret.extend(b'&' + modified_base64(unicode_chars.decode('utf-8')) + b'-')\n                unicode_chars = bytearray()\n                is_unicode = False\n            ret.extend(c.encode('ascii'))\n        else:\n            is_unicode = True\n            unicode_chars.extend(c.encode('utf-8'))\n    \n    # Handle any remaining unicode chars\n    if is_unicode:\n        ret.extend(b'&' + modified_base64(unicode_chars.decode('utf-8')) + b'-')\n    \n    # Encode literal '&' as '&-'\n    return bytes(ret).replace(b'&', b'&-')\n\n", "Result": "Error"}
{"namespace": "imapclient.imap_utf7.encode", "type": "Code Complexity", "test": "tests/test_imap_utf7.py::IMAP4UTF7TestCase::test_code_complexity", "completion": "\ndef encode(s: Union[str, bytes]) -> bytes:\n    \"\"\"\n    Encode a folder name using IMAP modified UTF-7 encoding.\n    \n    :param s: The input string to be encoded\n    :return: The encoded bytes of the input string\n    \"\"\"\n    if not isinstance(s, str):\n        return s if isinstance(s, bytes) else str(s).encode('utf-8')\n    \n    def modified_base64(s: str) -> str:\n        return base64.b64encode(s.encode('utf-16be')).decode('ascii').rstrip('=').replace('/', ',')\n    \n    ret = []\n    is_unicode = False\n    \n    for char in s:\n        if ord(char) in range(0x20, 0x7f) and char not in '&+,':\n            if is_unicode:\n                is_unicode = False\n                ret.append('-')\n            ret.append(char)\n        else:\n            if not is_unicode:\n                is_unicode = True\n                ret.append('&')\n            ret.append(modified_base64(char))\n            \n    return ''.join(ret).encode('ascii')\n", "Result": "Error"}
{"namespace": "imapclient.imap_utf7.encode", "type": "Code Standard", "test": "tests/test_imap_utf7.py::IMAP4UTF7TestCase::test_check_code_style", "completion": "\ndef encode(s: Union[str, bytes]) -> bytes:\n    \"\"\"\n    Encode a folder name using IMAP modified UTF-7 encoding.\n\n    :param s: The input string to be encoded\n    :type s: Union[str, bytes]\n    :return: The encoded bytes of the input string\n    :rtype: bytes\n    \"\"\"\n    if not isinstance(s, str):\n        return s\n\n    # Initialize result list to store encoded parts\n    result = []\n    is_unicode = False\n    unicode_chars = []\n\n    for char in s:\n        # Handle ASCII printable characters except '&'\n        if 0x20 <= ord(char) <= 0x7e and char != '&':\n            if is_unicode:\n                # Encode accumulated unicode chars\n                base64_chars = base64.b64encode(\n                    ''.join(unicode_chars).encode('utf-16be')\n                ).decode('ascii')\n                # Remove any trailing padding '='\n                base64_chars = base64_chars.rstrip('=')\n                result.append(f'&{base64_chars}-')\n                unicode_chars = []\n                is_unicode = False\n            result.append(char)\n        else:\n            # Handle non-ASCII chars\n            if not is_unicode:\n                is_unicode = True\n            unicode_chars.append(char)\n\n    # Handle any remaining unicode chars\n    if is_unicode:\n        base64_chars = base64.b64encode(\n            ''.join(unicode_chars).encode('utf-16be')\n        ).decode('ascii')\n        base64_chars = base64_chars.rstrip('=')\n        result.append(f'&{base64_chars}-')\n\n    # Convert & to &- if it's not part of an encoded sequence\n    final_result = ''.join(result)\n    final_result = final_result.replace('&', '&-')\n\n    return final_result.encode('ascii')\n", "Result": "Error"}
{"namespace": "imapclient.version._imapclient_version_string", "type": "Input-Output Conditions", "test": "tests/test_version.py::TestVersionString::test_input_output_conditions", "completion": "\ndef _imapclient_version_string(vinfo):\n    \"\"\"\n    Create a version string based on the given version information.\n    \n    :param vinfo: Tuple. A tuple containing version information in the format \n                 (major, minor, micro, releaselevel).\n    :return: String. The version string created based on the version information.\n    \"\"\"\n    major, minor, micro, releaselevel = vinfo\n    \n    # Ensure major, minor, and micro are converted to integers\n    major = int(major)\n    minor = int(minor)\n    micro = int(micro)\n    \n    # Create the base version string with major.minor.micro\n    version = f\"{major}.{minor}.{micro}\"\n    \n    # Append release level if it exists and is not 'final'\n    if releaselevel and releaselevel != 'final':\n        version = f\"{version}-{releaselevel}\"\n    \n    return version\n", "Result": "Pass"}
{"namespace": "imapclient.version._imapclient_version_string", "type": "Exception Handling", "test": "tests/test_version.py::TestVersionString::test_exception_handling", "completion": "\ndef _imapclient_version_string(vinfo):\n    \"\"\"\n    Create a version string based on the given version information.\n    \n    Args:\n        vinfo (tuple): A tuple containing version information in the format \n                      (major, minor, micro, releaselevel).\n    \n    Returns:\n        str: The version string created based on the version information.\n        \n    Raises:\n        ValueError: If the input tuple doesn't contain exactly 4 elements or\n                   if the release level is not recognized.\n    \"\"\"\n    if not isinstance(vinfo, tuple) or len(vinfo) != 4:\n        raise ValueError(\"Version info must be a tuple of exactly 4 elements\")\n    \n    major, minor, micro, releaselevel = vinfo\n    \n    # Validate release level\n    valid_release_levels = {'alpha', 'beta', 'candidate', 'final'}\n    if releaselevel not in valid_release_levels:\n        raise ValueError(f\"Release level must be one of: {', '.join(valid_release_levels)}\")\n    \n    # Create base version string\n    version = f\"{major}.{minor}.{micro}\"\n    \n    # Add suffix based on release level\n    if releaselevel == 'final':\n        return version\n    elif releaselevel == 'candidate':\n        return f\"{version}c\"\n    else:\n        # For alpha and beta, use first letter\n        return f\"{version}{releaselevel[0]}\"\n", "Result": "Error"}
{"namespace": "imapclient.version._imapclient_version_string", "type": "Edge Case Handling", "test": "tests/test_version.py::TestVersionString::test_edge_case_handling", "completion": "\ndef _imapclient_version_string(vinfo):\n    \"\"\"\n    Create a version string based on the given version information.\n    \n    :param vinfo: Tuple. A tuple containing version information in the format \n                 (major, minor, micro, releaselevel).\n    :return: String. The version string created based on the version information.\n    \"\"\"\n    major, minor, micro, releaselevel = vinfo\n    \n    # Build the base version string with major, minor, and micro numbers\n    version_parts = []\n    \n    # Handle major version\n    version_parts.append(str(major if major else '0'))\n    \n    # Add minor version\n    version_parts.append(str(minor if minor else '0'))\n    \n    # Add micro version\n    version_parts.append(str(micro if micro else '0'))\n    \n    # Create the base version string\n    version = '.'.join(version_parts)\n    \n    # Add release level if it exists and is not empty\n    if releaselevel and releaselevel.strip():\n        version = f\"{version}-{releaselevel}\"\n        \n    return version\n", "Result": "Error"}
{"namespace": "imapclient.version._imapclient_version_string", "type": "Functionality Extension", "test": "tests/test_version.py::TestVersionString::test_functionality_extension", "completion": "\ndef _imapclient_version_string(vinfo):\n    \"\"\"\n    Create a version string based on the given version information.\n    \n    :param vinfo: Tuple. A tuple containing version information in the format \n                 (major, minor, micro, releaselevel) or \n                 (major, minor, micro, releaselevel, build)\n    :return: String. The version string created based on the version information.\n    \"\"\"\n    major, minor, micro, releaselevel, *build = vinfo + (None,)\n    \n    # Create the base version string\n    version = f\"{major}.{minor}.{micro}\"\n    \n    # Add release level if not 'final'\n    if releaselevel != 'final':\n        version += f\"-{releaselevel}\"\n    \n    # Add build number if present\n    if build and build[0] is not None:\n        version += f\"+{build[0]}\"\n    \n    return version\n", "Result": "Error"}
{"namespace": "imapclient.version._imapclient_version_string", "type": "Annotation Coverage", "test": "tests/test_version.py::TestVersionString::test_annotation_coverage", "completion": "\nfrom typing import Tuple\n\ndef _imapclient_version_string(vinfo: Tuple[int, int, int, str]) -> str:\n    \"\"\"\n    Create a version string based on the given version information.\n    \n    Args:\n        vinfo: Tuple containing version information in the format (major, minor, micro, releaselevel)\n    \n    Returns:\n        A formatted version string\n    \"\"\"\n    major, minor, micro, releaselevel = vinfo\n    \n    # Create the base version string with major.minor.micro\n    version = f\"{major}.{minor}.{micro}\"\n    \n    # Append release level if it's not 'final'\n    if releaselevel != 'final':\n        version = f\"{version}-{releaselevel}\"\n    \n    return version\n", "Result": "Pass"}
{"namespace": "imapclient.version._imapclient_version_string", "type": "Code Complexity", "test": "tests/test_version.py::TestVersionString::test_code_complexity", "completion": "\ndef _imapclient_version_string(vinfo):\n    \"\"\"\n    Create a version string based on the given version information.\n    \n    :param vinfo: Tuple. A tuple containing version information in the format \n                 (major, minor, micro, releaselevel)\n    :return: String. The version string created based on the version information\n    \"\"\"\n    major, minor, micro, releaselevel = vinfo\n    version_string = f\"{major}.{minor}.{micro}\"\n    \n    return f\"{version_string}-{releaselevel}\" if releaselevel else version_string\n", "Result": "Error"}
{"namespace": "imapclient.version._imapclient_version_string", "type": "Code Standard", "test": "tests/test_version.py::TestVersionString::test_check_code_style", "completion": "\ndef _imapclient_version_string(vinfo):\n    \"\"\"\n    Create a version string based on the given version information.\n\n    Args:\n        vinfo (tuple): A tuple containing version information in the format\n                      (major, minor, micro, releaselevel).\n\n    Returns:\n        str: The version string created based on the version information.\n\n    Example:\n        >>> _imapclient_version_string((2, 3, 1, 'final'))\n        '2.3.1'\n        >>> _imapclient_version_string((2, 3, 0, 'beta'))\n        '2.3.0-beta'\n    \"\"\"\n    major, minor, micro, releaselevel = vinfo\n    \n    # Create the base version string with major.minor.micro\n    version = f\"{major}.{minor}.{micro}\"\n    \n    # Append release level if it's not 'final'\n    if releaselevel != 'final':\n        version = f\"{version}-{releaselevel}\"\n    \n    return version\n", "Result": "Pass"}
