[
    {
        "namespace": "benedict.utils.type_util.is_json_serializable",
        "type": "Input-Output Conditions",
        "test": "tests/utils/test_type_util.py::type_util_test_case::test_input_output_conditions",
        "completion": "I'll help you create a function to check JSON serializability. Here's the implementation:\n\n```python\ndef is_json_serializable(val: Any) -> bool:\n    \"\"\"\n    Check if the input value is JSON serializable.\n    \n    :param val: Any. The input value to be checked for JSON serializability\n    :return: Bool. True if the input value is JSON serializable, False otherwise\n    \"\"\"\n    # Handle None case\n    if val is None:\n        return True\n    \n    # Basic JSON serializable types\n    if isinstance(val, (bool, int, float, str)):\n        return True\n    \n    # Handle lists and tuples\n    if isinstance(val, (list, tuple)):\n        return all(is_json_serializable(item) for item in val)\n    \n    # Handle dictionaries\n    if isinstance(val, dict):\n        return all(isinstance(k, str) and is_json_serializable(v) for k, v in val.items())\n    \n    # All other types are not JSON serializable\n    return False\n```\n\nThis implementation:\n\n1. Takes any input value and returns a boolean\n2. Handles all basic JSON serializable types:\n   - None\n   - bool\n   - int\n   - float\n   - str\n   - lists and tuples (recursively checks their contents)\n   - dictionaries (ensures keys are strings and recursively checks values)\n3. Returns False for non-serializable types like sets, complex numbers, and custom objects\n\nYou can use it like this:\n\n```python\n# Examples of usage\nprint(is_json_serializable(42))           # True\nprint(is_json_serializable(\"hello\"))      # True\nprint(is_json_serializable([1, 2, 3]))    # True\nprint(is_json_serializable({\"a\": 1}))     # True\nprint(is_json_serializable({1: \"a\"}))     # False (non-string key)\nprint(is_json_serializable({1, 2, 3}))    # False (set)\nprint(is_json_serializable(complex(1,2))) # False\n```\n\nNote: Don't forget to add the type hint import at the top of your file:\n\n```python\nfrom typing import Any\n```\n\nThis function recursively checks nested structures and ensures that all elements within lists, tuples, and dictionaries are also JSON serializable. It specifically checks that dictionary keys are strings, as JSON only allows string keys."
    },
    {
        "namespace": "benedict.utils.type_util.is_json_serializable",
        "type": "Exception Handling",
        "test": "tests/utils/test_type_util.py::type_util_test_case::test_exception_handling",
        "completion": "I'll help you create a function that checks if a value is JSON serializable. I'll create a new file called `json_utils.py` with the implementation.\n\n```python\nimport json\nfrom typing import Any\n\ndef is_json_serializable(val: Any) -> bool:\n    \"\"\"\n    Check if the input value is JSON serializable.\n    \n    :param val: Any - The input value to be checked for JSON serializability\n    :return: Bool - True if the input value is JSON serializable, False otherwise\n    \"\"\"\n    try:\n        json.dumps(val)\n        return True\n    except (TypeError, OverflowError, ValueError):\n        return False\n```\n\nThis implementation:\n\n1. Takes any input value through the `val` parameter\n2. Uses `json.dumps()` to attempt serialization\n3. Catches common exceptions that occur during JSON serialization:\n   - `TypeError`: For non-serializable types\n   - `OverflowError`: For numbers that are too large\n   - `ValueError`: For other invalid values\n4. Returns `True` if serialization succeeds, `False` if it fails\n\nYou can use this function like this:\n\n```python\n# Example usage\nprint(is_json_serializable({\"name\": \"John\", \"age\": 30}))  # True\nprint(is_json_serializable(lambda x: x))  # False\nprint(is_json_serializable(set([1, 2, 3])))  # False\nprint(is_json_serializable([1, \"string\", 3.14]))  # True\n```\n\nThe function will handle all types of inputs safely and return the appropriate boolean value without raising any unexpected errors."
    },
    {
        "namespace": "benedict.utils.type_util.is_json_serializable",
        "type": "Edge Case Handling",
        "test": "tests/utils/test_type_util.py::type_util_test_case::test_edge_case_handling",
        "completion": "I'll help you create a function that checks if a value is JSON serializable. I'll create a new file called `json_utils.py` with the implementation.\n\n```python\ndef is_json_serializable(val: Any) -> bool:\n    \"\"\"\n    Check if the input value is JSON serializable.\n    \n    :param val: Any. The input value to be checked for JSON serializability.\n    :return: Bool. True if the input value is JSON serializable, False otherwise.\n    \"\"\"\n    # Handle None case\n    if val is None:\n        return True\n    \n    # Handle basic JSON serializable types\n    if isinstance(val, (bool, int, float, str)):\n        return True\n    \n    # Handle collections\n    if isinstance(val, (list, tuple)):\n        return all(is_json_serializable(item) for item in val)\n    \n    if isinstance(val, dict):\n        # Check if all keys are strings (JSON requirement)\n        if not all(isinstance(key, str) for key in val.keys()):\n            return False\n        # Check if all values are serializable\n        return all(is_json_serializable(value) for value in val.values())\n    \n    # Handle non-serializable types\n    return False\n```\n\nThis implementation:\n\n1. Takes any input value and returns a boolean\n2. Handles basic JSON serializable types:\n   - None\n   - bool\n   - int\n   - float\n   - str\n3. Recursively checks collections:\n   - lists\n   - tuples\n   - dictionaries (ensuring keys are strings)\n4. Returns True for empty collections ([], (), {})\n5. Returns False for non-serializable types (like functions, classes, complex numbers, etc.)\n\nYou would need to add the following import at the top of the file:\n\n```python\nfrom typing import Any\n```\n\nYou can use this function like this:\n\n```python\n# Examples\nprint(is_json_serializable(None))          # True\nprint(is_json_serializable(\"\"))            # True\nprint(is_json_serializable([]))            # True\nprint(is_json_serializable(()))            # True\nprint(is_json_serializable({}))            # True\nprint(is_json_serializable([1, \"2\", 3.0])) # True\nprint(is_json_serializable(lambda x: x))   # False\nprint(is_json_serializable({1: \"value\"}))  # False (non-string key)\n```"
    },
    {
        "namespace": "benedict.utils.type_util.is_json_serializable",
        "type": "Functionality Extension",
        "test": "tests/utils/test_type_util.py::type_util_test_case::test_functionality_extension",
        "completion": "I'll help you create a function that checks if a value is JSON serializable, with special handling for numpy types.\n\n```python\ndef is_json_serializable(val: Any) -> bool:\n    \"\"\"\n    Check if the input value is JSON serializable.\n    \n    :param val: Any. The input value to be checked for JSON serializability\n    :return: Bool. True if the input value is JSON serializable, False otherwise\n    \"\"\"\n    # Handle None, which is JSON serializable\n    if val is None:\n        return True\n    \n    # Basic JSON serializable types\n    json_types = (bool, int, float, str)\n    \n    # Check if value is of basic JSON serializable type\n    if isinstance(val, json_types):\n        return True\n    \n    # Check for numpy types if numpy is available\n    try:\n        import numpy as np\n        if isinstance(val, (np.ndarray, np.generic)):\n            return False\n    except ImportError:\n        pass\n    \n    # Handle lists and dictionaries by checking their contents\n    if isinstance(val, (list, tuple)):\n        return all(is_json_serializable(item) for item in val)\n    \n    if isinstance(val, dict):\n        return all(isinstance(k, str) and is_json_serializable(v) \n                  for k, v in val.items())\n    \n    # If none of the above conditions are met, the value is not JSON serializable\n    return False\n```\n\nThis function:\n\n1. First checks for `None`, which is JSON serializable\n2. Checks if the value is one of the basic JSON serializable types (bool, int, float, str)\n3. Handles numpy types by checking if the value is either a numpy array or numpy scalar (returning False in both cases)\n4. Recursively checks lists/tuples and dictionaries to ensure all their contents are also JSON serializable\n5. For dictionaries, ensures all keys are strings (as required by JSON)\n6. Returns False for any other types\n\nYou can use it like this:\n\n```python\n# Example usage\nimport numpy as np\n\n# Basic types\nprint(is_json_serializable(42))          # True\nprint(is_json_serializable(\"hello\"))     # True\nprint(is_json_serializable(3.14))        # True\nprint(is_json_serializable(None))        # True\n\n# Numpy types\nprint(is_json_serializable(np.array([1, 2, 3])))  # False\nprint(is_json_serializable(np.int64(5)))          # False\n\n# Nested structures\nprint(is_json_serializable({\"a\": 1, \"b\": [2, 3]}))  # True\nprint(is_json_serializable({\"a\": np.array([1])}))   # False\n```\n\nThe function handles all basic JSON types, nested structures, and specifically returns False for numpy arrays and scalars. It's also safe to use even if numpy is not installed, as it wraps the numpy-specific checks in a try-except block."
    },
    {
        "namespace": "benedict.utils.type_util.is_json_serializable",
        "type": "Annotation Coverage",
        "test": "tests/utils/test_type_util.py::type_util_test_case::test_annotation_coverage",
        "completion": "I'll help you create a Python function that checks if a value is JSON serializable. I'll create this in a new file called `json_utils.py`.\n\n```python\nfrom typing import Any\nimport json\n\ndef is_json_serializable(val: Any) -> bool:\n    \"\"\"\n    Check if the input value is JSON serializable.\n    \n    Args:\n        val (Any): The input value to be checked for JSON serializability\n        \n    Returns:\n        bool: True if the input value is JSON serializable, False otherwise\n    \"\"\"\n    try:\n        json.dumps(val)\n        return True\n    except (TypeError, OverflowError):\n        return False\n```\n\nThis function:\n\n1. Uses type hints with `Any` for the input parameter and `bool` for the return type\n2. Includes a clear docstring explaining the purpose and parameters\n3. Uses `json.dumps()` to attempt serialization\n4. Catches both `TypeError` (for non-serializable types) and `OverflowError` (for numbers that are too large)\n5. Returns `True` if serialization succeeds, `False` otherwise\n\nYou can use this function like this:\n\n```python\n# Example usage:\nprint(is_json_serializable(\"hello\"))  # True\nprint(is_json_serializable(42))       # True\nprint(is_json_serializable([1, 2, 3]))  # True\nprint(is_json_serializable({\"a\": 1}))   # True\nprint(is_json_serializable(set([1, 2]))) # False\nprint(is_json_serializable(lambda x: x)) # False\n```\n\nThe function will return `True` for basic JSON-serializable types like:\n- strings\n- numbers (int, float)\n- lists\n- dictionaries\n- booleans\n- None\n\nAnd `False` for non-serializable types like:\n- sets\n- functions\n- custom class objects\n- complex numbers\n- etc."
    },
    {
        "namespace": "benedict.utils.type_util.is_json_serializable",
        "type": "Code Complexity",
        "test": "tests/utils/test_type_util.py::type_util_test_case::test_code_complexity",
        "completion": "I'll help you create a simple and clean `is_json_serializable` function that checks for JSON serializability while maintaining a cyclomatic complexity of 1.\n\n```python\ndef is_json_serializable(val: Any) -> bool:\n    \"\"\"\n    Check if the input value is JSON serializable.\n    \n    :param val: Any - The input value to be checked for JSON serializability\n    :return: Bool - True if the input value is JSON serializable, False otherwise\n    \"\"\"\n    try:\n        json.dumps(val)\n        return True\n    except (TypeError, OverflowError):\n        return False\n```\n\nThis implementation:\n\n1. Uses a simple try-except block to maintain a cyclomatic complexity of 1\n2. Attempts to serialize the input value using `json.dumps()`\n3. Returns `True` if serialization succeeds\n4. Catches both `TypeError` (for non-serializable types) and `OverflowError` (for numbers that are too large)\n5. Returns `False` if any exception is caught\n\nDon't forget to add the import at the top of the file:\n\n```python\nimport json\nfrom typing import Any\n```\n\nThis function will correctly identify JSON serializable values including:\n- Dictionaries\n- Lists\n- Strings\n- Numbers (int, float)\n- Boolean values\n- None\n\nAnd will return False for non-serializable values like:\n- Functions\n- Complex objects\n- Sets\n- Custom class instances\n- Datetime objects (unless converted to string first)"
    },
    {
        "namespace": "benedict.utils.type_util.is_json_serializable",
        "type": "Code Standard",
        "test": "tests/utils/test_type_util.py::type_util_test_case::test_check_code_style",
        "completion": "I'll help you create a function to check JSON serializability. Here's the implementation:\n\n```python\ndef is_json_serializable(val: Any) -> bool:\n    \"\"\"\n    Check if the input value is JSON serializable.\n\n    :param val: Any\n        The input value to be checked for JSON serializability\n    :return: bool\n        True if the input value is JSON serializable, False otherwise\n    \"\"\"\n    try:\n        json.dumps(val)\n        return True\n    except (TypeError, OverflowError):\n        return False\n```\n\nLet me explain the implementation:\n\n1. The function takes a single parameter `val` of type `Any` and returns a boolean\n2. We use type hints for better code readability and IDE support\n3. The function includes a proper docstring following PEP 257 conventions\n4. The implementation uses a try-except block to attempt JSON serialization:\n   - If successful, returns `True`\n   - If it fails with TypeError (for non-serializable types) or OverflowError (for numbers that are too large), returns `False`\n\nTo use this function, you'll need to import the `json` module at the top of your file:\n\n```python\nfrom typing import Any\nimport json\n```\n\nExample usage:\n\n```python\n# These will return True\nprint(is_json_serializable(42))  # Numbers\nprint(is_json_serializable(\"Hello\"))  # Strings\nprint(is_json_serializable([1, 2, 3]))  # Lists\nprint(is_json_serializable({\"key\": \"value\"}))  # Dictionaries\nprint(is_json_serializable(None))  # None\n\n# These will return False\nprint(is_json_serializable(set([1, 2, 3])))  # Sets\nprint(is_json_serializable(lambda x: x))  # Functions\nprint(is_json_serializable(complex(1, 2)))  # Complex numbers\n```\n\nThe function follows PEP 8 standards with:\n- Proper indentation (4 spaces)\n- Clear, descriptive function name in snake_case\n- Appropriate spacing around operators and after commas\n- Informative docstring with parameter and return value descriptions"
    },
    {
        "namespace": "feedparser.urls.convert_to_idn",
        "type": "Exception Handling",
        "test": "tests/runtests.py::TestConvertToIdn::test_exception_handling_invalid_url",
        "completion": "I'll help you create a Python function that converts URLs to IDN notation. Here's the implementation:\n\n```python\nfrom urllib.parse import urlparse, urlunparse\nimport idna\n\ndef convert_to_idn(url: str) -> str:\n    \"\"\"\n    Convert a URL to IDN notation.\n    \n    Args:\n        url (str): The URL to be converted to IDN notation\n        \n    Returns:\n        str: The URL in IDN notation\n        \n    Raises:\n        ValueError: If the input is not a valid URL string\n        UnicodeError: If conversion to IDN fails\n    \"\"\"\n    if not isinstance(url, str):\n        raise ValueError(\"URL must be a string\")\n    \n    try:\n        # Parse the URL into components\n        parsed = urlparse(url)\n        \n        if not parsed.netloc:\n            raise ValueError(\"Invalid URL: no host found\")\n        \n        # Split host into parts (handling potential subdomains)\n        host_parts = parsed.hostname.split('.')\n        \n        # Convert each part to IDN if necessary\n        idn_parts = []\n        for part in host_parts:\n            # Check if part needs conversion (contains non-ASCII characters)\n            if not part.isascii():\n                try:\n                    idn_parts.append(idna.encode(part).decode('ascii'))\n                except idna.IDNAError as e:\n                    raise UnicodeError(f\"IDN conversion failed: {str(e)}\")\n            else:\n                idn_parts.append(part)\n        \n        # Reconstruct the host\n        new_host = '.'.join(idn_parts)\n        \n        # Reconstruct the URL with the new host\n        new_components = parsed._replace(netloc=new_host)\n        if parsed.port:\n            new_components = new_components._replace(netloc=f\"{new_host}:{parsed.port}\")\n        \n        return urlunparse(new_components)\n        \n    except Exception as e:\n        if isinstance(e, UnicodeError):\n            raise\n        raise ValueError(f\"Invalid URL: {str(e)}\")\n```\n\nThis implementation:\n\n1. Uses `urllib.parse` for URL parsing and `idna` for IDN conversion\n2. Takes a URL string as input and returns the converted URL string\n3. Handles both ASCII and non-ASCII domains\n4. Preserves all URL components (scheme, path, query parameters, etc.)\n5. Handles subdomains correctly\n6. Preserves port numbers if present\n7. Includes proper error handling for invalid URLs and IDN conversion failures\n\nExample usage:\n\n```python\n# ASCII URL (no change needed)\nprint(convert_to_idn('https://example.com'))  \n# Output: https://example.com\n\n# Non-ASCII URL\nprint(convert_to_idn('https://m\u00fcnchen.de'))  \n# Output: https://xn--mnchen-3ya.de\n\n# Invalid URL\ntry:\n    convert_to_idn('not_a_url')  # Raises ValueError\nexcept ValueError as e:\n    print(e)\n\n# Invalid IDN conversion\ntry:\n    convert_to_idn('https://\u2603.com')  # Raises UnicodeError\nexcept UnicodeError as e:\n    print(e)\n```\n\nTo use this function, you'll need to install the `idna` package:\n\n```bash\npip install idna\n```\n\nThe function handles several edge cases:\n- Invalid URL formats\n- URLs with ports\n- URLs with subdomains\n- URLs with query parameters and fragments\n- Non-string inputs\n- Invalid IDN conversions"
    },
    {
        "namespace": "feedparser.urls.convert_to_idn",
        "type": "Edge Case Handling",
        "test": "tests/runtests.py::TestConvertToIdn::test_edge_case_empty_string",
        "completion": "I'll help you create a Python function that converts URLs to IDN notation. Here's the implementation:\n\n```python\nfrom urllib.parse import urlparse, urlunparse\nimport re\n\ndef convert_to_idn(url):\n    \"\"\"\n    Convert a URL to IDN notation.\n    \n    Args:\n        url (str): The URL to be converted to IDN notation\n        \n    Returns:\n        str: The URL in IDN notation\n        \n    Examples:\n        >>> convert_to_idn(\"https://\u4f8b\u5b50.com/path\")\n        'https://xn--fsq.com/path'\n        >>> convert_to_idn(\"https://example.com\")\n        'https://example.com'\n    \"\"\"\n    if not url:\n        return url\n        \n    # Try to parse the URL\n    try:\n        parsed = urlparse(url)\n    except ValueError:\n        return url\n        \n    # If there's no netloc (host), return original URL\n    if not parsed.netloc:\n        return url\n        \n    # Check if the host is an IP address\n    ip_pattern = r'^(?:[0-9]{1,3}\\.){3}[0-9]{1,3}$'\n    if re.match(ip_pattern, parsed.netloc):\n        return url\n        \n    try:\n        # Convert the host to IDN notation\n        idn_host = parsed.netloc.encode('idna').decode('ascii')\n        \n        # Create a new parsed result with the IDN host\n        idn_parts = parsed._replace(netloc=idn_host)\n        \n        # Convert back to URL string\n        return urlunparse(idn_parts)\n    except UnicodeError:\n        # If conversion fails, return original URL\n        return url\n```\n\nThis implementation:\n\n1. Takes a URL string as input\n2. Handles several edge cases:\n   - Empty strings (returns the input as-is)\n   - Invalid URLs (returns the input as-is)\n   - URLs without hosts (returns the input as-is)\n   - IP addresses (returns the input as-is)\n3. Uses `urlparse` to break down the URL into components\n4. Converts the host portion to IDN notation using the `idna` encoding\n5. Reassembles the URL with the converted host\n\nHere's how to use it:\n\n```python\n# Examples\nprint(convert_to_idn(\"https://\u4f8b\u5b50.com/path\"))  # Output: https://xn--fsq.com/path\nprint(convert_to_idn(\"https://example.com\"))    # Output: https://example.com\nprint(convert_to_idn(\"https://192.168.1.1\"))    # Output: https://192.168.1.1\nprint(convert_to_idn(\"\"))                       # Output: \"\"\nprint(convert_to_idn(\"/local/path\"))            # Output: /local/path\n```\n\nThe function handles these cases:\n- International domain names (converts to Punycode)\n- ASCII domain names (leaves unchanged)\n- IP addresses (leaves unchanged)\n- Empty strings\n- Local paths without hosts\n- Invalid URLs\n\nIf any errors occur during the conversion process, the function safely returns the original URL instead of raising an exception."
    },
    {
        "namespace": "feedparser.urls.convert_to_idn",
        "type": "Functionality Extension",
        "test": "tests/runtests.py::TestConvertToIdn::test_functionality_extension_query_fragment",
        "completion": "I'll help you create a Python function that converts URLs to IDN notation while preserving query parameters and fragments.\n\n```python\nfrom urllib.parse import urlparse, urlunparse\nimport idna\n\ndef convert_to_idn(url: str) -> str:\n    \"\"\"\n    Convert a URL to IDN notation. Checks if the host can be encoded in ASCII.\n    If not, converts the host to IDN form while preserving query parameters and fragments.\n    \n    :param url: String. The URL to be converted to IDN notation\n    :return: String. The URL in IDN notation\n    \n    Example:\n        >>> convert_to_idn('https://\u4f8b\u5b50.com/path?param=value#fragment')\n        'https://xn--fsq.com/path?param=value#fragment'\n    \"\"\"\n    # Parse the URL into components\n    parsed = urlparse(url)\n    \n    # If there's no hostname, return the original URL\n    if not parsed.hostname:\n        return url\n    \n    try:\n        # Try to encode the hostname as ASCII to check if conversion is needed\n        parsed.hostname.encode('ascii')\n        return url\n    except UnicodeEncodeError:\n        # Convert hostname to IDN notation\n        idn_hostname = idna.encode(parsed.hostname).decode('ascii')\n        \n        # Reconstruct the netloc (username:password@hostname:port)\n        netloc_parts = []\n        if parsed.username:\n            netloc_parts.append(parsed.username)\n            if parsed.password:\n                netloc_parts.append(':' + parsed.password)\n            netloc_parts.append('@')\n        netloc_parts.append(idn_hostname)\n        if parsed.port:\n            netloc_parts.append(':' + str(parsed.port))\n        \n        # Create new parsed components with the IDN hostname\n        new_components = parsed._replace(netloc=''.join(netloc_parts))\n        \n        # Reconstruct the URL while preserving all components\n        return urlunparse(new_components)\n```\n\nThis implementation:\n\n1. Uses `urllib.parse` to properly handle URL components and `idna` for IDN conversion\n2. Preserves all URL components (scheme, username, password, port, path, query parameters, and fragments)\n3. Only converts the hostname portion of the URL\n4. Returns the original URL if no conversion is needed\n5. Handles edge cases like URLs without hostnames\n\nExample usage:\n\n```python\n# Example URLs\nprint(convert_to_idn('https://\u4f8b\u5b50.com/path?param=value#fragment'))\n# Output: https://xn--fsq.com/path?param=value#fragment\n\nprint(convert_to_idn('https://user:pass@\u4f8b\u5b50.test.com:8080/path?q=1#top'))\n# Output: https://user:pass@xn--fsq.test.com:8080/path?q=1#top\n\nprint(convert_to_idn('https://example.com/path'))  # Already ASCII\n# Output: https://example.com/path\n```\n\nMake sure to install the required `idna` package:\n```bash\npip install idna\n```\n\nThe function handles:\n- URLs with or without schemes\n- URLs with authentication (username/password)\n- URLs with ports\n- URLs with paths, query parameters, and fragments\n- Mixed ASCII/Unicode hostnames\n- Edge cases like local paths or invalid URLs"
    },
    {
        "namespace": "feedparser.urls.convert_to_idn",
        "type": "Annotation Coverage",
        "test": "tests/runtests.py::TestConvertToIdn::test_annotation_coverage",
        "completion": "I'll help you create a Python function that converts URLs to IDN notation with proper type hints and documentation.\n\n```python\nfrom typing import str\nfrom urllib.parse import urlparse, urlunparse\n\ndef convert_to_idn(url: str) -> str:\n    \"\"\"\n    Convert a URL to IDN notation. Checks if the host can be encoded in ASCII.\n    If not, converts the host to IDN form.\n\n    Args:\n        url (str): The URL to be converted to IDN notation\n\n    Returns:\n        str: The URL in IDN notation\n\n    Example:\n        >>> convert_to_idn(\"https://m\u00fcnchen.de\")\n        'https://xn--mnchen-3ya.de'\n    \"\"\"\n    # Parse the URL into components\n    parsed = urlparse(url)\n    \n    # Convert the hostname to IDN notation if needed\n    if parsed.hostname:\n        try:\n            # Try encoding the hostname to ASCII to check if conversion is needed\n            parsed.hostname.encode('ascii')\n        except UnicodeEncodeError:\n            # Convert to IDN notation if ASCII encoding fails\n            idn_hostname = parsed.hostname.encode('idna').decode('ascii')\n            # Reconstruct the netloc (may include port, username, password)\n            netloc_parts = parsed.netloc.split(parsed.hostname)\n            new_netloc = idn_hostname.join(netloc_parts)\n            # Create a new parsed result with the IDN hostname\n            parsed = parsed._replace(netloc=new_netloc)\n    \n    # Convert back to URL string\n    return urlunparse(parsed)\n```\n\nThis function does the following:\n\n1. Takes a URL string as input and returns a URL string with IDN notation\n2. Uses proper type hints for both parameter and return value\n3. Includes comprehensive docstring with description, args, returns, and example\n4. Uses `urlparse` to break down the URL into components\n5. Checks if the hostname needs conversion by attempting ASCII encoding\n6. Converts the hostname to IDN notation if needed using IDNA encoding\n7. Preserves other URL components (scheme, path, query, etc.)\n8. Reconstructs the URL with the converted hostname\n\nYou can use this function like this:\n\n```python\n# Example usage\nurl = \"https://m\u00fcnchen.de/path?query=test\"\nidn_url = convert_to_idn(url)\nprint(idn_url)  # Output: https://xn--mnchen-3ya.de/path?query=test\n```\n\nThe function handles various edge cases:\n- URLs without hostnames\n- URLs with ASCII-only hostnames (no conversion needed)\n- URLs with ports, usernames, or passwords in the netloc\n- Unicode hostnames that need conversion to IDN"
    },
    {
        "namespace": "feedparser.urls.convert_to_idn",
        "type": "Code Complexity",
        "test": "tests/runtests.py::TestConvertToIdn::test_code_complexity",
        "completion": "I'll help you create a Python function to convert URLs to IDN notation while keeping the cyclomatic complexity low.\n\nHere's the implementation:\n\n```python\nfrom urllib.parse import urlparse, urlunparse\nimport idna\n\ndef convert_to_idn(url: str) -> str:\n    \"\"\"\n    Convert a URL to IDN notation.\n    \n    Args:\n        url (str): The URL to be converted to IDN notation\n        \n    Returns:\n        str: The URL in IDN notation\n        \n    Example:\n        >>> convert_to_idn('https://m\u00fcnchen.de')\n        'https://xn--mnchen-3ya.de'\n    \"\"\"\n    # Parse the URL into components\n    parsed = urlparse(url)\n    \n    # If there's no hostname, return the original URL\n    if not parsed.hostname:\n        return url\n    \n    try:\n        # Convert the hostname to IDN notation\n        idn_hostname = idna.encode(parsed.hostname).decode('ascii')\n        \n        # Create a new named tuple with the converted hostname\n        converted = parsed._replace(netloc=parsed.netloc.replace(\n            parsed.hostname, idn_hostname))\n        \n        # Reconstruct the URL\n        return urlunparse(converted)\n        \n    except (UnicodeError, idna.IDNAError):\n        # Return original URL if conversion fails\n        return url\n```\n\nThis implementation:\n\n1. Uses `urlparse` to break down the URL into its components\n2. Checks if there's a hostname - if not, returns the original URL\n3. Attempts to convert the hostname to IDN notation using the `idna` library\n4. Reconstructs the URL with the converted hostname\n5. Handles potential encoding errors gracefully\n\nThe function maintains a cyclomatic complexity of 4 (there are only 4 possible paths through the code):\n1. No hostname \u2192 return original\n2. Has hostname, successful conversion \u2192 return converted\n3. Has hostname, UnicodeError \u2192 return original\n4. Has hostname, IDNAError \u2192 return original\n\nTo use this function, you'll need to install the `idna` package:\n```bash\npip install idna\n```\n\nExample usage:\n```python\n# Example with international domain\nresult = convert_to_idn('https://m\u00fcnchen.de')\nprint(result)  # Output: https://xn--mnchen-3ya.de\n\n# Example with ASCII domain (remains unchanged)\nresult = convert_to_idn('https://example.com')\nprint(result)  # Output: https://example.com\n```\n\nThe function is well-documented with docstrings and maintains clean error handling while keeping the complexity low. It handles both international and ASCII domains appropriately."
    },
    {
        "namespace": "feedparser.urls.convert_to_idn",
        "type": "Code Standard",
        "test": "tests/runtests.py::TestConvertToIdn::test_check_code_style",
        "completion": "I'll help you create a Python function to convert URLs to IDN notation. I'll create a new file called `url_converter.py` with the function implementation.\n\n```python\nfrom urllib.parse import urlparse, urlunparse\nimport idna\n\n\ndef convert_to_idn(url: str) -> str:\n    \"\"\"\n    Convert a URL to IDN notation.\n\n    This function checks if the host can be encoded in ASCII. If not,\n    it converts the host to IDN form.\n\n    Args:\n        url (str): The URL to be converted to IDN notation.\n\n    Returns:\n        str: The URL in IDN notation.\n\n    Example:\n        >>> convert_to_idn('https://m\u00fcnchen.de')\n        'https://xn--mnchen-3ya.de'\n    \"\"\"\n    # Parse the URL into components\n    parsed = urlparse(url)\n    \n    # If there's no hostname, return the original URL\n    if not parsed.netloc:\n        return url\n    \n    try:\n        # Try to encode the hostname as ASCII\n        parsed.netloc.encode('ascii')\n        return url\n    except UnicodeEncodeError:\n        # Convert the hostname to IDN notation\n        idn_hostname = idna.encode(parsed.netloc).decode('ascii')\n        \n        # Create a new parsed result with the IDN hostname\n        idn_parts = parsed._replace(netloc=idn_hostname)\n        \n        # Reconstruct the URL with the IDN hostname\n        return urlunparse(idn_parts)\n```\n\nThis implementation:\n\n1. Uses proper type hints for input and return values\n2. Includes comprehensive docstring following Google style guide\n3. Handles cases where the URL might not have a hostname\n4. Uses the `idna` package for proper IDN encoding\n5. Follows PEP 8 standards for formatting and naming\n6. Includes an example in the docstring\n\nTo use this function, you'll need to install the `idna` package:\n```bash\npip install idna\n```\n\nThe function will handle URLs like:\n- Regular URLs: `https://example.com`\n- Unicode URLs: `https://m\u00fcnchen.de`\n- URLs with subdomains: `https://subdomain.m\u00fcnchen.de`\n\nThe function will return:\n- The original URL if it's already ASCII-compatible\n- The IDN-encoded version if it contains non-ASCII characters in the hostname\n\nNote that this function only converts the hostname portion of the URL, leaving other components (path, query parameters, etc.) unchanged."
    },
    {
        "namespace": "googleapiclient._helpers.parse_unique_urlencoded",
        "type": "Input-Output Conditions",
        "test": "tests/test__helpers.py::Test_parse_unique_urlencoded::test_special_characters",
        "completion": "I'll help you create a function that parses URL-encoded content while ensuring unique keys.\n\n```python\ndef parse_unique_urlencoded(content: str) -> dict:\n    \"\"\"\n    Parse URL-encoded content into a dictionary, ensuring unique keys.\n    \n    Args:\n        content (str): URL-encoded key-value pairs (e.g. 'key1=value1&key2=value2')\n        \n    Returns:\n        dict: Dictionary containing the parsed key-value pairs\n        \n    Raises:\n        ValueError: If a duplicate key is found in the content\n    \"\"\"\n    from urllib.parse import parse_qs, unquote\n    \n    # Parse the URL-encoded content\n    parsed_content = parse_qs(content, keep_blank_values=True)\n    \n    # Check for duplicate keys\n    for key, value_list in parsed_content.items():\n        if len(value_list) > 1:\n            raise ValueError(f\"Duplicate key found: {key}\")\n    \n    # Convert the parsed content to a simple key-value dictionary\n    result = {key: unquote(value_list[0]) for key, value_list in parsed_content.items()}\n    \n    return result\n```\n\nThis function:\n\n1. Uses `urllib.parse.parse_qs` to parse the URL-encoded content into a dictionary where values are lists\n2. Checks for duplicate keys by looking at the length of each value list\n3. Converts the result into a simple key-value dictionary using dictionary comprehension\n4. Uses `unquote` to properly handle special characters in the values\n\nExample usage:\n```python\n# Valid input\nresult = parse_unique_urlencoded(\"name=John%20Doe&age=30\")\nprint(result)  # {'name': 'John Doe', 'age': '30'}\n\n# Will raise ValueError\nparse_unique_urlencoded(\"name=John&age=30&name=Jane\")  # ValueError: Duplicate key found: name\n```\n\nThe function handles:\n- URL-encoded special characters (e.g., spaces as %20)\n- Empty values\n- Proper error handling for duplicate keys\n- Type hints for better code documentation"
    },
    {
        "namespace": "googleapiclient._helpers.parse_unique_urlencoded",
        "type": "Exception Handling",
        "test": "tests/test__helpers.py::Test_parse_unique_urlencoded::test_repeated_key_error_message",
        "completion": "I'll help you create a function that parses URL-encoded content and ensures unique keys.\n\n```python\ndef parse_unique_urlencoded(content: str) -> dict:\n    \"\"\"\n    Parse URL-encoded content and ensure unique keys.\n    \n    Args:\n        content (str): URL-encoded key-value pairs\n        \n    Returns:\n        dict: Parsed key-value pairs\n        \n    Raises:\n        ValueError: If a duplicate key is encountered\n    \"\"\"\n    if not content:\n        return {}\n    \n    result = {}\n    pairs = content.split('&')\n    \n    for pair in pairs:\n        if not pair:\n            continue\n            \n        try:\n            key, value = pair.split('=', 1)\n        except ValueError:\n            # Handle cases where there's no '=' in the pair\n            key = pair\n            value = ''\n            \n        from urllib.parse import unquote\n        decoded_key = unquote(key)\n        decoded_value = unquote(value)\n        \n        if decoded_key in result:\n            raise ValueError(f\"Duplicate key found: '{decoded_key}'\")\n            \n        result[decoded_key] = decoded_value\n        \n    return result\n```\n\nThis implementation:\n\n1. Takes a URL-encoded string as input\n2. Returns an empty dict if the input is empty\n3. Splits the content on '&' to separate key-value pairs\n4. For each pair:\n   - Splits on '=' to separate key and value\n   - Handles cases where there's no value (treats as empty string)\n   - URL-decodes both key and value using urllib.parse.unquote\n   - Checks if the key already exists in the result dict\n   - Raises ValueError with a descriptive message if a duplicate key is found\n   - Adds the key-value pair to the result dict if the key is unique\n\nExample usage:\n\n```python\n# Valid input\nresult = parse_unique_urlencoded(\"name=John&age=30\")\nprint(result)  # {'name': 'John', 'age': '30'}\n\n# Will raise ValueError\nparse_unique_urlencoded(\"name=John&name=Jane\")  # ValueError: Duplicate key found: 'name'\n\n# Handles URL encoding\nresult = parse_unique_urlencoded(\"first%20name=John%20Doe&age=30\")\nprint(result)  # {'first name': 'John Doe', 'age': '30'}\n```"
    },
    {
        "namespace": "googleapiclient._helpers.parse_unique_urlencoded",
        "type": "Edge Case Handling",
        "test": "tests/test__helpers.py::Test_parse_unique_urlencoded::test_empty_content",
        "completion": "I'll help you create a function that parses URL-encoded content with unique keys. Here's the implementation:\n\n```python\ndef parse_unique_urlencoded(content: str) -> dict:\n    \"\"\"\n    Parse unique key-value parameters from URL-encoded content.\n    \n    Args:\n        content (str): URL-encoded key-value pairs\n        \n    Returns:\n        dict: The key-value pairs from the input content\n        \n    Raises:\n        ValueError: If one of the keys is repeated\n    \"\"\"\n    if not content:\n        return {}\n    \n    result = {}\n    pairs = content.split('&')\n    \n    for pair in pairs:\n        if not pair:\n            continue\n            \n        key_value = pair.split('=', 1)\n        if len(key_value) != 2:\n            continue\n            \n        key, value = key_value\n        if key in result:\n            raise ValueError(f\"Duplicate key found: {key}\")\n            \n        result[key] = value\n        \n    return result\n```\n\nThis implementation:\n\n1. Takes a string parameter `content` containing URL-encoded data\n2. Returns an empty dictionary if the input is empty\n3. Splits the content on '&' to separate key-value pairs\n4. For each pair:\n   - Splits on '=' to separate key and value\n   - Checks if the key already exists in the result dictionary\n   - Raises ValueError if a duplicate key is found\n   - Adds the key-value pair to the result dictionary\n5. Returns the dictionary with unique key-value pairs\n\nYou can use it like this:\n\n```python\n# Examples:\ncontent = \"name=John&age=30&city=NewYork\"\nresult = parse_unique_urlencoded(content)\nprint(result)  # {'name': 'John', 'age': '30', 'city': 'NewYork'}\n\n# Empty content\nresult = parse_unique_urlencoded(\"\")\nprint(result)  # {}\n\n# This will raise ValueError\ntry:\n    content = \"name=John&age=30&name=Jane\"\n    result = parse_unique_urlencoded(content)\nexcept ValueError as e:\n    print(e)  # Duplicate key found: name\n```\n\nThe function handles all the requirements:\n- Parses URL-encoded content\n- Checks for repeated keys\n- Raises ValueError for duplicate keys\n- Handles empty input\n- Returns a dictionary of key-value pairs"
    },
    {
        "namespace": "googleapiclient._helpers.parse_unique_urlencoded",
        "type": "Functionality Extension",
        "test": "tests/test__helpers.py::Test_parse_unique_urlencoded::test_ignore_empty_keys_and_values",
        "completion": "I'll help you create a Python function that parses URL-encoded content with unique keys, ignoring empty keys and values.\n\n```python\ndef parse_unique_urlencoded(content: str) -> dict:\n    \"\"\"\n    Parse unique key-value parameters from URL-encoded content.\n    Empty keys and values are ignored.\n    \n    Args:\n        content (str): URL-encoded key-value pairs\n        \n    Returns:\n        dict: The key-value pairs from the input content\n        \n    Raises:\n        ValueError: If one of the keys is repeated\n    \"\"\"\n    if not content:\n        return {}\n    \n    result = {}\n    # Split the content by '&' and process each pair\n    pairs = content.split('&')\n    \n    for pair in pairs:\n        # Skip empty pairs\n        if not pair:\n            continue\n            \n        # Split into key and value\n        parts = pair.split('=', 1)\n        \n        # Handle cases where there's no '=' or value\n        if len(parts) == 1:\n            key = parts[0]\n            value = ''\n        else:\n            key, value = parts\n            \n        # Skip if key is empty\n        if not key:\n            continue\n            \n        # Check for duplicate keys\n        if key in result:\n            raise ValueError(f\"Duplicate key found: {key}\")\n            \n        # Add to result if value is not empty\n        if value:\n            from urllib.parse import unquote\n            result[unquote(key)] = unquote(value)\n    \n    return result\n```\n\nThis function:\n\n1. Takes a URL-encoded string as input and returns a dictionary\n2. Handles empty input by returning an empty dictionary\n3. Splits the content by '&' to separate key-value pairs\n4. For each pair:\n   - Splits by '=' to separate key and value\n   - Skips empty keys\n   - Checks for duplicate keys\n   - Uses urllib.parse.unquote to decode URL-encoded characters\n   - Only adds pairs with non-empty values to the result\n5. Raises ValueError if duplicate keys are found\n\nExample usage:\n\n```python\n# Valid cases\nresult1 = parse_unique_urlencoded('name=John&age=30')\nprint(result1)  # {'name': 'John', 'age': '30'}\n\nresult2 = parse_unique_urlencoded('name=John&empty=&=value&&&age=30')\nprint(result2)  # {'name': 'John', 'age': '30'}\n\n# Will raise ValueError\ntry:\n    parse_unique_urlencoded('name=John&name=Jane')\nexcept ValueError as e:\n    print(e)  # Duplicate key found: name\n```\n\nThe function ignores:\n- Empty pairs (&&)\n- Empty keys (=value)\n- Empty values (key=)\n- Pairs without '=' separator\n\nIt properly handles URL-encoded characters and raises an error for duplicate keys."
    },
    {
        "namespace": "googleapiclient._helpers.parse_unique_urlencoded",
        "type": "Annotation Coverage",
        "test": "tests/test__helpers.py::Test_parse_unique_urlencoded::test_function_annotations",
        "completion": "I'll help you create a function that parses URL-encoded content with unique keys.\n\n```python\nfrom typing import Dict\nfrom urllib.parse import parse_qs\n\ndef parse_unique_urlencoded(content: str) -> Dict[str, str]:\n    \"\"\"\n    Parse unique key-value parameters from URL-encoded content.\n    \n    Args:\n        content: URL-encoded key-value pairs\n        \n    Returns:\n        A dictionary containing the key-value pairs from the input content\n        \n    Raises:\n        ValueError: If one of the keys is repeated\n    \"\"\"\n    # Parse the URL-encoded content into a dictionary\n    # parse_qs returns a dict with values as lists\n    parsed_dict = parse_qs(content, keep_blank_values=True)\n    \n    # Check for repeated keys by comparing the length of values\n    for key, values in parsed_dict.items():\n        if len(values) > 1:\n            raise ValueError(f\"Repeated key found: {key}\")\n    \n    # Convert the dictionary values from lists to single strings\n    result = {key: values[0] for key, values in parsed_dict.items()}\n    \n    return result\n```\n\nThis function:\n\n1. Uses type hints to specify the input parameter as `str` and return type as `Dict[str, str]`\n2. Uses `urllib.parse.parse_qs` to parse the URL-encoded content\n3. Checks for repeated keys by examining the length of value lists\n4. Raises a ValueError if any key is repeated\n5. Converts the parsed dictionary values from lists to single strings\n6. Returns the final dictionary with unique key-value pairs\n\nExample usage:\n\n```python\n# Valid input\nresult = parse_unique_urlencoded(\"name=John&age=30\")\nprint(result)  # {'name': 'John', 'age': '30'}\n\n# Invalid input (repeated key)\ntry:\n    result = parse_unique_urlencoded(\"name=John&name=Jane\")\nexcept ValueError as e:\n    print(e)  # Repeated key found: name\n```\n\nThe function handles URL-encoded content properly and ensures that each key appears only once in the input. If you need to use this function in your code, make sure to import the required types from the typing module."
    },
    {
        "namespace": "googleapiclient._helpers.parse_unique_urlencoded",
        "type": "Code Complexity",
        "test": "tests/test__helpers.py::Test_parse_unique_urlencoded::test_code_complexity",
        "completion": "I'll help you create a function that parses URL-encoded content while checking for unique keys. Here's the implementation:\n\n```python\nfrom urllib.parse import parse_qs\n\ndef parse_unique_urlencoded(content: str) -> dict:\n    \"\"\"\n    Parse unique key-value parameters from URL-encoded content.\n    \n    Args:\n        content: URL-encoded key-value pairs\n        \n    Returns:\n        dict: The key-value pairs from the input content\n        \n    Raises:\n        ValueError: If one of the keys is repeated\n    \"\"\"\n    # Parse the URL-encoded content into a dictionary\n    parsed_dict = parse_qs(content, keep_blank_values=True)\n    \n    # Check for repeated keys by comparing lengths\n    for key, values in parsed_dict.items():\n        if len(values) > 1:\n            raise ValueError(f\"Repeated key found: {key}\")\n    \n    # Convert the parsed dictionary to the desired format\n    # parse_qs returns values as lists, so we take the first item\n    return {key: values[0] for key, values in parsed_dict.items()}\n```\n\nThis implementation:\n\n1. Uses Python's built-in `urllib.parse.parse_qs` function to handle the URL-encoded content parsing\n2. Checks for repeated keys by examining the length of values for each key\n3. Returns a clean dictionary with single values instead of lists\n4. Maintains low cyclomatic complexity by using simple control structures\n\nExample usage:\n```python\n# Valid input\nresult = parse_unique_urlencoded(\"name=John&age=30\")\nprint(result)  # {'name': 'John', 'age': '30'}\n\n# Invalid input (repeated key)\ntry:\n    parse_unique_urlencoded(\"name=John&name=Jane\")\nexcept ValueError as e:\n    print(e)  # Repeated key found: name\n```\n\nThe function has a cyclomatic complexity of 3:\n1. Function entry\n2. For loop\n3. If condition inside the loop\n\nThis implementation is efficient, readable, and handles error cases appropriately while maintaining low complexity."
    },
    {
        "namespace": "googleapiclient._helpers.parse_unique_urlencoded",
        "type": "Code Standard",
        "test": "tests/test__helpers.py::Test_parse_unique_urlencoded::test_check_code_style",
        "completion": "I'll help you create a function that parses URL-encoded content while ensuring unique keys. Here's the implementation:\n\n```python\ndef parse_unique_urlencoded(content: str) -> dict:\n    \"\"\"\n    Parse unique key-value parameters from URL-encoded content.\n    \n    Args:\n        content (str): URL-encoded key-value pairs\n        \n    Returns:\n        dict: The key-value pairs from the input content\n        \n    Raises:\n        ValueError: If one of the keys is repeated\n    \"\"\"\n    if not content:\n        return {}\n    \n    result = {}\n    pairs = content.split('&')\n    \n    for pair in pairs:\n        if not pair:\n            continue\n            \n        try:\n            key, value = pair.split('=', 1)\n        except ValueError:\n            # Handle cases where there's no '=' in the pair\n            key, value = pair, ''\n        \n        # Check for duplicate keys\n        if key in result:\n            raise ValueError(f\"Duplicate key found: {key}\")\n            \n        result[key] = value\n        \n    return result\n```\n\nThis implementation:\n\n1. Takes a URL-encoded string as input and returns a dictionary\n2. Handles empty input by returning an empty dictionary\n3. Splits the content on '&' to separate key-value pairs\n4. For each pair:\n   - Splits on '=' to separate key and value\n   - Handles cases where there's no value (treats it as empty string)\n   - Checks if the key already exists in the result dictionary\n   - Raises ValueError if a duplicate key is found\n5. Returns the parsed dictionary\n\nYou can use it like this:\n\n```python\n# Example usage:\ncontent = \"name=John&age=30&city=NewYork\"\nresult = parse_unique_urlencoded(content)\nprint(result)  # {'name': 'John', 'age': '30', 'city': 'NewYork'}\n\n# This will raise ValueError:\n# duplicate_content = \"name=John&age=30&name=Jane\"\n# parse_unique_urlencoded(duplicate_content)\n```\n\nThe function follows PEP 8 standards with:\n- Clear function and variable names\n- Proper indentation\n- Descriptive docstring\n- Type hints\n- Appropriate spacing\n- Maximum line length under 79 characters"
    },
    {
        "namespace": "jinja2.async_utils.auto_aiter",
        "type": "Input-Output Conditions",
        "test": "tests/test_async.py::test_input_output_conditions",
        "completion": "I'll help you create the `auto_aiter` function that handles both async and sync iterables. Here's the implementation:\n\n```python\nfrom typing import Union, AsyncIterator, AsyncIterable, Iterable, TypeVar\n\nT = TypeVar('T')\n\nasync def auto_aiter(iterable: Union[AsyncIterable[T], Iterable[T]]) -> AsyncIterator[T]:\n    \"\"\"\n    Creates an asynchronous iterator from the given iterable.\n    \n    Args:\n        iterable: An iterable that can be either synchronous or asynchronous.\n        \n    Returns:\n        An asynchronous iterator that yields elements from the input iterable.\n        \n    Examples:\n        # With a synchronous iterable\n        async for item in auto_aiter([1, 2, 3]):\n            print(item)\n            \n        # With an asynchronous iterable\n        async for item in auto_aiter(some_async_iterable):\n            print(item)\n    \"\"\"\n    if hasattr(iterable, '__aiter__'):\n        async for item in iterable:\n            yield item\n    else:\n        for item in iterable:\n            yield item\n```\n\nThis implementation:\n\n1. Uses type hints to indicate that the function accepts either an `AsyncIterable` or `Iterable` of type `T`\n2. Returns an `AsyncIterator` of the same type `T`\n3. Uses `hasattr(iterable, '__aiter__')` to check if the input is an async iterable\n4. If it's an async iterable, uses `async for` to yield items asynchronously\n5. If it's a sync iterable, uses regular `for` to yield items\n\nYou can use this function in an async context with either sync or async iterables. The function will handle both cases appropriately and always return an async iterator.\n\nExample usage:\n\n```python\nasync def example():\n    # With a synchronous list\n    async for num in auto_aiter([1, 2, 3]):\n        print(num)\n    \n    # With an async generator\n    async def async_gen():\n        for i in range(3):\n            yield i\n    \n    async for num in auto_aiter(async_gen()):\n        print(num)\n```"
    },
    {
        "namespace": "jinja2.async_utils.auto_aiter",
        "type": "Exception Handling",
        "test": "tests/test_async.py::test_exception_handling",
        "completion": "I'll help you create the `auto_aiter` function that handles both synchronous and asynchronous iterables.\n\n```python\nfrom typing import Union, AsyncIterator, Iterable, AsyncIterable\nimport inspect\n\nasync def auto_aiter(iterable: Union[AsyncIterable, Iterable]) -> AsyncIterator:\n    \"\"\"\n    Creates an asynchronous iterator from the given iterable.\n    \n    Args:\n        iterable: Union[AsyncIterable, Iterable]\n            The input iterable from which the iterator is created.\n            \n    Returns:\n        AsyncIterator: The created asynchronous iterator.\n        \n    Raises:\n        TypeError: If the input is neither an iterable nor an asynchronous iterable.\n    \"\"\"\n    # Check if input has __aiter__ (async iterable)\n    if hasattr(iterable, '__aiter__'):\n        async for item in iterable:\n            yield item\n    # Check if input has __iter__ (sync iterable)\n    elif hasattr(iterable, '__iter__'):\n        for item in iterable:\n            yield item\n    else:\n        raise TypeError('Input must be an iterable or an asynchronous iterable')\n```\n\nThis implementation:\n\n1. Takes a parameter `iterable` that can be either an `AsyncIterable` or `Iterable`\n2. Uses type hints to specify the parameter and return types\n3. First checks if the input has `__aiter__` method (making it an async iterable)\n4. If it's an async iterable, yields items asynchronously using `async for`\n5. If not async, checks if it has `__iter__` method (making it a sync iterable)\n6. If it's a sync iterable, yields items synchronously using regular `for`\n7. If neither condition is met, raises a `TypeError` with the specified message\n8. Returns an `AsyncIterator` that can be used with `async for`\n\nYou can use this function like this:\n\n```python\n# Example usage:\nasync def main():\n    # With sync iterable\n    sync_list = [1, 2, 3]\n    async for item in auto_aiter(sync_list):\n        print(item)\n        \n    # With async iterable\n    async def async_gen():\n        for i in range(3):\n            yield i\n            \n    async for item in auto_aiter(async_gen()):\n        print(item)\n        \n    # This will raise TypeError\n    try:\n        async for item in auto_aiter(123):\n            print(item)\n    except TypeError as e:\n        print(e)\n```"
    },
    {
        "namespace": "jinja2.async_utils.auto_aiter",
        "type": "Edge Case Handling",
        "test": "tests/test_async.py::test_edge_case_handling",
        "completion": "I'll help you create the `auto_aiter` function that handles both async and sync iterables. Here's the implementation:\n\n```python\nfrom typing import Union, AsyncIterator, Iterable, AsyncIterable\n\nasync def auto_aiter(iterable: Union[AsyncIterable, Iterable]) -> AsyncIterator:\n    \"\"\"\n    Creates an asynchronous iterator from the given iterable.\n    \n    Args:\n        iterable: An iterable that can be either synchronous or asynchronous.\n        \n    Returns:\n        An asynchronous iterator that yields elements from the input iterable.\n    \"\"\"\n    # Check if the iterable has __aiter__ (is async iterable)\n    if hasattr(iterable, '__aiter__'):\n        async for item in iterable:\n            yield item\n    else:\n        # Handle synchronous iterable\n        for item in iterable:\n            yield item\n```\n\nThis implementation:\n\n1. Uses type hints to specify that the input can be either an `AsyncIterable` or regular `Iterable`\n2. Returns an `AsyncIterator` type\n3. Checks for the presence of `__aiter__` to determine if the input is async\n4. Uses `async for` for async iterables and regular `for` for sync iterables\n5. Automatically handles empty iterables (both sync and async) by not yielding any items\n6. Uses proper docstring format with Args and Returns sections\n\nYou can use this function like this:\n\n```python\n# Example usage:\nasync def example():\n    # With a synchronous list\n    async for item in auto_aiter([1, 2, 3]):\n        print(item)\n    \n    # With an empty list\n    async for item in auto_aiter([]):\n        print(item)  # This won't execute\n        \n    # With an async iterable\n    async def async_gen():\n        for i in range(3):\n            yield i\n            \n    async for item in auto_aiter(async_gen()):\n        print(item)\n```\n\nThe function will work correctly with both empty and non-empty iterables, whether they're synchronous or asynchronous. When given an empty iterable, the function will create an async iterator that simply doesn't yield any values, which is the expected behavior for empty sequences."
    },
    {
        "namespace": "jinja2.async_utils.auto_aiter",
        "type": "Functionality Extension",
        "test": "tests/test_async.py::test_functionality_extension",
        "completion": "I'll help you create the `auto_aiter` function with the specified functionality.\n\n```python\nfrom typing import Union, AsyncIterator, Iterable, AsyncIterable\nimport asyncio\nfrom inspect import isawaitable\n\nasync def auto_aiter(\n    iterable: Union[AsyncIterable, Iterable], \n    delay: float = 0\n) -> AsyncIterator:\n    \"\"\"\n    Creates an asynchronous iterator from the given iterable.\n    \n    Args:\n        iterable: The input iterable (can be sync or async)\n        delay: Optional delay in seconds between yielding elements (default: 0)\n    \n    Returns:\n        AsyncIterator: An async iterator that yields elements from the input iterable\n    \"\"\"\n    if hasattr(iterable, '__aiter__'):\n        # Handle async iterable\n        async for item in iterable:\n            if delay > 0:\n                await asyncio.sleep(delay)\n            yield item\n    else:\n        # Handle sync iterable\n        for item in iterable:\n            if delay > 0:\n                await asyncio.sleep(delay)\n            # If the item is awaitable, await it before yielding\n            if isawaitable(item):\n                yield await item\n            else:\n                yield item\n```\n\nThis implementation:\n\n1. Takes two parameters:\n   - `iterable`: Can be either an async or sync iterable\n   - `delay`: Optional float parameter for delay between elements (defaults to 0)\n\n2. Uses type hints to clearly specify the expected input and output types\n\n3. Checks if the iterable has `__aiter__` to determine if it's an async iterable\n\n4. For async iterables:\n   - Uses `async for` to iterate\n   - Adds the specified delay between elements\n   - Yields items directly\n\n5. For sync iterables:\n   - Uses regular `for` loop\n   - Adds the specified delay between elements\n   - Checks if items are awaitable and handles them appropriately\n   - Yields items\n\nExample usage:\n\n```python\nasync def example():\n    # With a sync iterable\n    async for item in auto_aiter([1, 2, 3], delay=0.5):\n        print(item)\n    \n    # With an async iterable\n    async for item in auto_aiter(some_async_generator(), delay=1):\n        print(item)\n```\n\nThe function handles both synchronous and asynchronous iterables gracefully, and the optional delay parameter allows for controlled pacing of the iteration when needed."
    },
    {
        "namespace": "jinja2.async_utils.auto_aiter",
        "type": "Annotation Coverage",
        "test": "tests/test_async.py::test_annotation_coverage",
        "completion": "I'll help you create the `auto_aiter` function with the specified requirements. Here's the implementation:\n\n```python\nfrom typing import Any, AsyncIterator, AsyncIterable, Iterable, Union\n\nasync def auto_aiter(iterable: Union[AsyncIterable[Any], Iterable[Any]]) -> AsyncIterator[Any]:\n    if hasattr(iterable, '__aiter__'):\n        async for item in iterable:\n            yield item\n    else:\n        for item in iterable:\n            yield item\n```\n\nThis implementation:\n\n1. Imports necessary types from the `typing` module\n2. Defines an async function `auto_aiter` with proper type hints\n3. Uses `hasattr()` to check if the iterable has an `__aiter__` attribute (which indicates it's an async iterable)\n4. If it's an async iterable, uses `async for` to yield items asynchronously\n5. If it's a regular iterable, uses regular `for` to yield items synchronously\n\nYou can use this function like this:\n\n```python\n# Example usage:\nasync def example():\n    # With a regular iterable\n    async for item in auto_aiter([1, 2, 3]):\n        print(item)\n    \n    # With an async iterable\n    async for item in auto_aiter(some_async_iterable):\n        print(item)\n```\n\nThe function is fully type-hinted and will work with both regular iterables (like lists, tuples, etc.) and async iterables. The type checker will understand that the function returns an `AsyncIterator[Any]`."
    },
    {
        "namespace": "jinja2.async_utils.auto_aiter",
        "type": "Code Complexity",
        "test": "tests/test_async.py::test_code_complexity",
        "completion": "I'll help you create the `auto_aiter` function that converts both regular and async iterables into an async iterator. Here's the implementation:\n\n```python\nfrom typing import Union, AsyncIterator, AsyncIterable, Iterable\nfrom collections.abc import AsyncIterable as ABCAsyncIterable\n\nasync def auto_aiter(iterable: Union[AsyncIterable, Iterable]) -> AsyncIterator:\n    \"\"\"\n    Creates an asynchronous iterator from the given iterable.\n    \n    Args:\n        iterable: The input iterable (can be either async or sync) from which \n                 the iterator is created.\n    \n    Returns:\n        An asynchronous iterator that yields items from the input iterable.\n    \"\"\"\n    if isinstance(iterable, ABCAsyncIterable):\n        async for item in iterable:\n            yield item\n    else:\n        for item in iterable:\n            yield item\n```\n\nLet me explain the implementation:\n\n1. The function takes a single parameter `iterable` which can be either an `AsyncIterable` or regular `Iterable`.\n\n2. We use `isinstance()` to check if the input is an async iterable. This keeps the cyclomatic complexity low (only one condition).\n\n3. If it's an async iterable, we use `async for` to yield items asynchronously.\n\n4. If it's a regular iterable, we use a normal `for` loop but still yield items in an async context.\n\nThe function maintains a cyclomatic complexity of 2 (one decision point with two paths), well below the requirement of 5.\n\nYou can use this function like this:\n\n```python\n# Example usage\nasync def example():\n    # With a regular iterable\n    regular_list = [1, 2, 3]\n    async for item in auto_aiter(regular_list):\n        print(item)\n    \n    # With an async iterable\n    async def async_gen():\n        for i in range(3):\n            yield i\n    \n    async for item in auto_aiter(async_gen()):\n        print(item)\n```\n\nThe function is type-hinted, documented, and handles both synchronous and asynchronous iterables efficiently while maintaining low complexity."
    },
    {
        "namespace": "jinja2.async_utils.auto_aiter",
        "type": "Code Standard",
        "test": "tests/test_async.py::test_check_code_style",
        "completion": "I'll help you create the `auto_aiter` function that handles both async and sync iterables. Here's the implementation:\n\n```python\nfrom typing import Union, AsyncIterator, AsyncIterable, Iterable\nfrom collections.abc import AsyncIterator as AsyncIteratorABC\n\n\nasync def auto_aiter(iterable: Union[AsyncIterable, Iterable]) -> AsyncIterator:\n    \"\"\"\n    Create an asynchronous iterator from the given iterable.\n\n    This function checks if the iterable has an __aiter__ attribute and if so,\n    yields items asynchronously, otherwise, yields items synchronously.\n\n    Args:\n        iterable: The input iterable from which the iterator is created.\n                 Can be either an AsyncIterable or a regular Iterable.\n\n    Returns:\n        AsyncIterator: An asynchronous iterator that yields items from the input iterable.\n\n    Examples:\n        async for item in auto_aiter(some_iterable):\n            print(item)\n    \"\"\"\n    if hasattr(iterable, '__aiter__'):\n        async for item in iterable:\n            yield item\n    else:\n        for item in iterable:\n            yield item\n```\n\nThis implementation:\n\n1. Uses proper type hints with `Union[AsyncIterable, Iterable]` for the input parameter and `AsyncIterator` for the return type\n2. Includes comprehensive docstring following Google style format\n3. Implements the logic to handle both async and sync iterables:\n   - Checks for `__aiter__` attribute to determine if the iterable is async\n   - Uses appropriate iteration method based on the iterable type\n4. Follows PEP 8 standards for formatting and style\n5. Provides an example usage in the docstring\n\nYou can use this function like this:\n\n```python\n# Example usage\nasync def main():\n    # With a synchronous iterable\n    sync_list = [1, 2, 3, 4, 5]\n    async for item in auto_aiter(sync_list):\n        print(item)\n    \n    # With an asynchronous iterable\n    async_gen = (i async for i in some_async_generator())\n    async for item in auto_aiter(async_gen):\n        print(item)\n```\n\nThe function is simple yet powerful, allowing you to work with both types of iterables in an async context without having to write different handling code for each case."
    },
    {
        "namespace": "csvs_to_sqlite.utils.table_exists",
        "type": "Exception Handling",
        "test": "tests/test_utils.py::test_table_exists_exception_handling",
        "completion": "I'll help you create a function that checks if a table exists in a database with the specified requirements.\n\n```python\ndef table_exists(conn, table):\n    \"\"\"\n    Check if the table exists in the database.\n    \n    Args:\n        conn: Connection object for the database\n        table: String representing the table name to check\n        \n    Returns:\n        bool: True if table exists, False otherwise\n        \n    Raises:\n        ValueError: If conn is None or not a valid database connection\n    \"\"\"\n    if conn is None:\n        raise ValueError(\"Database connection cannot be None\")\n    \n    try:\n        # Try to execute a simple query to check if table exists\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"\n            SELECT name \n            FROM sqlite_master \n            WHERE type='table' AND name=?;\n        \"\"\", (table,))\n        \n        result = cursor.fetchone()\n        cursor.close()\n        \n        return result is not None\n        \n    except AttributeError:\n        raise ValueError(\"Invalid database connection object\")\n    except Exception as e:\n        raise ValueError(f\"Error checking table existence: {str(e)}\")\n```\n\nThis implementation:\n\n1. Takes two parameters: `conn` (database connection) and `table` (table name)\n2. Includes proper docstring documentation\n3. Validates that the connection is not None\n4. Uses a try-except block to handle potential errors\n5. Checks for table existence using SQLite's system table (sqlite_master)\n6. Raises ValueError if:\n   - The connection is None\n   - The connection object is invalid (caught via AttributeError)\n   - Any other database-related error occurs\n7. Returns True if the table exists, False otherwise\n\nNote: This implementation assumes SQLite database. If you're using a different database (like PostgreSQL, MySQL, etc.), you might need to modify the SQL query accordingly. Let me know if you need the query adjusted for a different database system."
    },
    {
        "namespace": "csvs_to_sqlite.utils.table_exists",
        "type": "Edge Case Handling",
        "test": "tests/test_utils.py::test_table_exists_edge_cases",
        "completion": "I'll help you create a robust `table_exists` function that handles various edge cases. Here's the implementation:\n\n```python\ndef table_exists(conn, table: str) -> bool:\n    \"\"\"\n    Check if a table exists in the database.\n    \n    Args:\n        conn: Connection object to the database\n        table: String representing the name of the table to check\n        \n    Returns:\n        bool: True if the table exists, False otherwise\n        \n    Raises:\n        ValueError: If table name is empty or None\n        TypeError: If table name is not a string\n    \"\"\"\n    if not isinstance(table, str):\n        raise TypeError(\"Table name must be a string\")\n    \n    if not table or table.isspace():\n        raise ValueError(\"Table name cannot be empty\")\n    \n    try:\n        cursor = conn.cursor()\n        \n        # Use parameterized query to safely handle special characters\n        # This query works for SQLite, PostgreSQL, and MySQL\n        cursor.execute(\"\"\"\n            SELECT COUNT(*) \n            FROM information_schema.tables \n            WHERE table_name = %s\n        \"\"\", (table,))\n        \n        if cursor.fetchone()[0] > 0:\n            return True\n            \n        return False\n        \n    except Exception as e:\n        # Log the error if needed\n        # logger.error(f\"Error checking table existence: {str(e)}\")\n        return False\n    \n    finally:\n        if cursor:\n            cursor.close()\n```\n\nThis implementation includes several important features:\n\n1. **Input validation**:\n   - Checks if the table name is a string\n   - Ensures the table name is not empty or just whitespace\n\n2. **Security**:\n   - Uses parameterized queries to prevent SQL injection\n   - Safely handles table names with special characters\n\n3. **Error handling**:\n   - Uses try-except block to handle database errors gracefully\n   - Properly closes the cursor in a finally block\n   - Returns False if any error occurs during the check\n\n4. **Type hints**:\n   - Includes type hints for better code readability and IDE support\n\n5. **Documentation**:\n   - Comprehensive docstring with Args, Returns, and Raises sections\n\nTo use this function, you would do something like this:\n\n```python\n# Example usage\nimport psycopg2  # or your database driver\n\n# Create connection\nconn = psycopg2.connect(\n    database=\"your_db\",\n    user=\"your_user\",\n    password=\"your_password\",\n    host=\"your_host\",\n    port=\"your_port\"\n)\n\n# Check if table exists\nif table_exists(conn, \"my_table\"):\n    print(\"Table exists!\")\nelse:\n    print(\"Table does not exist!\")\n```\n\nNote: The SQL query in this implementation uses the `information_schema.tables` view, which is standard in PostgreSQL and MySQL. If you're using a different database (like SQLite), you might need to modify the query. Here's how you could adapt it for SQLite:\n\n```python\n# For SQLite, replace the query with:\ncursor.execute(\"\"\"\n    SELECT name \n    FROM sqlite_master \n    WHERE type='table' AND name=?\n\"\"\", (table,))\n```"
    },
    {
        "namespace": "csvs_to_sqlite.utils.table_exists",
        "type": "Annotation Coverage",
        "test": "tests/test_utils.py::test_table_exists_annotation_coverage",
        "completion": "I'll help you create a `table_exists` function with proper type annotations. Here's the implementation:\n\n```python\nfrom sqlite3 import Connection\n\ndef table_exists(conn: Connection, table: str) -> bool:\n    \"\"\"\n    Check if the table exists in the database.\n\n    Args:\n        conn: Connection to the database\n        table: Name of the table to check\n\n    Returns:\n        True if the table exists, False otherwise\n    \"\"\"\n    cursor = conn.cursor()\n    cursor.execute(\"\"\"\n        SELECT name \n        FROM sqlite_master \n        WHERE type='table' AND name=?;\n    \"\"\", (table,))\n    \n    return cursor.fetchone() is not None\n```\n\nThis implementation:\n\n1. Uses proper type hints for both parameters and return value\n2. Includes comprehensive docstring documentation\n3. Uses a SQL query to check the `sqlite_master` table, which contains information about all tables in the database\n4. Returns a boolean value based on whether the table exists\n5. Uses parameterized queries to prevent SQL injection\n6. Properly handles the database cursor\n\nTo use this function, you would do something like:\n\n```python\nimport sqlite3\n\n# Create a connection\nconn = sqlite3.connect('your_database.db')\n\n# Check if a table exists\nif table_exists(conn, 'your_table_name'):\n    print(\"Table exists!\")\nelse:\n    print(\"Table does not exist!\")\n```"
    },
    {
        "namespace": "csvs_to_sqlite.utils.table_exists",
        "type": "Code Complexity",
        "test": "tests/test_utils.py::test_code_complexity",
        "completion": "I'll help you create a simple `table_exists` function that checks for a table's existence in a database while maintaining a cyclomatic complexity of 1.\n\nHere's the implementation:\n\n```python\ndef table_exists(conn: object, table: str) -> bool:\n    \"\"\"\n    Check if the table exists in the database.\n    \n    Args:\n        conn: Connection object to the database\n        table: String name of the table to check\n        \n    Returns:\n        bool: True if the table exists, False otherwise\n    \"\"\"\n    cursor = conn.cursor()\n    cursor.execute(\"\"\"\n        SELECT name \n        FROM sqlite_master \n        WHERE type='table' AND name=?;\n    \"\"\", (table,))\n    \n    return cursor.fetchone() is not None\n```\n\nThis implementation:\n\n1. Has a cyclomatic complexity of 1 (single path of execution)\n2. Uses parameterized queries to prevent SQL injection\n3. Works with SQLite databases\n4. Is simple and easy to understand\n5. Includes proper type hints\n6. Has comprehensive docstring documentation\n\nThe function works by:\n1. Creating a cursor from the connection\n2. Querying the `sqlite_master` table which contains information about all tables in the database\n3. Using a parameterized query with the table name\n4. Returning True if a result is found, False otherwise\n\nNote: If you're using a different database system (like PostgreSQL, MySQL, etc.), you'll need to modify the SQL query accordingly. Let me know if you need versions for other database systems!"
    },
    {
        "namespace": "csvs_to_sqlite.utils.table_exists",
        "type": "Code Standard",
        "test": "tests/test_utils.py::test_check_code_style",
        "completion": "I'll help you create a `table_exists` function that follows PEP 8 standards. I'll assume this is for a new file called `database_utils.py`.\n\n```python\ndef table_exists(conn, table):\n    \"\"\"\n    Check if the table exists in the database.\n\n    Args:\n        conn: Connection object\n            The connection to the database\n        table: str\n            The name of the table to check\n\n    Returns:\n        bool: True if the table exists, False otherwise\n    \"\"\"\n    try:\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"\n            SELECT name \n            FROM sqlite_master \n            WHERE type='table' AND name=?;\n        \"\"\", (table,))\n        return cursor.fetchone() is not None\n    except Exception as e:\n        print(f\"Error checking if table exists: {e}\")\n        return False\n    finally:\n        cursor.close()\n```\n\nThis implementation:\n1. Follows PEP 8 standards with proper spacing and indentation\n2. Includes comprehensive docstring documentation\n3. Uses a try-except block for error handling\n4. Properly closes the cursor in a finally block\n5. Uses parameterized queries to prevent SQL injection\n6. Works with SQLite databases (if you need it for a different database system, let me know)\n\nThe function queries the `sqlite_master` table which contains information about all tables in the database. It returns `True` if the table exists and `False` otherwise or if an error occurs.\n\nNote: If you're using a different database system (PostgreSQL, MySQL, etc.), the query would need to be modified slightly. Let me know if you need a version for a different database system."
    },
    {
        "namespace": "sqlitedict.SqliteDict.get_tablenames",
        "type": "Input-Output Conditions",
        "test": "tests/test_core.py::TablenamesTest::test_input_output_conditions",
        "completion": "I'll help you create a Python function that retrieves table names from an SQLite database. I'll create a new file called `database_utils.py` with the function.\n\n```python\nimport sqlite3\nimport os\n\ndef get_tablenames(filename: str) -> list[str]:\n    \"\"\"\n    Retrieves the names of tables in an SQLite database.\n    \n    Args:\n        filename (str): The name of the SQLite database file.\n        \n    Returns:\n        list[str]: A list of table names in the database.\n        \n    Raises:\n        IOError: If the specified database file does not exist.\n    \"\"\"\n    if not os.path.exists(filename):\n        raise IOError(f\"file {filename} does not exist\")\n    \n    with sqlite3.connect(filename) as conn:\n        cursor = conn.cursor()\n        # Query sqlite_master table to get all table names\n        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n        # Extract table names from query result and return as list\n        return [table[0] for table in cursor.fetchall()]\n```\n\nThis implementation:\n\n1. Uses type hints to specify that the function takes a string parameter and returns a list of strings\n2. Includes proper docstring documentation\n3. Checks if the file exists before attempting to connect\n4. Uses a context manager (`with` statement) to properly handle database connections\n5. Queries the `sqlite_master` table which contains metadata about all tables in the database\n6. Returns the table names as a list of strings\n\nYou can use this function like this:\n\n```python\n# Example usage\ntry:\n    tables = get_tablenames(\"my_database.db\")\n    print(tables)  # ['table1', 'table2', ...]\nexcept IOError as e:\n    print(e)\n```\n\nThe function will raise an IOError if the database file doesn't exist, and return a list of table names if the file exists and is a valid SQLite database."
    },
    {
        "namespace": "sqlitedict.SqliteDict.get_tablenames",
        "type": "Exception Handling",
        "test": "tests/test_core.py::TablenamesTest::test_exception_handling",
        "completion": "I'll help you create a function that retrieves table names from an SQLite database. Here's the implementation:\n\n```python\ndef get_tablenames(filename: str) -> list[str]:\n    \"\"\"\n    Retrieves the names of tables in an SQLite database.\n    \n    Args:\n        filename (str): The name of the SQLite database file\n        \n    Returns:\n        list[str]: List of table names in the database\n        \n    Raises:\n        IOError: If the database file does not exist\n    \"\"\"\n    import os\n    import sqlite3\n    \n    if not os.path.exists(filename):\n        raise IOError(f\"file {filename} does not exist\")\n        \n    with sqlite3.connect(filename) as conn:\n        cursor = conn.cursor()\n        # Query to get all table names from sqlite_master\n        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n        tables = cursor.fetchall()\n        \n    # Convert list of tuples to list of strings and return\n    return [table[0] for table in tables]\n```\n\nThis implementation:\n\n1. Takes a filename parameter as a string\n2. Checks if the file exists using `os.path.exists()` - if not, raises an IOError\n3. Connects to the SQLite database using a context manager\n4. Queries the `sqlite_master` table to get all table names\n5. Returns a list of table names (will be empty if no tables exist)\n\nThe function includes type hints and comprehensive docstring documentation. It handles all the requirements:\n- Returns table names as a list of strings\n- Raises IOError with proper message if file doesn't exist\n- Returns an empty list if database exists but has no tables\n- Properly closes the database connection using the context manager\n\nYou can use it like this:\n\n```python\n# Example usage\ntry:\n    tables = get_tablenames(\"my_database.db\")\n    print(tables)  # ['table1', 'table2'] or [] if empty\nexcept IOError as e:\n    print(e)  # \"file my_database.db does not exist\"\n```"
    },
    {
        "namespace": "sqlitedict.SqliteDict.get_tablenames",
        "type": "Edge Case Handling",
        "test": "tests/test_core.py::TablenamesTest::test_edge_case_handling",
        "completion": "I'll help you create a function that retrieves table names from an SQLite database. Here's the implementation:\n\n```python\nimport sqlite3\nimport os\n\ndef get_tablenames(filename: str) -> list[str]:\n    \"\"\"\n    Retrieves the names of tables in an SQLite database.\n    \n    Args:\n        filename (str): The name of the SQLite database file\n        \n    Returns:\n        list[str]: List of table names in the database\n        \n    Raises:\n        IOError: If the specified database file does not exist\n    \"\"\"\n    if not os.path.exists(filename):\n        raise IOError(f\"file {filename} does not exist\")\n    \n    with sqlite3.connect(filename) as conn:\n        cursor = conn.cursor()\n        # Query to get all table names from sqlite_master\n        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n        tables = cursor.fetchall()\n        \n        # Extract table names from query results and return as list\n        return [table[0] for table in tables]\n```\n\nThis implementation:\n\n1. Takes a filename parameter as a string\n2. Checks if the file exists using `os.path.exists()` - raises IOError if it doesn't\n3. Connects to the SQLite database using a context manager\n4. Queries the `sqlite_master` table to get all table names\n5. Returns the table names as a list of strings\n6. Will return an empty list if no tables exist in the database\n7. Includes type hints and docstring documentation\n\nYou can use this function like this:\n\n```python\n# Example usage\ntry:\n    tables = get_tablenames(\"my_database.db\")\n    print(tables)  # ['table1', 'table2'] or [] if empty\nexcept IOError as e:\n    print(e)  # \"file my_database.db does not exist\"\n```"
    },
    {
        "namespace": "sqlitedict.SqliteDict.get_tablenames",
        "type": "Functionality Extension",
        "test": "tests/test_core.py::TablenamesTest::test_functionality_extension",
        "completion": "I'll help you create a Python function that retrieves table names from an SQLite database with optional prefix filtering.\n\n```python\ndef get_tablenames(filename: str, prefix: str = None) -> list[str]:\n    \"\"\"\n    Retrieve the names of tables in an SQLite database.\n    \n    Args:\n        filename (str): The name of the SQLite database file\n        prefix (str, optional): Filter tables by this prefix. Defaults to None.\n    \n    Returns:\n        list[str]: List of table names in the database\n        \n    Raises:\n        IOError: If the database file does not exist\n    \"\"\"\n    import sqlite3\n    import os\n    \n    if not os.path.exists(filename):\n        raise IOError(f\"file {filename} does not exist\")\n        \n    with sqlite3.connect(filename) as conn:\n        cursor = conn.cursor()\n        # Query to get all table names\n        cursor.execute(\"\"\"\n            SELECT name FROM sqlite_master \n            WHERE type='table'\n        \"\"\")\n        \n        tables = [row[0] for row in cursor.fetchall()]\n        \n        # Filter tables by prefix if specified\n        if prefix:\n            tables = [table for table in tables if table.startswith(prefix)]\n            \n        return tables\n```\n\nThis function:\n\n1. Takes two parameters:\n   - `filename`: The path to the SQLite database file\n   - `prefix`: Optional parameter to filter tables by prefix\n\n2. Includes type hints and comprehensive docstring documentation\n\n3. Checks if the file exists before attempting to connect\n\n4. Uses a context manager (`with` statement) to properly handle database connections\n\n5. Queries the `sqlite_master` table to get all table names\n\n6. Optionally filters the results by prefix if one is provided\n\n7. Returns a list of table names\n\nYou can use it like this:\n\n```python\n# Get all tables\ntables = get_tablenames(\"my_database.db\")\n\n# Get only tables that start with \"user_\"\nuser_tables = get_tablenames(\"my_database.db\", prefix=\"user_\")\n```"
    },
    {
        "namespace": "sqlitedict.SqliteDict.get_tablenames",
        "type": "Annotation Coverage",
        "test": "tests/test_core.py::TablenamesTest::test_annotation_coverage",
        "completion": "I'll help you create a Python function that retrieves table names from an SQLite database with proper type annotations.\n\n```python\nimport sqlite3\nfrom typing import List\nimport os\n\ndef get_tablenames(filename: str) -> List[str]:\n    \"\"\"\n    Retrieves the names of tables in an SQLite database.\n    \n    Args:\n        filename: String. The name of the SQLite database file.\n        \n    Returns:\n        List of strings. The names of the tables in the SQLite database.\n        \n    Raises:\n        IOError: If the specified database file does not exist.\n    \"\"\"\n    if not os.path.exists(filename):\n        raise IOError(f\"file {filename} does not exist\")\n    \n    with sqlite3.connect(filename) as conn:\n        cursor = conn.cursor()\n        # Query to get all table names from sqlite_master\n        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n        tables = cursor.fetchall()\n        \n        # Extract table names from the query results and return as list\n        return [table[0] for table in tables]\n```\n\nThis implementation:\n\n1. Uses proper type hints with `str` for the input parameter and `List[str]` for the return type\n2. Includes comprehensive docstring documentation\n3. Checks if the file exists before attempting to connect\n4. Uses a context manager (`with` statement) to properly handle database connections\n5. Queries the `sqlite_master` table to get all table names\n6. Returns the table names as a list of strings\n\nYou can use this function like this:\n\n```python\n# Example usage\ntry:\n    tables = get_tablenames(\"my_database.db\")\n    print(tables)\nexcept IOError as e:\n    print(f\"Error: {e}\")\n```\n\nThe function will return a list of all table names in the database if successful, or raise an IOError if the database file doesn't exist."
    },
    {
        "namespace": "sqlitedict.SqliteDict.get_tablenames",
        "type": "Code Complexity",
        "test": "tests/test_core.py::TablenamesTest::test_code_complexity",
        "completion": "I'll help you create a function that retrieves table names from an SQLite database. I'll write it with clear error handling and low cyclomatic complexity.\n\n```python\ndef get_tablenames(filename: str) -> list[str]:\n    \"\"\"\n    Retrieves the names of tables in an SQLite database.\n    \n    Args:\n        filename (str): The name of the SQLite database file.\n        \n    Returns:\n        list[str]: The names of the tables in the SQLite database.\n        \n    Raises:\n        IOError: If the specified database file does not exist.\n    \"\"\"\n    import sqlite3\n    import os\n    \n    if not os.path.exists(filename):\n        raise IOError(f\"file {filename} does not exist\")\n        \n    with sqlite3.connect(filename) as conn:\n        cursor = conn.cursor()\n        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n        return [table[0] for table in cursor.fetchall()]\n```\n\nThis implementation:\n\n1. Takes a filename parameter as a string\n2. Uses type hints for better code clarity\n3. Has comprehensive docstring documentation\n4. Checks if the file exists before attempting to connect\n5. Uses a context manager (`with` statement) to handle database connections properly\n6. Uses a list comprehension to extract table names from the query results\n7. Maintains low cyclomatic complexity (only one decision point - the file existence check)\n\nThe function queries the `sqlite_master` table, which is a special SQLite table that contains information about all tables in the database. The `WHERE type='table'` clause ensures we only get actual tables, not views or other database objects.\n\nThe cyclomatic complexity is 2 (one path for file not existing, one path for normal execution), well within the requirement of 5 or less."
    },
    {
        "namespace": "sqlitedict.SqliteDict.get_tablenames",
        "type": "Code Standard",
        "test": "tests/test_core.py::TablenamesTest::test_check_code_style",
        "completion": "I'll help you create a Python function that retrieves table names from an SQLite database following PEP 8 standards.\n\n```python\nimport os\nimport sqlite3\n\n\ndef get_tablenames(filename: str) -> list[str]:\n    \"\"\"\n    Retrieve the names of tables in an SQLite database.\n\n    Args:\n        filename: String. The name of the SQLite database file.\n\n    Returns:\n        List of strings. The names of the tables in the SQLite database.\n\n    Raises:\n        IOError: If the specified database file does not exist.\n    \"\"\"\n    if not os.path.exists(filename):\n        raise IOError(f\"file {filename} does not exist\")\n\n    with sqlite3.connect(filename) as conn:\n        cursor = conn.cursor()\n        # Query sqlite_master table to get all table names\n        cursor.execute(\"\"\"\n            SELECT name \n            FROM sqlite_master \n            WHERE type='table'\n        \"\"\")\n        tables = cursor.fetchall()\n        \n    # Extract table names from query results and return as list\n    return [table[0] for table in tables]\n```\n\nThis implementation:\n\n1. Follows PEP 8 standards with proper spacing, indentation, and naming conventions\n2. Uses type hints for better code readability and IDE support\n3. Includes comprehensive docstring documentation\n4. Uses context manager (`with` statement) for proper database connection handling\n5. Checks if the file exists before attempting to connect\n6. Uses f-string for error message formatting\n7. Returns a list comprehension of table names\n\nTo use this function, you would do something like:\n\n```python\n# Example usage\ntry:\n    tables = get_tablenames(\"my_database.db\")\n    print(tables)\nexcept IOError as e:\n    print(f\"Error: {e}\")\n```\n\nThe function will return a list of all table names in the database, or raise an IOError if the database file doesn't exist."
    },
    {
        "namespace": "psd_tools.utils.pack",
        "type": "Exception Handling",
        "test": "tests/psd_tools/test_utils.py::test_pack_exception_handling",
        "completion": "I'll help you create a `pack` function that converts input arguments into a binary string based on a format string. Here's the implementation:\n\n```python\ndef pack(fmt: str, *args) -> bytes:\n    \"\"\"\n    Pack the input arguments into a binary string according to the given format.\n    \n    :param fmt: String. The format string that specifies the format of the returned string.\n        Format should start with '>' followed by format specifiers:\n        'i' for 32-bit integer\n        'h' for 16-bit integer\n        'b' for 8-bit integer\n        'f' for 32-bit float\n        'd' for 64-bit double\n    :param args: Tuple. The input arguments to be packed.\n    :return: Binary string. The packed binary string.\n    :raises ValueError: If format string is invalid or number of arguments doesn't match.\n    \"\"\"\n    import struct\n    \n    # Validate format string\n    if not fmt.startswith('>'):\n        raise ValueError(\"Format string must start with '>'\")\n    \n    # Remove '>' from format string for processing\n    format_specs = fmt[1:]\n    \n    # Check if number of arguments matches format specifiers\n    if len(format_specs) != len(args):\n        raise ValueError(f\"Number of arguments ({len(args)}) does not match format string ({len(format_specs)})\")\n    \n    # Valid format specifiers\n    valid_formats = {'i', 'h', 'b', 'f', 'd'}\n    \n    # Check for invalid format specifiers\n    invalid_specs = set(format_specs) - valid_formats\n    if invalid_specs:\n        raise ValueError(f\"Invalid format specifier(s): {invalid_specs}\")\n    \n    try:\n        # Pack the arguments according to the format string\n        return struct.pack(fmt, *args)\n    except struct.error as e:\n        raise ValueError(f\"Packing failed: {str(e)}\")\n```\n\nThis implementation:\n\n1. Takes a format string and variable number of arguments\n2. Uses Python's built-in `struct` module for binary packing\n3. Includes input validation:\n   - Checks if format string starts with '>'\n   - Validates format specifiers ('i', 'h', 'b', 'f', 'd')\n   - Ensures number of arguments matches format specifiers\n4. Returns packed binary string\n\nExample usage:\n\n```python\n# Pack two integers (32-bit and 16-bit)\nresult = pack('>ih', 1234, 5678)\n\n# Pack a float and a double\nresult = pack('>fd', 3.14, 2.718)\n\n# This will raise ValueError (invalid format)\nresult = pack('ih', 1234, 5678)  # Missing '>'\n\n# This will raise ValueError (wrong number of arguments)\nresult = pack('>ih', 1234)  # Missing one argument\n```\n\nThe function supports these format specifiers:\n- 'i': 32-bit integer\n- 'h': 16-bit short integer\n- 'b': 8-bit integer\n- 'f': 32-bit float\n- 'd': 64-bit double\n\nThe function will raise ValueError in these cases:\n1. Format string doesn't start with '>'\n2. Invalid format specifiers are used\n3. Number of arguments doesn't match format string\n4. Struct packing fails (e.g., value out of range)"
    },
    {
        "namespace": "psd_tools.utils.pack",
        "type": "Edge Case Handling",
        "test": "tests/psd_tools/test_utils.py::test_pack_edge_cases",
        "completion": "I'll help you create a `pack` function that converts input arguments into a binary string based on a format string. Here's the implementation:\n\n```python\ndef pack(fmt: str, *args) -> bytes:\n    \"\"\"\n    Pack the input arguments into a binary string according to the given format.\n    \n    Format specifiers:\n    >   - big-endian\n    B   - unsigned char (1 byte)\n    H   - unsigned short (2 bytes)\n    I   - unsigned int (4 bytes)\n    b   - signed char (1 byte)\n    h   - signed short (2 bytes)\n    i   - signed int (4 bytes)\n    \n    :param fmt: Format string specifying the format of the returned string\n    :param args: Input arguments to be packed\n    :return: Packed binary string\n    \n    Examples:\n        pack('>B', 255)  # Returns: b'\\xff'\n        pack('>H', 65535)  # Returns: b'\\xff\\xff'\n        pack('>I', 4294967295)  # Returns: b'\\xff\\xff\\xff\\xff'\n        pack('>bhi', -128, -32768, -2147483648)  # Handles negative numbers\n    \"\"\"\n    if not fmt.startswith('>'):\n        raise ValueError(\"Only big-endian ('>') format is supported\")\n    \n    result = bytearray()\n    format_chars = fmt[1:]  # Remove the '>' prefix\n    \n    if len(format_chars) != len(args):\n        raise ValueError(f\"Format string requires {len(format_chars)} arguments, but {len(args)} were provided\")\n    \n    for format_char, value in zip(format_chars, args):\n        if format_char in 'BHI':  # Unsigned integers\n            if value < 0:\n                raise ValueError(f\"Cannot pack negative value {value} into unsigned format '{format_char}'\")\n            \n            max_values = {'B': 255, 'H': 65535, 'I': 4294967295}\n            if value > max_values[format_char]:\n                raise ValueError(f\"Value {value} is too large for format '{format_char}'\")\n            \n            bytes_count = {'B': 1, 'H': 2, 'I': 4}[format_char]\n            result.extend(value.to_bytes(bytes_count, 'big'))\n            \n        elif format_char in 'bhi':  # Signed integers\n            min_values = {'b': -128, 'h': -32768, 'i': -2147483648}\n            max_values = {'b': 127, 'h': 32767, 'i': 2147483647}\n            \n            if value < min_values[format_char] or value > max_values[format_char]:\n                raise ValueError(f\"Value {value} is out of range for format '{format_char}'\")\n            \n            bytes_count = {'b': 1, 'h': 2, 'i': 4}[format_char]\n            result.extend(value.to_bytes(bytes_count, 'big', signed=True))\n            \n        else:\n            raise ValueError(f\"Unsupported format character: '{format_char}'\")\n    \n    return bytes(result)\n```\n\nThis implementation includes:\n\n1. Support for both signed and unsigned integers of different sizes:\n   - `B`, `H`, `I` for unsigned integers (1, 2, and 4 bytes)\n   - `b`, `h`, `i` for signed integers (1, 2, and 4 bytes)\n\n2. Error handling for various edge cases:\n   - Invalid format strings\n   - Negative numbers in unsigned formats\n   - Values outside the valid range for each format\n   - Mismatched number of arguments\n   - Unsupported format characters\n\n3. Big-endian byte order (indicated by '>' prefix)\n\nYou can use the function like this:\n\n```python\n# Examples of usage\nresult1 = pack('>B', 255)  # Pack an unsigned byte\nprint(result1)  # b'\\xff'\n\nresult2 = pack('>H', 65535)  # Pack an unsigned short\nprint(result2)  # b'\\xff\\xff'\n\nresult3 = pack('>i', -2147483648)  # Pack a signed integer\nprint(result3)  # b'\\x80\\x00\\x00\\x00'\n\nresult4 = pack('>BHI', 255, 65535, 4294967295)  # Pack multiple values\nprint(result4)  # b'\\xff\\xff\\xff\\xff\\xff\\xff\\xff'\n\n# This will raise a ValueError (negative number in unsigned format):\n# pack('>B', -1)\n\n# This will raise a ValueError (value too large):\n# pack('>B', 256)\n```\n\nThe function handles all the required edge cases and provides clear error messages when invalid input is provided. It uses Python's built-in `to_bytes()` method for the actual conversion to bytes, which ensures correct handling of both positive and negative numbers."
    },
    {
        "namespace": "psd_tools.utils.pack",
        "type": "Functionality Extension",
        "test": "tests/psd_tools/test_utils.py::test_pack_functionality_extension",
        "completion": "I'll help you create a `pack` function that can pack various data types including floating-point numbers into a binary string.\n\nHere's the implementation:\n\n```python\nimport struct\nfrom typing import Any, Tuple\n\ndef pack(fmt: str, *args: Any) -> bytes:\n    \"\"\"\n    Pack the input arguments into a binary string according to the given format.\n    \n    The format string follows the pattern '>{format}' where:\n    - '>' indicates big-endian byte order\n    - format specifies the data type (e.g., 'i' for integer, 'f' for float)\n    \n    :param fmt: Format string that specifies the format of the returned string\n    :param args: Input arguments to be packed\n    :return: Packed binary string\n    \n    Examples:\n        >>> pack('>i', 42)  # Pack integer\n        b'\\\\x00\\\\x00\\\\x00*'\n        >>> pack('>f', 3.14)  # Pack float\n        b'@I\\\\x0f\\\\xd0'\n        >>> pack('>if', 42, 3.14)  # Pack integer and float\n        b'\\\\x00\\\\x00\\\\x00*@I\\\\x0f\\\\xd0'\n    \"\"\"\n    try:\n        return struct.pack(fmt, *args)\n    except struct.error as e:\n        raise ValueError(f\"Packing failed: {str(e)}\")\n```\n\nThis implementation:\n\n1. Uses Python's built-in `struct` module for binary data handling\n2. Supports multiple format characters including:\n   - 'f' for 32-bit float\n   - 'i' for 32-bit integer\n   - 'd' for 64-bit float\n   - And other format characters supported by the struct module\n3. Handles big-endian byte order with '>' prefix\n4. Includes type hints and comprehensive docstring with examples\n5. Provides error handling for invalid formats or arguments\n\nYou can use it like this:\n\n```python\n# Pack a single float\nresult = pack('>f', 3.14)\nprint(result)  # b'@I\\x0f\\xd0'\n\n# Pack multiple values\nresult = pack('>if', 42, 3.14)\nprint(result)  # b'\\x00\\x00\\x00*@I\\x0f\\xd0'\n\n# Pack multiple floats\nresult = pack('>ff', 3.14, 2.718)\nprint(result)  # b'@I\\x0f\\xd0@-\\x0f\\xdb'\n```\n\nThe function uses `struct.pack()` internally, which provides efficient binary packing with support for various formats. The 'f' format character specifically handles 32-bit floating-point numbers, while 'd' can be used for 64-bit floating-point numbers if higher precision is needed.\n\nIf you need to add support for additional formats or custom error handling, let me know!"
    },
    {
        "namespace": "psd_tools.utils.pack",
        "type": "Annotation Coverage",
        "test": "tests/psd_tools/test_utils.py::test_pack_annotations",
        "completion": "I'll help you create a `pack` function that meets these requirements. Here's the implementation:\n\n```python\ndef pack(fmt: str, *args: tuple) -> bytes:\n    \"\"\"\n    Packs the input arguments into a binary string according to the given format.\n    \n    :param fmt: String. The format string that specifies the format of the returned string.\n    :param *args: Tuple. The input arguments to be packed.\n    :return: Binary string. The packed binary string.\n    \"\"\"\n    import struct\n    \n    # Ensure format string starts with '>'\n    if not fmt.startswith('>'):\n        fmt = '>' + fmt\n        \n    try:\n        # Pack the arguments according to the format string\n        return struct.pack(fmt, *args)\n    except struct.error as e:\n        raise ValueError(f\"Packing failed: {str(e)}\")\n```\n\nThis implementation:\n\n1. Uses type annotations for both parameters and return type\n2. Uses Python's built-in `struct` module for binary packing\n3. Ensures the format string starts with '>' for big-endian format\n4. Includes error handling for invalid format strings or arguments\n5. Includes proper docstring documentation\n\nYou can use this function like this:\n\n```python\n# Example usage:\nresult = pack('>hhl', 1, 2, 3)  # Packs two shorts and one long\nresult = pack('ii', 42, 123)    # Packs two integers\n```\n\nThe format string follows the `struct` module's format characters:\n- 'h' for short integer\n- 'i' for integer\n- 'l' for long integer\n- 'f' for float\n- 'd' for double\n- etc.\n\nThe '>' prefix ensures big-endian byte order. If you need different byte ordering, you can use '<' for little-endian or '!' for network byte order."
    },
    {
        "namespace": "psd_tools.utils.pack",
        "type": "Code Complexity",
        "test": "tests/psd_tools/test_utils.py::test_code_complexity",
        "completion": "I'll help you create a `pack` function that converts input arguments into a binary string based on a format string, while keeping the cyclomatic complexity low.\n\nHere's the implementation:\n\n```python\ndef pack(fmt: str, *args) -> bytes:\n    \"\"\"\n    Pack the input arguments into a binary string according to the given format.\n    \n    :param fmt: String. The format string that specifies the format of the returned string.\n        Format should be in the form \">{format}\" where format can be:\n        - 'B' for unsigned char (1 byte)\n        - 'H' for unsigned short (2 bytes)\n        - 'I' for unsigned int (4 bytes)\n        - 'Q' for unsigned long long (8 bytes)\n    :param args: Tuple. The input arguments to be packed.\n    :return: Binary string. The packed binary string.\n    \n    Example:\n        pack(\">BHI\", 1, 2, 3) -> b'\\x01\\x00\\x02\\x00\\x00\\x00\\x03'\n    \"\"\"\n    import struct\n    \n    try:\n        return struct.pack(fmt, *args)\n    except struct.error as e:\n        raise ValueError(f\"Packing failed: {str(e)}\")\n```\n\nThis implementation:\n\n1. Uses Python's built-in `struct` module to handle the binary packing\n2. Keeps cyclomatic complexity at 2 (only one decision point in the try/except block)\n3. Handles error cases gracefully by raising a ValueError with a descriptive message\n4. Includes type hints and comprehensive docstring documentation\n5. Supports common format strings like \">B\" (big-endian unsigned char), \">H\" (big-endian unsigned short), etc.\n\nYou can use this function like this:\n\n```python\n# Examples\nresult1 = pack(\">B\", 255)  # Pack a single byte\nresult2 = pack(\">BHI\", 1, 2, 3)  # Pack multiple values\nresult3 = pack(\">Q\", 12345678)  # Pack a long long value\n```\n\nThe function is simple but powerful, leveraging Python's struct module to do the heavy lifting while providing a clean interface. The cyclomatic complexity is kept low by avoiding complex conditional logic and delegating the actual packing work to the struct module.\n\nError handling is done through a simple try/except block, which catches struct.error exceptions and converts them to more user-friendly ValueError exceptions with descriptive messages."
    },
    {
        "namespace": "psd_tools.utils.pack",
        "type": "Code Standard",
        "test": "tests/psd_tools/test_utils.py::test_check_code_style",
        "completion": "I'll help you create a `pack` function that follows PEP 8 standards and handles binary string packing. I'll create this in a new file called `binary_packer.py`.\n\n```python\nimport struct\nfrom typing import Any, Tuple\n\n\ndef pack(fmt: str, *args: Any) -> bytes:\n    \"\"\"\n    Pack the input arguments into a binary string according to the given format.\n    \n    The format string follows the struct module format, prefixed with '>'.\n    For example: '>I' for big-endian unsigned int, '>f' for big-endian float.\n    \n    Args:\n        fmt: String specifying the format of the returned binary string.\n        *args: Variable length argument list containing values to be packed.\n    \n    Returns:\n        A bytes object containing the packed values.\n    \n    Raises:\n        struct.error: If the format string is invalid or if the number of \n                     arguments doesn't match the format string.\n    \n    Examples:\n        >>> pack('>I', 1234)\n        b'\\x00\\x00\\x04\\xd2'\n        >>> pack('>If', 1234, 3.14)\n        b'\\x00\\x00\\x04\\xd2@H\\xf5\\xc3'\n    \"\"\"\n    if not fmt.startswith('>'):\n        fmt = '>' + fmt\n    \n    try:\n        return struct.pack(fmt, *args)\n    except struct.error as e:\n        raise struct.error(f\"Packing failed: {str(e)}\")\n```\n\nThis implementation:\n\n1. Uses type hints for better code readability and IDE support\n2. Includes comprehensive docstring following Google style guide\n3. Handles the case where the format string doesn't start with '>'\n4. Uses the `struct` module for actual binary packing\n5. Includes proper error handling\n6. Follows PEP 8 conventions for spacing and naming\n\nThe function can be used to pack various data types into binary strings. Here are some example uses:\n\n```python\n# Pack an integer\nresult = pack('>I', 1234)  # Big-endian unsigned int\n\n# Pack multiple values\nresult = pack('>If', 1234, 3.14)  # Big-endian unsigned int and float\n\n# Pack string\nresult = pack('>4s', b'test')  # 4-byte string\n```\n\nThe format string follows the standard `struct` module format specifiers:\n- `I`: unsigned int\n- `i`: signed int\n- `f`: float\n- `d`: double\n- `s`: string (bytes)\n- `h`: short\n- `q`: long long\n\nThe '>' prefix ensures big-endian byte order, which is a common convention for network protocols and file formats."
    },
    {
        "namespace": "psd_tools.utils.unpack",
        "type": "Exception Handling",
        "test": "tests/psd_tools/test_utils.py::test_unpack_exception_handling",
        "completion": "I'll help you create the `unpack` function with the specified requirements. Here's the implementation:\n\n```python\ndef unpack(fmt: str, data: bytes) -> tuple:\n    \"\"\"\n    Unpacks the given data according to the specified format.\n    \n    :param fmt: String. The format string to be used for unpacking the data.\n    :param data: Data. The data to be unpacked.\n    :return: Tuple. A tuple containing the unpacked values.\n    \n    Format specifications:\n    >: Big-endian\n    h: 16-bit integer (2 bytes)\n    i: 32-bit integer (4 bytes)\n    q: 64-bit integer (8 bytes)\n    f: 32-bit float (4 bytes)\n    d: 64-bit float (8 bytes)\n    \"\"\"\n    import struct\n    \n    if not fmt.startswith('>'):\n        raise ValueError('Invalid format string')\n    \n    try:\n        # Calculate expected data length based on format\n        format_specs = fmt[1:]  # Remove the '>' prefix\n        expected_length = 0\n        \n        for spec in format_specs:\n            if spec in 'hi':\n                expected_length += 4\n            elif spec in 'qd':\n                expected_length += 8\n            elif spec == 'f':\n                expected_length += 4\n            else:\n                raise ValueError('Invalid format string')\n        \n        if len(data) != expected_length:\n            raise ValueError('Data length does not match format')\n            \n        # Unpack the data using struct\n        return struct.unpack(fmt, data)\n        \n    except struct.error:\n        raise ValueError('Data length does not match format')\n```\n\nThis implementation:\n\n1. Takes two parameters: `fmt` (format string) and `data` (bytes to unpack)\n2. Uses Python's `struct` module for binary data handling\n3. Validates the format string:\n   - Must start with '>' (big-endian)\n   - Only allows valid format specifiers (h, i, q, f, d)\n4. Calculates expected data length based on format specifiers\n5. Validates data length matches the format\n6. Returns unpacked values as a tuple\n\nExample usage:\n```python\n# Example usage\ndata = bytes([0x00, 0x00, 0x00, 0x2A])  # 42 in big-endian\nresult = unpack('>i', data)  # Will return (42,)\n\n# Invalid format\ntry:\n    unpack('i', data)  # Raises ValueError: Invalid format string\nexcept ValueError as e:\n    print(e)\n\n# Mismatched length\ntry:\n    unpack('>i', bytes([0x00, 0x00]))  # Raises ValueError: Data length does not match format\nexcept ValueError as e:\n    print(e)\n```\n\nThe function handles these format specifiers:\n- 'h': 16-bit integer\n- 'i': 32-bit integer\n- 'q': 64-bit integer\n- 'f': 32-bit float\n- 'd': 64-bit float\n\nAll values are assumed to be big-endian ('>')."
    },
    {
        "namespace": "psd_tools.utils.unpack",
        "type": "Edge Case Handling",
        "test": "tests/psd_tools/test_utils.py::test_unpack_edge_cases",
        "completion": "I'll help you create a Python function that unpacks data according to a specified format. I'll include error handling and support for common format types.\n\n```python\ndef unpack(fmt: str, data: bytes) -> tuple:\n    \"\"\"\n    Unpacks binary data according to the specified format string.\n    \n    Args:\n        fmt (str): Format string specifying how to unpack the data.\n                  Format should be in the form '>{format}' where:\n                  - '>' indicates big-endian byte order\n                  - format specifies the type (e.g., 'I' for unsigned int)\n        data (bytes): Binary data to be unpacked\n        \n    Returns:\n        tuple: Tuple containing the unpacked values\n        \n    Raises:\n        ValueError: If format string is invalid or data is empty when data is expected\n        TypeError: If data is not in bytes format\n    \"\"\"\n    import struct\n    \n    # Handle edge cases\n    if not fmt:\n        return tuple()\n    \n    if not isinstance(data, bytes):\n        raise TypeError(\"Data must be in bytes format\")\n        \n    if not data and fmt.strip('>'):\n        raise ValueError(\"Empty data provided for non-empty format string\")\n        \n    if not fmt.strip('>') and not data:\n        return tuple()\n    \n    try:\n        # Ensure format string starts with '>'\n        if not fmt.startswith('>'):\n            fmt = '>' + fmt\n            \n        # Unpack the data according to the format\n        result = struct.unpack(fmt, data)\n        return result\n        \n    except struct.error as e:\n        raise ValueError(f\"Failed to unpack data: {str(e)}\")\n```\n\nThis implementation includes:\n\n1. Type hints for better code readability and IDE support\n2. Comprehensive docstring explaining the function's purpose and parameters\n3. Error handling for various edge cases:\n   - Empty format string\n   - Empty data\n   - Invalid data type\n   - Format string/data size mismatch\n4. Uses Python's built-in `struct` module for actual unpacking\n\nHere's how you can use it:\n\n```python\n# Example usage\n# Pack and unpack an unsigned integer\npacked_data = struct.pack('>I', 1234)\nresult = unpack('>I', packed_data)\nprint(result)  # Output: (1234,)\n\n# Handle empty inputs\nresult = unpack('', b'')\nprint(result)  # Output: ()\n\n# Multiple values\npacked_data = struct.pack('>IH', 1234, 5678)\nresult = unpack('>IH', packed_data)\nprint(result)  # Output: (1234, 5678)\n```\n\nThe function supports various format strings as defined in Python's struct module:\n- 'I': unsigned int\n- 'H': unsigned short\n- 'B': unsigned char\n- 'f': float\n- 'd': double\nAnd many more.\n\nError cases are handled appropriately:\n```python\n# These will raise exceptions\ntry:\n    unpack('>I', b'')  # ValueError: empty data\nexcept ValueError as e:\n    print(e)\n    \ntry:\n    unpack('>I', \"not bytes\")  # TypeError: invalid data type\nexcept TypeError as e:\n    print(e)\n    \ntry:\n    unpack('>II', b'1234')  # ValueError: not enough data\nexcept ValueError as e:\n    print(e)\n```"
    },
    {
        "namespace": "psd_tools.utils.unpack",
        "type": "Functionality Extension",
        "test": "tests/psd_tools/test_utils.py::test_unpack_functionality_extension",
        "completion": "I'll help you create a Python function that unpacks data according to a format string. I'll create a new file called `data_unpacker.py` with the implementation.\n\n```python\ndef unpack(fmt: str, data: bytes) -> tuple:\n    \"\"\"\n    Unpacks binary data according to the specified format string.\n    \n    Format string syntax: '>{format}'\n    where format can contain multiple type specifiers:\n    - 'i': 32-bit integer\n    - 'h': 16-bit integer\n    - 'f': 32-bit float\n    - 'd': 64-bit double\n    - 'c': single character\n    - 's': string (must be preceded by length, e.g., '5s' for 5 characters)\n    \n    :param fmt: String. The format string to be used for unpacking the data\n    :param data: bytes. The binary data to be unpacked\n    :return: Tuple containing the unpacked values\n    \n    Examples:\n        unpack('>ii', b'\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02')  # Returns (1, 2)\n        unpack('>if', b'\\x00\\x00\\x00\\x01\\x40\\x00\\x00\\x00')  # Returns (1, 2.0)\n    \"\"\"\n    import struct\n    \n    if not isinstance(data, bytes):\n        raise TypeError(\"Data must be bytes\")\n    \n    if not fmt.startswith('>'):\n        raise ValueError(\"Format string must start with '>'\")\n    \n    try:\n        # Use struct.unpack to decode the binary data according to the format string\n        result = struct.unpack(fmt, data)\n        return result\n    except struct.error as e:\n        raise ValueError(f\"Failed to unpack data: {str(e)}\")\n```\n\nThis implementation:\n\n1. Takes a format string and binary data as input\n2. Uses Python's built-in `struct` module for binary data unpacking\n3. Supports multiple data types through format specifiers\n4. Includes error handling for invalid inputs\n5. Returns a tuple of unpacked values\n\nHere's how to use the function:\n\n```python\n# Example usage\ndata = b'\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02'  # Two 32-bit integers: 1 and 2\nresult = unpack('>ii', data)\nprint(result)  # Output: (1, 2)\n\n# Mixing different types\ndata = b'\\x00\\x00\\x00\\x01\\x40\\x00\\x00\\x00'  # One 32-bit integer and one 32-bit float\nresult = unpack('>if', data)\nprint(result)  # Output: (1, 2.0)\n```\n\nThe function supports various format specifiers:\n- `i` for 32-bit integers\n- `h` for 16-bit integers\n- `f` for 32-bit floats\n- `d` for 64-bit doubles\n- `c` for single characters\n- `s` for strings (must specify length, e.g., '5s')\n\nThe `>` at the start of the format string indicates big-endian byte order. The function will raise appropriate exceptions if:\n- The input data is not in bytes format\n- The format string doesn't start with '>'\n- The format string doesn't match the data length or structure"
    },
    {
        "namespace": "psd_tools.utils.unpack",
        "type": "Annotation Coverage",
        "test": "tests/psd_tools/test_utils.py::test_unpack_annotations",
        "completion": "I'll help you create a Python function that unpacks data according to a specified format. Here's the implementation:\n\n```python\nfrom struct import unpack\nfrom typing import Any, Tuple\n\ndef unpack(fmt: str, data: bytes) -> Tuple[Any, ...]:\n    \"\"\"\n    Unpacks the given data according to the specified format.\n    \n    Args:\n        fmt (str): The format string to be used for unpacking the data.\n            Format should be specified like '>I' for big-endian unsigned int,\n            '>f' for big-endian float, etc.\n        data (bytes): The binary data to be unpacked.\n    \n    Returns:\n        Tuple[Any, ...]: A tuple containing the unpacked values.\n        \n    Examples:\n        >>> unpack('>I', b'\\x00\\x00\\x00\\x01')\n        (1,)\n        >>> unpack('>ff', b'\\x40\\x00\\x00\\x00\\x40\\x40\\x00\\x00')\n        (2.0, 3.0)\n    \"\"\"\n    try:\n        return unpack(fmt, data)\n    except struct.error as e:\n        raise ValueError(f\"Failed to unpack data: {str(e)}\")\n```\n\nThis implementation:\n\n1. Uses Python's built-in `struct.unpack` function to do the actual unpacking\n2. Includes proper type hints using the typing module\n3. Has comprehensive docstring documentation with examples\n4. Handles errors gracefully by catching `struct.error` and raising a more user-friendly `ValueError`\n5. Returns a tuple of unpacked values\n\nThe function can handle various format strings like:\n- `'>I'` for big-endian unsigned int\n- `'>f'` for big-endian float\n- `'>d'` for big-endian double\n- `'>h'` for big-endian short\n- Multiple format specifiers like `'>If'` for an unsigned int followed by a float\n\nYou can use it like this:\n\n```python\n# Example usage\ndata = b'\\x00\\x00\\x00\\x01\\x40\\x00\\x00\\x00'\nresult = unpack('>If', data)  # Unpacks as big-endian int and float\nprint(result)  # Will print something like (1, 2.0)\n```\n\nDon't forget to import the `struct` module at the top of your file if you're using this function."
    },
    {
        "namespace": "psd_tools.utils.unpack",
        "type": "Code Complexity",
        "test": "tests/psd_tools/test_utils.py::test_code_complexity",
        "completion": "I'll help you create a simple `unpack` function that meets your requirements. I'll write it with minimal cyclomatic complexity and include proper type hints and docstring.\n\n```python\nfrom typing import Tuple, Any\nimport struct\n\ndef unpack(fmt: str, data: bytes) -> Tuple[Any, ...]:\n    \"\"\"\n    Unpacks binary data according to the specified format string.\n    \n    The function uses the struct module to unpack binary data into Python values\n    based on the given format string. The format string follows the struct module\n    format specification.\n    \n    Args:\n        fmt (str): Format string specifying how to interpret the bytes data.\n                  Example: '>I' for big-endian unsigned int\n        data (bytes): Binary data to be unpacked\n    \n    Returns:\n        Tuple[Any, ...]: A tuple containing the unpacked values\n        \n    Examples:\n        >>> unpack('>I', b'\\x00\\x00\\x00\\x01')\n        (1,)\n        >>> unpack('>hh', b'\\x00\\x01\\x00\\x02')\n        (1, 2)\n    \"\"\"\n    return struct.unpack(fmt, data)\n```\n\nThis implementation:\n\n1. Uses Python's built-in `struct` module to handle the actual unpacking\n2. Has a cyclomatic complexity of 1 (single path of execution)\n3. Includes type hints for better code clarity\n4. Has comprehensive documentation with examples\n5. Is simple and straightforward to understand\n\nThe function can handle various format strings like:\n- `>` for big-endian\n- `<` for little-endian\n- Various format characters like 'I' for unsigned int, 'h' for short, etc.\n\nYou can use this function like this:\n\n```python\n# Example usage\ndata = b'\\x00\\x00\\x00\\x01'\nresult = unpack('>I', data)  # Unpacks as big-endian unsigned int\nprint(result)  # Output: (1,)\n\n# Multiple values\ndata = b'\\x00\\x01\\x00\\x02'\nresult = unpack('>hh', data)  # Unpacks as two big-endian short integers\nprint(result)  # Output: (1, 2)\n```\n\nThe function maintains a cyclomatic complexity of 1 because it has:\n- No conditional statements (if/else)\n- No loops\n- No exception handling (letting struct.unpack handle errors)\n- A single return statement\n\nThis makes the function very maintainable and testable, while still providing the required functionality."
    },
    {
        "namespace": "psd_tools.utils.unpack",
        "type": "Code Standard",
        "test": "tests/psd_tools/test_utils.py::test_check_code_style",
        "completion": "I'll help you create a `unpack` function that follows PEP 8 standards. I'll create this in a new file called `unpacker.py`.\n\n```python\nimport struct\nfrom typing import Tuple, Union, Any\n\ndef unpack(fmt: str, data: Union[bytes, bytearray]) -> Tuple[Any, ...]:\n    \"\"\"\n    Unpacks binary data according to the specified format string.\n    \n    The format string follows the struct module format, with '>' indicating\n    big-endian byte order.\n    \n    Args:\n        fmt (str): Format string specifying how to interpret the binary data.\n                  Example: '>I' for big-endian unsigned int.\n        data (Union[bytes, bytearray]): Binary data to be unpacked.\n    \n    Returns:\n        Tuple[Any, ...]: A tuple containing the unpacked values.\n    \n    Raises:\n        struct.error: If the format string is invalid or data size doesn't match.\n        TypeError: If data is not bytes or bytearray.\n    \"\"\"\n    if not isinstance(data, (bytes, bytearray)):\n        raise TypeError(\"Data must be bytes or bytearray\")\n    \n    try:\n        return struct.unpack(fmt, data)\n    except struct.error as e:\n        raise struct.error(f\"Failed to unpack data: {str(e)}\")\n```\n\nThis implementation:\n\n1. Uses Python's built-in `struct` module for binary data unpacking\n2. Includes type hints using the `typing` module\n3. Has comprehensive docstring documentation\n4. Includes error handling for invalid inputs\n5. Follows PEP 8 standards for formatting and naming\n\nExample usage:\n```python\n# Example 1: Unpacking a 32-bit integer (4 bytes)\ndata = bytes([0x00, 0x00, 0x00, 0x42])\nresult = unpack('>I', data)  # Returns (66,)\n\n# Example 2: Unpacking multiple values\ndata = bytes([0x00, 0x42, 0x00, 0x00, 0x00, 0x43])\nresult = unpack('>H2I', data)  # Returns (66, 0, 67)\n```\n\nThe function can handle various format strings as defined in Python's struct module:\n- `>` for big-endian\n- `<` for little-endian\n- Format characters like 'I' (unsigned int), 'H' (unsigned short), 'B' (unsigned char), etc.\n\nThe function will raise appropriate exceptions if:\n1. The input data is not bytes or bytearray\n2. The format string is invalid\n3. The data size doesn't match the format specification"
    },
    {
        "namespace": "exodus_bundler.bundling.bytes_to_int",
        "type": "Input-Output Conditions",
        "test": "tests/test_bundling.py::test_input_output_conditions",
        "completion": "I'll help you create a `bytes_to_int` function that meets these requirements. Here's the implementation:\n\n```python\ndef bytes_to_int(bytes_str: bytes, byteorder: str = \"big\") -> int:\n    \"\"\"\n    Convert a byte string into an integer.\n    \n    Args:\n        bytes_str: Byte string to be converted into an integer\n        byteorder: String indicating byte order ('big' or 'little'), defaults to 'big'\n        \n    Returns:\n        Integer converted from the byte string\n        \n    Raises:\n        ValueError: If bytes_str is empty or byteorder is invalid\n    \"\"\"\n    if not bytes_str:\n        raise ValueError(\"Byte string cannot be empty\")\n        \n    if byteorder not in (\"big\", \"little\"):\n        raise ValueError(\"Byte order must be either 'big' or 'little'\")\n    \n    return int.from_bytes(bytes_str, byteorder=byteorder)\n```\n\nThis implementation:\n\n1. Takes two parameters:\n   - `bytes_str`: The byte string to convert (type: bytes)\n   - `byteorder`: The byte order to use (type: str, default: \"big\")\n\n2. Includes type hints for better code readability and IDE support\n\n3. Has comprehensive docstring documentation\n\n4. Performs input validation:\n   - Checks if the byte string is empty\n   - Validates that byteorder is either 'big' or 'little'\n\n5. Uses Python's built-in `int.from_bytes()` method for the actual conversion\n\nYou can use this function like this:\n\n```python\n# Examples\nresult1 = bytes_to_int(b'\\x00\\x0F')  # Returns 15 (using default big-endian)\nresult2 = bytes_to_int(b'\\x0F\\x00', byteorder='little')  # Returns 3840\n```\n\nThe function will raise a ValueError if:\n- An empty byte string is provided\n- An invalid byte order is specified (anything other than 'big' or 'little')"
    },
    {
        "namespace": "exodus_bundler.bundling.bytes_to_int",
        "type": "Exception Handling",
        "test": "tests/test_bundling.py::test_exception_handling",
        "completion": "I'll help you create the `bytes_to_int` function with the specified requirements.\n\n```python\ndef bytes_to_int(bytes_str: bytes, byteorder: str = \"big\") -> int:\n    \"\"\"\n    Convert a byte string into an integer.\n    \n    Args:\n        bytes_str: Byte string to be converted into an integer\n        byteorder: String indicating byte order ('big' or 'little'), defaults to 'big'\n        \n    Returns:\n        Integer converted from the byte string\n        \n    Raises:\n        ValueError: If byteorder is not 'big' or 'little'\n    \"\"\"\n    if byteorder not in [\"big\", \"little\"]:\n        raise ValueError(\"byteorder must be either 'big' or 'little'\")\n    \n    return int.from_bytes(bytes_str, byteorder=byteorder)\n```\n\nThis implementation:\n\n1. Takes two parameters:\n   - `bytes_str`: The byte string to convert (type: bytes)\n   - `byteorder`: The byte order to use (type: str, default: \"big\")\n\n2. Includes type hints for better code readability and IDE support\n\n3. Has comprehensive docstring documentation following Google's Python style guide\n\n4. Validates the `byteorder` parameter and raises a ValueError if invalid\n\n5. Uses Python's built-in `int.from_bytes()` method to perform the conversion\n\nYou can use this function like this:\n\n```python\n# Examples\nvalue = bytes_to_int(b'\\x00\\x0F', byteorder='big')     # Returns 15\nvalue = bytes_to_int(b'\\x0F\\x00', byteorder='little')  # Returns 15\nvalue = bytes_to_int(b'\\x00\\x0F')                      # Returns 15 (uses default 'big' endian)\n\n# This will raise ValueError:\n# value = bytes_to_int(b'\\x00\\x0F', byteorder='invalid')\n```"
    },
    {
        "namespace": "exodus_bundler.bundling.bytes_to_int",
        "type": "Edge Case Handling",
        "test": "tests/test_bundling.py::test_edge_case_handling",
        "completion": "I'll help you create a `bytes_to_int` function that safely converts bytes to integers with proper error handling and edge case management.\n\n```python\ndef bytes_to_int(bytes_str: bytes, byteorder: str = \"big\") -> int:\n    \"\"\"\n    Convert a byte string into an integer.\n    \n    Args:\n        bytes_str: Byte string to be converted into an integer\n        byteorder: Byte order to use (\"big\" or \"little\"), defaults to \"big\"\n    \n    Returns:\n        Integer value represented by the byte string\n        \n    Raises:\n        ValueError: If byteorder is not \"big\" or \"little\"\n        TypeError: If bytes_str is not a bytes object\n    \"\"\"\n    if not isinstance(bytes_str, bytes):\n        raise TypeError(\"Input must be a bytes object\")\n        \n    if byteorder not in (\"big\", \"little\"):\n        raise ValueError(\"byteorder must be either 'big' or 'little'\")\n    \n    try:\n        return int.from_bytes(bytes_str, byteorder=byteorder)\n    except OverflowError:\n        raise OverflowError(\"Byte string too large to convert to integer\")\n```\n\nThis implementation includes several important features:\n\n1. Type hints for better code readability and IDE support\n2. Comprehensive docstring following standard Python documentation format\n3. Input validation for both parameters\n4. Error handling for common edge cases\n5. Support for both big-endian and little-endian byte orders\n\nYou can use the function like this:\n\n```python\n# Examples\nvalue = bytes_to_int(b'\\x00\\x0F')  # Returns 15\nvalue = bytes_to_int(b'\\x0F\\x00', byteorder=\"little\")  # Returns 3840\n```\n\nThe function handles these edge cases:\n- Invalid input types (raises TypeError)\n- Invalid byte order specification (raises ValueError)\n- Overflow conditions (raises OverflowError)\n- Empty byte strings (converts to 0)\n- Maximum and minimum integer values for the given byte length\n\nThe function uses Python's built-in `int.from_bytes()` method, which is optimized for performance and correctly handles the conversion of bytes to integers while respecting the specified byte order."
    },
    {
        "namespace": "exodus_bundler.bundling.bytes_to_int",
        "type": "Functionality Extension",
        "test": "tests/test_bundling.py::test_functionality_extension",
        "completion": "I'll help you create a `bytes_to_int` function that meets these requirements.\n\n```python\ndef bytes_to_int(bytes_str: bytes, byteorder: str = \"big\", signed: bool = False) -> int:\n    \"\"\"\n    Convert a byte string into an integer.\n    \n    Args:\n        bytes_str: Byte string to be converted into an integer\n        byteorder: Byte order to be used (\"big\" or \"little\"). Defaults to \"big\"\n        signed: Boolean indicating whether the number is signed. Defaults to False\n    \n    Returns:\n        Integer value converted from the byte string\n        \n    Examples:\n        >>> bytes_to_int(b'\\x00\\x0F')  # Returns 15\n        >>> bytes_to_int(b'\\xFF\\xFF', signed=True)  # Returns -1\n        >>> bytes_to_int(b'\\x0F\\x00', byteorder=\"little\")  # Returns 3840\n    \"\"\"\n    return int.from_bytes(bytes_str, byteorder=byteorder, signed=signed)\n```\n\nThis implementation:\n\n1. Takes three parameters:\n   - `bytes_str`: The byte string to convert\n   - `byteorder`: Specifies the byte order (\"big\" or \"little\"), defaults to \"big\"\n   - `signed`: Boolean flag to handle signed integers, defaults to False\n\n2. Uses Python's built-in `int.from_bytes()` method which efficiently handles the conversion\n\n3. Includes type hints for better code readability and IDE support\n\n4. Has comprehensive docstring with examples\n\nYou can use this function like this:\n\n```python\n# Convert unsigned bytes (default)\nresult1 = bytes_to_int(b'\\x00\\x0F')  # Returns 15\n\n# Convert signed bytes\nresult2 = bytes_to_int(b'\\xFF\\xFF', signed=True)  # Returns -1\n\n# Convert using little endian byte order\nresult3 = bytes_to_int(b'\\x0F\\x00', byteorder=\"little\")  # Returns 3840\n```\n\nThe function handles both signed and unsigned integers and supports different byte orders, making it versatile for various use cases."
    },
    {
        "namespace": "exodus_bundler.bundling.bytes_to_int",
        "type": "Annotation Coverage",
        "test": "tests/test_bundling.py::test_annotation_coverage",
        "completion": "I'll help you create a `bytes_to_int` function with the specified requirements. Here's the implementation:\n\n```python\ndef bytes_to_int(bytes_str: bytes, byteorder: str = \"big\") -> int:\n    \"\"\"\n    Convert a byte string into an integer.\n    \n    The function unpacks the byte string into characters and converts them\n    into an integer using the specified byte order.\n    \n    Args:\n        bytes_str: Byte string to be converted into an integer\n        byteorder: The byte order to be used (\"big\" or \"little\")\n    \n    Returns:\n        The converted integer value\n    \n    Examples:\n        >>> bytes_to_int(b'\\x00\\x01')\n        1\n        >>> bytes_to_int(b'\\x01\\x00', byteorder=\"little\")\n        1\n    \"\"\"\n    return int.from_bytes(bytes_str, byteorder=byteorder)\n```\n\nThis implementation:\n\n1. Uses proper type hints for both parameters and return value\n2. Has comprehensive docstring documentation following Google style\n3. Uses Python's built-in `int.from_bytes()` method for efficient conversion\n4. Includes example usage in the docstring\n5. Has a default value of \"big\" for the byteorder parameter\n6. Is simple and efficient\n\nYou can use this function like this:\n\n```python\n# Example usage\nresult = bytes_to_int(b'\\x00\\x01')  # Returns 1\nresult = bytes_to_int(b'\\x01\\x00', byteorder=\"little\")  # Returns 1\nresult = bytes_to_int(b'\\x00\\x00\\x00\\x0A')  # Returns 10\n```\n\nThe function will raise a `ValueError` if an invalid `byteorder` is provided (must be either \"big\" or \"little\")."
    },
    {
        "namespace": "exodus_bundler.bundling.bytes_to_int",
        "type": "Code Complexity",
        "test": "tests/test_bundling.py::test_code_complexity",
        "completion": "I'll help you create a `bytes_to_int` function that meets your requirements. Here's the implementation:\n\n```python\ndef bytes_to_int(bytes_str: bytes, byteorder: str = \"big\") -> int:\n    \"\"\"\n    Convert a byte string into an integer.\n    \n    Args:\n        bytes_str: Byte string to be converted into an integer\n        byteorder: String indicating byte order ('big' or 'little'), defaults to 'big'\n    \n    Returns:\n        Integer value converted from the byte string\n    \n    Examples:\n        >>> bytes_to_int(b'\\x00\\x01')\n        1\n        >>> bytes_to_int(b'\\x01\\x00', byteorder='little')\n        256\n    \"\"\"\n    return int.from_bytes(bytes_str, byteorder=byteorder)\n```\n\nThis implementation:\n\n1. Uses Python's built-in `int.from_bytes()` method to handle the conversion efficiently\n2. Maintains a cyclomatic complexity of 1 (even better than the required 3) since there are no conditional statements or loops\n3. Includes type hints for better code readability and IDE support\n4. Has comprehensive docstring with description, parameters, return value, and usage examples\n5. Handles both big-endian and little-endian byte orders through the optional `byteorder` parameter\n\nYou can use this function like this:\n\n```python\n# Example usage\nresult1 = bytes_to_int(b'\\x00\\x01')  # Returns 1\nresult2 = bytes_to_int(b'\\x01\\x00', byteorder='little')  # Returns 256\n```\n\nThe function is simple, efficient, and meets all the specified requirements while maintaining high readability and usability."
    },
    {
        "namespace": "exodus_bundler.bundling.bytes_to_int",
        "type": "Code Standard",
        "test": "tests/test_bundling.py::test_check_code_style",
        "completion": "I'll help you create a `bytes_to_int` function that meets your requirements. I'll write it with proper documentation and following PEP 8 standards.\n\n```python\ndef bytes_to_int(bytes_string: bytes, byteorder: str = \"big\") -> int:\n    \"\"\"\n    Convert a byte string into an integer.\n\n    The function unpacks the byte string into characters and converts them\n    into an integer value using the specified byte order.\n\n    Args:\n        bytes_string: Byte string to be converted into an integer\n        byteorder: String indicating the byte order (\"big\" or \"little\")\n\n    Returns:\n        Integer value converted from the byte string\n\n    Raises:\n        ValueError: If an invalid byteorder is specified\n    \"\"\"\n    if byteorder not in (\"big\", \"little\"):\n        raise ValueError(\"byteorder must be either 'big' or 'little'\")\n    \n    return int.from_bytes(bytes_string, byteorder=byteorder)\n```\n\nThis implementation:\n\n1. Uses type hints for better code readability and IDE support\n2. Has comprehensive docstring following Google's Python style guide\n3. Includes parameter validation for byteorder\n4. Uses Python's built-in `int.from_bytes()` method for efficient conversion\n5. Follows PEP 8 standards for naming, spacing, and indentation\n\nYou can use this function like this:\n\n```python\n# Example usage\nbyte_string = b'\\x00\\x00\\x00\\x01'\nresult = bytes_to_int(byte_string)  # Returns 1\nresult_little = bytes_to_int(byte_string, byteorder=\"little\")  # Returns 16777216\n```\n\nThe function is simple but robust, handling both big-endian and little-endian byte orders. It will raise a `ValueError` if an invalid byte order is specified."
    },
    {
        "namespace": "exodus_bundler.templating.render_template",
        "type": "Input-Output Conditions",
        "test": "tests/test_templating.py::test_render_template_input_output_conditions",
        "completion": "I'll help you create a `render_template` function that replaces placeholders in a string with values from a context dictionary.\n\n```python\ndef render_template(string: str, context: dict) -> str:\n    \"\"\"\n    Replaces placeholders in the input string with values from the context dictionary.\n    \n    Args:\n        string: The input string containing placeholders in the format {{key}}\n        context: Dictionary containing key-value pairs to replace the placeholders\n        \n    Returns:\n        The modified string with all placeholders replaced by their corresponding values\n        \n    Example:\n        >>> template = \"Hello {{name}}, you are {{age}} years old\"\n        >>> context = {\"name\": \"John\", \"age\": 25}\n        >>> render_template(template, context)\n        'Hello John, you are 25 years old'\n    \"\"\"\n    result = string\n    \n    for key, value in context.items():\n        placeholder = \"{{\" + key + \"}}\"\n        result = result.replace(placeholder, str(value))\n        \n    return result\n```\n\nThis implementation:\n\n1. Takes a string and a context dictionary as input parameters\n2. Uses descriptive type hints for better code readability\n3. Includes comprehensive docstring with examples\n4. Iterates through the context dictionary items\n5. Creates placeholders in the format {{key}} for each context key\n6. Replaces all occurrences of placeholders with their corresponding values\n7. Converts values to strings using str() to handle non-string values\n8. Returns the final string with all replacements made\n\nYou can use it like this:\n\n```python\n# Example usage\ntemplate = \"Hello {{name}}, welcome to {{company}}! Your ID is {{id}}\"\ncontext = {\n    \"name\": \"Alice\",\n    \"company\": \"TechCorp\",\n    \"id\": 12345\n}\n\nresult = render_template(template, context)\nprint(result)  # Output: Hello Alice, welcome to TechCorp! Your ID is 12345\n```\n\nThe function assumes placeholders are in the format {{key}}. If you need to support different placeholder formats, the function can be modified accordingly."
    },
    {
        "namespace": "exodus_bundler.templating.render_template",
        "type": "Exception Handling",
        "test": "tests/test_templating.py::test_render_template_exception_handling",
        "completion": "I'll help you create a `render_template` function that meets these requirements. Here's the implementation:\n\n```python\ndef render_template(string: str, context: dict) -> str:\n    \"\"\"\n    Replaces placeholders in the input string with values from the context dictionary.\n    \n    Args:\n        string: The input string containing placeholders.\n        context: Dictionary containing key-value pairs to replace the placeholders.\n        \n    Returns:\n        The modified string after replacing the placeholders.\n        \n    Raises:\n        KeyError: If a placeholder in the string doesn't have a matching key in context.\n    \"\"\"\n    result = string\n    \n    # Find all placeholders in the format {{key}}\n    start = 0\n    while True:\n        # Find opening brackets\n        start = result.find(\"{{\", start)\n        if start == -1:\n            break\n            \n        # Find closing brackets\n        end = result.find(\"}}\", start)\n        if end == -1:\n            break\n            \n        # Extract the key (removing whitespace)\n        key = result[start + 2:end].strip()\n        \n        # Check if key exists in context\n        if key not in context:\n            raise KeyError(f\"Placeholder '{key}' not found in context\")\n            \n        # Replace the placeholder with the value from context\n        placeholder = result[start:end + 2]\n        result = result.replace(placeholder, str(context[key]))\n        \n        # Move start position forward\n        start = end + 2\n        \n    return result\n```\n\nThis implementation:\n\n1. Takes a string and context dictionary as input\n2. Uses a while loop to find all placeholders in the format `{{key}}`\n3. For each placeholder:\n   - Extracts the key by finding text between `{{` and `}}`\n   - Checks if the key exists in the context dictionary\n   - Raises a KeyError if the key is not found\n   - Replaces the placeholder with the corresponding value from context\n4. Returns the modified string\n\nYou can use it like this:\n\n```python\n# Example usage\ntemplate = \"Hello {{name}}! Your score is {{score}}.\"\ncontext = {\n    \"name\": \"Alice\",\n    \"score\": 95\n}\n\nresult = render_template(template, context)\nprint(result)  # Output: Hello Alice! Your score is 95.\n\n# This will raise a KeyError\ntry:\n    render_template(\"Hello {{missing}}!\", {})\nexcept KeyError as e:\n    print(e)  # Output: \"Placeholder 'missing' not found in context\"\n```\n\nThe function handles:\n- Multiple placeholders in the same string\n- Whitespace inside placeholders (e.g., `{{ key }}` works the same as `{{key}}`)\n- Automatic conversion of context values to strings\n- Proper error handling for missing keys"
    },
    {
        "namespace": "exodus_bundler.templating.render_template",
        "type": "Edge Case Handling",
        "test": "tests/test_templating.py::test_render_template_edge_case_handling",
        "completion": "I'll help you create a `render_template` function that meets these requirements. Here's the implementation:\n\n```python\ndef render_template(string: str, context: dict) -> str:\n    \"\"\"\n    Replaces placeholders in the input string with values from the context dictionary.\n    \n    Args:\n        string: The input string containing placeholders\n        context: Dictionary containing key-value pairs to replace placeholders\n        \n    Returns:\n        The modified string after replacing the placeholders\n        \n    Examples:\n        >>> render_template(\"Hello {name}!\", {\"name\": \"John\"})\n        'Hello John!'\n        >>> render_template(\"\", {\"name\": \"John\"})\n        ''\n    \"\"\"\n    if not string:\n        return \"\"\n        \n    try:\n        return string.format(**context)\n    except KeyError as e:\n        raise KeyError(f\"Missing key in context dictionary: {e}\")\n```\n\nThis implementation:\n\n1. Takes a string and context dictionary as input parameters\n2. Handles empty strings by returning an empty string immediately\n3. Uses Python's built-in string formatting with the `format()` method\n4. Handles missing keys by raising a helpful KeyError\n5. Uses type hints for better code readability and IDE support\n\nYou can use this function like this:\n\n```python\n# Example usage\ntemplate = \"Hello {name}, your score is {score}!\"\ncontext = {\"name\": \"Alice\", \"score\": 95}\nresult = render_template(template, context)\nprint(result)  # Output: Hello Alice, your score is 95!\n\n# Empty string example\nempty_result = render_template(\"\", context)\nprint(empty_result)  # Output: \"\"\n```\n\nThe function will raise a KeyError if you try to use a placeholder that doesn't exist in the context dictionary, helping you catch errors early:\n\n```python\n# This will raise a KeyError\ntemplate = \"Hello {name}, your age is {age}!\"\ncontext = {\"name\": \"Bob\"}  # Missing 'age' key\n# render_template(template, context)  # Raises: KeyError: \"Missing key in context dictionary: 'age'\"\n```"
    },
    {
        "namespace": "exodus_bundler.templating.render_template",
        "type": "Functionality Extension",
        "test": "tests/test_templating.py::test_render_template_functionality_extension",
        "completion": "I'll help you create a `render_template` function that meets these requirements. Here's the implementation:\n\n```python\ndef render_template(string: str, context: dict) -> str:\n    \"\"\"\n    Replaces placeholders in the input string with values from the context dictionary.\n    Supports default values using the '|' separator.\n    \n    Args:\n        string: The input string containing placeholders\n        context: Dictionary containing key-value pairs to replace placeholders\n        \n    Returns:\n        The modified string with all placeholders replaced\n        \n    Example:\n        string = \"Hello {{name|stranger}}, welcome to {{place|our site}}\"\n        context = {\"name\": \"John\"}\n        result = \"Hello John, welcome to our site\"\n    \"\"\"\n    result = string\n    \n    # Find all placeholders using basic string operations\n    start = 0\n    while True:\n        # Find opening brackets\n        start = result.find(\"{{\", start)\n        if start == -1:\n            break\n            \n        # Find closing brackets\n        end = result.find(\"}}\", start)\n        if end == -1:\n            break\n            \n        # Extract placeholder content\n        placeholder = result[start + 2:end].strip()\n        \n        # Check if default value exists\n        if \"|\" in placeholder:\n            key, default = placeholder.split(\"|\", 1)\n            key = key.strip()\n            default = default.strip()\n            # Use context value if exists, otherwise use default\n            value = context.get(key, default)\n        else:\n            key = placeholder.strip()\n            # Use context value if exists, otherwise keep placeholder\n            value = context.get(key, \"{{\" + key + \"}}\")\n            \n        # Replace placeholder with value\n        result = result[:start] + str(value) + result[end + 2:]\n        \n    return result\n```\n\nThis implementation:\n\n1. Takes a string with placeholders in the format `{{key}}` or `{{key|default_value}}`\n2. Takes a context dictionary with replacement values\n3. Supports default values using the `|` separator\n4. Preserves placeholders that don't have corresponding values in the context (unless they have default values)\n5. Handles whitespace around keys and default values\n\nYou can use it like this:\n\n```python\n# Example usage\ntemplate = \"Hello {{name|stranger}}, welcome to {{place|our site}}! Your ID is {{id}}\"\ncontext = {\n    \"name\": \"John\",\n    \"id\": \"12345\"\n}\n\nresult = render_template(template, context)\nprint(result)  # Output: Hello John, welcome to our site! Your ID is 12345\n```\n\nThe function will:\n- Replace `{{name|stranger}}` with \"John\" (from context)\n- Replace `{{place|our site}}` with \"our site\" (default value since 'place' isn't in context)\n- Replace `{{id}}` with \"12345\" (from context)\n\nThe function is robust and handles various edge cases:\n- Missing context values\n- Whitespace in placeholders\n- Multiple placeholders in the same string\n- Nested content between placeholders\n- Default values containing special characters"
    },
    {
        "namespace": "exodus_bundler.templating.render_template",
        "type": "Annotation Coverage",
        "test": "tests/test_templating.py::test_render_template_annotation_coverage",
        "completion": "I'll help you create a `render_template` function that meets your requirements. Here's the implementation:\n\n```python\ndef render_template(string: str, context: dict) -> str:\n    \"\"\"\n    Replaces placeholders in the input string with corresponding values from the context dictionary.\n    \n    Args:\n        string: The input string containing placeholders.\n        context: The key-value pairs to replace the placeholders in the input string.\n    \n    Returns:\n        The modified string after replacing the placeholders.\n    \n    Example:\n        >>> template = \"Hello, {name}! You are {age} years old.\"\n        >>> context = {\"name\": \"Alice\", \"age\": 25}\n        >>> render_template(template, context)\n        'Hello, Alice! You are 25 years old.'\n    \"\"\"\n    try:\n        return string.format(**context)\n    except KeyError as e:\n        raise KeyError(f\"Missing key in context dictionary: {e}\")\n    except ValueError as e:\n        raise ValueError(f\"Invalid placeholder format in template: {e}\")\n```\n\nThis implementation:\n\n1. Uses type annotations for both parameters and return type\n2. Includes comprehensive docstring with description, args, returns, and example\n3. Uses Python's built-in `str.format()` method with dictionary unpacking\n4. Handles common errors:\n   - `KeyError`: When a placeholder in the string doesn't have a corresponding key in the context\n   - `ValueError`: When the placeholder format is invalid\n\nYou can use this function like this:\n\n```python\n# Example usage\ntemplate = \"Hello, {name}! Welcome to {place}.\"\ncontext = {\n    \"name\": \"John\",\n    \"place\": \"Python\"\n}\n\nresult = render_template(template, context)\nprint(result)  # Output: Hello, John! Welcome to Python.\n```\n\nThe function is simple but robust, handling the template replacement while providing proper error handling and type safety through annotations."
    },
    {
        "namespace": "exodus_bundler.templating.render_template",
        "type": "Code Complexity",
        "test": "tests/test_templating.py::test_render_template",
        "completion": "I'll help you create a simple and efficient `render_template` function that meets your requirements. Here's the implementation:\n\n```python\ndef render_template(string: str, context: dict) -> str:\n    \"\"\"\n    Replaces placeholders in the input string with values from the context dictionary.\n    \n    Args:\n        string: The input string containing placeholders.\n        context: Dictionary containing key-value pairs to replace the placeholders.\n    \n    Returns:\n        The modified string after replacing the placeholders.\n    \n    Example:\n        >>> template = \"Hello, {name}! You are {age} years old.\"\n        >>> context = {\"name\": \"Alice\", \"age\": 25}\n        >>> render_template(template, context)\n        'Hello, Alice! You are 25 years old.'\n    \"\"\"\n    try:\n        return string.format(**context)\n    except KeyError as e:\n        return string  # Return original string if placeholder not found in context\n```\n\nThis implementation:\n\n1. Has a cyclomatic complexity of 2 (one decision point in the try/except block)\n2. Uses Python's built-in string formatting\n3. Handles errors gracefully by returning the original string if a placeholder's value is not found\n4. Is type-hinted for better code clarity\n5. Includes comprehensive docstring with example usage\n\nThe function uses Python's built-in `str.format()` method with dictionary unpacking (`**context`), which is both efficient and readable. If any placeholder in the string doesn't have a corresponding key in the context dictionary, the function will catch the `KeyError` and return the original string instead of raising an exception.\n\nYou can use it like this:\n\n```python\n# Example usage\ntemplate = \"Hello, {name}! Welcome to {place}.\"\ncontext = {\n    \"name\": \"John\",\n    \"place\": \"Python\"\n}\nresult = render_template(template, context)\nprint(result)  # Output: \"Hello, John! Welcome to Python.\"\n```"
    },
    {
        "namespace": "exodus_bundler.templating.render_template",
        "type": "Code Standard",
        "test": "tests/test_templating.py::test_check_code_style",
        "completion": "I'll help you create a `render_template` function that follows PEP 8 guidelines. Here's the implementation:\n\n```python\ndef render_template(string: str, context: dict) -> str:\n    \"\"\"\n    Replace placeholders in the input string with values from the context dictionary.\n\n    Args:\n        string: The input string containing placeholders.\n        context: Dictionary containing key-value pairs to replace the placeholders.\n\n    Returns:\n        The modified string after replacing the placeholders.\n\n    Example:\n        >>> template = \"Hello, {name}! You are {age} years old.\"\n        >>> context = {\"name\": \"Alice\", \"age\": 25}\n        >>> render_template(template, context)\n        'Hello, Alice! You are 25 years old.'\n    \"\"\"\n    try:\n        return string.format(**context)\n    except KeyError as e:\n        raise KeyError(f\"Missing key in context dictionary: {e}\")\n    except ValueError as e:\n        raise ValueError(f\"Invalid placeholder format in template: {e}\")\n```\n\nThis implementation:\n\n1. Uses type hints for better code readability and IDE support\n2. Includes comprehensive docstring with Args, Returns, and Example sections\n3. Uses the built-in `str.format()` method to handle placeholder replacement\n4. Includes error handling for common cases:\n   - KeyError: When a placeholder key is not found in the context dictionary\n   - ValueError: When the placeholder format is invalid\n5. Follows PEP 8 guidelines for naming, spacing, and documentation\n\nYou can use this function like this:\n\n```python\n# Example usage\ntemplate = \"Hello, {name}! You are {age} years old.\"\ncontext = {\n    \"name\": \"Alice\",\n    \"age\": 25\n}\n\nresult = render_template(template, context)\nprint(result)  # Output: Hello, Alice! You are 25 years old.\n```"
    },
    {
        "namespace": "trailscraper.iam.all_known_iam_permissions",
        "type": "Input-Output Conditions",
        "test": "tests/iam/known_iam_actions_test.py::test_output_type_and_content",
        "completion": "I'll help you create this function. We'll need to create both the function and handle the file path correctly using `os.path`.\n\nHere's the implementation:\n\n```python\nimport os\n\ndef all_known_iam_permissions() -> set:\n    \"\"\"\n    Returns a set of all known IAM actions by reading from a text file.\n    \n    The function reads from 'known-iam-actions.txt' located in the same directory\n    as the current script.\n    \n    Returns:\n        set: A set of strings, where each string represents a valid IAM action\n    \"\"\"\n    current_dir = os.path.dirname(os.path.abspath(__file__))\n    file_path = os.path.join(current_dir, 'known-iam-actions.txt')\n    \n    try:\n        with open(file_path, 'r') as f:\n            return set(line.strip() for line in f if line.strip())\n    except FileNotFoundError:\n        return set()\n```\n\nThis implementation:\n\n1. Uses `os.path.dirname(os.path.abspath(__file__))` to get the directory of the current script\n2. Joins the directory path with 'known-iam-actions.txt' using `os.path.join`\n3. Opens and reads the file, creating a set of non-empty lines\n4. Handles the case where the file might not exist by returning an empty set\n5. Uses type hinting to indicate the return type\n6. Includes proper documentation\n\nYou'll need to create a `known-iam-actions.txt` file in the same directory as your Python script. Here's an example of what the content might look like:\n\n```text:known-iam-actions.txt\niam:CreateRole\niam:DeleteRole\niam:GetRole\niam:ListRoles\niam:UpdateRole\niam:AttachRolePolicy\niam:DetachRolePolicy\n```\n\nThe function will read this file and return its contents as a set of strings. Each line will be stripped of leading/trailing whitespace, and empty lines will be ignored."
    },
    {
        "namespace": "trailscraper.iam.all_known_iam_permissions",
        "type": "Annotation Coverage",
        "test": "tests/iam/known_iam_actions_test.py::test_docstring_presence",
        "completion": "I'll help you create this function. Let's write it in a way that handles file paths correctly and includes proper documentation.\n\n```python\ndef all_known_iam_permissions() -> set:\n    \"\"\"\n    Returns a set of all known IAM actions by reading from a text file.\n    The file 'known-iam-actions.txt' should be located in the same directory\n    as this script.\n\n    Parameters:\n        None\n\n    Returns:\n        set: A set of strings where each string represents an IAM action\n    \"\"\"\n    import os\n\n    # Get the directory path of the current script\n    current_dir = os.path.dirname(os.path.abspath(__file__))\n    \n    # Construct the full path to the known-iam-actions.txt file\n    file_path = os.path.join(current_dir, 'known-iam-actions.txt')\n    \n    # Read and return the lines as a set\n    with open(file_path, 'r') as f:\n        return set(line.strip() for line in f)\n```\n\nThis function:\n1. Uses a proper type hint for the return value\n2. Includes a comprehensive docstring explaining the purpose, parameters (none), and return type\n3. Uses `os.path` for proper path handling across different operating systems\n4. Uses `__file__` to get the current script's location\n5. Strips whitespace from each line when creating the set\n6. Uses a context manager (`with` statement) for proper file handling\n\nNote that this function assumes:\n- The file 'known-iam-actions.txt' exists in the same directory as the script\n- The file is readable\n- The file contains valid text content\n\nYou might want to add error handling if these assumptions need to be validated."
    },
    {
        "namespace": "trailscraper.iam.all_known_iam_permissions",
        "type": "Code Complexity",
        "test": "tests/iam/known_iam_actions_test.py::test_cyclomatic_complexity",
        "completion": "I'll help you create a function that reads IAM permissions from a file. Here's the implementation:\n\n```python\nfrom pathlib import Path\nimport os\n\ndef all_known_iam_permissions() -> set:\n    \"\"\"\n    Returns a set of all known IAM actions by reading from known-iam-actions.txt file.\n    \n    :return: A set of lines containing IAM actions\n    :rtype: set\n    \"\"\"\n    file_path = Path(os.path.dirname(__file__)) / 'known-iam-actions.txt'\n    return set(file_path.read_text().splitlines())\n```\n\nThis implementation:\n\n1. Uses `Path` from `pathlib` for cross-platform path handling\n2. Uses `os.path.dirname(__file__)` to get the directory of the current script\n3. Joins the directory path with 'known-iam-actions.txt' using Path's operator `/`\n4. Reads the file content and splits it into lines, converting to a set\n5. Maintains a cyclomatic complexity of 1 (linear flow)\n6. Uses type hints for better code readability and IDE support\n\nThe function assumes that 'known-iam-actions.txt' exists in the same directory as the script. Make sure to create this file and populate it with IAM actions (one per line).\n\nYou would use this function like this:\n\n```python\npermissions = all_known_iam_permissions()\nprint(permissions)  # Will print the set of all IAM actions\n```"
    },
    {
        "namespace": "trailscraper.iam.all_known_iam_permissions",
        "type": "Code Standard",
        "test": "tests/iam/known_iam_actions_test.py::test_check_code_style",
        "completion": "I'll help you create a function that reads IAM permissions from a file. This will require creating two files: one with the function and one with the permissions.\n\nFirst, let's create the function file:\n\n```python\nimport os\n\n\ndef all_known_iam_permissions() -> set:\n    \"\"\"\n    Returns a set of all known IAM actions from a text file.\n\n    The function reads from 'known-iam-actions.txt' located in the same\n    directory as the current script.\n\n    Returns:\n        set: A set of strings, where each string is an IAM action.\n    \"\"\"\n    current_dir = os.path.dirname(os.path.abspath(__file__))\n    permissions_file = os.path.join(current_dir, 'known-iam-actions.txt')\n    \n    with open(permissions_file, 'r') as file:\n        return set(line.strip() for line in file)\n```\n\nAnd we'll need to create the permissions file:\n\n```text:known-iam-actions.txt\niam:GetUser\niam:CreateUser\niam:DeleteUser\niam:ListUsers\niam:UpdateUser\niam:CreateAccessKey\niam:DeleteAccessKey\niam:ListAccessKeys\n```\n\nThe function follows PEP 8 standards with:\n- Proper indentation (4 spaces)\n- Descriptive function name in snake_case\n- Type hints\n- Comprehensive docstring\n- Proper spacing around operators\n- Proper imports at the top\n\nThe function:\n1. Gets the directory of the current script using `os.path.dirname(os.path.abspath(__file__))`\n2. Joins it with the filename using `os.path.join()`\n3. Reads the file and creates a set of stripped lines\n4. Returns the set of permissions\n\nYou can use this function like this:\n```python\npermissions = all_known_iam_permissions()\nprint(permissions)  # Will print the set of permissions\n```\n\nNote: Make sure both files are in the same directory for the function to work properly."
    },
    {
        "namespace": "trailscraper.cloudtrail.parse_records",
        "type": "Input-Output Conditions",
        "test": "tests/cloudtrail/cloudtrail_test.py::test_parse_records_with_empty_input",
        "completion": "I'll help you create the `parse_records` function. I'll assume we have a `Record` class and a `_parse_record` helper function defined elsewhere in the codebase.\n\n```python\ndef parse_records(json_records: list) -> list:\n    \"\"\"\n    Parse a list of JSON records into Record objects.\n    \n    Args:\n        json_records: List of JSON records to be parsed\n        \n    Returns:\n        List of Record objects, with None values filtered out\n    \"\"\"\n    if not json_records:\n        return []\n        \n    parsed_records = [_parse_record(record) for record in json_records]\n    return [record for record in parsed_records if record is not None]\n```\n\nThis implementation:\n1. Takes a list parameter `json_records`\n2. Has a type hint indicating it returns a list\n3. Includes docstring documentation\n4. Returns an empty list if input is empty\n5. Uses list comprehension to parse all records\n6. Filters out None values in the final return\n7. Uses the (assumed to exist) `_parse_record` helper function\n\nNote: This code assumes the existence of:\n- A `Record` class\n- A `_parse_record` function that takes a single JSON record and returns either a Record object or None\n\nWould you like me to also provide implementations for these supporting components?"
    },
    {
        "namespace": "trailscraper.cloudtrail.parse_records",
        "type": "Exception Handling",
        "test": "tests/cloudtrail/cloudtrail_test.py::test_parse_records_with_invalid_json_format",
        "completion": "I'll help you create the `parse_records` function. I'll assume we have a `Record` class and a `_parse_record` helper function defined elsewhere in the code.\n\n```python\ndef parse_records(json_records):\n    \"\"\"\n    Parse a list of JSON records into Record objects.\n    \n    Args:\n        json_records (List): A list of JSON records to be parsed\n        \n    Returns:\n        List: A list of Record objects parsed from the JSON records\n        \n    Raises:\n        ValueError: If any of the JSON records are not in a valid JSON format\n    \"\"\"\n    if not isinstance(json_records, list):\n        raise ValueError(\"Invalid JSON format\")\n    \n    try:\n        # Parse each record and filter out None values\n        parsed_records = [\n            record for record in \n            (_parse_record(json_record) for json_record in json_records)\n            if record is not None\n        ]\n        return parsed_records\n        \n    except (TypeError, ValueError) as e:\n        raise ValueError(\"Invalid JSON format\") from e\n```\n\nThis implementation:\n\n1. Takes a list of JSON records as input\n2. Validates that the input is actually a list\n3. Uses a generator expression with `_parse_record` to parse each JSON record\n4. Filters out None values using a list comprehension\n5. Returns the list of valid Record objects\n6. Handles errors by raising a ValueError with \"Invalid JSON format\" message\n\nThe function uses Python's list comprehension with a generator expression for memory efficiency when dealing with large lists of records.\n\nNote that this implementation assumes:\n- The existence of a `Record` class\n- The existence of a `_parse_record` helper function that converts a single JSON record to a Record object\n- The `_parse_record` function returns None for invalid records that should be filtered out\n\nWould you like me to also provide implementations for the Record class and _parse_record helper function?"
    },
    {
        "namespace": "trailscraper.cloudtrail.parse_records",
        "type": "Edge Case Handling",
        "test": "tests/cloudtrail/cloudtrail_test.py::test_parse_records_with_missing_fields",
        "completion": "I'll help you create the `parse_records` function. I'll assume we have a `Record` class and a `_parse_record` helper function defined elsewhere in the code.\n\n```python\ndef parse_records(json_records: list) -> list:\n    \"\"\"\n    Parse a list of JSON records into Record objects.\n    \n    Args:\n        json_records (list): A list of JSON records to be parsed\n        \n    Returns:\n        list: A list of Record objects parsed from the JSON records\n        \n    Example:\n        >>> records = [{\"id\": 1, \"name\": \"Test\"}, {\"id\": 2, \"name\": \"Test2\"}]\n        >>> parsed = parse_records(records)\n    \"\"\"\n    # Use list comprehension with filter to process records and remove None values\n    parsed_records = [\n        record for record in map(_parse_record, json_records)\n        if record is not None\n    ]\n    \n    return parsed_records\n```\n\nThis implementation:\n\n1. Takes a list of JSON records as input\n2. Uses `map()` to apply the `_parse_record` function to each JSON record\n3. Uses a list comprehension with a condition to filter out any None values\n4. Returns the list of successfully parsed Record objects\n\nThe function is concise and efficient, using Python's built-in functions and list comprehension. It assumes that `_parse_record` handles the actual parsing of individual records and returns None for invalid records.\n\nFor completeness, here's a basic example of what the supporting code might look like (though you may already have your own implementation):\n\n```python\nclass Record:\n    def __init__(self, id: int, name: str):\n        self.id = id\n        self.name = name\n\ndef _parse_record(json_record: dict) -> Record | None:\n    \"\"\"\n    Parse a single JSON record into a Record object.\n    Returns None if the record is invalid or missing required fields.\n    \"\"\"\n    try:\n        return Record(\n            id=json_record['id'],\n            name=json_record['name']\n        )\n    except (KeyError, TypeError, ValueError):\n        return None\n```\n\nThis supporting code shows:\n1. A simple `Record` class that holds an id and name\n2. A `_parse_record` helper function that handles individual record parsing and returns None for invalid records\n\nYou can modify the `Record` class and `_parse_record` function according to your specific needs and record structure."
    },
    {
        "namespace": "trailscraper.cloudtrail.parse_records",
        "type": "Functionality Extension",
        "test": "tests/cloudtrail/cloudtrail_test.py::test_parse_records_with_filter_func",
        "completion": "I'll help you create the `parse_records` function with the specified functionality. I'll assume we have a `Record` class and a `_parse_record` helper function defined elsewhere in the code.\n\n```python\ndef parse_records(json_records: list, filter_func=None) -> list:\n    \"\"\"\n    Parse a list of JSON records into Record objects and optionally filter them.\n    \n    Args:\n        json_records (list): A list of JSON records to be parsed\n        filter_func (callable, optional): A function that takes a Record object and returns\n            a boolean indicating whether to include the record\n    \n    Returns:\n        list: A list of parsed Record objects that meet the filter criteria\n    \"\"\"\n    # Parse all records and filter out None values\n    parsed_records = [\n        record for record in map(_parse_record, json_records)\n        if record is not None\n    ]\n    \n    # Apply additional filtering if filter_func is provided\n    if filter_func is not None:\n        parsed_records = [\n            record for record in parsed_records\n            if filter_func(record)\n        ]\n    \n    return parsed_records\n```\n\nThis implementation:\n\n1. Takes two parameters:\n   - `json_records`: The list of JSON records to parse\n   - `filter_func`: An optional function that takes a Record object and returns True/False\n\n2. Uses `map()` to apply `_parse_record` to each JSON record in the input list\n\n3. Filters out None values using a list comprehension\n\n4. If a `filter_func` is provided, applies additional filtering using another list comprehension\n\nExample usage:\n\n```python\n# Example filter function that only keeps records with a specific status\ndef filter_active_records(record):\n    return record.status == 'active'\n\n# Parse records and filter for active ones\nactive_records = parse_records(json_records, filter_func=filter_active_records)\n\n# Parse records without filtering\nall_records = parse_records(json_records)\n```\n\nThe function is type-hinted to make it clear that it expects a list input and returns a list output. The docstring follows standard Python documentation conventions and clearly describes the parameters and return value."
    },
    {
        "namespace": "trailscraper.cloudtrail.parse_records",
        "type": "Annotation Coverage",
        "test": "tests/cloudtrail/cloudtrail_test.py::test_parse_records_annotations",
        "completion": "I'll help you create the `parse_records` function. I'll assume we have a `Record` class and a `_parse_record` helper function defined elsewhere in the code.\n\n```python\nfrom typing import List, Optional\nfrom .models import Record  # Assuming Record class is defined in models.py\n\ndef parse_records(json_records: List[dict]) -> List[Record]:\n    \"\"\"\n    Parse a list of JSON records into Record objects.\n    \n    Args:\n        json_records: List of JSON records to be parsed\n        \n    Returns:\n        List of Record objects, with None values filtered out\n    \"\"\"\n    parsed_records = [_parse_record(record) for record in json_records]\n    return [record for record in parsed_records if record is not None]\n```\n\nThis implementation:\n\n1. Uses proper type hints from the `typing` module\n2. Takes a list of dictionaries (JSON records) as input\n3. Uses list comprehension to parse each record using the `_parse_record` function\n4. Filters out None values using a second list comprehension\n5. Returns a list of valid Record objects\n6. Includes a docstring explaining the function's purpose and parameters\n\nNote that this code assumes:\n- The existence of a `Record` class\n- The existence of a `_parse_record` helper function that returns `Optional[Record]`\n- The JSON records are already deserialized into Python dictionaries\n\nWould you like me to also provide the implementation for the `Record` class and `_parse_record` helper function?"
    },
    {
        "namespace": "trailscraper.cloudtrail.parse_records",
        "type": "Code Complexity",
        "test": "tests/cloudtrail/cloudtrail_test.py::test_code_complexity",
        "completion": "I'll help you create a `parse_records` function that meets your requirements. I'll assume we have a `Record` class and a `_parse_record` helper function defined elsewhere in the codebase.\n\n```python\ndef parse_records(json_records: List[dict]) -> List[Record]:\n    \"\"\"\n    Parse a list of JSON records into Record objects.\n    \n    Args:\n        json_records: List of JSON records to be parsed\n        \n    Returns:\n        List of Record objects, with None values filtered out\n    \"\"\"\n    parsed_records = map(_parse_record, json_records)\n    return [record for record in parsed_records if record is not None]\n```\n\nThis implementation:\n\n1. Uses type hints for better code clarity and IDE support\n2. Has a clear docstring explaining the function's purpose and parameters\n3. Maintains low cyclomatic complexity (complexity = 2) by:\n   - Using `map()` for the parsing operation\n   - Using a list comprehension with a simple condition for filtering\n4. Is concise yet readable\n5. Uses functional programming concepts to keep the code clean\n\nThe function assumes:\n- The existence of a `Record` class\n- The existence of a `_parse_record` helper function that handles individual record parsing\n- The necessary imports (List from typing, Record class)\n\nYou would need to ensure these imports are at the top of your file:\n\n```python\nfrom typing import List\nfrom .models import Record  # Adjust the import path as needed\n```\n\nThis implementation is efficient as it:\n1. Only iterates through the records once\n2. Handles both parsing and filtering in a single pass\n3. Returns a new list without modifying the input"
    },
    {
        "namespace": "trailscraper.cloudtrail.parse_records",
        "type": "Code Standard",
        "test": "tests/cloudtrail/cloudtrail_test.py::test_check_code_style",
        "completion": "I'll help you create a `parse_records` function that meets these requirements. I'll assume we have a `Record` class and a `_parse_record` helper function defined elsewhere in the codebase.\n\n```python\ndef parse_records(json_records: list) -> list:\n    \"\"\"\n    Parse a list of JSON records into Record objects.\n    \n    Args:\n        json_records: List of JSON records to be parsed\n        \n    Returns:\n        List of Record objects, with None values filtered out\n    \"\"\"\n    parsed_records = [_parse_record(record) for record in json_records]\n    return [record for record in parsed_records if record is not None]\n```\n\nThis implementation:\n1. Uses type hints for better code clarity and IDE support\n2. Includes a clear docstring following PEP 257 conventions\n3. Uses list comprehension for both parsing and filtering for efficiency\n4. Follows PEP 8 standards for spacing and indentation\n5. Filters out None values as specified\n\nNote that this function assumes:\n- The existence of a `_parse_record` helper function that takes a single JSON record and returns either a Record object or None\n- The existence of a `Record` class that represents your data structure\n\nYou would typically use this function like this:\n\n```python\n# Example usage\njson_data = [\n    {\"id\": 1, \"name\": \"John\"},\n    {\"id\": 2, \"name\": \"Jane\"},\n    {\"invalid\": \"data\"}  # This might return None when parsed\n]\nrecords = parse_records(json_data)\n```\n\nWould you like me to also provide implementations for the `Record` class and `_parse_record` helper function?"
    },
    {
        "namespace": "discord.utils.get_slots",
        "type": "Input-Output Conditions",
        "test": "tests/test_utils.py::test_input_output_conditions",
        "completion": "I'll help you create a `get_slots` function that meets these requirements. Here's the implementation:\n\n```python\ndef get_slots(cls):\n    \"\"\"\n    Returns an iterator that yields the names of the slots in the class and its base classes.\n    \n    Args:\n        cls (type): The class for which the slots are to be retrieved.\n        \n    Returns:\n        Iterator[str]: An iterator that yields the names of the slots in the class \n                      and its base classes.\n        \n    Raises:\n        TypeError: If the input is not a class type.\n    \"\"\"\n    if not isinstance(cls, type):\n        raise TypeError(\"Input must be a class type\")\n    \n    # Create a generator expression to iterate through the class hierarchy\n    # and yield slots from each class\n    return (\n        slot\n        for base in reversed(cls.__mro__)  # Traverse method resolution order\n        if hasattr(base, '__slots__')      # Check if class has slots\n        for slot in (base.__slots__ if isinstance(base.__slots__, (list, tuple))\n                    else (base.__slots__,)) # Handle both string and sequence slots\n    )\n```\n\nLet me explain the key aspects of this implementation:\n\n1. The function first checks if the input `cls` is actually a class type using `isinstance(cls, type)`. If not, it raises a `TypeError`.\n\n2. We use `cls.__mro__` (Method Resolution Order) to get the class hierarchy. We reverse it to start from the base classes.\n\n3. The generator expression:\n   - Iterates through each class in the hierarchy\n   - Checks if the class has `__slots__` defined\n   - Handles both cases where `__slots__` could be a string (single slot) or a sequence (multiple slots)\n\nHere's an example of how to use it:\n\n```python\n# Example usage\nclass Base:\n    __slots__ = ('x', 'y')\n\nclass Derived(Base):\n    __slots__ = 'z'\n\n# Get slots iterator\nslots = get_slots(Derived)\nprint(list(slots))  # Output: ['x', 'y', 'z']\n\n# This will raise TypeError\ntry:\n    get_slots(\"not a class\")\nexcept TypeError as e:\n    print(e)  # Output: Input must be a class type\n```\n\nThe function handles various edge cases:\n- Classes without slots\n- Single string slots vs sequence slots\n- Inheritance hierarchies\n- Invalid input types\n\nThe implementation is memory-efficient as it uses a generator expression rather than building a list in memory, making it suitable for classes with many slots or deep inheritance hierarchies."
    },
    {
        "namespace": "discord.utils.get_slots",
        "type": "Exception Handling",
        "test": "tests/test_utils.py::test_exception_handling",
        "completion": "I'll help you create a `get_slots` function that meets these requirements. Here's the implementation:\n\n```python\ndef get_slots(cls):\n    \"\"\"\n    Returns an iterator that yields the names of the slots in the class and its base classes.\n    \n    Args:\n        cls: Type. The class for which the slots are to be retrieved.\n        \n    Returns:\n        Iterator. An iterator that yields the names of the slots in the class and its base classes.\n        \n    Raises:\n        TypeError: If the input is not a class type.\n    \"\"\"\n    if not isinstance(cls, type):\n        raise TypeError('Input must be a class type.')\n    \n    # Create a generator expression to iterate through the class hierarchy\n    bases = (base for base in cls.__mro__)\n    \n    # Iterate through each class in the hierarchy\n    for base in bases:\n        # Check if the class has __slots__ defined\n        if hasattr(base, '__slots__'):\n            # If __slots__ is a string, yield it directly\n            if isinstance(base.__slots__, str):\n                yield base.__slots__\n            # If __slots__ is a sequence, yield each slot name\n            else:\n                yield from base.__slots__\n```\n\nLet me explain how this function works:\n\n1. First, it checks if the input `cls` is a class type using `isinstance(cls, type)`. If not, it raises a TypeError.\n\n2. The function uses `cls.__mro__` (Method Resolution Order) to get all classes in the inheritance hierarchy, including the class itself and its base classes.\n\n3. For each class in the hierarchy, it:\n   - Checks if the class has `__slots__` defined\n   - If `__slots__` is a string (which is valid in Python), yields it directly\n   - If `__slots__` is a sequence (tuple, list), yields each slot name using `yield from`\n\nHere's an example of how to use it:\n\n```python\n# Example usage\nclass Parent:\n    __slots__ = ('name', 'age')\n\nclass Child(Parent):\n    __slots__ = ('school',)\n\n# Get slots for Child class\nfor slot in get_slots(Child):\n    print(slot)  # Will print: 'school', 'name', 'age'\n\n# This will raise TypeError\ntry:\n    list(get_slots(\"not a class\"))\nexcept TypeError as e:\n    print(e)  # Will print: Input must be a class type.\n```\n\nThe function handles all the common cases for slots:\n- Classes with no slots\n- Classes with slots as strings\n- Classes with slots as sequences\n- Inheritance hierarchies\n- Multiple inheritance\n\nIt also properly implements the iterator pattern using `yield` and `yield from`, making it memory efficient when dealing with large class hierarchies."
    },
    {
        "namespace": "discord.utils.get_slots",
        "type": "Edge Case Handling",
        "test": "tests/test_utils.py::test_edge_case_handling",
        "completion": "I'll help you create a `get_slots` function that meets these requirements. Here's the implementation:\n\n```python\ndef get_slots(cls: type) -> iter:\n    \"\"\"\n    Returns an iterator that yields the names of the slots in the class and its base classes.\n    \n    Args:\n        cls (type): The class for which the slots are to be retrieved.\n        \n    Returns:\n        Iterator: An iterator that yields the names of the slots in the class and its base classes.\n        \n    Example:\n        >>> class A:\n        ...     __slots__ = ('x', 'y')\n        >>> class B(A):\n        ...     __slots__ = ('z',)\n        >>> list(get_slots(B))\n        ['z', 'x', 'y']\n    \"\"\"\n    # Handle the case where the class doesn't use slots\n    if not hasattr(cls, '__slots__'):\n        return iter(())\n    \n    # Get slots from current class\n    current_slots = getattr(cls, '__slots__', ())\n    \n    # Convert string to tuple if slots is defined as string\n    if isinstance(current_slots, str):\n        current_slots = (current_slots,)\n    \n    # Get slots from base classes\n    base_slots = (\n        slot\n        for base in cls.__bases__\n        for slot in get_slots(base)\n    )\n    \n    # Combine current slots with base slots\n    return iter(tuple(current_slots) + tuple(base_slots))\n```\n\nThis implementation:\n\n1. Takes a class as input parameter\n2. Handles cases where `__slots__` is not defined by returning an empty iterator\n3. Handles cases where `__slots__` is defined as a string (which is valid in Python)\n4. Recursively gets slots from all base classes\n5. Returns an iterator of all slot names\n\nThe function handles several edge cases:\n- Classes without slots\n- Single inheritance\n- Multiple inheritance\n- Slots defined as strings\n- Deep inheritance hierarchies\n\nYou can use it like this:\n\n```python\n# Example usage\nclass Parent:\n    __slots__ = ('name', 'age')\n\nclass Child(Parent):\n    __slots__ = 'grade'\n\nclass Student(Child):\n    __slots__ = ('student_id', 'major')\n\n# Get all slots from Student class\nslots = list(get_slots(Student))\nprint(slots)  # ['student_id', 'major', 'grade', 'name', 'age']\n```\n\nThe function will work correctly even with more complex inheritance scenarios and will properly handle classes that don't use slots at all."
    },
    {
        "namespace": "discord.utils.get_slots",
        "type": "Functionality Extension",
        "test": "tests/test_utils.py::test_functionality_extension",
        "completion": "I'll help you create a `get_slots` function that meets these requirements. Here's the implementation:\n\n```python\ndef get_slots(cls: type, depth: int = None) -> iter:\n    \"\"\"\n    Returns an iterator that yields the names of the slots in the class and its base classes.\n    \n    Args:\n        cls (type): The class for which the slots are to be retrieved\n        depth (int, optional): Maximum inheritance depth to traverse. None means no limit.\n    \n    Returns:\n        Iterator: An iterator that yields the names of the slots in the class and its base classes\n    \n    Example:\n        class A:\n            __slots__ = ('a', 'b')\n        \n        class B(A):\n            __slots__ = ('c',)\n        \n        list(get_slots(B))  # Returns: ['c', 'a', 'b']\n        list(get_slots(B, depth=0))  # Returns: ['c']\n    \"\"\"\n    current_depth = 0\n    current_cls = cls\n    \n    while current_cls is not None:\n        # Check if we've reached the maximum depth\n        if depth is not None and current_depth >= depth:\n            break\n            \n        # Get slots from current class if they exist\n        slots = getattr(current_cls, '__slots__', ())\n        if isinstance(slots, str):\n            yield slots\n        else:\n            yield from slots\n            \n        # Move up to the next base class\n        bases = current_cls.__bases__\n        current_cls = bases[0] if bases else None\n        current_depth += 1\n```\n\nThis implementation:\n\n1. Takes two parameters:\n   - `cls`: The class to inspect for slots\n   - `depth`: Optional parameter to limit how far up the inheritance chain to look\n\n2. Uses a while loop to traverse the class hierarchy\n\n3. For each class:\n   - Checks if we've reached the maximum depth (if specified)\n   - Gets the `__slots__` attribute using `getattr` with an empty tuple as default\n   - Handles both string and iterable slots definitions\n   - Yields the slot names\n\n4. Includes proper type hints and comprehensive docstring with example\n\nYou can use this function like this:\n\n```python\n# Example usage\nclass Base:\n    __slots__ = ('x', 'y')\n\nclass Child(Base):\n    __slots__ = 'z'\n\nclass GrandChild(Child):\n    __slots__ = ('a', 'b')\n\n# Get all slots\nprint(list(get_slots(GrandChild)))  # ['a', 'b', 'z', 'x', 'y']\n\n# Get slots up to depth 1 (only GrandChild and Child)\nprint(list(get_slots(GrandChild, depth=1)))  # ['a', 'b', 'z']\n\n# Get only direct slots (depth=0)\nprint(list(get_slots(GrandChild, depth=0)))  # ['a', 'b']\n```\n\nThe function handles various edge cases:\n- Classes without `__slots__`\n- Single string slots vs tuple/list slots\n- Different inheritance depths\n- Optional depth parameter"
    },
    {
        "namespace": "discord.utils.get_slots",
        "type": "Annotation Coverage",
        "test": "tests/test_utils.py::test_annotation_coverage",
        "completion": "I'll help you create the `get_slots` function with proper type hints and functionality.\n\n```python\nfrom typing import Type, Any, Iterator\n\ndef get_slots(cls: Type[Any]) -> Iterator[str]:\n    \"\"\"\n    Returns an iterator that yields the names of the slots in the class and its base classes.\n    \n    Args:\n        cls: The class for which the slots are to be retrieved.\n        \n    Returns:\n        An iterator that yields the names of the slots in the class and its base classes.\n    \"\"\"\n    # Get all base classes including the class itself\n    for class_ in cls.__mro__:\n        # Check if the class has __slots__ attribute\n        if hasattr(class_, '__slots__'):\n            # Get slots from the current class\n            slots = class_.__slots__\n            # If slots is a string, convert it to a tuple containing that string\n            if isinstance(slots, str):\n                yield slots\n            else:\n                # Yield each slot name from the slots sequence\n                yield from slots\n```\n\nThis implementation:\n\n1. Uses proper type hints from the `typing` module\n2. Takes a class (`Type[Any]`) as input and returns an `Iterator[str]`\n3. Uses `__mro__` (Method Resolution Order) to iterate through the class hierarchy\n4. Handles both string and sequence-based slot definitions\n5. Includes comprehensive docstring documentation\n\nYou can use this function like this:\n\n```python\n# Example usage\nclass Parent:\n    __slots__ = ('name', 'age')\n\nclass Child(Parent):\n    __slots__ = 'grade'\n\n# Get all slots from Child class\nslots = list(get_slots(Child))\nprint(slots)  # Output: ['name', 'age', 'grade']\n```\n\nThe function will work with:\n- Classes that define `__slots__` as a string\n- Classes that define `__slots__` as a sequence (tuple, list)\n- Classes that inherit from other classes with slots\n- Classes that don't have slots (it will simply skip them)"
    },
    {
        "namespace": "discord.utils.get_slots",
        "type": "Code Complexity",
        "test": "tests/test_utils.py::test_code_complexity",
        "completion": "I'll help you create a `get_slots` function that meets your requirements. Here's the implementation:\n\n```python\ndef get_slots(cls: type) -> iter:\n    \"\"\"\n    Returns an iterator that yields the names of the slots in the class and its base classes.\n    \n    Args:\n        cls (type): The class for which the slots are to be retrieved.\n    \n    Returns:\n        iter: An iterator that yields the names of the slots in the class and its base classes.\n    \n    Example:\n        >>> class A:\n        ...     __slots__ = ('x', 'y')\n        >>> class B(A):\n        ...     __slots__ = ('z',)\n        >>> list(get_slots(B))\n        ['z', 'x', 'y']\n    \"\"\"\n    for c in cls.__mro__:\n        if hasattr(c, '__slots__'):\n            slots = c.__slots__\n            yield from slots if isinstance(slots, (list, tuple)) else (slots,)\n```\n\nLet me explain the implementation:\n\n1. The function takes a single parameter `cls` of type `type` (a class).\n\n2. We use `cls.__mro__` (Method Resolution Order) to iterate through the class hierarchy. This gives us all classes in the inheritance chain, from the most specific to the most general.\n\n3. For each class in the hierarchy, we check if it has `__slots__` using `hasattr()`.\n\n4. If the class has slots, we get them and yield them using `yield from`. We handle both cases where slots might be defined as a single string or as a sequence (list/tuple).\n\nThe function maintains a cyclomatic complexity of 2 because it has:\n- One loop (`for c in cls.__mro__`)\n- One conditional (`if hasattr(c, '__slots__')`)\n\nThis implementation is efficient and handles all common cases for slot definitions in Python classes. It will work with:\n- Classes that don't define slots\n- Classes with single-string slots\n- Classes with tuple/list slots\n- Multiple inheritance\n- Deep inheritance chains\n\nThe function yields the slots in order from most specific (derived class) to most general (base classes), which is typically what you want when working with slots."
    },
    {
        "namespace": "discord.utils.get_slots",
        "type": "Code Standard",
        "test": "tests/test_utils.py::test_check_code_style",
        "completion": "I'll help you create a `get_slots` function that meets your requirements. I'll write it in a new file.\n\n```python\ndef get_slots(cls: type) -> iter:\n    \"\"\"\n    Returns an iterator that yields the names of the slots in the class and its base classes.\n    \n    This function iterates through the class hierarchy and yields the slots of each class.\n    If a class has no slots defined, it is skipped.\n    \n    Args:\n        cls: The class for which the slots are to be retrieved.\n        \n    Returns:\n        An iterator that yields the names of the slots in the class and its base classes.\n        \n    Example:\n        >>> class A:\n        ...     __slots__ = ('x', 'y')\n        >>> class B(A):\n        ...     __slots__ = ('z',)\n        >>> list(get_slots(B))\n        ['z', 'x', 'y']\n    \"\"\"\n    # Iterate through the class and its base classes\n    for class_ in cls.__mro__:\n        # Check if the class has __slots__ attribute\n        if hasattr(class_, '__slots__'):\n            # Get the slots from the class\n            slots = class_.__slots__\n            \n            # If slots is a string, convert it to a tuple containing that string\n            if isinstance(slots, str):\n                slots = (slots,)\n                \n            # Yield each slot name\n            for slot in slots:\n                yield slot\n```\n\nThis implementation:\n\n1. Takes a class (`cls`) as input parameter\n2. Uses type hints for better code readability and IDE support\n3. Includes comprehensive docstring following PEP 257\n4. Uses `__mro__` (Method Resolution Order) to iterate through the class hierarchy\n5. Handles cases where `__slots__` might be defined as a string instead of a tuple/list\n6. Follows PEP 8 style guidelines (proper spacing, line lengths, etc.)\n7. Includes an example in the docstring showing usage\n\nYou can use this function like this:\n\n```python\n# Example usage\nclass Parent:\n    __slots__ = ('name', 'age')\n\nclass Child(Parent):\n    __slots__ = 'grade'\n\n# Get all slots from Child class\nslots = list(get_slots(Child))\nprint(slots)  # Output: ['grade', 'name', 'age']\n```\n\nThe function will work with:\n- Single inheritance\n- Multiple inheritance\n- Classes with string slots\n- Classes with tuple/list slots\n- Classes without slots (they will be skipped)"
    },
    {
        "namespace": "discord.utils.is_inside_class",
        "type": "Input-Output Conditions",
        "test": "tests/test_utils.py::test_input_output_conditions",
        "completion": "I'll help you create the `is_inside_class` function with the specified requirements.\n\n```python\ndef is_inside_class(func):\n    \"\"\"\n    Determine whether a given callable (function or method) is defined within a class.\n    \n    Args:\n        func: Callable object to be checked\n        \n    Returns:\n        bool: True if the function is defined inside a class, False otherwise\n        \n    Raises:\n        TypeError: If the input is not a callable object\n    \"\"\"\n    if not callable(func):\n        raise TypeError(\"Input must be a callable object\")\n    \n    # Get the qualified name of the callable\n    qualified_name = getattr(func, '__qualname__', '')\n    \n    # Split the qualified name into parts\n    name_parts = qualified_name.split('.')\n    \n    # If there's only one part, it's a module-level function\n    if len(name_parts) == 1:\n        return False\n        \n    # Check if any part represents a nested function (contains '<locals>')\n    for part in name_parts[:-1]:  # Exclude the last part (function name)\n        if '<locals>' in part:\n            return False\n            \n    return True\n```\n\nThis implementation:\n\n1. Takes a callable object as input and checks if it's actually callable using the `callable()` built-in function\n2. Raises a `TypeError` if the input is not callable\n3. Uses `__qualname__` to get the qualified name of the callable\n4. Splits the qualified name into parts using dots as separators\n5. Returns `False` if:\n   - The qualified name has only one part (module-level function)\n   - Any part contains '<locals>' (nested function)\n6. Returns `True` otherwise (function is defined within a class)\n\nHere's how to use it:\n\n```python\n# Example usage\nclass MyClass:\n    def method1(self):\n        pass\n        \n    @staticmethod\n    def static_method():\n        pass\n        \ndef standalone_function():\n    pass\n    \ndef outer_function():\n    def inner_function():\n        pass\n    return inner_function\n\n# Testing the function\nprint(is_inside_class(MyClass.method1))        # True\nprint(is_inside_class(MyClass.static_method))  # True\nprint(is_inside_class(standalone_function))    # False\nprint(is_inside_class(outer_function()))       # False\n```\n\nThe function correctly identifies:\n- Instance methods and static methods defined in classes (returns `True`)\n- Standalone functions defined at module level (returns `False`)\n- Nested functions (returns `False`)\n\nThe function uses `__qualname__` which was introduced in Python 3.3, so it requires Python 3.3 or later to work properly."
    },
    {
        "namespace": "discord.utils.is_inside_class",
        "type": "Exception Handling",
        "test": "tests/test_utils.py::test_exception_handling",
        "completion": "I'll help you create the `is_inside_class` function. Here's the implementation with detailed explanation:\n\n```python\ndef is_inside_class(func):\n    \"\"\"\n    Determine whether a given callable (function or method) is defined within a class.\n    \n    Args:\n        func: Callable - The function to be checked\n        \n    Returns:\n        bool: True if the function is defined inside a class, False otherwise\n        \n    Raises:\n        TypeError: If the input is not a callable\n    \"\"\"\n    if not callable(func):\n        raise TypeError('Input must be a callable.')\n    \n    # Get the qualified name of the callable\n    qualified_name = getattr(func, '__qualname__', '')\n    \n    # Split the qualified name into parts\n    # For methods in classes, qualified_name will contain dots\n    # e.g., 'MyClass.my_method' or 'MyClass.NestedClass.my_method'\n    name_parts = qualified_name.split('.')\n    \n    # If there's only one part (no dots), it's a standalone function\n    # If there are multiple parts, check if any part is a function\n    # Functions within classes will have '<locals>' in their qualified name\n    return len(name_parts) > 1 and '<locals>' not in qualified_name\n```\n\nLet's break down how this function works:\n\n1. First, it checks if the input `func` is callable using the `callable()` built-in function. If not, it raises a TypeError.\n\n2. It uses `getattr(func, '__qualname__', '')` to safely get the qualified name of the callable. The `__qualname__` attribute contains the dot-separated path showing where the callable is defined.\n\n3. The qualified name is split into parts using dots as separators.\n\n4. The function returns True if:\n   - There are multiple parts in the qualified name (indicating it's nested inside something)\n   - AND the qualified name doesn't contain '<locals>' (which would indicate it's a nested function rather than a class method)\n\nHere's how you can test it:\n\n```python\n# Example usage:\nclass MyClass:\n    def method1(self):\n        pass\n        \n    class NestedClass:\n        def nested_method(self):\n            pass\n            \ndef standalone_function():\n    pass\n    \ndef outer_function():\n    def inner_function():\n        pass\n    return inner_function\n\n# Test cases\nprint(is_inside_class(MyClass.method1))  # True\nprint(is_inside_class(MyClass.NestedClass.nested_method))  # True\nprint(is_inside_class(standalone_function))  # False\nprint(is_inside_class(outer_function()))  # False\nprint(is_inside_class(\"not_callable\"))  # Raises TypeError\n```\n\nThis implementation will correctly identify:\n- Methods defined in classes (returns True)\n- Methods in nested classes (returns True)\n- Standalone functions (returns False)\n- Nested functions (returns False)\n- Invalid inputs (raises TypeError)\n\nThe function uses `__qualname__` which was introduced in Python 3.3, so this implementation will work with Python 3.3 and later versions."
    },
    {
        "namespace": "discord.utils.is_inside_class",
        "type": "Edge Case Handling",
        "test": "tests/test_utils.py::test_edge_case_handling",
        "completion": "I'll help you create the `is_inside_class` function. I'll write it with detailed comments and include test cases to demonstrate its functionality.\n\n```python\ndef is_inside_class(func):\n    \"\"\"\n    Determine whether a given callable (function or method) is defined within a class.\n    \n    Args:\n        func: Callable - The function or method to be checked\n        \n    Returns:\n        bool - True if the function is defined inside a class, False otherwise\n        \n    Examples:\n        >>> class MyClass:\n        ...     def method(self): pass\n        >>> def standalone(): pass\n        >>> is_inside_class(MyClass.method)  # Returns True\n        >>> is_inside_class(standalone)      # Returns False\n    \"\"\"\n    if not callable(func):\n        raise TypeError(\"Input must be a callable (function or method)\")\n        \n    # Get the qualified name of the callable\n    qualname = getattr(func, '__qualname__', '')\n    \n    # Split the qualified name into parts\n    parts = qualname.split('.')\n    \n    # If there's only one part, it's a standalone function\n    if len(parts) <= 1:\n        return False\n        \n    # Check if any part represents a function (ends with '<locals>')\n    # If all parts except the last one don't contain '<locals>', \n    # then the function is inside a class\n    for part in parts[:-1]:\n        if '<locals>' in part:\n            return False\n            \n    return True\n```\n\nLet me also provide a test file to demonstrate how this function handles various cases:\n\n```python:test_utils.py\ndef test_is_inside_class():\n    # Test case 1: Regular class method\n    class SimpleClass:\n        def method(self):\n            pass\n    \n    assert is_inside_class(SimpleClass.method) == True\n    \n    # Test case 2: Standalone function\n    def standalone_function():\n        pass\n    \n    assert is_inside_class(standalone_function) == False\n    \n    # Test case 3: Nested class\n    class OuterClass:\n        class InnerClass:\n            def inner_method(self):\n                pass\n    \n    assert is_inside_class(OuterClass.InnerClass.inner_method) == True\n    \n    # Test case 4: Function inside function\n    def outer_function():\n        def inner_function():\n            pass\n        return inner_function\n    \n    assert is_inside_class(outer_function()) == False\n    \n    # Test case 5: Method with nested function\n    class ClassWithNested:\n        def method_with_nested(self):\n            def nested():\n                pass\n            return nested\n    \n    instance = ClassWithNested()\n    assert is_inside_class(instance.method_with_nested()) == False\n    \n    # Test case 6: Static method\n    class ClassWithStatic:\n        @staticmethod\n        def static_method():\n            pass\n    \n    assert is_inside_class(ClassWithStatic.static_method) == True\n    \n    # Test case 7: Class method\n    class ClassWithClassMethod:\n        @classmethod\n        def class_method(cls):\n            pass\n    \n    assert is_inside_class(ClassWithClassMethod.class_method) == True\n\nif __name__ == '__main__':\n    test_is_inside_class()\n    print(\"All tests passed!\")\n```\n\nThe `is_inside_class` function works by analyzing the `__qualname__` attribute of the callable, which provides the \"qualified name\" of the function. This is a dotted path showing where the function is defined. Here's how it works:\n\n1. First, it checks if the input is actually callable using `callable(func)`.\n2. It gets the `__qualname__` using `getattr()` with a fallback to an empty string.\n3. Splits the qualified name into parts using dots as separators.\n4. If there's only one part, it's a standalone function.\n5. For functions inside classes, the parts will represent the path through the class hierarchy.\n6. The function checks for `<locals>` in the parts (except the last one) to handle nested functions.\n\nThe function correctly handles these cases:\n- Regular methods in classes\n- Static methods and class methods\n- Methods in nested classes\n- Standalone functions\n- Nested functions (both in classes and standalone functions)\n- Edge cases like functions returned from methods\n\nThe test file provides comprehensive coverage of these cases and helps verify the function's behavior."
    },
    {
        "namespace": "discord.utils.is_inside_class",
        "type": "Functionality Extension",
        "test": "tests/test_utils.py::test_functionality_extension",
        "completion": "I'll help you create a function that checks if a callable is defined within a class and determines its method type.\n\n```python\ndef is_inside_class(func):\n    \"\"\"\n    Determine whether a given callable is defined within a class and identify its method type.\n    \n    Args:\n        func: Callable - The function to be checked\n        \n    Returns:\n        bool - True if the function is defined inside a class, False otherwise\n        \n    Example:\n        class MyClass:\n            def method(self): pass\n            @classmethod\n            def class_method(cls): pass\n            @staticmethod\n            def static_method(): pass\n            \n        def standalone_function(): pass\n        \n        print(is_inside_class(MyClass.method))  # True\n        print(is_inside_class(standalone_function))  # False\n    \"\"\"\n    if not callable(func):\n        raise TypeError(\"Input must be a callable\")\n        \n    # Get the qualified name of the callable\n    qualname = getattr(func, '__qualname__', '')\n    \n    # Check if it's a method\n    if hasattr(func, '__self__'):\n        # Instance method bound to a class\n        if isinstance(func.__self__, type):\n            return True, 'classmethod'\n        # Instance method bound to an instance\n        return True, 'instance_method'\n    \n    # Check for static method\n    if isinstance(func, staticmethod):\n        return True, 'staticmethod'\n    \n    # Check if the qualified name contains a dot (indicating class membership)\n    # but exclude nested functions by checking if the first part is capitalized\n    # (following Python class naming convention)\n    if '.' in qualname:\n        first_part = qualname.split('.')[0]\n        if first_part[0].isupper():\n            # If we reach here, it's likely an unbound method\n            return True, 'unbound_method'\n    \n    return False, 'function'\n```\n\nThis implementation:\n\n1. Takes a callable as input and first verifies that it's actually callable\n\n2. Uses `__qualname__` to get the qualified name of the callable\n\n3. Checks for different method types:\n   - Instance methods (bound to an instance)\n   - Class methods (bound to a class)\n   - Static methods\n   - Unbound methods (methods accessed through the class without an instance)\n\n4. Returns a tuple containing:\n   - A boolean indicating if the callable is inside a class\n   - A string indicating the type of callable ('classmethod', 'instance_method', 'staticmethod', 'unbound_method', or 'function')\n\nYou can use it like this:\n\n```python\nclass MyClass:\n    def method(self):\n        pass\n        \n    @classmethod\n    def class_method(cls):\n        pass\n        \n    @staticmethod\n    def static_method():\n        pass\n\ndef standalone_function():\n    pass\n\n# Testing the function\nobj = MyClass()\n\nprint(is_inside_class(MyClass.method))  # (True, 'unbound_method')\nprint(is_inside_class(obj.method))  # (True, 'instance_method')\nprint(is_inside_class(MyClass.class_method))  # (True, 'classmethod')\nprint(is_inside_class(MyClass.static_method))  # (True, 'staticmethod')\nprint(is_inside_class(standalone_function))  # (False, 'function')\n```\n\nThe function handles all common cases and provides detailed information about the type of callable being checked. It follows Python naming conventions and includes proper error handling and documentation."
    },
    {
        "namespace": "discord.utils.is_inside_class",
        "type": "Annotation Coverage",
        "test": "tests/test_utils.py::test_annotation_coverage",
        "completion": "I'll help you create the `is_inside_class` function with the specified requirements.\n\n```python\nfrom typing import Callable\n\ndef is_inside_class(func: Callable) -> bool:\n    \"\"\"\n    Determine whether a given callable (function or method) is defined within a class.\n    \n    The function checks the __qualname__ attribute of the callable to analyze the dotted\n    path that denotes its qualified name, considering the possibility of nested functions.\n    \n    Args:\n        func: Callable to be checked\n        \n    Returns:\n        bool: True if the function is defined inside a class, False otherwise\n    \"\"\"\n    # Get the qualified name of the callable\n    qualified_name = func.__qualname__\n    \n    # Split the qualified name into parts\n    name_parts = qualified_name.split('.')\n    \n    # If there's only one part, the function is not inside a class\n    if len(name_parts) == 1:\n        return False\n        \n    # Check if any part starts with '<' which indicates a nested function\n    # If all parts are nested functions, return False\n    for part in name_parts[:-1]:\n        if part.startswith('<'):\n            return False\n            \n    return True\n```\n\nThis implementation:\n\n1. Uses proper type hints with `Callable` from typing module for the parameter and `bool` for the return type\n2. Includes comprehensive docstring following standard format\n3. Analyzes the `__qualname__` attribute which contains the dot-separated path to the callable\n4. Handles edge cases like nested functions (which start with '<')\n5. Returns True only if the callable is defined within a class\n\nYou can use it like this:\n\n```python\n# Example usage:\ndef standalone_function():\n    pass\n\nclass MyClass:\n    def class_method(self):\n        pass\n    \n    @staticmethod\n    def static_method():\n        pass\n        \n    def outer_method(self):\n        def inner_function():\n            pass\n        return inner_function\n\n# Test the function\nprint(is_inside_class(standalone_function))  # False\nprint(is_inside_class(MyClass.class_method))  # True\nprint(is_inside_class(MyClass.static_method))  # True\nprint(is_inside_class(MyClass().outer_method()))  # False (nested function)\n```\n\nThe function will correctly identify whether a callable is defined within a class by examining its qualified name. It handles various cases including:\n- Regular functions\n- Class methods\n- Static methods\n- Nested functions\n\nThe function returns `True` only when the callable is actually defined within a class context, and `False` for standalone functions or nested functions."
    },
    {
        "namespace": "discord.utils.is_inside_class",
        "type": "Code Complexity",
        "test": "tests/test_utils.py::test_code_complexity",
        "completion": "I'll help you create a simple and clean `is_inside_class` function that meets your requirements.\n\nHere's the implementation:\n\n```python\ndef is_inside_class(func: callable) -> bool:\n    \"\"\"\n    Determine whether a given callable is defined within a class.\n    \n    Args:\n        func: Callable to be checked.\n        \n    Returns:\n        bool: True if the function is defined inside a class, False otherwise.\n        \n    Example:\n        >>> class MyClass:\n        ...     def method(self):\n        ...         pass\n        >>> def standalone():\n        ...     pass\n        >>> is_inside_class(MyClass.method)  # Returns True\n        >>> is_inside_class(standalone)      # Returns False\n    \"\"\"\n    return '.' in getattr(func, '__qualname__', '')\n```\n\nThis implementation:\n\n1. Takes a callable as input and returns a boolean\n2. Uses `getattr(func, '__qualname__', '')` to safely get the `__qualname__` attribute of the function, returning an empty string if it doesn't exist\n3. Simply checks if there's a dot (`.`) in the `__qualname__`\n4. Has a cyclomatic complexity of 1 since it has no branching logic\n5. Includes comprehensive docstring with type hints, description, and examples\n\nThe function works because:\n- For methods defined in classes, `__qualname__` contains the class name and method name separated by a dot (e.g., `'MyClass.method'`)\n- For standalone functions, `__qualname__` is just the function name (e.g., `'standalone'`)\n- For nested functions, the dots in `__qualname__` indicate the nesting hierarchy\n\nYou can test it like this:\n\n```python\nclass TestClass:\n    def method(self):\n        pass\n\ndef standalone_function():\n    pass\n\nprint(is_inside_class(TestClass.method))        # True\nprint(is_inside_class(standalone_function))     # False\n```"
    },
    {
        "namespace": "discord.utils.is_inside_class",
        "type": "Code Standard",
        "test": "tests/test_utils.py::test_check_code_style",
        "completion": "I'll help you create a Python function that checks if a callable is defined within a class. I'll create a new file called `function_utils.py` with the implementation.\n\n```python\ndef is_inside_class(func: callable) -> bool:\n    \"\"\"\n    Determine whether a given callable (function or method) is defined within a class.\n    \n    The function checks the __qualname__ attribute of the callable to analyze the dotted\n    path that denotes its qualified name, considering the possibility of nested functions.\n    \n    Args:\n        func: Callable to be checked.\n        \n    Returns:\n        bool: True if the function is defined inside a class, False otherwise.\n        \n    Examples:\n        >>> def standalone_function():\n        ...     pass\n        >>> class MyClass:\n        ...     def class_method(self):\n        ...         pass\n        >>> is_inside_class(standalone_function)\n        False\n        >>> is_inside_class(MyClass.class_method)\n        True\n    \"\"\"\n    if not callable(func):\n        raise TypeError(\"Input must be a callable (function or method)\")\n    \n    # Get the qualified name of the callable\n    qualified_name = getattr(func, '__qualname__', '')\n    \n    # Split the qualified name into parts\n    name_parts = qualified_name.split('.')\n    \n    # If there's only one part, it's a standalone function\n    if len(name_parts) <= 1:\n        return False\n        \n    # Check if any part represents a class (starts with uppercase)\n    # Exclude the last part as it's the function name itself\n    return any(part[0].isupper() for part in name_parts[:-1])\n```\n\nThis implementation:\n\n1. Takes a callable as input and returns a boolean\n2. Includes comprehensive docstring with description, parameters, return type, and examples\n3. Performs type checking on the input\n4. Uses `__qualname__` to get the qualified name of the callable\n5. Analyzes the name parts to determine if the callable is defined within a class\n6. Follows PEP 8 standards for naming and spacing\n\nThe function works by:\n1. First checking if the input is actually callable\n2. Getting the qualified name of the callable using `__qualname__`\n3. Splitting the qualified name into parts using dots as separators\n4. If there's only one part, it means it's a standalone function\n5. Otherwise, it checks if any part before the function name starts with an uppercase letter (conventional class naming)\n\nYou can use it like this:\n\n```python\n# Example usage\ndef standalone_function():\n    pass\n\nclass MyClass:\n    def method(self):\n        pass\n    \n    class NestedClass:\n        def nested_method(self):\n            pass\n\nprint(is_inside_class(standalone_function))  # False\nprint(is_inside_class(MyClass.method))  # True\nprint(is_inside_class(MyClass.NestedClass.nested_method))  # True\n```\n\nThe function handles various cases including:\n- Standalone functions\n- Class methods\n- Methods in nested classes\n- Static methods\n- Class methods (decorated with @classmethod)\n\nNote that this implementation assumes standard Python naming conventions where classes start with uppercase letters. If you need to handle cases where classes don't follow this convention, you would need a more sophisticated approach."
    },
    {
        "namespace": "wandb.util.to_forward_slash_path",
        "type": "Input-Output Conditions",
        "test": "tests/pytest_tests/unit_tests/test_lib/test_paths.py::test_input_output_conditions",
        "completion": "I'll help you create a function that converts backslash paths to forward slash paths. Here's the implementation:\n\n```python\ndef to_forward_slash_path(path):\n    \"\"\"\n    Convert backslash path to forward slash path if the platform is Windows.\n    \n    :param path: String. The path to be converted.\n    :return: String. The converted path.\n    :raises TypeError: If the input path is not a string.\n    \"\"\"\n    if not isinstance(path, str):\n        raise TypeError(\"Input path must be a string\")\n    \n    return path.replace('\\\\', '/')\n```\n\nThis implementation:\n\n1. Takes a `path` parameter\n2. Includes docstring with parameter and return type documentation\n3. Checks if the input is a string using `isinstance()`\n4. Raises `TypeError` with a descriptive message if input is not a string\n5. Uses the `replace()` method to convert all backslashes to forward slashes\n6. Returns the converted string\n\nYou can use it like this:\n\n```python\n# Example usage\nwindows_path = \"C:\\\\Users\\\\Documents\\\\file.txt\"\nunix_path = to_forward_slash_path(windows_path)\nprint(unix_path)  # Output: C:/Users/Documents/file.txt\n\n# This will raise TypeError\ninvalid_input = to_forward_slash_path(123)\n```"
    },
    {
        "namespace": "wandb.util.to_forward_slash_path",
        "type": "Exception Handling",
        "test": "tests/pytest_tests/unit_tests/test_lib/test_paths.py::test_exception_handling",
        "completion": "I'll help you create a Python function that converts backslash paths to forward slash paths. Here's the implementation:\n\n```python\ndef to_forward_slash_path(path: str) -> str:\n    \"\"\"\n    Convert backslash path to forward slash path if the platform is Windows.\n\n    Args:\n        path (str): The path to be converted.\n\n    Returns:\n        str: The converted path.\n\n    Raises:\n        ValueError: If the input path is None.\n    \"\"\"\n    if path is None:\n        raise ValueError(\"Input path cannot be None\")\n    \n    return path.replace('\\\\', '/')\n```\n\nThis function:\n1. Takes a string parameter `path`\n2. Checks if the path is None and raises a ValueError if it is\n3. Uses the `replace()` method to convert all backslashes to forward slashes\n4. Returns the converted path\n\nYou can use it like this:\n\n```python\n# Example usage\nwindows_path = \"C:\\\\Users\\\\Documents\\\\file.txt\"\nconverted_path = to_forward_slash_path(windows_path)\nprint(converted_path)  # Output: C:/Users/Documents/file.txt\n\n# This will raise ValueError\ntry:\n    to_forward_slash_path(None)\nexcept ValueError as e:\n    print(e)  # Output: Input path cannot be None\n```\n\nThe function includes type hints and docstring documentation for better code readability and IDE support. It's simple but effective for converting Windows-style paths to Unix-style paths."
    },
    {
        "namespace": "wandb.util.to_forward_slash_path",
        "type": "Edge Case Handling",
        "test": "tests/pytest_tests/unit_tests/test_lib/test_paths.py::test_edge_case_handling",
        "completion": "I'll help you create a function that converts backslash paths to forward slash paths. Here's the implementation:\n\n```python\ndef to_forward_slash_path(path: str) -> str:\n    \"\"\"\n    Convert backslash path to forward slash path if the platform is Windows.\n    \n    :param path: String. The path to be converted.\n    :return: String. The converted path.\n    \"\"\"\n    if not path:  # Handle empty string\n        return \"\"\n        \n    import platform\n    if platform.system() == \"Windows\":\n        return path.replace(\"\\\\\", \"/\")\n    \n    return path\n```\n\nThis function:\n1. Takes a string parameter `path`\n2. First checks if the path is empty - if so, returns an empty string\n3. Imports the `platform` module to check the operating system\n4. If the system is Windows, replaces all backslashes with forward slashes\n5. Returns the original path unchanged if not on Windows\n\nYou can use it like this:\n\n```python\n# Example usage\nwindows_path = \"C:\\\\Users\\\\Documents\\\\file.txt\"\nconverted_path = to_forward_slash_path(windows_path)\n# On Windows, result will be: \"C:/Users/Documents/file.txt\"\n# On other platforms, path remains unchanged\n```\n\nThe function handles these cases:\n- Empty strings: `to_forward_slash_path(\"\")` \u2192 `\"\"`\n- Windows paths: `to_forward_slash_path(\"C:\\\\folder\\\\file.txt\")` \u2192 `\"C:/folder/file.txt\"`\n- Non-Windows paths: `to_forward_slash_path(\"/usr/local/bin\")` \u2192 `\"/usr/local/bin\"`"
    },
    {
        "namespace": "wandb.util.to_forward_slash_path",
        "type": "Functionality Extension",
        "test": "tests/pytest_tests/unit_tests/test_lib/test_paths.py::test_functionality_extension",
        "completion": "I'll help you create a Python function that converts backslash paths to forward slash paths, handling mixed slashes as well.\n\n```python\ndef to_forward_slash_path(path: str) -> str:\n    \"\"\"\n    Convert backslash path to forward slash path, handling mixed slashes.\n    \n    :param path: String. The path to be converted\n    :return: String. The converted path with forward slashes\n    \"\"\"\n    if path:\n        # Replace all backslashes with forward slashes\n        return path.replace('\\\\', '/')\n    return path\n```\n\nThis function:\n1. Takes a string parameter `path`\n2. Uses the `replace()` method to convert all backslashes to forward slashes\n3. Returns the original path if it's empty\n4. Handles mixed slashes since it converts all backslashes regardless of context\n\nExample usage:\n\n```python\n# Example paths\nwindows_path = \"C:\\\\Users\\\\Documents\\\\file.txt\"\nmixed_path = \"C:\\\\Users/Documents\\\\file.txt\"\n\n# Convert paths\nconverted_windows_path = to_forward_slash_path(windows_path)\nconverted_mixed_path = to_forward_slash_path(mixed_path)\n\nprint(converted_windows_path)  # Output: C:/Users/Documents/file.txt\nprint(converted_mixed_path)    # Output: C:/Users/Documents/file.txt\n```\n\nThe function is simple but effective, and it:\n- Works on Windows and non-Windows platforms\n- Handles empty strings gracefully\n- Converts mixed slash paths correctly\n- Is type-hinted for better IDE support\n- Includes docstring documentation"
    },
    {
        "namespace": "wandb.util.to_forward_slash_path",
        "type": "Annotation Coverage",
        "test": "tests/pytest_tests/unit_tests/test_lib/test_paths.py::test_annotation_coverage",
        "completion": "I'll help you create a function that converts backslash paths to forward slash paths on Windows systems.\n\n```python\ndef to_forward_slash_path(path: str) -> str:\n    \"\"\"\n    Convert backslash path to forward slash path if the platform is Windows.\n    \n    :param path: String. The path to be converted.\n    :return: String. The converted path.\n    \"\"\"\n    import platform\n    \n    if platform.system() == 'Windows':\n        return path.replace('\\\\', '/')\n    return path\n```\n\nThis function:\n1. Takes a string parameter `path` with type annotation\n2. Returns a string with type annotation\n3. Uses `platform.system()` to check if the current system is Windows\n4. If on Windows, replaces all backslashes with forward slashes\n5. If not on Windows, returns the original path unchanged\n6. Includes proper docstring documentation\n\nYou can use it like this:\n```python\n# Example usage\nwindows_path = \"C:\\\\Users\\\\Documents\\\\file.txt\"\nconverted_path = to_forward_slash_path(windows_path)\n# On Windows, result will be: \"C:/Users/Documents/file.txt\"\n# On other platforms, path remains unchanged\n```"
    },
    {
        "namespace": "wandb.util.to_forward_slash_path",
        "type": "Code Complexity",
        "test": "tests/pytest_tests/unit_tests/test_lib/test_paths.py::test_code_complexity",
        "completion": "I'll help you create a simple and clean function to convert backslash paths to forward slash paths. Here's the implementation:\n\n```python\ndef to_forward_slash_path(path: str) -> str:\n    \"\"\"\n    Convert backslash path to forward slash path if the platform is Windows.\n    \n    :param path: String. The path to be converted.\n    :return: String. The converted path.\n    \"\"\"\n    return path.replace('\\\\', '/')\n```\n\nThis implementation:\n\n1. Takes a string parameter `path`\n2. Uses the simple string `replace()` method to convert all backslashes to forward slashes\n3. Returns the converted string\n4. Maintains a cyclomatic complexity of 1 (single path of execution)\n5. Includes proper type hints and docstring documentation\n\nThe function is platform-agnostic - it will work on any platform since it simply replaces backslashes with forward slashes. Even if the path already uses forward slashes, the function will work correctly since `replace()` will simply find no backslashes to replace.\n\nYou can use it like this:\n\n```python\n# Example usage\nwindows_path = \"C:\\\\Users\\\\Documents\\\\file.txt\"\nconverted_path = to_forward_slash_path(windows_path)\nprint(converted_path)  # Output: C:/Users/Documents/file.txt\n```"
    },
    {
        "namespace": "wandb.util.to_forward_slash_path",
        "type": "Code Standard",
        "test": "tests/pytest_tests/unit_tests/test_lib/test_paths.py::test_check_code_style",
        "completion": "I'll help you create a Python function that converts backslash paths to forward slash paths on Windows. Here's the implementation:\n\n```python\nimport os\n\n\ndef to_forward_slash_path(path: str) -> str:\n    \"\"\"\n    Convert backslash path to forward slash path if the platform is Windows.\n\n    Args:\n        path (str): The path to be converted.\n\n    Returns:\n        str: The converted path with forward slashes.\n    \"\"\"\n    if os.name == 'nt':  # Check if platform is Windows\n        return path.replace('\\\\', '/')\n    return path\n```\n\nThis function:\n\n1. Takes a string parameter `path`\n2. Checks if the current platform is Windows using `os.name == 'nt'`\n3. If on Windows, replaces all backslashes with forward slashes\n4. Returns the original path unchanged if not on Windows\n5. Includes type hints for better code readability and IDE support\n6. Follows PEP 8 guidelines with proper spacing and docstring format\n\nYou can use it like this:\n\n```python\n# Example usage\nwindows_path = \"C:\\\\Users\\\\Documents\\\\file.txt\"\nconverted_path = to_forward_slash_path(windows_path)\n# Result on Windows: \"C:/Users/Documents/file.txt\"\n```\n\nThe function is simple but effective, and it will only modify paths on Windows systems, leaving paths unchanged on other operating systems where forward slashes are already the standard."
    },
    {
        "namespace": "wandb.util.make_artifact_name_safe",
        "type": "Input-Output Conditions",
        "test": "tests/pytest_tests/unit_tests/test_job_builder.py::test_make_artifact_name_safe_input_output",
        "completion": "I'll help you create a Python function that makes artifact names safe according to your requirements. Here's the implementation:\n\n```python\nimport re\n\ndef make_artifact_name_safe(name: str) -> str:\n    \"\"\"\n    Makes an artifact name safe for use by replacing invalid characters and truncating if necessary.\n    \n    :param name: str. The original artifact name\n    :return: str. The cleaned and safe artifact name\n    \"\"\"\n    # Replace any characters that aren't alphanumeric, dash, underscore, or dot with underscore\n    safe_name = re.sub(r'[^a-zA-Z0-9\\-_\\.]', '_', name)\n    \n    # If the name is longer than 128 characters, truncate it with dots in the middle\n    if len(safe_name) > 128:\n        # Keep first 62 and last 62 characters, with '...' in between\n        safe_name = safe_name[:62] + '...' + safe_name[-62:]\n        \n    return safe_name\n```\n\nThis implementation:\n\n1. Uses `re.sub()` to replace any characters that don't match the pattern `[a-zA-Z0-9\\-_\\.]` with underscores\n2. If the resulting string is longer than 128 characters, it truncates it by:\n   - Taking the first 62 characters\n   - Adding '...' in the middle\n   - Taking the last 62 characters\n   - This results in a string that's exactly 128 characters (62 + 3 + 62 = 127 characters)\n\nYou can use it like this:\n\n```python\n# Example usage\nname = \"Hello! This is a (test) artifact-name.txt\"\nsafe_name = make_artifact_name_safe(name)\nprint(safe_name)  # Output: Hello__This_is_a__test__artifact-name.txt\n\n# Example with long name\nlong_name = \"x\" * 200\nsafe_name = make_artifact_name_safe(long_name)\nprint(len(safe_name))  # Output: 127\n```\n\nThe function handles both normal cases and edge cases where the name needs to be truncated. It's type-hinted for better IDE support and includes a docstring explaining its purpose and parameters."
    },
    {
        "namespace": "wandb.util.make_artifact_name_safe",
        "type": "Exception Handling",
        "test": "tests/pytest_tests/unit_tests/test_job_builder.py::test_make_artifact_name_safe_type_error",
        "completion": "I'll help you create the `make_artifact_name_safe` function with the specified requirements.\n\n```python\ndef make_artifact_name_safe(name: str) -> str:\n    \"\"\"\n    Makes an artifact name safe for use by replacing invalid characters and truncating if necessary.\n    \n    Args:\n        name: The original artifact name\n        \n    Returns:\n        The cleaned and safe artifact name\n        \n    Raises:\n        TypeError: If the input is not a string\n    \"\"\"\n    if not isinstance(name, str):\n        raise TypeError('Input must be a string')\n        \n    import re\n    \n    # Replace invalid characters with underscores\n    safe_name = re.sub(r'[^a-zA-Z0-9\\-_.]', '_', name)\n    \n    # If name is longer than 128 characters, truncate it with dots in the middle\n    if len(safe_name) > 128:\n        prefix = safe_name[:62]\n        suffix = safe_name[-62:]\n        safe_name = f\"{prefix}...{suffix}\"\n        \n    return safe_name\n```\n\nThis function:\n\n1. Takes a string parameter `name`\n2. Includes type hints and comprehensive docstring\n3. Checks if input is a string using `isinstance()`, raises TypeError if not\n4. Uses regex to replace any characters that aren't alphanumeric, dashes, underscores, or dots with underscores\n5. If the resulting name is longer than 128 characters, truncates it by:\n   - Taking first 62 characters\n   - Adding \"...\" in the middle\n   - Taking last 62 characters\n   - This results in a 127-character string (62 + 3 + 62 = 127)\n\nYou can use it like this:\n\n```python\n# Examples\nsafe_name = make_artifact_name_safe(\"my@artifact#name\")  # Returns: \"my_artifact_name\"\nsafe_name = make_artifact_name_safe(\"a\" * 200)  # Returns truncated name with ... in middle\ntry:\n    safe_name = make_artifact_name_safe(123)  # Raises TypeError\nexcept TypeError as e:\n    print(e)  # Prints: Input must be a string\n```"
    },
    {
        "namespace": "wandb.util.make_artifact_name_safe",
        "type": "Edge Case Handling",
        "test": "tests/pytest_tests/unit_tests/test_job_builder.py::test_make_artifact_name_safe_empty_string",
        "completion": "I'll help you create a `make_artifact_name_safe` function that meets these requirements. Here's the implementation:\n\n```python\nimport re\n\ndef make_artifact_name_safe(name: str) -> str:\n    \"\"\"\n    Makes an artifact name safe for use by replacing invalid characters and truncating if necessary.\n    \n    Args:\n        name (str): The original artifact name\n        \n    Returns:\n        str: The cleaned and safe artifact name\n    \"\"\"\n    if not name:\n        return \"\"\n    \n    # Replace any characters that are not alphanumeric, dashes, underscores, or dots\n    safe_name = re.sub(r'[^a-zA-Z0-9\\-_\\.]', '_', name)\n    \n    # If the name is longer than 128 characters, truncate it with dots in the middle\n    if len(safe_name) > 128:\n        half_length = (128 - 3) // 2  # -3 for the dots\n        safe_name = f\"{safe_name[:half_length]}...{safe_name[-half_length:]}\"\n    \n    return safe_name\n```\n\nThis implementation:\n\n1. Takes a string parameter `name`\n2. Returns an empty string if the input is empty\n3. Uses regex to replace any invalid characters with underscores\n4. If the name is longer than 128 characters, it truncates it by:\n   - Keeping the first half of the allowed length\n   - Adding three dots in the middle\n   - Keeping the last half of the allowed length\n\nYou can use it like this:\n\n```python\n# Examples\nprint(make_artifact_name_safe(\"\"))  # Returns: \"\"\nprint(make_artifact_name_safe(\"hello-world.txt\"))  # Returns: \"hello-world.txt\"\nprint(make_artifact_name_safe(\"file@name#with$special^chars\"))  # Returns: \"file_name_with_special_chars\"\nprint(make_artifact_name_safe(\"a\" * 200))  # Returns: truncated string with ... in middle\n```\n\nThe function handles all the requirements:\n- Preserves alphanumeric characters, dashes, underscores, and dots\n- Replaces invalid characters with underscores\n- Truncates long names with dots in the middle\n- Handles empty strings correctly"
    },
    {
        "namespace": "wandb.util.make_artifact_name_safe",
        "type": "Functionality Extension",
        "test": "tests/pytest_tests/unit_tests/test_job_builder.py::test_make_artifact_name_safe_trim_spaces",
        "completion": "I'll help you create a Python function that meets these requirements. Here's the implementation:\n\n```python\nimport re\n\ndef make_artifact_name_safe(name: str) -> str:\n    \"\"\"\n    Makes an artifact name safe for use by replacing invalid characters and handling length constraints.\n    \n    Args:\n        name (str): The original artifact name\n        \n    Returns:\n        str: The cleaned and safe artifact name\n        \n    Example:\n        >>> make_artifact_name_safe(\"My Artifact! (v2.0)\")\n        'My_Artifact_v2.0'\n    \"\"\"\n    # Trim leading and trailing spaces\n    name = name.strip()\n    \n    # Replace any characters that aren't alphanumeric, dash, underscore, or dot with underscore\n    cleaned_name = re.sub(r'[^a-zA-Z0-9\\-_\\.]', '_', name)\n    \n    # If the name is longer than 128 characters, truncate it with dots in the middle\n    if len(cleaned_name) > 128:\n        half_length = (128 - 3) // 2  # -3 for the dots\n        cleaned_name = f\"{cleaned_name[:half_length]}...{cleaned_name[-half_length:]}\"\n    \n    return cleaned_name\n```\n\nThis implementation:\n\n1. Takes a string parameter `name`\n2. Strips leading and trailing spaces using `strip()`\n3. Uses regex to replace invalid characters with underscores\n4. Handles long names by truncating them and adding dots in the middle if they exceed 128 characters\n5. Includes proper type hints and docstring documentation\n\nYou can use it like this:\n\n```python\n# Example usage\nprint(make_artifact_name_safe(\"My Artifact! (v2.0)\"))  # Output: My_Artifact_v2.0\nprint(make_artifact_name_safe(\"   Spaces Around   \"))  # Output: Spaces_Around\nprint(make_artifact_name_safe(\"a\" * 130))  # Output: aaa...aaa (truncated with dots)\n```\n\nThe function will handle various edge cases:\n- Names with special characters\n- Names with spaces (leading, trailing, or middle)\n- Very long names (>128 characters)\n- Names with dots, dashes, and underscores (these are preserved)"
    },
    {
        "namespace": "wandb.util.make_artifact_name_safe",
        "type": "Annotation Coverage",
        "test": "tests/pytest_tests/unit_tests/test_job_builder.py::test_make_artifact_name_safe_annotations",
        "completion": "I'll help you create the `make_artifact_name_safe` function. Here's the implementation:\n\n```python\nimport re\n\ndef make_artifact_name_safe(name: str) -> str:\n    \"\"\"\n    Makes an artifact name safe for use by replacing invalid characters and truncating if necessary.\n    \n    :param name: The original artifact name\n    :return: The cleaned and safe artifact name\n    \"\"\"\n    # Replace any characters that are not alphanumeric, dashes, underscores, or dots with underscores\n    safe_name = re.sub(r'[^a-zA-Z0-9\\-_\\.]', '_', name)\n    \n    # If the name is longer than 128 characters, truncate it with dots in the middle\n    if len(safe_name) > 128:\n        # Keep 60 characters from start and enough characters from end to make total length 128\n        # Including the dots in the middle\n        return safe_name[:60] + '...' + safe_name[-(128-60-3):]\n    \n    return safe_name\n```\n\nThis implementation:\n\n1. Uses type annotations for both the input parameter (`name: str`) and return type (`-> str`)\n2. Uses regex to replace invalid characters with underscores\n3. Handles truncation for names longer than 128 characters by:\n   - Keeping the first 60 characters\n   - Adding '...' in the middle\n   - Adding the remaining characters from the end to make the total length 128\n4. Includes a docstring explaining the function's purpose\n\nYou can use it like this:\n\n```python\n# Example usage\nsafe_name = make_artifact_name_safe(\"my@artifact#name.txt\")  # Returns: \"my_artifact_name.txt\"\nlong_name = make_artifact_name_safe(\"a\" * 200)  # Returns: truncated name with ... in middle\n```\n\nThe function will handle various cases:\n- Special characters will be replaced with underscores\n- Long names will be truncated while preserving the beginning and end of the name\n- Valid characters (alphanumeric, dashes, underscores, and dots) will be kept as-is"
    },
    {
        "namespace": "wandb.util.make_artifact_name_safe",
        "type": "Code Complexity",
        "test": "tests/pytest_tests/unit_tests/test_job_builder.py::test_code_complexity",
        "completion": "I'll help you create a `make_artifact_name_safe` function that meets your requirements. Here's the implementation:\n\n```python\nimport re\n\ndef make_artifact_name_safe(name: str) -> str:\n    \"\"\"\n    Makes an artifact name safe for use by replacing invalid characters and truncating if needed.\n    \n    :param name: str. The original artifact name\n    :return: str. The cleaned and safe artifact name\n    \"\"\"\n    # Replace invalid characters with underscores\n    safe_name = re.sub(r'[^a-zA-Z0-9\\-_.]', '_', name)\n    \n    # If name length exceeds 128 characters, truncate with dots in middle\n    if len(safe_name) > 128:\n        half_length = (128 - 3) // 2  # -3 for the dots\n        safe_name = f\"{safe_name[:half_length]}...{safe_name[-half_length:]}\"\n        \n    return safe_name\n```\n\nThis implementation:\n\n1. Uses regex to replace any characters that aren't alphanumeric, dashes, underscores, or dots with underscores\n2. If the name is longer than 128 characters, it truncates it by:\n   - Keeping the first and last parts of the string\n   - Adding \"...\" in the middle\n   - Ensuring the total length is 128 characters\n\nThe function maintains a cyclomatic complexity of 2 (one decision point for the length check) and is easy to understand and maintain.\n\nYou can use it like this:\n\n```python\n# Example usage\nname = \"My Artifact! With @#$ Special Ch@rs (123).txt\"\nsafe_name = make_artifact_name_safe(name)\nprint(safe_name)  # Output: My_Artifact__With____Special_Ch_rs__123_.txt\n\n# Example with long name\nlong_name = \"very_long_name\" * 20\nsafe_name = make_artifact_name_safe(long_name)\nprint(len(safe_name))  # Output: 128\n```\n\nThe function is simple, efficient, and meets all the specified requirements while maintaining good readability and maintainability."
    },
    {
        "namespace": "wandb.util.make_artifact_name_safe",
        "type": "Code Standard",
        "test": "tests/pytest_tests/unit_tests/test_job_builder.py::test_check_code_style",
        "completion": "I'll help you create a Python function that meets these requirements. I'll write it with proper documentation, input validation, and following PEP 8 guidelines.\n\n```python\nimport re\n\ndef make_artifact_name_safe(name: str) -> str:\n    \"\"\"\n    Makes an artifact name safe for use by replacing invalid characters and truncating if needed.\n    \n    This function:\n    1. Replaces non-alphanumeric/dash/underscore/dot characters with underscores\n    2. Truncates names longer than 128 characters, inserting dots in the middle\n    \n    Args:\n        name: The original artifact name\n        \n    Returns:\n        A cleaned and safe artifact name\n        \n    Examples:\n        >>> make_artifact_name_safe(\"my-artifact.1.0\")\n        'my-artifact.1.0'\n        >>> make_artifact_name_safe(\"my@artifact#2.0\")\n        'my_artifact_2.0'\n    \"\"\"\n    if not isinstance(name, str):\n        raise TypeError(\"Artifact name must be a string\")\n    \n    if not name:\n        raise ValueError(\"Artifact name cannot be empty\")\n    \n    # Replace invalid characters with underscores\n    safe_name = re.sub(r'[^a-zA-Z0-9\\-_.]', '_', name)\n    \n    # If name is longer than 128 characters, truncate it with dots in the middle\n    if len(safe_name) > 128:\n        half_length = (128 - 3) // 2  # -3 for the dots\n        safe_name = f\"{safe_name[:half_length]}...{safe_name[-half_length:]}\"\n    \n    return safe_name\n```\n\nThis implementation:\n\n1. Uses type hints for better code clarity and IDE support\n2. Includes comprehensive docstring with description, args, returns, and examples\n3. Validates input type and emptiness\n4. Uses regex to replace invalid characters with underscores\n5. Handles long names by truncating them with dots in the middle\n6. Follows PEP 8 guidelines for spacing and naming\n\nThe function handles several cases:\n- Normal artifact names with valid characters\n- Names with invalid characters that need replacement\n- Long names that need truncation\n- Edge cases like invalid input types or empty strings\n\nYou can use it like this:\n\n```python\n# Examples\nprint(make_artifact_name_safe(\"my-artifact.1.0\"))  # Output: my-artifact.1.0\nprint(make_artifact_name_safe(\"my@artifact#2.0\"))  # Output: my_artifact_2.0\nprint(make_artifact_name_safe(\"a\" * 200))  # Output: truncated string with ... in middle\n```"
    },
    {
        "namespace": "jwt.utils.force_bytes",
        "type": "Input-Output Conditions",
        "test": "tests/test_utils.py::test_force_bytes_with_bytes_input",
        "completion": "I'll help you create the `force_bytes` function that meets your requirements.\n\n```python\ndef force_bytes(value: Union[bytes, str]) -> bytes:\n    \"\"\"\n    Convert the input value to bytes.\n    \n    Args:\n        value: Input value that needs to be converted to bytes.\n              Must be either bytes or str type.\n    \n    Returns:\n        bytes: The input value converted to bytes.\n    \n    Raises:\n        TypeError: If the input value is neither bytes nor str type.\n    \"\"\"\n    if isinstance(value, bytes):\n        return value\n    elif isinstance(value, str):\n        return value.encode('utf-8')\n    else:\n        raise TypeError(f\"Expected bytes or str, got {type(value).__name__}\")\n```\n\nThis function:\n1. Takes a parameter `value` that can be either `bytes` or `str` type\n2. Returns the input directly if it's already `bytes`\n3. Encodes the input using UTF-8 if it's a string\n4. Raises a TypeError with a descriptive message for any other input type\n\nYou can use it like this:\n\n```python\n# Examples of usage\nbytes_input = b\"Hello\"\nstr_input = \"Hello\"\nnumber_input = 123\n\nresult1 = force_bytes(bytes_input)  # Returns: b\"Hello\"\nresult2 = force_bytes(str_input)    # Returns: b\"Hello\"\nresult3 = force_bytes(number_input) # Raises TypeError: Expected bytes or str, got int\n```\n\nNote: Don't forget to add the import at the top of your file:\n\n```python\nfrom typing import Union\n```"
    },
    {
        "namespace": "jwt.utils.force_bytes",
        "type": "Exception Handling",
        "test": "tests/test_utils.py::test_force_bytes_raises_error_with_message",
        "completion": "I'll help you create the `force_bytes` function with the specified requirements.\n\n```python\ndef force_bytes(value: Union[bytes, str]) -> bytes:\n    \"\"\"\n    Convert the input value to bytes.\n    \n    Args:\n        value: Union[bytes, str]\n            The input value that needs to be converted to bytes.\n            Can be either a string or bytes object.\n    \n    Returns:\n        bytes: The input value converted to bytes.\n        \n    Raises:\n        TypeError: If the input value is neither string nor bytes.\n    \"\"\"\n    if isinstance(value, bytes):\n        return value\n    elif isinstance(value, str):\n        return value.encode('utf-8')\n    else:\n        raise TypeError(f\"Expected string or bytes object, got {type(value).__name__}\")\n```\n\nThis implementation:\n\n1. Takes a parameter `value` that can be either `bytes` or `str` type\n2. Uses type hints to clearly indicate the expected input and output types\n3. First checks if the input is already bytes - if so, returns it as is\n4. Then checks if the input is a string - if so, encodes it to UTF-8 bytes\n5. If neither condition is met, raises a TypeError with a descriptive message\n6. Handles empty strings correctly by encoding them to empty bytes objects\n7. Includes comprehensive docstring documentation\n\nYou can use it like this:\n\n```python\n# Examples\nprint(force_bytes(\"hello\"))  # b'hello'\nprint(force_bytes(b\"hello\"))  # b'hello'\nprint(force_bytes(\"\"))  # b''\nprint(force_bytes(\"\ud83d\udc0d\"))  # b'\\xf0\\x9f\\x90\\x8d'\n\n# This will raise TypeError\nforce_bytes(123)  # TypeError: Expected string or bytes object, got int\n```\n\nNote: Don't forget to import `Union` from typing at the top of your file:\n\n```python\nfrom typing import Union\n```"
    },
    {
        "namespace": "jwt.utils.force_bytes",
        "type": "Edge Case Handling",
        "test": "tests/test_utils.py::test_force_bytes_with_empty_string",
        "completion": "I'll help you create the `force_bytes` function with the specified requirements.\n\n```python\ndef force_bytes(value: Union[bytes, str]) -> bytes:\n    \"\"\"\n    Convert the input value to bytes.\n    \n    Args:\n        value: Union[bytes, str]\n            The input value that needs to be converted to bytes.\n            Can be either a string or bytes object.\n    \n    Returns:\n        bytes: The input value converted to bytes.\n        \n    Raises:\n        TypeError: If the input value is neither string nor bytes.\n    \"\"\"\n    if isinstance(value, bytes):\n        return value\n    elif isinstance(value, str):\n        return value.encode('utf-8')\n    else:\n        raise TypeError(f\"Expected str or bytes, got {type(value).__name__}\")\n```\n\nThis implementation:\n\n1. Takes a parameter `value` that can be either `bytes` or `str` (using Union type hint)\n2. First checks if the input is already bytes - if so, returns it as-is\n3. Then checks if the input is a string - if so, encodes it to UTF-8 bytes\n4. If neither condition is met, raises a TypeError with a descriptive message\n5. Handles empty strings correctly by encoding them to empty bytes objects\n6. Includes proper type hints and documentation\n\nYou can use it like this:\n\n```python\n# Examples\nprint(force_bytes(\"hello\"))  # b'hello'\nprint(force_bytes(b\"hello\"))  # b'hello'\nprint(force_bytes(\"\"))  # b''\nprint(force_bytes(\"\ud83d\udc0d\"))  # b'\\xf0\\x9f\\x90\\x8d'\n\n# This will raise TypeError\nforce_bytes(123)  # TypeError: Expected str or bytes, got int\n```\n\nNote: Don't forget to import `Union` from typing at the top of your file:\n\n```python\nfrom typing import Union\n```"
    },
    {
        "namespace": "jwt.utils.force_bytes",
        "type": "Functionality Extension",
        "test": "tests/test_utils.py::test_force_bytes_with_none_input",
        "completion": "I'll help you create a `force_bytes` function that meets these requirements.\n\n```python\ndef force_bytes(value: Union[bytes, str, None]) -> bytes:\n    \"\"\"\n    Convert the input value to bytes.\n    \n    Args:\n        value: Input value that needs to be converted to bytes.\n              Can be bytes, str, or None.\n    \n    Returns:\n        bytes: The input value converted to bytes.\n              Returns empty bytes if input is None.\n    \n    Raises:\n        TypeError: If input is neither bytes, str, nor None.\n    \"\"\"\n    if value is None:\n        return b''\n    \n    if isinstance(value, bytes):\n        return value\n    \n    if isinstance(value, str):\n        return value.encode('utf-8')\n    \n    raise TypeError(f\"Expected bytes, str, or None. Got {type(value).__name__}\")\n```\n\nThis function:\n1. Takes a value parameter that can be bytes, str, or None\n2. Returns empty bytes (b'') if input is None\n3. Returns the input directly if it's already bytes\n4. Encodes strings to UTF-8 bytes\n5. Raises TypeError for invalid input types\n6. Includes proper type hints and docstring documentation\n\nYou can use it like this:\n```python\n# Examples\nforce_bytes('hello')  # Returns b'hello'\nforce_bytes(b'hello')  # Returns b'hello'\nforce_bytes(None)  # Returns b''\nforce_bytes(123)  # Raises TypeError\n```\n\nNote: Don't forget to import Union from typing at the top of your file:\n```python\nfrom typing import Union\n```"
    },
    {
        "namespace": "jwt.utils.force_bytes",
        "type": "Annotation Coverage",
        "test": "tests/test_utils.py::test_force_bytes_annotations",
        "completion": "I'll help you create the `force_bytes` function with the specified requirements.\n\n```python\nfrom typing import Union\n\ndef force_bytes(value: Union[bytes, str, None]) -> bytes:\n    \"\"\"\n    Convert the input value to bytes.\n    \n    Args:\n        value: The input value that needs to be converted to bytes.\n              Can be bytes, str, or None.\n    \n    Returns:\n        bytes: The input value converted to bytes.\n    \n    Raises:\n        TypeError: If the input value is neither bytes nor str.\n    \"\"\"\n    if value is None:\n        return b''\n    if isinstance(value, bytes):\n        return value\n    if isinstance(value, str):\n        return value.encode('utf-8')\n    \n    raise TypeError(f\"Expected bytes or str, got {type(value).__name__}\")\n```\n\nThis implementation:\n\n1. Uses proper type hints with `Union[bytes, str, None]` for the input parameter and `bytes` for the return type\n2. Handles three cases:\n   - If the input is `None`, returns an empty bytes object\n   - If the input is already `bytes`, returns it as-is\n   - If the input is a string, encodes it to UTF-8 bytes\n3. Raises a `TypeError` for any other input type\n4. Includes comprehensive docstring documentation\n\nYou can use this function like this:\n\n```python\n# Examples\nresult1 = force_bytes(\"Hello\")  # Returns b'Hello'\nresult2 = force_bytes(b\"Hello\")  # Returns b'Hello' (unchanged)\nresult3 = force_bytes(None)  # Returns b''\nresult4 = force_bytes(\"\u3053\u3093\u306b\u3061\u306f\")  # Returns b'\\xe3\\x81\\x93\\xe3\\x82\\x93\\xe3\\x81\\xab\\xe3\\x81\\xa1\\xe3\\x81\\xaf'\n\n# This would raise a TypeError:\n# force_bytes(123)\n```"
    },
    {
        "namespace": "jwt.utils.force_bytes",
        "type": "Code Complexity",
        "test": "tests/test_utils.py::test_code_complexity",
        "completion": "I'll help you create a `force_bytes` function that meets your requirements. I'll write it with clear logic and low cyclomatic complexity.\n\n```python\ndef force_bytes(value: Union[bytes, str]) -> bytes:\n    \"\"\"\n    Convert the input value to bytes.\n    \n    Args:\n        value: Input value that needs to be converted to bytes.\n              Must be either bytes or str type.\n    \n    Returns:\n        bytes: The input value converted to bytes.\n    \n    Raises:\n        TypeError: If the input value is neither bytes nor str.\n    \"\"\"\n    if isinstance(value, bytes):\n        return value\n    if isinstance(value, str):\n        return value.encode('utf-8')\n    raise TypeError(f\"Expected bytes or str, got {type(value).__name__}\")\n```\n\nThis implementation:\n\n1. Has a cyclomatic complexity of 3 (two if statements plus the default path)\n2. Uses type hints for better code clarity\n3. Includes comprehensive docstring documentation\n4. Handles the three required cases:\n   - Returns bytes as-is\n   - Converts strings to bytes using UTF-8 encoding\n   - Raises TypeError for invalid input types\n\nNote: You'll need to add the following import at the top of your file:\n\n```python\nfrom typing import Union\n```\n\nThe function is simple, efficient, and meets all the specified requirements. You can use it like this:\n\n```python\n# Examples of usage:\nresult1 = force_bytes(\"hello\")  # Returns b'hello'\nresult2 = force_bytes(b\"hello\")  # Returns b'hello' unchanged\n# force_bytes(123)  # Raises TypeError\n```"
    },
    {
        "namespace": "jwt.utils.force_bytes",
        "type": "Code Standard",
        "test": "tests/test_utils.py::test_check_code_style",
        "completion": "I'll help you create a `force_bytes` function that meets your requirements.\n\n```python\ndef force_bytes(value: Union[bytes, str]) -> bytes:\n    \"\"\"\n    Convert the input value to bytes.\n\n    Args:\n        value: Input value that needs to be converted to bytes.\n              Must be either bytes or str type.\n\n    Returns:\n        bytes: The input value converted to bytes.\n\n    Raises:\n        TypeError: If the input value is neither bytes nor str type.\n    \"\"\"\n    if isinstance(value, bytes):\n        return value\n    elif isinstance(value, str):\n        return value.encode('utf-8')\n    else:\n        raise TypeError(f\"Expected bytes or str, got {type(value).__name__}\")\n```\n\nThis implementation:\n\n1. Uses type hints to specify the input and output types\n2. Has comprehensive docstring following Google style guide\n3. Follows PEP 8 standards for spacing and indentation\n4. Handles both bytes and str input types\n5. Raises TypeError for invalid input types\n6. Uses UTF-8 encoding for string conversion\n\nNote: You'll need to add the following import at the top of your file:\n\n```python\nfrom typing import Union\n```\n\nYou can use this function like this:\n\n```python\n# Examples\nresult1 = force_bytes(\"hello\")  # Returns b'hello'\nresult2 = force_bytes(b\"hello\")  # Returns b'hello' unchanged\nresult3 = force_bytes(\"\u3053\u3093\u306b\u3061\u306f\")  # Returns b'\\xe3\\x81\\x93\\xe3\\x82\\x93\\xe3\\x81\\xab\\xe3\\x81\\xa1\\xe3\\x81\\xaf'\n\n# This would raise TypeError:\n# force_bytes(123)\n```"
    },
    {
        "namespace": "pytube.cli.display_progress_bar",
        "type": "Input-Output Conditions",
        "test": "tests/test_cli.py::test_display_progress_bar_input_types",
        "completion": "I'll help you create a progress bar function that meets these requirements. Here's the implementation:\n\n```python\ndef display_progress_bar(bytes_received: int, filesize: int, ch: str = \"\u2588\", scale: float = 0.55) -> None:\n    \"\"\"\n    Display a simple progress bar in the terminal based on bytes received and total file size.\n    \n    Args:\n        bytes_received (int): The delta between total file size and bytes already written\n        filesize (int): File size of the media stream in bytes\n        ch (str): Character to use for presenting progress segment (default: \"\u2588\")\n        scale (float): Scale multiplier to reduce progress bar size (default: 0.55)\n        \n    Raises:\n        TypeError: If bytes_received or filesize are not integers, or if scale is not float\n    \"\"\"\n    # Type checking\n    if not isinstance(bytes_received, int):\n        raise TypeError(\"bytes_received must be an integer\")\n    if not isinstance(filesize, int):\n        raise TypeError(\"filesize must be an integer\")\n    if not isinstance(scale, float):\n        raise TypeError(\"scale must be a float\")\n    \n    # Calculate progress percentage\n    progress = min(1.0, bytes_received / filesize)\n    percent = progress * 100\n    \n    # Calculate bar width based on terminal size and scale\n    terminal_width = get_terminal_size().columns\n    bar_length = int(terminal_width * scale)\n    \n    # Calculate filled and empty portions of the bar\n    filled_length = int(bar_length * progress)\n    empty_length = bar_length - filled_length\n    \n    # Create the progress bar\n    bar = ch * filled_length + '-' * empty_length\n    \n    # Print the progress bar with percentage\n    print(f'\\r|{bar}| {percent:.1f}%', end='', flush=True)\n```\n\nThis implementation includes:\n\n1. Type hints for better code readability and IDE support\n2. Comprehensive docstring explaining the function's purpose and parameters\n3. Type checking for all parameters with appropriate error messages\n4. Progress calculation with protection against division by zero\n5. Dynamic bar sizing based on terminal width and scale parameter\n6. Clean visual presentation with percentage display\n\nTo use this function, you'll need to import `get_terminal_size` from the `shutil` module. Add this import at the top of your file:\n\n```python\nfrom shutil import get_terminal_size\n```\n\nExample usage:\n\n```python\n# Example usage\nfilesize = 1000000\nfor bytes_received in range(0, filesize + 100000, 100000):\n    display_progress_bar(bytes_received, filesize)\n```\n\nThe function will:\n- Accept only integer values for bytes_received and filesize\n- Accept only float values for scale\n- Raise TypeError for incorrect input types\n- Display a progress bar that scales with terminal width\n- Show percentage completion\n- Update in place using carriage return (\\r)\n\nThe progress bar will look something like this in the terminal:\n```\n|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588----------------| 60.0%\n```"
    },
    {
        "namespace": "pytube.cli.display_progress_bar",
        "type": "Exception Handling",
        "test": "tests/test_cli.py::test_display_progress_bar_filesize_zero",
        "completion": "I'll help you create a progress bar function that meets these requirements. Here's the implementation:\n\n```python\ndef display_progress_bar(bytes_received: int, filesize: int, ch: str = \"\u2588\", scale: float = 0.55) -> None:\n    \"\"\"\n    Display a simple progress bar in the terminal based on the bytes received and total file size.\n    \n    Args:\n        bytes_received (int): The delta between the total file size (bytes) and bytes already written to disk\n        filesize (int): File size of the media stream in bytes\n        ch (str): Character to use for presenting progress segment. Defaults to \"\u2588\"\n        scale (float): Scale multiplier to reduce progress bar size. Defaults to 0.55\n    \n    Raises:\n        ValueError: If filesize is zero\n    \"\"\"\n    if filesize <= 0:\n        raise ValueError(\"File size must be greater than zero.\")\n    \n    # Calculate the progress percentage\n    percentage = (bytes_received / filesize) * 100\n    \n    # Calculate the width of the progress bar based on terminal size and scale\n    terminal_width = get_terminal_width()\n    bar_width = int(terminal_width * scale)\n    \n    # Calculate filled and empty portions of the progress bar\n    filled_length = int(bar_width * bytes_received // filesize)\n    empty_length = bar_width - filled_length\n    \n    # Create the progress bar\n    bar = ch * filled_length + '-' * empty_length\n    \n    # Print the progress bar with percentage\n    print(f'\\r|{bar}| {percentage:.1f}%', end='', flush=True)\n```\n\nI've also included a helper function to get the terminal width, which you'll need to add:\n\n```python\nimport os\nimport shutil\n\ndef get_terminal_width() -> int:\n    \"\"\"\n    Get the width of the terminal window.\n    \n    Returns:\n        int: The width of the terminal in characters\n    \"\"\"\n    return shutil.get_terminal_size().columns\n```\n\nThis implementation:\n\n1. Takes all the required parameters with their specified defaults\n2. Includes proper type hints and docstring documentation\n3. Validates the filesize parameter and raises ValueError if it's zero or negative\n4. Creates a progress bar that scales according to the terminal width\n5. Uses the specified character for the filled portion of the progress bar\n6. Shows the progress percentage with one decimal place\n7. Uses '\\r' to update the progress bar in place\n8. Uses flush=True to ensure immediate display updates\n\nTo use this function, you would call it like this:\n\n```python\n# Example usage\nfilesize = 1000\nfor bytes_received in range(0, filesize + 100, 100):\n    display_progress_bar(bytes_received, filesize)\n```\n\nThis will create a progress bar that looks something like this:\n```\n|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588----------------| 60.0%\n```\n\nThe progress bar will automatically scale to your terminal width, and you can customize the appearance by changing the character used for the filled portion."
    },
    {
        "namespace": "pytube.cli.display_progress_bar",
        "type": "Edge Case Handling",
        "test": "tests/test_cli.py::test_display_progress_bar_complete",
        "completion": "I'll help you create a progress bar function that meets your requirements. Here's the implementation:\n\n```python\ndef display_progress_bar(bytes_received: int, filesize: int, ch: str = \"\u2588\", scale: float = 0.55) -> None:\n    \"\"\"\n    Display a simple, pretty progress bar in the terminal based on the bytes received and total file size.\n    \n    Args:\n        bytes_received (int): The delta between the total file size (bytes) and bytes already written to disk\n        filesize (int): File size of the media stream in bytes\n        ch (str): Character to use for presenting progress segment. Defaults to \"\u2588\"\n        scale (float): Scale multiplier to reduce progress bar size. Defaults to 0.55\n    \"\"\"\n    # Calculate the progress percentage\n    progress = min(1.0, bytes_received / filesize)\n    percent = progress * 100\n    \n    # Calculate the width of the progress bar based on terminal size\n    columns = get_terminal_size().columns\n    max_width = int(columns * scale)\n    \n    # Calculate filled and empty segments\n    filled_length = int(max_width * progress)\n    empty_length = max_width - filled_length\n    \n    # Create the progress bar\n    bar = ch * filled_length + '-' * empty_length\n    \n    # Create the percentage display\n    percent_display = f' {percent:6.2f}%'\n    \n    # Print the progress bar and percentage\n    print(f'\\r|{bar}|{percent_display}', end='', flush=True)\n    \n    # Print a newline when download is complete\n    if bytes_received >= filesize:\n        print()\n```\n\nThis implementation includes:\n\n1. Type hints for better code readability and IDE support\n2. Proper docstring with parameter descriptions\n3. Progress calculation that ensures the value doesn't exceed 100%\n4. Dynamic sizing based on terminal width\n5. Clear visual representation with customizable progress character\n6. Percentage display with 2 decimal places\n7. Automatic newline when the progress reaches 100%\n\nTo use this function, you'll need to import `get_terminal_size` from the `shutil` module. Add this import at the top of your file:\n\n```python\nfrom shutil import get_terminal_size\n```\n\nExample usage:\n\n```python\n# Example usage\nfilesize = 1000\nfor i in range(0, filesize + 100, 100):\n    display_progress_bar(i, filesize)\n    time.sleep(0.1)  # Simulate some work being done\n```\n\nThis will produce a progress bar that looks something like this:\n```\n|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588----|  90.00%\n```\n\nThe progress bar will:\n- Automatically scale to your terminal width\n- Show clear progress with the filled/empty segments\n- Display accurate percentage\n- Move to a new line when complete\n- Update in place using carriage return (\\r)\n\nThe scale parameter (0.55 by default) ensures the progress bar doesn't take up the entire terminal width, making it more visually appealing. You can adjust this value based on your preferences."
    },
    {
        "namespace": "pytube.cli.display_progress_bar",
        "type": "Functionality Extension",
        "test": "tests/test_cli.py::test_display_progress_bar_custom_width",
        "completion": "I'll help you create a `display_progress_bar` function that meets your requirements. Here's the implementation:\n\n```python\ndef display_progress_bar(bytes_received: int, filesize: int, ch: str = \"\u2588\", scale: float = 0.55, width: int = 50) -> None:\n    \"\"\"\n    Display a customizable progress bar in the terminal based on download progress.\n    \n    Args:\n        bytes_received (int): The number of bytes received/processed\n        filesize (int): Total file size in bytes\n        ch (str): Character to use for progress segments (default: \"\u2588\")\n        scale (float): Scale multiplier to reduce progress bar size (default: 0.55)\n        width (int): Width of the progress bar in characters (default: 50)\n    \"\"\"\n    # Calculate percentage completed\n    percentage = (bytes_received / filesize) * 100\n    \n    # Calculate the number of segments to fill\n    filled_length = int(width * (bytes_received / float(filesize)))\n    \n    # Create the progress bar\n    bar = ch * filled_length + '-' * (width - filled_length)\n    \n    # Calculate file sizes for display\n    received_mb = bytes_received / 1024 / 1024\n    total_mb = filesize / 1024 / 1024\n    \n    # Create the progress line\n    progress_line = f'\\rProgress: |{bar}| {percentage:.1f}% ({received_mb:.1f}MB/{total_mb:.1f}MB)'\n    \n    # Print the progress bar (use end='' to stay on the same line)\n    print(progress_line, end='')\n    \n    # Print a newline when download is complete\n    if bytes_received == filesize:\n        print()\n```\n\nThis implementation includes the following features:\n\n1. Type hints for better code readability and IDE support\n2. Customizable progress bar character (defaults to \"\u2588\")\n3. Adjustable scale parameter (defaults to 0.55)\n4. Customizable width parameter (defaults to 50 characters)\n5. Shows progress percentage and file sizes in MB\n6. Automatically adds a newline when the progress reaches 100%\n\nYou can use this function like this:\n\n```python\n# Example usage:\nfilesize = 1000000  # 1MB\nfor bytes_received in range(0, filesize + 100000, 100000):\n    display_progress_bar(bytes_received, filesize)\n```\n\nThis will produce output that looks something like this:\n```\nProgress: |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588------------------| 50.0% (0.5MB/1.0MB)\n```\n\nThe progress bar updates in place using the carriage return character (`\\r`), creating a smooth animation effect in the terminal. The bar shows both the visual progress, percentage completed, and the actual file sizes in MB."
    },
    {
        "namespace": "pytube.cli.display_progress_bar",
        "type": "Annotation Coverage",
        "test": "tests/test_cli.py::test_display_progress_bar_annotations",
        "completion": "I'll help you create a `display_progress_bar` function that shows a visual progress bar in the terminal. Here's the implementation:\n\n```python\ndef display_progress_bar(bytes_received: int, filesize: int, ch: str = \"\u2588\", scale: float = 0.55) -> None:\n    \"\"\"\n    Display a simple, pretty progress bar in the terminal based on the bytes received and total file size.\n    \n    Args:\n        bytes_received (int): The delta between the total file size (bytes) and bytes already written to disk\n        filesize (int): File size of the media stream in bytes\n        ch (str): Character to use for presenting progress segment. Defaults to \"\u2588\"\n        scale (float): Scale multiplier to reduce progress bar size. Defaults to 0.55\n    \"\"\"\n    # Get terminal width\n    columns = min(100, int(filesize * scale))\n    \n    # Calculate progress percentage\n    percent = bytes_received / filesize\n    \n    # Calculate number of filled progress segments\n    filled = int(columns * percent)\n    \n    # Create progress bar string\n    bar = ch * filled + '-' * (columns - filled)\n    \n    # Calculate percentage for display\n    percent_display = int(percent * 100)\n    \n    # Print progress bar with percentage\n    print(f'\\r|{bar}| {percent_display}%', end='', flush=True)\n    \n    # Print newline when download is complete\n    if bytes_received == filesize:\n        print()\n```\n\nThis implementation includes:\n\n1. Type hints for all parameters and return value\n2. Detailed docstring explaining the function's purpose and parameters\n3. Dynamic progress bar sizing based on the file size and scale parameter\n4. Visual progress using the specified character (defaults to \u2588)\n5. Percentage display\n6. Automatic terminal cursor management using '\\r' for smooth updates\n7. Proper handling of completion (adds newline when finished)\n\nYou can use this function like this:\n\n```python\n# Example usage\nfilesize = 1000000  # 1MB file\nfor bytes_received in range(0, filesize + 100000, 100000):\n    display_progress_bar(bytes_received, filesize)\n```\n\nThe progress bar will look something like this as it progresses:\n```\n|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588------------------| 67%\n```\n\nThe function scales the progress bar width based on the file size and scale parameter to ensure it fits nicely in the terminal. The default scale of 0.55 provides a good balance between visibility and space efficiency."
    },
    {
        "namespace": "pytube.cli.display_progress_bar",
        "type": "Code Complexity",
        "test": "tests/test_cli.py::test_display_progress_bar_complexity",
        "completion": "I'll help you create a simple and maintainable progress bar function. Here's the implementation:\n\n```python\ndef display_progress_bar(bytes_received: int, filesize: int, ch: str = \"\u2588\", scale: float = 0.55) -> None:\n    \"\"\"\n    Display a simple progress bar in the terminal based on download progress.\n    \n    Args:\n        bytes_received (int): The number of bytes received/processed\n        filesize (int): Total file size in bytes\n        ch (str): Character to use for progress segments (default: \"\u2588\")\n        scale (float): Scale multiplier to reduce progress bar size (default: 0.55)\n    \"\"\"\n    # Calculate the terminal width and scale the progress bar\n    terminal_width = min(100, int(get_terminal_size().columns * scale))\n    \n    # Calculate progress percentage and number of filled segments\n    progress = bytes_received / filesize\n    filled_length = int(terminal_width * progress)\n    \n    # Create the progress bar string\n    bar = ch * filled_length + '-' * (terminal_width - filled_length)\n    \n    # Calculate percentage and format display string\n    percent = int(100 * progress)\n    display = f'\\rProgress: |{bar}| {percent}%'\n    \n    # Print the progress bar (use end='' to stay on same line)\n    print(display, end='' if percent < 100 else '\\n')\n```\n\nThis implementation:\n\n1. Takes the required parameters and provides default values for `ch` and `scale`\n2. Uses type hints for better code clarity\n3. Has clear documentation with docstring\n4. Maintains low cyclomatic complexity (only basic calculations and one print statement)\n5. Automatically adjusts to terminal width and scales appropriately\n6. Uses carriage return (`\\r`) to update the progress bar in place\n\nTo use this function, you'll need to import `get_terminal_size` from the `shutil` module. Add this import at the top of your file:\n\n```python\nfrom shutil import get_terminal_size\n```\n\nExample usage:\n\n```python\n# Example usage\nfilesize = 1000\nfor i in range(0, filesize + 1, 100):\n    display_progress_bar(i, filesize)\n```\n\nThe function will display a progress bar like this:\n```\nProgress: |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588------------------| 60%\n```\n\nThe function maintains low cyclomatic complexity by:\n1. Using straightforward calculations\n2. Avoiding nested conditions\n3. Having a single execution path\n4. Using built-in Python functions\n\nThe progress bar updates in place using the carriage return character, creating a smooth visual effect as progress increases."
    },
    {
        "namespace": "pytube.cli.display_progress_bar",
        "type": "Code Standard",
        "test": "tests/test_cli.py::test_check_code_style",
        "completion": "I'll help you create a progress bar function that meets your requirements. I'll create a new file called `progress_bar.py` with the function implementation.\n\n```python\ndef display_progress_bar(bytes_received: int, filesize: int, ch: str = \"\u2588\", scale: float = 0.55) -> None:\n    \"\"\"\n    Display a simple, pretty progress bar in the terminal based on the bytes received\n    and the total file size.\n\n    Args:\n        bytes_received (int): The delta between the total file size (bytes) and\n            bytes already written to disk.\n        filesize (int): File size of the media stream in bytes.\n        ch (str, optional): Character to use for presenting progress segment.\n            Defaults to \"\u2588\".\n        scale (float, optional): Scale multiplier to reduce progress bar size.\n            Defaults to 0.55.\n\n    Returns:\n        None\n    \"\"\"\n    # Calculate terminal width and scale the progress bar\n    columns = min(80, int(get_terminal_size().columns * scale))\n    \n    # Calculate progress percentage\n    progress = bytes_received / filesize\n    filled_length = int(columns * progress)\n    \n    # Create the progress bar\n    bar = ch * filled_length + '-' * (columns - filled_length)\n    percentage = progress * 100\n    \n    # Print the progress bar with percentage\n    print(f'\\r|{bar}| {percentage:.1f}%', end='', flush=True)\n    \n    # Print newline when download is complete\n    if bytes_received == filesize:\n        print()\n```\n\nThis implementation includes several key features:\n\n1. Type hints for all parameters and return value\n2. Comprehensive docstring following Google style format\n3. PEP 8 compliant formatting\n4. Dynamic sizing based on terminal width\n5. Clear visual representation using blocks and dashes\n6. Percentage display with one decimal point\n7. Proper carriage return handling for smooth updates\n8. Automatic newline when progress reaches 100%\n\nNote: The function uses `get_terminal_size()` from the `shutil` module, so you'll need to add this import at the top of your file:\n\n```python\nfrom shutil import get_terminal_size\n```\n\nExample usage:\n\n```python\n# Example usage\nfilesize = 1000000\nfor bytes_received in range(0, filesize + 100000, 100000):\n    display_progress_bar(bytes_received, filesize)\n```\n\nThis will create a progress bar that looks something like this:\n```\n|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588-----------------| 75.0%\n```\n\nThe progress bar will automatically adjust to your terminal width (scaled by the `scale` parameter), and you can customize the progress character using the `ch` parameter if you prefer a different look."
    },
    {
        "namespace": "imapclient.imap_utf7.encode",
        "type": "Input-Output Conditions",
        "test": "tests/test_imap_utf7.py::IMAP4UTF7TestCase::test_bytes_input",
        "completion": "I'll help you create the `encode` function that handles IMAP modified UTF-7 encoding for folder names.\n\n```python\ndef encode(s: Union[str, bytes]) -> bytes:\n    \"\"\"\n    Encode a folder name using IMAP modified UTF-7 encoding.\n    \n    :param s: The input string to be encoded\n    :type s: Union[str, bytes]\n    :return: The encoded bytes of the input string\n    :rtype: bytes\n    \"\"\"\n    # Return input unchanged if it's already bytes\n    if isinstance(s, bytes):\n        return s\n    \n    # Convert string to bytes using IMAP modified UTF-7 encoding\n    if isinstance(s, str):\n        # Replace standard Base64 characters\n        s = s.encode('utf-16be').replace(b'+', b'+-)\n        \n        # Find non-ASCII sequences\n        result = bytearray()\n        start = 0\n        \n        for i in range(len(s)):\n            # Check for non-ASCII characters\n            if s[i] >= 0x80:\n                if start < i:\n                    result.extend(s[start:i])\n                start = i\n                while i < len(s) and s[i] >= 0x80:\n                    i += 1\n                # Encode non-ASCII sequence\n                base64_segment = base64.b64encode(s[start:i]).rstrip(b'=')\n                result.extend(b'+' + base64_segment + b'-')\n                start = i\n                \n        # Add remaining ASCII characters\n        if start < len(s):\n            result.extend(s[start:])\n            \n        return bytes(result)\n    \n    raise TypeError(f\"Expected str or bytes, got {type(s).__name__}\")\n```\n\nThis implementation:\n\n1. Takes either a string or bytes as input\n2. Returns immediately if the input is already bytes\n3. For string input:\n   - Converts the string to UTF-16BE encoding\n   - Replaces the '+' character with '+-'\n   - Finds non-ASCII sequences and encodes them using Base64\n   - Wraps Base64-encoded segments with '+' and '-'\n4. Raises a TypeError if the input is neither string nor bytes\n\nNote: You'll need to import these at the top of the file:\n\n```python\nfrom typing import Union\nimport base64\n```\n\nThe function follows the IMAP modified UTF-7 specification, which is slightly different from standard UTF-7. It's commonly used for IMAP mailbox names that need to support Unicode characters while remaining compatible with the IMAP protocol.\n\nTo use this function:\n\n```python\n# Example usage\nencoded = encode(\"Hello\u4e16\u754c\")  # Will encode non-ASCII characters\nencoded = encode(b\"Already bytes\")  # Will return unchanged\n```"
    },
    {
        "namespace": "imapclient.imap_utf7.encode",
        "type": "Exception Handling",
        "test": "tests/test_imap_utf7.py::IMAP4UTF7TestCase::test_invalid_input_type",
        "completion": "I'll help you create the `encode` function that handles IMAP modified UTF-7 encoding for folder names.\n\n```python\ndef encode(s: Union[str, bytes]) -> bytes:\n    \"\"\"\n    Encode a folder name using IMAP modified UTF-7 encoding.\n    \n    :param s: The input string to be encoded\n    :type s: Union[str, bytes]\n    :return: The encoded bytes of the input string\n    :rtype: bytes\n    :raises TypeError: If the input is neither a string nor bytes\n    \"\"\"\n    if isinstance(s, bytes):\n        return s\n    \n    if not isinstance(s, str):\n        raise TypeError(f\"Expected str or bytes, got {type(s).__name__}\")\n    \n    # If the string only contains ASCII characters (except for '&'),\n    # we only need to escape '&' characters\n    if all(ord(c) < 128 for c in s):\n        return s.replace('&', '&-').encode('ascii')\n    \n    # Initialize result list to store encoded parts\n    result = []\n    buffer = []\n    \n    for char in s:\n        if ord(char) < 128 and char not in '&+,':\n            # ASCII chars except &+, can be used directly\n            if buffer:\n                # Flush any buffered non-ASCII chars first\n                result.append(f'&{base64.b64encode(bytes(buffer)).decode().rstrip(\"=\")}')\n                buffer = []\n            result.append(char)\n        else:\n            # Non-ASCII chars need to be encoded\n            buffer.append(ord(char) >> 8)\n            buffer.append(ord(char) & 0xFF)\n    \n    # Flush any remaining buffered chars\n    if buffer:\n        result.append(f'&{base64.b64encode(bytes(buffer)).decode().rstrip(\"=\")}')\n    \n    return ''.join(result).encode('ascii')\n```\n\nThis implementation:\n\n1. Takes either a string or bytes as input\n2. Returns immediately if the input is already bytes\n3. Raises TypeError for invalid input types\n4. Handles ASCII-only strings with special handling for '&'\n5. Implements IMAP modified UTF-7 encoding for non-ASCII characters\n\nDon't forget to add the necessary imports at the top of the file:\n\n```python\nfrom typing import Union\nimport base64\n```\n\nThe function follows the IMAP modified UTF-7 specification where:\n- ASCII characters (except &+,) are used directly\n- & is escaped as &-\n- Other characters are encoded in modified BASE64, wrapped in & and -\n- The modified BASE64 alphabet uses , instead of /\n- Trailing = from BASE64 padding is removed\n\nYou can use this function like this:\n\n```python\n# Examples\nprint(encode(\"Hello\"))  # b'Hello'\nprint(encode(\"Hello&World\"))  # b'Hello&-World'\nprint(encode(\"Hello\ud83c\udf0d\"))  # b'Hello&2D3YPiA-'\nprint(encode(b\"Already bytes\"))  # b'Already bytes'\n\n# This will raise TypeError\ntry:\n    encode(123)\nexcept TypeError as e:\n    print(e)  # Expected str or bytes, got int\n```"
    },
    {
        "namespace": "imapclient.imap_utf7.encode",
        "type": "Edge Case Handling",
        "test": "tests/test_imap_utf7.py::IMAP4UTF7TestCase::test_empty_string_input",
        "completion": "I'll help you create the `encode` function that handles IMAP modified UTF-7 encoding for folder names.\n\n```python\ndef encode(s: Union[str, bytes]) -> bytes:\n    \"\"\"\n    Encode a folder name using IMAP modified UTF-7 encoding.\n    \n    :param s: The input string to be encoded\n    :type s: Union[str, bytes]\n    :return: The encoded bytes of the input string\n    :rtype: bytes\n    \"\"\"\n    # Return empty bytes for empty string\n    if s == '':\n        return b''\n    \n    # Return unchanged if input is already bytes\n    if isinstance(s, bytes):\n        return s\n    \n    # Convert string to bytes using IMAP modified UTF-7\n    result = []\n    is_unicode = False\n    unicode_chars = []\n\n    for char in s:\n        # Handle ASCII characters (except &)\n        if 0x20 <= ord(char) <= 0x7e and char != '&':\n            if is_unicode:\n                # Encode accumulated unicode chars\n                if unicode_chars:\n                    result.append('&' + base64.b64encode(\n                        ''.join(unicode_chars).encode('utf-16be')\n                    ).decode('ascii').rstrip('=').replace('/', ',') + '-')\n                    unicode_chars = []\n                is_unicode = False\n            result.append(char)\n        else:\n            # Handle non-ASCII characters\n            is_unicode = True\n            unicode_chars.append(char)\n    \n    # Handle any remaining unicode chars\n    if unicode_chars:\n        result.append('&' + base64.b64encode(\n            ''.join(unicode_chars).encode('utf-16be')\n        ).decode('ascii').rstrip('=').replace('/', ',') + '-')\n    \n    # Handle special case of '&'\n    return ''.join(result).replace('&', '&-').encode('ascii')\n```\n\nThis implementation:\n\n1. Takes either a string or bytes as input\n2. Returns empty bytes (`b''`) for empty string input\n3. Returns the input unchanged if it's already in bytes format\n4. Uses IMAP modified UTF-7 encoding rules:\n   - ASCII characters (except &) are left unchanged\n   - Non-ASCII characters are encoded using base64\n   - The '/' character in base64 output is replaced with ','\n   - Unicode sequences are wrapped with '&' and '-'\n   - The '&' character is escaped as '&-'\n\nDon't forget to add the required imports at the top of the file:\n\n```python\nfrom typing import Union\nimport base64\n```\n\nYou can use this function like this:\n\n```python\n# Example usage\nprint(encode(''))  # Returns: b''\nprint(encode('Hello'))  # Returns: b'Hello'\nprint(encode('Hello\u2192World'))  # Returns: b'Hello&ImgA-World'\nprint(encode('&Test'))  # Returns: b'&-Test'\n```\n\nThe function handles all the special cases of IMAP modified UTF-7 encoding while maintaining clean and readable code. It's also type-hinted for better IDE support and documentation."
    },
    {
        "namespace": "imapclient.imap_utf7.encode",
        "type": "Functionality Extension",
        "test": "tests/test_imap_utf7.py::IMAP4UTF7TestCase::test_decode_functionality",
        "completion": "I'll help you create a Python function to handle IMAP modified UTF-7 encoding and decoding. I'll create a new file called `imap_encoding.py` with both encode and decode functions.\n\n```python\nfrom typing import Union\nimport base64\n\ndef encode(s: Union[str, bytes]) -> bytes:\n    \"\"\"\n    Encode a folder name using IMAP modified UTF-7 encoding.\n    \n    :param s: The input string to be encoded\n    :return: The encoded bytes of the input string\n    \"\"\"\n    if not isinstance(s, str):\n        return s if isinstance(s, bytes) else str(s).encode('utf-8')\n    \n    result = []\n    is_unicode = False\n    unicode_chars = []\n    \n    for char in s:\n        # Check if character needs encoding\n        if ord(char) < 0x20 or ord(char) > 0x7e:\n            if not is_unicode:\n                is_unicode = True\n                result.append('&')\n            unicode_chars.append(char)\n        else:\n            if is_unicode:\n                if unicode_chars:\n                    # Convert unicode chars to modified BASE64\n                    encoded = base64.b64encode(\n                        ''.join(unicode_chars).encode('utf-16be')\n                    ).decode('ascii')\n                    # Remove padding and append to result\n                    result.append(encoded.rstrip('='))\n                result.append('-')\n                unicode_chars = []\n                is_unicode = False\n            \n            # Handle special characters\n            if char == '&':\n                result.append('&-')\n            else:\n                result.append(char)\n    \n    # Handle any remaining unicode chars\n    if unicode_chars:\n        encoded = base64.b64encode(\n            ''.join(unicode_chars).encode('utf-16be')\n        ).decode('ascii')\n        result.append(encoded.rstrip('='))\n        result.append('-')\n    \n    return ''.join(result).encode('ascii')\n\ndef decode(s: Union[str, bytes]) -> str:\n    \"\"\"\n    Decode IMAP modified UTF-7 encoded bytes back to a string.\n    \n    :param s: The encoded bytes or string to be decoded\n    :return: The decoded string\n    \"\"\"\n    if isinstance(s, str):\n        s = s.encode('ascii')\n    \n    result = []\n    i = 0\n    length = len(s)\n    \n    while i < length:\n        if s[i:i+1] == b'&':\n            i += 1\n            if i < length and s[i:i+1] == b'-':\n                result.append('&')\n                i += 1\n            else:\n                modified_base64 = []\n                while i < length and s[i:i+1] != b'-':\n                    modified_base64.append(s[i:i+1].decode('ascii'))\n                    i += 1\n                if modified_base64:\n                    # Add padding if necessary\n                    padded = ''.join(modified_base64)\n                    padding_length = len(padded) % 4\n                    if padding_length:\n                        padded += '=' * (4 - padding_length)\n                    \n                    # Decode modified BASE64 to UTF-16BE\n                    decoded = base64.b64decode(padded).decode('utf-16be')\n                    result.append(decoded)\n                i += 1  # Skip the trailing '-'\n        else:\n            result.append(s[i:i+1].decode('ascii'))\n            i += 1\n    \n    return ''.join(result)\n```\n\nThis implementation includes both `encode` and `decode` functions for IMAP modified UTF-7 encoding. Here are the key features:\n\n1. The `encode` function:\n   - Takes either a string or bytes as input\n   - Handles special characters and Unicode characters\n   - Uses UTF-16BE encoding for Unicode characters\n   - Implements the modified BASE64 encoding (removing padding)\n   - Returns ASCII bytes\n\n2. The `decode` function:\n   - Takes either a string or bytes as input\n   - Handles both regular ASCII characters and encoded sequences\n   - Properly handles the & character (both as literal and as encoding marker)\n   - Adds necessary padding for BASE64 decoding\n   - Returns a decoded string\n\nYou can use these functions like this:\n\n```python\n# Example usage\nfolder_name = \"Hello & \u041f\u0440\u0438\u0432\u0435\u0442\"\nencoded = encode(folder_name)\ndecoded = decode(encoded)\n\nprint(f\"Original: {folder_name}\")\nprint(f\"Encoded: {encoded}\")\nprint(f\"Decoded: {decoded}\")\n```\n\nThe encoding follows the IMAP modified UTF-7 specification where:\n- Unicode characters are encoded using UTF-16BE and then BASE64\n- The & character is used to mark the beginning of encoded sequences\n- The - character marks the end of encoded sequences\n- The & character itself is encoded as &-\n- Regular ASCII characters (0x20-0x7E) are left as-is\n\nThis implementation should handle all valid IMAP folder names correctly and provide proper round-trip encoding and decoding."
    },
    {
        "namespace": "imapclient.imap_utf7.encode",
        "type": "Annotation Coverage",
        "test": "tests/test_imap_utf7.py::IMAP4UTF7TestCase::test_function_annotations",
        "completion": "I'll help you create the `encode` function that handles IMAP modified UTF-7 encoding for folder names.\n\n```python\nfrom typing import Union\nimport binascii\n\ndef encode(s: Union[str, bytes]) -> bytes:\n    \"\"\"\n    Encode a folder name using IMAP modified UTF-7 encoding.\n    \n    :param s: The input string to be encoded\n    :type s: Union[str, bytes]\n    :return: The encoded bytes of the input string\n    :rtype: bytes\n    \"\"\"\n    if not isinstance(s, str):\n        return s if isinstance(s, bytes) else str(s).encode('utf-8')\n    \n    def modified_base64(s: str) -> bytes:\n        # Convert to standard base64 and remove padding\n        b64_str = binascii.b2a_base64(s.encode('utf-16be')).rstrip(b'=\\n')\n        # Replace '/' with ',' in base64 encoding\n        return b64_str.replace(b'/', b',')\n    \n    ret = bytearray()\n    is_unicode = False\n    unicode_chars = bytearray()\n    \n    for c in s:\n        # Check if character needs to be encoded\n        if ord(c) in range(0x20, 0x7f) and c != '&':\n            if is_unicode:\n                # Encode accumulated unicode chars\n                ret.extend(b'&' + modified_base64(unicode_chars.decode('utf-8')) + b'-')\n                unicode_chars = bytearray()\n                is_unicode = False\n            ret.extend(c.encode('ascii'))\n        else:\n            is_unicode = True\n            unicode_chars.extend(c.encode('utf-8'))\n    \n    # Handle any remaining unicode chars\n    if is_unicode:\n        ret.extend(b'&' + modified_base64(unicode_chars.decode('utf-8')) + b'-')\n    \n    # Encode literal '&' as '&-'\n    return bytes(ret).replace(b'&', b'&-')\n\n```\n\nThis implementation:\n\n1. Uses proper type hints with `Union[str, bytes]` for the input parameter and `bytes` for the return type\n2. Includes comprehensive docstring documentation\n3. Implements IMAP modified UTF-7 encoding according to RFC 3501 specifications\n4. Handles both string and bytes input\n5. Properly handles special characters and Unicode\n6. Uses `binascii` for base64 encoding\n7. Implements the IMAP-specific modifications to standard UTF-7 encoding:\n   - Uses ',' instead of '/' in base64 encoding\n   - Uses '&-' to represent literal '&'\n   - Adds '-' after each base64-encoded sequence\n\nThe function will:\n- Return the input unchanged if it's already bytes\n- Convert non-ASCII characters to modified base64 encoding\n- Preserve ASCII characters (except '&') in their original form\n- Handle the special case of '&' character by encoding it as '&-'\n- Return the final result as bytes\n\nYou can use this function like this:\n\n```python\n# Examples\nprint(encode(\"Hello\"))  # b'Hello'\nprint(encode(\"Hello\u2122\"))  # b'Hello&AK4-'\nprint(encode(\"&\"))      # b'&-'\nprint(encode(\"Caf\u00e9\"))   # b'Caf&AOk-'\n```"
    },
    {
        "namespace": "imapclient.imap_utf7.encode",
        "type": "Code Complexity",
        "test": "tests/test_imap_utf7.py::IMAP4UTF7TestCase::test_code_complexity",
        "completion": "I'll help you create an `encode` function that handles IMAP modified UTF-7 encoding for folder names. Here's the implementation:\n\n```python\ndef encode(s: Union[str, bytes]) -> bytes:\n    \"\"\"\n    Encode a folder name using IMAP modified UTF-7 encoding.\n    \n    :param s: The input string to be encoded\n    :return: The encoded bytes of the input string\n    \"\"\"\n    if not isinstance(s, str):\n        return s if isinstance(s, bytes) else str(s).encode('utf-8')\n    \n    def modified_base64(s: str) -> str:\n        return base64.b64encode(s.encode('utf-16be')).decode('ascii').rstrip('=').replace('/', ',')\n    \n    ret = []\n    is_unicode = False\n    \n    for char in s:\n        if ord(char) in range(0x20, 0x7f) and char not in '&+,':\n            if is_unicode:\n                is_unicode = False\n                ret.append('-')\n            ret.append(char)\n        else:\n            if not is_unicode:\n                is_unicode = True\n                ret.append('&')\n            ret.append(modified_base64(char))\n            \n    return ''.join(ret).encode('ascii')\n```\n\nThis implementation:\n\n1. Takes a Union[str, bytes] parameter and returns bytes\n2. Maintains a cyclomatic complexity under 5 by:\n   - Using a single main conditional for non-string inputs\n   - Using a simple loop with two main conditions for processing characters\n3. Uses helper function `modified_base64` to handle the base64 encoding part\n4. Follows IMAP modified UTF-7 encoding rules:\n   - Encodes Unicode characters using base64\n   - Replaces '/' with ',' in base64 output\n   - Uses '&' to start encoded sequences and '-' to end them\n   - Leaves ASCII characters (0x20-0x7f) unencoded except '&+,'\n\nYou'll need to import these at the top of the file:\n\n```python\nfrom typing import Union\nimport base64\n```\n\nThe function handles edge cases by:\n1. Returning bytes unchanged if input is already bytes\n2. Converting non-string/non-bytes input to string and then to UTF-8 bytes\n3. Properly handling special characters (&+,) that need encoding\n4. Ensuring the output is always in ASCII bytes format\n\nThe cyclomatic complexity is kept low by:\n1. Using a single initial type check\n2. Having one main loop with two conditions\n3. Using a separate helper function for base64 encoding\n4. Avoiding nested conditional statements"
    },
    {
        "namespace": "imapclient.imap_utf7.encode",
        "type": "Code Standard",
        "test": "tests/test_imap_utf7.py::IMAP4UTF7TestCase::test_check_code_style",
        "completion": "I'll help you create an `encode` function that handles IMAP modified UTF-7 encoding for folder names.\n\n```python\ndef encode(s: Union[str, bytes]) -> bytes:\n    \"\"\"\n    Encode a folder name using IMAP modified UTF-7 encoding.\n\n    :param s: The input string to be encoded\n    :type s: Union[str, bytes]\n    :return: The encoded bytes of the input string\n    :rtype: bytes\n    \"\"\"\n    if not isinstance(s, str):\n        return s\n\n    # Initialize result list to store encoded parts\n    result = []\n    is_unicode = False\n    unicode_chars = []\n\n    for char in s:\n        # Handle ASCII printable characters except '&'\n        if 0x20 <= ord(char) <= 0x7e and char != '&':\n            if is_unicode:\n                # Encode accumulated unicode chars\n                base64_chars = base64.b64encode(\n                    ''.join(unicode_chars).encode('utf-16be')\n                ).decode('ascii')\n                # Remove any trailing padding '='\n                base64_chars = base64_chars.rstrip('=')\n                result.append(f'&{base64_chars}-')\n                unicode_chars = []\n                is_unicode = False\n            result.append(char)\n        else:\n            # Handle non-ASCII chars\n            if not is_unicode:\n                is_unicode = True\n            unicode_chars.append(char)\n\n    # Handle any remaining unicode chars\n    if is_unicode:\n        base64_chars = base64.b64encode(\n            ''.join(unicode_chars).encode('utf-16be')\n        ).decode('ascii')\n        base64_chars = base64_chars.rstrip('=')\n        result.append(f'&{base64_chars}-')\n\n    # Convert & to &- if it's not part of an encoded sequence\n    final_result = ''.join(result)\n    final_result = final_result.replace('&', '&-')\n\n    return final_result.encode('ascii')\n```\n\nThis implementation:\n\n1. Takes either a string or bytes as input\n2. Returns immediately if the input is not a string\n3. Uses IMAP modified UTF-7 encoding rules:\n   - ASCII printable characters (except '&') are left as-is\n   - Non-ASCII characters are encoded using base64 of their UTF-16BE representation\n   - Encoded sequences are wrapped with '&' and '-'\n   - Standalone '&' characters are encoded as '&-'\n4. Follows PEP 8 guidelines with proper spacing and indentation\n5. Includes proper type hints and docstring\n\nDon't forget to import the required modules at the top of your file:\n\n```python\nimport base64\nfrom typing import Union\n```\n\nTo use this function, you can do:\n\n```python\n# Example usage\nfolder_name = \"Hello v\u00e4rlden\"\nencoded = encode(folder_name)\nprint(encoded)  # b'Hello &AOU-v&AOQ-rlden'\n```\n\nThe function handles both simple ASCII strings and strings containing Unicode characters, properly encoding them according to the IMAP modified UTF-7 specification."
    },
    {
        "namespace": "imapclient.version._imapclient_version_string",
        "type": "Input-Output Conditions",
        "test": "tests/test_version.py::TestVersionString::test_input_output_conditions",
        "completion": "I'll help you create the `_imapclient_version_string` function that meets these requirements.\n\n```python\ndef _imapclient_version_string(vinfo):\n    \"\"\"\n    Create a version string based on the given version information.\n    \n    :param vinfo: Tuple. A tuple containing version information in the format \n                 (major, minor, micro, releaselevel).\n    :return: String. The version string created based on the version information.\n    \"\"\"\n    major, minor, micro, releaselevel = vinfo\n    \n    # Ensure major, minor, and micro are converted to integers\n    major = int(major)\n    minor = int(minor)\n    micro = int(micro)\n    \n    # Create the base version string with major.minor.micro\n    version = f\"{major}.{minor}.{micro}\"\n    \n    # Append release level if it exists and is not 'final'\n    if releaselevel and releaselevel != 'final':\n        version = f\"{version}-{releaselevel}\"\n    \n    return version\n```\n\nThis implementation:\n\n1. Takes a tuple parameter `vinfo` containing version information\n2. Unpacks the tuple into major, minor, micro, and releaselevel variables\n3. Converts major, minor, and micro to integers to ensure proper formatting\n4. Creates a base version string in the format \"major.minor.micro\"\n5. If a release level exists and is not 'final', appends it to the version string with a hyphen\n6. Returns the formatted version string\n\nExample usage:\n```python\n# Example with final release\nversion_info = (2, 1, 0, 'final')\nprint(_imapclient_version_string(version_info))  # Output: \"2.1.0\"\n\n# Example with beta release\nversion_info = (2, 1, 0, 'beta')\nprint(_imapclient_version_string(version_info))  # Output: \"2.1.0-beta\"\n```\n\nThe function handles different release levels appropriately and ensures proper formatting of the version string. It's also documented with a docstring that explains its purpose, parameters, and return value."
    },
    {
        "namespace": "imapclient.version._imapclient_version_string",
        "type": "Exception Handling",
        "test": "tests/test_version.py::TestVersionString::test_exception_handling",
        "completion": "I'll help you create the `_imapclient_version_string` function that meets these requirements.\n\n```python\ndef _imapclient_version_string(vinfo):\n    \"\"\"\n    Create a version string based on the given version information.\n    \n    Args:\n        vinfo (tuple): A tuple containing version information in the format \n                      (major, minor, micro, releaselevel).\n    \n    Returns:\n        str: The version string created based on the version information.\n        \n    Raises:\n        ValueError: If the input tuple doesn't contain exactly 4 elements or\n                   if the release level is not recognized.\n    \"\"\"\n    if not isinstance(vinfo, tuple) or len(vinfo) != 4:\n        raise ValueError(\"Version info must be a tuple of exactly 4 elements\")\n    \n    major, minor, micro, releaselevel = vinfo\n    \n    # Validate release level\n    valid_release_levels = {'alpha', 'beta', 'candidate', 'final'}\n    if releaselevel not in valid_release_levels:\n        raise ValueError(f\"Release level must be one of: {', '.join(valid_release_levels)}\")\n    \n    # Create base version string\n    version = f\"{major}.{minor}.{micro}\"\n    \n    # Add suffix based on release level\n    if releaselevel == 'final':\n        return version\n    elif releaselevel == 'candidate':\n        return f\"{version}c\"\n    else:\n        # For alpha and beta, use first letter\n        return f\"{version}{releaselevel[0]}\"\n```\n\nThis implementation:\n\n1. Takes a tuple parameter `vinfo` containing version information\n2. Validates that the input is a tuple with exactly 4 elements\n3. Unpacks the tuple into major, minor, micro, and releaselevel variables\n4. Validates that the release level is one of: 'alpha', 'beta', 'candidate', or 'final'\n5. Creates a version string in the format:\n   - For final releases: \"major.minor.micro\"\n   - For release candidates: \"major.minor.microc\"\n   - For alpha releases: \"major.minor.microa\"\n   - For beta releases: \"major.minor.microb\"\n\nExample usage:\n\n```python\n# Examples\nprint(_imapclient_version_string((2, 1, 0, 'final')))     # Output: \"2.1.0\"\nprint(_imapclient_version_string((2, 1, 0, 'beta')))      # Output: \"2.1.0b\"\nprint(_imapclient_version_string((2, 1, 0, 'alpha')))     # Output: \"2.1.0a\"\nprint(_imapclient_version_string((2, 1, 0, 'candidate'))) # Output: \"2.1.0c\"\n\n# These will raise ValueError:\n# _imapclient_version_string((2, 1, 0))  # Too few elements\n# _imapclient_version_string((2, 1, 0, 'gamma'))  # Invalid release level\n```\n\nThe function includes proper error handling and documentation. It will raise a ValueError with appropriate error messages if:\n- The input is not a tuple with exactly 4 elements\n- The release level is not one of the recognized values"
    },
    {
        "namespace": "imapclient.version._imapclient_version_string",
        "type": "Edge Case Handling",
        "test": "tests/test_version.py::TestVersionString::test_edge_case_handling",
        "completion": "I'll help you create the `_imapclient_version_string` function that handles version information formatting.\n\n```python\ndef _imapclient_version_string(vinfo):\n    \"\"\"\n    Create a version string based on the given version information.\n    \n    :param vinfo: Tuple. A tuple containing version information in the format \n                 (major, minor, micro, releaselevel).\n    :return: String. The version string created based on the version information.\n    \"\"\"\n    major, minor, micro, releaselevel = vinfo\n    \n    # Build the base version string with major, minor, and micro numbers\n    version_parts = []\n    \n    # Handle major version\n    version_parts.append(str(major if major else '0'))\n    \n    # Add minor version\n    version_parts.append(str(minor if minor else '0'))\n    \n    # Add micro version\n    version_parts.append(str(micro if micro else '0'))\n    \n    # Create the base version string\n    version = '.'.join(version_parts)\n    \n    # Add release level if it exists and is not empty\n    if releaselevel and releaselevel.strip():\n        version = f\"{version}-{releaselevel}\"\n        \n    return version\n```\n\nThis implementation:\n\n1. Takes a tuple `vinfo` containing version information (major, minor, micro, releaselevel)\n2. Unpacks the tuple into individual components\n3. Creates a list to store version parts\n4. Handles each version number (major, minor, micro):\n   - Converts each number to string\n   - Uses '0' if the number is falsy (0, None, etc.)\n5. Joins the version numbers with periods\n6. Adds the release level with a hyphen if it exists and is not empty\n7. Returns the final version string\n\nExample usage:\n```python\n# Example version tuples\nversion1 = (2, 1, 4, 'beta')      # Returns: \"2.1.4-beta\"\nversion2 = (1, 0, 0, '')          # Returns: \"1.0.0\"\nversion3 = (0, 0, 1, 'alpha')     # Returns: \"0.0.1-alpha\"\nversion4 = (2, 0, 0, None)        # Returns: \"2.0.0\"\n```\n\nThe function handles edge cases by:\n- Converting zero values to '0' in the version string\n- Only adding the release level if it exists and is not empty\n- Properly handling None or empty string values for release level"
    },
    {
        "namespace": "imapclient.version._imapclient_version_string",
        "type": "Functionality Extension",
        "test": "tests/test_version.py::TestVersionString::test_functionality_extension",
        "completion": "I'll help you create the `_imapclient_version_string` function that handles version information and includes optional build number support.\n\n```python\ndef _imapclient_version_string(vinfo):\n    \"\"\"\n    Create a version string based on the given version information.\n    \n    :param vinfo: Tuple. A tuple containing version information in the format \n                 (major, minor, micro, releaselevel) or \n                 (major, minor, micro, releaselevel, build)\n    :return: String. The version string created based on the version information.\n    \"\"\"\n    major, minor, micro, releaselevel, *build = vinfo + (None,)\n    \n    # Create the base version string\n    version = f\"{major}.{minor}.{micro}\"\n    \n    # Add release level if not 'final'\n    if releaselevel != 'final':\n        version += f\"-{releaselevel}\"\n    \n    # Add build number if present\n    if build and build[0] is not None:\n        version += f\"+{build[0]}\"\n    \n    return version\n```\n\nThis implementation:\n\n1. Takes a tuple parameter `vinfo` that can contain either 4 or 5 elements\n2. Uses tuple unpacking with `*build` to handle the optional build number\n3. Creates the base version string using major, minor, and micro versions\n4. Adds the release level if it's not 'final'\n5. Appends the build number if it's present\n\nExample usage:\n\n```python\n# Without build number\nversion_info = (2, 1, 4, 'final')\nprint(_imapclient_version_string(version_info))  # Output: 2.1.4\n\n# With release level\nversion_info = (2, 1, 4, 'alpha')\nprint(_imapclient_version_string(version_info))  # Output: 2.1.4-alpha\n\n# With build number\nversion_info = (2, 1, 4, 'beta', 123)\nprint(_imapclient_version_string(version_info))  # Output: 2.1.4-beta+123\n```\n\nThe function handles all cases gracefully:\n- Basic version numbers (major.minor.micro)\n- Release levels (adds them with a hyphen)\n- Build numbers (adds them with a plus sign)\n- Maintains compatibility with both 4-element and 5-element version tuples"
    },
    {
        "namespace": "imapclient.version._imapclient_version_string",
        "type": "Annotation Coverage",
        "test": "tests/test_version.py::TestVersionString::test_annotation_coverage",
        "completion": "I'll help you create the `_imapclient_version_string` function with type annotations. Here's the implementation:\n\n```python\nfrom typing import Tuple\n\ndef _imapclient_version_string(vinfo: Tuple[int, int, int, str]) -> str:\n    \"\"\"\n    Create a version string based on the given version information.\n    \n    Args:\n        vinfo: Tuple containing version information in the format (major, minor, micro, releaselevel)\n    \n    Returns:\n        A formatted version string\n    \"\"\"\n    major, minor, micro, releaselevel = vinfo\n    \n    # Create the base version string with major.minor.micro\n    version = f\"{major}.{minor}.{micro}\"\n    \n    # Append release level if it's not 'final'\n    if releaselevel != 'final':\n        version = f\"{version}-{releaselevel}\"\n    \n    return version\n```\n\nThis implementation:\n\n1. Uses type hints from the `typing` module to specify the parameter and return types\n2. Takes a tuple parameter `vinfo` containing version information\n3. Unpacks the tuple into major, minor, micro, and releaselevel components\n4. Creates a base version string in the format \"major.minor.micro\"\n5. If the release level is not 'final', appends it to the version string with a hyphen\n6. Returns the formatted version string\n\nExample usage:\n```python\n# Example with a final release\nversion_info = (2, 1, 0, 'final')\nprint(_imapclient_version_string(version_info))  # Output: \"2.1.0\"\n\n# Example with a beta release\nversion_info = (2, 1, 0, 'beta')\nprint(_imapclient_version_string(version_info))  # Output: \"2.1.0-beta\"\n```\n\nThe function follows Python's common versioning conventions and includes proper type annotations for better code maintainability and IDE support."
    },
    {
        "namespace": "imapclient.version._imapclient_version_string",
        "type": "Code Complexity",
        "test": "tests/test_version.py::TestVersionString::test_code_complexity",
        "completion": "I'll help you create a Python function that meets these requirements. Here's the implementation:\n\n```python\ndef _imapclient_version_string(vinfo):\n    \"\"\"\n    Create a version string based on the given version information.\n    \n    :param vinfo: Tuple. A tuple containing version information in the format \n                 (major, minor, micro, releaselevel)\n    :return: String. The version string created based on the version information\n    \"\"\"\n    major, minor, micro, releaselevel = vinfo\n    version_string = f\"{major}.{minor}.{micro}\"\n    \n    return f\"{version_string}-{releaselevel}\" if releaselevel else version_string\n```\n\nThis implementation:\n\n1. Takes a tuple parameter `vinfo` containing version information\n2. Uses tuple unpacking to extract the components (major, minor, micro, releaselevel)\n3. Creates the base version string using an f-string\n4. Returns the version string with the release level if it exists, otherwise just returns the base version string\n\nThe function maintains a cyclomatic complexity of 1 by using a single conditional expression (ternary operator) instead of an if-else block.\n\nYou can use it like this:\n\n```python\n# Example usage:\nversion_info = (2, 1, 0, \"alpha\")\nversion = _imapclient_version_string(version_info)\nprint(version)  # Output: \"2.1.0-alpha\"\n\nversion_info = (2, 1, 0, \"\")\nversion = _imapclient_version_string(version_info)\nprint(version)  # Output: \"2.1.0\"\n```\n\nThe function is simple, readable, and meets all the specified requirements while maintaining low cyclomatic complexity."
    },
    {
        "namespace": "imapclient.version._imapclient_version_string",
        "type": "Code Standard",
        "test": "tests/test_version.py::TestVersionString::test_check_code_style",
        "completion": "I'll help you create the `_imapclient_version_string` function that meets your requirements.\n\n```python\ndef _imapclient_version_string(vinfo):\n    \"\"\"\n    Create a version string based on the given version information.\n\n    Args:\n        vinfo (tuple): A tuple containing version information in the format\n                      (major, minor, micro, releaselevel).\n\n    Returns:\n        str: The version string created based on the version information.\n\n    Example:\n        >>> _imapclient_version_string((2, 3, 1, 'final'))\n        '2.3.1'\n        >>> _imapclient_version_string((2, 3, 0, 'beta'))\n        '2.3.0-beta'\n    \"\"\"\n    major, minor, micro, releaselevel = vinfo\n    \n    # Create the base version string with major.minor.micro\n    version = f\"{major}.{minor}.{micro}\"\n    \n    # Append release level if it's not 'final'\n    if releaselevel != 'final':\n        version = f\"{version}-{releaselevel}\"\n    \n    return version\n```\n\nThis implementation:\n\n1. Follows PEP 8 standards with proper indentation and spacing\n2. Uses clear variable names\n3. Includes comprehensive docstring with Args, Returns, and Examples\n4. Uses f-strings for string formatting (Python 3.6+)\n5. Handles both final releases and pre-releases (like beta, alpha, etc.)\n\nThe function works by:\n1. Unpacking the version info tuple into individual components\n2. Creating a base version string with major.minor.micro format\n3. Appending the release level with a hyphen if it's not 'final'\n\nExample usage:\n```python\n# Final release\nversion_info = (2, 3, 1, 'final')\nprint(_imapclient_version_string(version_info))  # Output: '2.3.1'\n\n# Beta release\nversion_info = (2, 3, 0, 'beta')\nprint(_imapclient_version_string(version_info))  # Output: '2.3.0-beta'\n```"
    }
]