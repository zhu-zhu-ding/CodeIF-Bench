{"namespace": "benedict.utils.type_util.is_json_serializable", "type": "Input-Output Conditions", "test": "tests/utils/test_type_util.py::type_util_test_case::test_input_output_conditions", "completion": "\ndef is_json_serializable(val: Any) -> bool:\n    \"\"\"\n    Check if the input value is JSON serializable.\n    \n    :param val: Any. The input value to be checked for JSON serializability\n    :return: Bool. True if the input value is JSON serializable, False otherwise\n    \n    Examples:\n        >>> is_json_serializable(42)  # int\n        True\n        >>> is_json_serializable(\"hello\")  # str\n        True\n        >>> is_json_serializable({1, 2, 3})  # set\n        False\n        >>> is_json_serializable(complex(1, 2))  # complex\n        False\n    \"\"\"\n    # Handle None case\n    if val is None:\n        return True\n    \n    # Check basic types\n    if isinstance(val, (bool, int, float, str)):\n        return True\n    \n    # Handle lists and tuples\n    if isinstance(val, (list, tuple)):\n        return all(is_json_serializable(item) for item in val)\n    \n    # Handle dictionaries\n    if isinstance(val, dict):\n        return (all(isinstance(k, str) for k in val.keys()) and  # JSON only allows string keys\n                all(is_json_serializable(v) for v in val.values()))\n    \n    # All other types are not JSON serializable\n    return False\n", "Result": "Error"}
{"namespace": "benedict.utils.type_util.is_json_serializable", "type": "Exception Handling", "test": "tests/utils/test_type_util.py::type_util_test_case::test_exception_handling", "completion": "\ndef is_json_serializable(val: Any) -> bool:\n    \"\"\"\n    Check if the input value is JSON serializable.\n    \n    This function handles all possible exceptions that might occur during JSON serialization\n    and returns False for any non-serializable value.\n    \n    :param val: Any. The input value to be checked for JSON serializability\n    :return: Bool. True if the input value is JSON serializable, False otherwise\n    \"\"\"\n    try:\n        json.dumps(val)\n        return True\n    except Exception:  # Catch all possible exceptions\n        return False\n", "Result": "Error"}
{"namespace": "benedict.utils.type_util.is_json_serializable", "type": "Edge Case Handling", "test": "tests/utils/test_type_util.py::type_util_test_case::test_edge_case_handling", "completion": "\ndef is_json_serializable(val: Any) -> bool:\n    \"\"\"\n    Check if the input value is JSON serializable.\n    \n    Handles edge cases including:\n    - Empty strings, lists, tuples, and dictionaries\n    - None values\n    - Basic JSON types (str, int, float, bool)\n    - Nested structures of these types\n    \n    :param val: Any. The input value to be checked for JSON serializability\n    :return: Bool. True if the input value is JSON serializable, False otherwise\n    \"\"\"\n    # Handle None explicitly\n    if val is None:\n        return True\n        \n    # Handle empty containers explicitly\n    if val in (\"\", [], (), {}):\n        return True\n        \n    # Handle basic JSON-serializable types\n    if isinstance(val, (bool, int, float, str)):\n        return True\n        \n    # Handle lists and tuples\n    if isinstance(val, (list, tuple)):\n        return all(is_json_serializable(item) for item in val)\n        \n    # Handle dictionaries\n    if isinstance(val, dict):\n        return all(isinstance(k, str) and is_json_serializable(v) for k, v in val.items())\n        \n    # Try json serialization for any other types\n    try:\n        json.dumps(val)\n        return True\n    except (TypeError, OverflowError):\n        return False\n", "Result": "Error"}
{"namespace": "benedict.utils.type_util.is_json_serializable", "type": "Functionality Extension", "test": "tests/utils/test_type_util.py::type_util_test_case::test_functionality_extension", "completion": "\ndef is_json_serializable(val: Any) -> bool:\n    \"\"\"\n    Check if the input value is JSON serializable.\n    Handles numpy data types, returning False for numpy arrays and numpy scalars.\n    \n    :param val: Any. The input value to be checked for JSON serializability\n    :return: Bool. True if the input value is JSON serializable, False otherwise\n    \"\"\"\n    # Check for numpy types first\n    try:\n        import numpy as np\n        if isinstance(val, (np.ndarray, np.generic)):\n            return False\n    except ImportError:\n        pass  # numpy not installed, continue with regular checks\n    \n    # Check regular JSON serializability\n    try:\n        json.dumps(val)\n        return True\n    except (TypeError, OverflowError):\n        return False\n", "Result": "Error"}
{"namespace": "benedict.utils.type_util.is_json_serializable", "type": "Annotation Coverage", "test": "tests/utils/test_type_util.py::type_util_test_case::test_annotation_coverage", "completion": "\nfrom typing import Any\nimport json\n\ndef is_json_serializable(val: Any) -> bool:\n    \"\"\"\n    Check if the input value is JSON serializable.\n    \n    :param val: Any. The input value to be checked for JSON serializability\n    :return: bool. True if the input value is JSON serializable, False otherwise\n    \"\"\"\n    try:\n        json.dumps(val)\n        return True\n    except (TypeError, OverflowError):\n        return False\n", "Result": "Pass"}
{"namespace": "benedict.utils.type_util.is_json_serializable", "type": "Code Complexity", "test": "tests/utils/test_type_util.py::type_util_test_case::test_code_complexity", "completion": "\ndef is_json_serializable(val: Any) -> bool:\n    \"\"\"\n    Check if the input value is JSON serializable.\n    Maintains a cyclomatic complexity of 1 by using a single return statement.\n    \n    :param val: Any. The input value to be checked for JSON serializability\n    :return: Bool. True if the input value is JSON serializable, False otherwise\n    \"\"\"\n    result = True\n    try:\n        json.dumps(val)\n    except (TypeError, OverflowError):\n        result = False\n    return result\n", "Result": "Error"}
{"namespace": "benedict.utils.type_util.is_json_serializable", "type": "Code Standard", "test": "tests/utils/test_type_util.py::type_util_test_case::test_check_code_style", "completion": "\nfrom typing import Any\nimport json\n\n\ndef is_json_serializable(val: Any) -> bool:\n    \"\"\"\n    Check if the input value is JSON serializable.\n\n    This function attempts to serialize the input value to JSON format.\n    JSON serializable types include:\n    - dict\n    - list\n    - str\n    - int\n    - float\n    - bool\n    - None\n\n    Args:\n        val: The input value to be checked for JSON serializability.\n\n    Returns:\n        bool: True if the input value is JSON serializable, False otherwise.\n\n    Examples:\n        >>> is_json_serializable({\"key\": \"value\"})\n        True\n        >>> is_json_serializable(lambda x: x)\n        False\n    \"\"\"\n    try:\n        json.dumps(val)\n        return True\n    except (TypeError, OverflowError):\n        return False\n", "Result": "Pass"}
{"namespace": "feedparser.urls.convert_to_idn", "type": "Exception Handling", "test": "tests/runtests.py::TestConvertToIdn::test_exception_handling_invalid_url", "completion": "\ndef convert_to_idn(url: str) -> str:\n    \"\"\"\n    Convert a URL to IDN notation.\n    \n    :param url: String. The URL to be converted to IDN notation\n    :return: String. The URL in IDN notation\n    :raises ValueError: If the input is not a valid URL string\n    :raises UnicodeError: If the conversion to IDN fails\n    \"\"\"\n    from urllib.parse import urlparse, urlunparse\n    import re\n\n    # Basic URL validation using regex\n    url_pattern = re.compile(\n        r'^(?:http|ftp)s?://'  # http:// or https:// or ftp:// or ftps://\n        r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+(?:[A-Z]{2,6}\\.?|[A-Z0-9-]{2,}\\.?)|'  # domain\n        r'localhost|'  # localhost\n        r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})'  # ip address\n        r'(?::\\d+)?'  # optional port\n        r'(?:/?|[/?]\\S+)$', re.IGNORECASE)\n\n    if not url_pattern.match(url):\n        raise ValueError(\"Invalid URL format\")\n\n    # Parse the URL into components\n    try:\n        parsed = urlparse(url)\n    except Exception as e:\n        raise ValueError(f\"Failed to parse URL: {str(e)}\")\n\n    # Check if hostname exists and needs conversion\n    if parsed.hostname:\n        try:\n            # Try encoding hostname in ASCII\n            parsed.hostname.encode('ascii')\n        except UnicodeEncodeError:\n            try:\n                # Convert to IDN if ASCII encoding fails\n                idn_hostname = parsed.hostname.encode('idna').decode('ascii')\n                # Create new components with converted hostname\n                components = list(parsed)\n                components[1] = idn_hostname\n                return urlunparse(components)\n            except Exception as e:\n                raise UnicodeError(f\"Failed to convert hostname to IDN: {str(e)}\")\n    \n    # Return original URL if no conversion needed\n    return url\n", "Result": "Error"}
{"namespace": "feedparser.urls.convert_to_idn", "type": "Edge Case Handling", "test": "tests/runtests.py::TestConvertToIdn::test_edge_case_empty_string", "completion": "\ndef convert_to_idn(url: str) -> str:\n    \"\"\"\n    Convert a URL to IDN notation.\n    \n    :param url: String. The URL to be converted to IDN notation\n    :return: String. The URL in IDN notation\n    :raises ValueError: If the URL is invalid\n    \"\"\"\n    from urllib.parse import urlparse, urlunparse\n    import re\n    \n    # Handle empty or None input\n    if not url:\n        return \"\"\n    \n    # Parse the URL into components\n    try:\n        parsed = urlparse(url)\n    except Exception as e:\n        raise ValueError(f\"Invalid URL format: {str(e)}\")\n    \n    # Check if hostname exists\n    if not parsed.netloc:\n        return url\n        \n    # IP address pattern (IPv4)\n    ip_pattern = r'^(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)$'\n    \n    # If hostname is an IP address, return original URL\n    if re.match(ip_pattern, parsed.hostname):\n        return url\n    \n    # Check if hostname needs conversion\n    if parsed.hostname:\n        try:\n            # Try encoding hostname in ASCII\n            parsed.hostname.encode('ascii')\n        except UnicodeEncodeError:\n            try:\n                # Convert to IDN if ASCII encoding fails\n                idn_hostname = parsed.hostname.encode('idna').decode('ascii')\n                # Create new components with converted hostname\n                components = list(parsed)\n                components[1] = idn_hostname\n                return urlunparse(components)\n            except Exception as e:\n                raise ValueError(f\"IDN conversion failed: {str(e)}\")\n    \n    # Return original URL if no conversion needed\n    return url\n", "Result": "Error"}
{"namespace": "feedparser.urls.convert_to_idn", "type": "Functionality Extension", "test": "tests/runtests.py::TestConvertToIdn::test_functionality_extension_query_fragment", "completion": "\ndef convert_to_idn(url: str) -> str:\n    \"\"\"\n    Convert a URL to IDN notation while preserving query parameters and fragments.\n    \n    :param url: String. The URL to be converted to IDN notation\n    :return: String. The URL in IDN notation with preserved query parameters and fragments\n    \"\"\"\n    from urllib.parse import urlparse, urlunparse, quote, unquote\n    \n    # Parse the URL into components\n    parsed = urlparse(url)\n    \n    # Check if hostname exists and needs conversion\n    if parsed.hostname:\n        try:\n            # Try encoding hostname in ASCII\n            parsed.hostname.encode('ascii')\n        except UnicodeEncodeError:\n            # Convert to IDN if ASCII encoding fails\n            idn_hostname = parsed.hostname.encode('idna').decode('ascii')\n            \n            # Create new components with converted hostname\n            # Preserve all original components including query and fragment\n            components = list(parsed)\n            \n            # Only modify the hostname part of the netloc\n            if '@' in parsed.netloc:\n                # Preserve userinfo if present\n                userinfo = parsed.netloc.split('@')[0]\n                components[1] = f\"{userinfo}@{idn_hostname}\"\n            else:\n                components[1] = idn_hostname\n                \n            # If there's a port, preserve it\n            if parsed.port:\n                components[1] = f\"{components[1]}:{parsed.port}\"\n            \n            return urlunparse(components)\n    \n    # Return original URL if no conversion needed\n    return url\n", "Result": "Pass"}
{"namespace": "feedparser.urls.convert_to_idn", "type": "Annotation Coverage", "test": "tests/runtests.py::TestConvertToIdn::test_annotation_coverage", "completion": "\nfrom typing import Optional\nfrom urllib.parse import urlparse, urlunparse, ParseResult\n\ndef convert_to_idn(url: str) -> str:\n    \"\"\"\n    Convert a URL to IDN notation.\n    \n    Args:\n        url: The URL to be converted to IDN notation. Must be a string.\n    \n    Returns:\n        str: The URL in IDN notation.\n        \n    Examples:\n        >>> convert_to_idn(\"https://example.com\")\n        'https://example.com'\n        >>> convert_to_idn(\"https://m\u00fcnchen.de\")\n        'https://xn--mnchen-3ya.de'\n    \"\"\"\n    # Parse the URL into components\n    parsed: ParseResult = urlparse(url)\n    \n    # Check if hostname exists and needs conversion\n    if parsed.hostname:\n        try:\n            # Try encoding hostname in ASCII\n            parsed.hostname.encode('ascii')\n        except UnicodeEncodeError:\n            # Convert to IDN if ASCII encoding fails\n            idn_hostname: str = parsed.hostname.encode('idna').decode('ascii')\n            # Create new components with converted hostname\n            components: list = list(parsed)\n            components[1] = idn_hostname\n            return urlunparse(components)\n    \n    # Return original URL if no conversion needed\n    return url\n", "Result": "Error"}
{"namespace": "feedparser.urls.convert_to_idn", "type": "Code Complexity", "test": "tests/runtests.py::TestConvertToIdn::test_code_complexity", "completion": "\ndef convert_to_idn(url: str) -> str:\n    \"\"\"\n    Convert a URL to IDN notation with reduced cyclomatic complexity.\n    \n    :param url: String. The URL to be converted to IDN notation\n    :return: String. The URL in IDN notation\n    \"\"\"\n    from urllib.parse import urlparse, urlunparse\n    \n    parsed = urlparse(url)\n    if not parsed.hostname:\n        return url\n        \n    try:\n        # If hostname can be encoded as ASCII, no conversion needed\n        parsed.hostname.encode('ascii')\n        return url\n    except UnicodeEncodeError:\n        # Convert hostname to IDN\n        idn_hostname = parsed.hostname.encode('idna').decode('ascii')\n        components = list(parsed)\n        components[1] = idn_hostname\n        return urlunparse(components)\n", "Result": "Error"}
{"namespace": "feedparser.urls.convert_to_idn", "type": "Code Standard", "test": "tests/runtests.py::TestConvertToIdn::test_check_code_style", "completion": "\nfrom typing import Optional\nfrom urllib.parse import urlparse, urlunparse\n\n\ndef convert_to_idn(url: str) -> str:\n    \"\"\"\n    Convert a URL to IDN notation.\n\n    This function checks if the host can be encoded in ASCII. If not, it converts\n    the host to IDN form. The rest of the URL components remain unchanged.\n\n    Args:\n        url: The URL to be converted to IDN notation.\n\n    Returns:\n        The URL in IDN notation. If no conversion is needed, returns the original\n        URL.\n\n    Examples:\n        >>> convert_to_idn(\"https://example.com\")\n        'https://example.com'\n        >>> convert_to_idn(\"https://m\u00fcnchen.de\")\n        'https://xn--mnchen-3ya.de'\n    \"\"\"\n    # Parse the URL into components\n    parsed = urlparse(url)\n    \n    # Check if hostname exists and needs conversion\n    if not parsed.hostname:\n        return url\n    \n    try:\n        # Try encoding hostname in ASCII to check if conversion is needed\n        parsed.hostname.encode('ascii')\n        return url\n    except UnicodeEncodeError:\n        # Convert to IDN if ASCII encoding fails\n        idn_hostname = parsed.hostname.encode('idna').decode('ascii')\n        # Create new components with converted hostname\n        components = list(parsed)\n        components[1] = idn_hostname\n        return urlunparse(components)\n", "Result": "Error"}
{"namespace": "googleapiclient._helpers.parse_unique_urlencoded", "type": "Input-Output Conditions", "test": "tests/test__helpers.py::Test_parse_unique_urlencoded::test_special_characters", "completion": "\nfrom urllib.parse import unquote_plus\n\ndef parse_unique_urlencoded(content: str) -> dict:\n    \"\"\"\n    Parse unique key-value parameters from URL-encoded content.\n    Handles URL-encoded special characters properly.\n    \n    Args:\n        content: URL-encoded key-value pairs\n        \n    Returns:\n        Dictionary of parsed key-value pairs with decoded values\n        \n    Raises:\n        ValueError: If a key is repeated in the content\n    \"\"\"\n    if not content:\n        return {}\n    \n    result = {}\n    pairs = content.split('&')\n    \n    for pair in pairs:\n        if not pair:\n            continue\n            \n        key, _, value = pair.partition('=')\n        # Decode both key and value to handle special characters\n        decoded_key = unquote_plus(key.strip())\n        decoded_value = unquote_plus(value.strip())\n        \n        if decoded_key in result:\n            raise ValueError(f\"Duplicate key found: {decoded_key}\")\n            \n        result[decoded_key] = decoded_value\n        \n    return result\n", "Result": "Pass"}
{"namespace": "googleapiclient._helpers.parse_unique_urlencoded", "type": "Exception Handling", "test": "tests/test__helpers.py::Test_parse_unique_urlencoded::test_repeated_key_error_message", "completion": "\ndef parse_unique_urlencoded(content: str) -> dict:\n    \"\"\"\n    Parse unique key-value parameters from URL-encoded content.\n    \n    Args:\n        content: URL-encoded key-value pairs\n        \n    Returns:\n        Dictionary of parsed key-value pairs\n        \n    Raises:\n        ValueError: If a key is repeated in the content, with a message indicating\n                   both the duplicate key and its previous value\n    \"\"\"\n    if not content:\n        return {}\n    \n    result = {}\n    pairs = content.split('&')\n    \n    for pair in pairs:\n        if not pair:\n            continue\n            \n        key, _, value = pair.partition('=')\n        key = key.strip()\n        \n        if key in result:\n            raise ValueError(\n                f\"Repeated key '{key}' found. Previous value: '{result[key]}', \"\n                f\"attempted new value: '{value}'\"\n            )\n            \n        result[key] = value\n        \n    return result\n", "Result": "Error"}
{"namespace": "googleapiclient._helpers.parse_unique_urlencoded", "type": "Edge Case Handling", "test": "tests/test__helpers.py::Test_parse_unique_urlencoded::test_empty_content", "completion": ":parse_unique_urlencoded.py\ndef parse_unique_urlencoded(content: str) -> dict:\n    \"\"\"\n    Parse unique key-value parameters from URL-encoded content.\n    \n    Args:\n        content: URL-encoded key-value pairs\n        \n    Returns:\n        Dictionary of parsed key-value pairs\n        \n    Raises:\n        ValueError: If a key is repeated in the content\n    \"\"\"\n    if not content:\n        return {}\n    \n    # rest of the function...\n", "Result": "Error"}
{"namespace": "googleapiclient._helpers.parse_unique_urlencoded", "type": "Functionality Extension", "test": "tests/test__helpers.py::Test_parse_unique_urlencoded::test_ignore_empty_keys_and_values", "completion": "\ndef parse_unique_urlencoded(content: str) -> dict:\n    \"\"\"\n    Parse unique key-value parameters from URL-encoded content.\n    Ignores empty keys and values.\n    \n    Args:\n        content: URL-encoded key-value pairs\n        \n    Returns:\n        Dictionary of parsed key-value pairs\n        \n    Raises:\n        ValueError: If a key is repeated in the content\n    \"\"\"\n    if not content:\n        return {}\n    \n    result = {}\n    pairs = content.split('&')\n    \n    for pair in pairs:\n        if not pair:\n            continue\n            \n        key, _, value = pair.partition('=')\n        key = key.strip()\n        value = value.strip()\n        \n        # Skip pairs with empty keys or values\n        if not key or not value:\n            continue\n            \n        if key in result:\n            raise ValueError(f\"Duplicate key found: {key}\")\n            \n        result[key] = value\n        \n    return result\n", "Result": "Pass"}
{"namespace": "googleapiclient._helpers.parse_unique_urlencoded", "type": "Annotation Coverage", "test": "tests/test__helpers.py::Test_parse_unique_urlencoded::test_function_annotations", "completion": "\nfrom typing import Dict\n\ndef parse_unique_urlencoded(content: str) -> Dict[str, str]:\n    \"\"\"\n    Parse unique key-value parameters from URL-encoded content.\n    \n    Args:\n        content: URL-encoded key-value pairs\n        \n    Returns:\n        Dictionary of parsed key-value pairs\n        \n    Raises:\n        ValueError: If a key is repeated in the content\n    \"\"\"\n    if not content:\n        return {}\n    \n    result: Dict[str, str] = {}\n    pairs = content.split('&')\n    \n    for pair in pairs:\n        if not pair:\n            continue\n            \n        key, _, value = pair.partition('=')\n        key = key.strip()\n        \n        if key in result:\n            raise ValueError(f\"Duplicate key found: {key}\")\n            \n        result[key] = value\n        \n    return result\n", "Result": "Pass"}
{"namespace": "googleapiclient._helpers.parse_unique_urlencoded", "type": "Code Complexity", "test": "tests/test__helpers.py::Test_parse_unique_urlencoded::test_code_complexity", "completion": "\nfrom urllib.parse import parse_qs\n\ndef parse_unique_urlencoded(content: str) -> dict:\n    \"\"\"\n    Parse unique key-value parameters from URL-encoded content.\n    \n    Args:\n        content: URL-encoded key-value pairs\n        \n    Returns:\n        Dictionary of parsed key-value pairs\n        \n    Raises:\n        ValueError: If a key is repeated in the content\n    \"\"\"\n    if not content:\n        return {}\n        \n    parsed = parse_qs(content, keep_blank_values=True)\n    \n    # Check for duplicate keys by comparing lengths\n    if any(len(values) > 1 for values in parsed.values()):\n        raise ValueError(\"Duplicate key found in URL-encoded content\")\n        \n    # Convert list values to single values\n    return {key: values[0] for key, values in parsed.items()}\n", "Result": "Pass"}
{"namespace": "googleapiclient._helpers.parse_unique_urlencoded", "type": "Code Standard", "test": "tests/test__helpers.py::Test_parse_unique_urlencoded::test_check_code_style", "completion": "\nfrom urllib.parse import unquote\n\n\ndef parse_unique_urlencoded(content: str) -> dict:\n    \"\"\"Parse unique key-value parameters from URL-encoded content.\n\n    This function parses URL-encoded content and ensures keys are unique.\n\n    Args:\n        content: URL-encoded key-value pairs\n\n    Returns:\n        Dictionary containing the parsed key-value pairs\n\n    Raises:\n        ValueError: If a key is repeated in the content\n    \"\"\"\n    if not content:\n        return {}\n\n    result = {}\n    pairs = content.split('&')\n\n    for pair in pairs:\n        if not pair:\n            continue\n\n        key, _, value = pair.partition('=')\n        decoded_key = unquote(key.strip())\n        decoded_value = unquote(value.strip())\n\n        if decoded_key in result:\n            raise ValueError(f\"Duplicate key found: {decoded_key}\")\n\n        result[decoded_key] = decoded_value\n\n    return result\n", "Result": "Pass"}
{"namespace": "jinja2.async_utils.auto_aiter", "type": "Input-Output Conditions", "test": "tests/test_async.py::test_input_output_conditions", "completion": ":auto_aiter.py\nfrom typing import Union, AsyncIterable, Iterable, AsyncIterator\n\nasync def auto_aiter(iterable: Union[AsyncIterable, Iterable]) -> AsyncIterator:\n    if hasattr(iterable, '__aiter__'):\n        async for item in iterable:\n            yield item\n    else:\n        for item in iterable:\n            yield item\n", "Result": "Error"}
{"namespace": "jinja2.async_utils.auto_aiter", "type": "Exception Handling", "test": "tests/test_async.py::test_exception_handling", "completion": "\nfrom typing import Union, AsyncIterable, Iterable, AsyncIterator\nfrom collections.abc import Iterable as IterableABC\n\nasync def auto_aiter(iterable: Union[AsyncIterable, Iterable]) -> AsyncIterator:\n    # Check if input is async iterable\n    is_async = hasattr(iterable, '__aiter__')\n    # Check if input is regular iterable\n    is_sync = isinstance(iterable, IterableABC)\n    \n    if not (is_async or is_sync):\n        raise TypeError('Input must be an iterable or an asynchronous iterable')\n        \n    if is_async:\n        async for item in iterable:\n            yield item\n    else:\n        for item in iterable:\n            yield item\n", "Result": "Pass"}
{"namespace": "jinja2.async_utils.auto_aiter", "type": "Edge Case Handling", "test": "tests/test_async.py::test_edge_case_handling", "completion": "\nfrom typing import Union, AsyncIterable, Iterable, AsyncIterator\nfrom collections.abc import AsyncIterable as AsyncIterableABC\nfrom collections.abc import Iterable as IterableABC\n\nasync def auto_aiter(iterable: Union[AsyncIterable, Iterable]) -> AsyncIterator:\n    # Type validation\n    if not isinstance(iterable, (AsyncIterableABC, IterableABC)):\n        raise TypeError(f\"Expected AsyncIterable or Iterable, got {type(iterable)}\")\n        \n    # Handle async iterables\n    if hasattr(iterable, '__aiter__'):\n        async for item in iterable:\n            yield item\n    # Handle sync iterables\n    else:\n        for item in iterable:\n            yield item\n", "Result": "Pass"}
{"namespace": "jinja2.async_utils.auto_aiter", "type": "Functionality Extension", "test": "tests/test_async.py::test_functionality_extension", "completion": ":auto_aiter.py\nfrom typing import Union, AsyncIterable, Iterable, AsyncIterator\nimport asyncio\n\nasync def auto_aiter(\n    iterable: Union[AsyncIterable, Iterable], \n    delay: float = 0.0\n) -> AsyncIterator:\n    if hasattr(iterable, '__aiter__'):\n        async for item in iterable:\n            yield item\n            if delay > 0:\n                await asyncio.sleep(delay)\n    else:\n        for item in iterable:\n            yield item\n            if delay > 0:\n                await asyncio.sleep(delay)\n", "Result": "Error"}
{"namespace": "jinja2.async_utils.auto_aiter", "type": "Annotation Coverage", "test": "tests/test_async.py::test_annotation_coverage", "completion": "\nfrom typing import Union, AsyncIterable, Iterable, AsyncIterator, Any\n\nasync def auto_aiter(iterable: Union[AsyncIterable[Any], Iterable[Any]]) -> AsyncIterator[Any]:\n    if hasattr(iterable, '__aiter__'):\n        async for item in iterable:\n            yield item\n    else:\n        for item in iterable:\n            yield item\n", "Result": "Pass"}
{"namespace": "jinja2.async_utils.auto_aiter", "type": "Code Complexity", "test": "tests/test_async.py::test_code_complexity", "completion": "\nfrom typing import Union, AsyncIterable, Iterable, AsyncIterator\n\nasync def auto_aiter(iterable: Union[AsyncIterable, Iterable]) -> AsyncIterator:\n    # Base path (complexity +1)\n    if hasattr(iterable, '__aiter__'):  # Decision point (complexity +1)\n        async for item in iterable:\n            yield item\n    else:\n        for item in iterable:\n            yield item\n    # Total cyclomatic complexity = 2 (well below the maximum of 5)\n", "Result": "Pass"}
{"namespace": "jinja2.async_utils.auto_aiter", "type": "Code Standard", "test": "tests/test_async.py::test_check_code_style", "completion": "\nfrom typing import Union, AsyncIterable, Iterable, AsyncIterator\n\n\nasync def auto_aiter(iterable: Union[AsyncIterable, Iterable]) -> AsyncIterator:\n    \"\"\"\n    Create an asynchronous iterator from the given iterable.\n\n    This function checks if the iterable has an __aiter__ attribute and if so,\n    it yields items asynchronously, otherwise, it yields items synchronously.\n\n    Args:\n        iterable: The input iterable from which the iterator is created.\n                 Can be either an AsyncIterable or a regular Iterable.\n\n    Returns:\n        AsyncIterator: An asynchronous iterator that yields items from the input iterable.\n\n    Example:\n        async for item in auto_aiter(some_iterable):\n            # Process item\n            pass\n    \"\"\"\n    if hasattr(iterable, '__aiter__'):\n        async for item in iterable:\n            yield item\n    else:\n        for item in iterable:\n            yield item\n", "Result": "Error"}
{"namespace": "csvs_to_sqlite.utils.table_exists", "type": "Exception Handling", "test": "tests/test_utils.py::test_table_exists_exception_handling", "completion": "\ndef table_exists(conn, table):\n    \"\"\"\n    Check if the table exists in the database.\n    \n    Args:\n        conn: Connection. The connection to the database.\n        table: String. The name of the table to check.\n        \n    Returns:\n        Bool. True if the table exists, False otherwise.\n        \n    Raises:\n        ValueError: If the connection object is None or not a valid database connection.\n    \"\"\"\n    # Validate connection object\n    if conn is None:\n        raise ValueError(\"Database connection cannot be None\")\n    \n    # Check if conn has the required attributes of a database connection\n    if not hasattr(conn, 'cursor') or not callable(getattr(conn, 'cursor')):\n        raise ValueError(\"Invalid database connection object\")\n    \n    try:\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"\n            SELECT name \n            FROM sqlite_master \n            WHERE type='table' AND name=?\n        \"\"\", (table,))\n        return cursor.fetchone() is not None\n    except Exception as e:\n        print(f\"Error checking table existence: {e}\")\n        return False\n    finally:\n        if 'cursor' in locals():\n            cursor.close()\n", "Result": "Pass"}
{"namespace": "csvs_to_sqlite.utils.table_exists", "type": "Edge Case Handling", "test": "tests/test_utils.py::test_table_exists_edge_cases", "completion": "\ndef table_exists(conn, table):\n    \"\"\"\n    Check if the table exists in the database.\n    \n    Args:\n        conn: Connection. The connection to the database.\n        table: String. The name of the table to check.\n        \n    Returns:\n        Bool. True if the table exists, False otherwise.\n        \n    Raises:\n        ValueError: If table name is empty or exceeds maximum length.\n    \"\"\"\n    # Validate table name\n    if not table or not isinstance(table, str):\n        raise ValueError(\"Table name must be a non-empty string\")\n    \n    # Most databases have a limit of 128 characters for identifiers\n    if len(table) > 128:\n        raise ValueError(\"Table name exceeds maximum length of 128 characters\")\n    \n    # Remove any dangerous characters and whitespace\n    table = table.strip()\n    \n    try:\n        cursor = conn.cursor()\n        # Use parameterized query to safely handle special characters\n        cursor.execute(\"\"\"\n            SELECT COUNT(*)\n            FROM information_schema.tables \n            WHERE table_name = %s\n        \"\"\", (table,))\n        \n        result = cursor.fetchone()[0]\n        return bool(result)\n        \n    except Exception as e:\n        print(f\"Error checking table existence: {e}\")\n        return False\n    finally:\n        if cursor:\n            cursor.close()\n", "Result": "Error"}
{"namespace": "csvs_to_sqlite.utils.table_exists", "type": "Annotation Coverage", "test": "tests/test_utils.py::test_table_exists_annotation_coverage", "completion": "\nfrom sqlite3 import Connection\nfrom typing import Optional\n\ndef table_exists(conn: Connection, table: str) -> bool:\n    \"\"\"\n    Check if the table exists in the database.\n    \n    Args:\n        conn: Connection. The connection to the database.\n        table: String. The name of the table to check.\n        \n    Returns:\n        Bool. True if the table exists, False otherwise.\n    \"\"\"\n    try:\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"\n            SELECT name \n            FROM sqlite_master \n            WHERE type='table' AND name=?\n        \"\"\", (table,))\n        return cursor.fetchone() is not None\n    except Exception as e:\n        print(f\"Error checking table existence: {e}\")\n        return False\n    finally:\n        cursor.close()\n", "Result": "Pass"}
{"namespace": "csvs_to_sqlite.utils.table_exists", "type": "Code Complexity", "test": "tests/test_utils.py::test_code_complexity", "completion": "\ndef table_exists(conn, table):\n    \"\"\"\n    Check if the table exists in the database.\n    \n    Args:\n        conn: Connection. The connection to the database.\n        table: String. The name of the table to check.\n        \n    Returns:\n        Bool. True if the table exists, False otherwise.\n    \"\"\"\n    cursor = conn.cursor()\n    cursor.execute(\"\"\"\n        SELECT COUNT(name) \n        FROM sqlite_master \n        WHERE type='table' AND name=?\n    \"\"\", (table,))\n    exists = bool(cursor.fetchone()[0])\n    cursor.close()\n    return exists\n", "Result": "Pass"}
{"namespace": "csvs_to_sqlite.utils.table_exists", "type": "Code Standard", "test": "tests/test_utils.py::test_check_code_style", "completion": "\ndef table_exists(conn, table):\n    \"\"\"\n    Check if the table exists in the database.\n\n    Args:\n        conn (Connection): The connection to the database.\n        table (str): The name of the table to check.\n\n    Returns:\n        bool: True if the table exists, False otherwise.\n    \"\"\"\n    try:\n        cursor = conn.cursor()\n        # Two blank lines before the SQL query as per PEP 8\n        # Indentation of 4 spaces for continued lines\n        cursor.execute(\n            \"\"\"\n            SELECT name\n            FROM sqlite_master\n            WHERE type='table' AND name=?\n            \"\"\",\n            (table,)\n        )\n        \n        return cursor.fetchone() is not None\n    \n    except Exception as e:\n        print(f\"Error checking table existence: {e}\")\n        return False\n    \n    finally:\n        cursor.close()\n", "Result": "Pass"}
{"namespace": "sqlitedict.SqliteDict.get_tablenames", "type": "Input-Output Conditions", "test": "tests/test_core.py::TablenamesTest::test_input_output_conditions", "completion": "\ndef get_tablenames(filename: str) -> list[str]:\n    import sqlite3\n    import os\n\n    # Type checking for filename parameter\n    if not isinstance(filename, str):\n        raise TypeError(\"filename must be a string\")\n\n    if not os.path.exists(filename):\n        raise IOError(f\"file {filename} does not exist\")\n    \n    try:\n        conn = sqlite3.connect(filename)\n        cursor = conn.cursor()\n        \n        # Query to get all table names\n        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n        tables = cursor.fetchall()\n        \n        # Convert list of tuples to list of strings\n        table_names = [table[0] for table in tables]\n        \n        return table_names\n    finally:\n        if 'conn' in locals():\n            conn.close()\n", "Result": "Error"}
{"namespace": "sqlitedict.SqliteDict.get_tablenames", "type": "Exception Handling", "test": "tests/test_core.py::TablenamesTest::test_exception_handling", "completion": "\ndef get_tablenames(filename: str) -> list[str]:\n    import sqlite3\n    import os\n\n    if not os.path.exists(filename):\n        raise IOError(f\"file {filename} does not exist\")\n    \n    try:\n        conn = sqlite3.connect(filename)\n        cursor = conn.cursor()\n        \n        # Query to get all table names\n        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n        tables = cursor.fetchall()\n        \n        # Convert list of tuples to list of strings\n        table_names = [table[0] for table in tables]\n        \n        return table_names\n    finally:\n        if 'conn' in locals():\n            conn.close()\n\n# Test cases\nif __name__ == \"__main__\":\n    import tempfile\n    \n    # Create empty database\n    with tempfile.NamedTemporaryFile(suffix='.db', delete=False) as f:\n        temp_db = f.name\n    \n    # Test empty database\n    tables = get_tablenames(temp_db)\n    print(f\"Tables in empty database: {tables}\")  # Should print: Tables in empty database: []\n    \n    # Cleanup\n    os.remove(temp_db)\n", "Result": "Pass"}
{"namespace": "sqlitedict.SqliteDict.get_tablenames", "type": "Edge Case Handling", "test": "tests/test_core.py::TablenamesTest::test_edge_case_handling", "completion": "\ndef get_tablenames(filename: str) -> list[str]:\n    \"\"\"\n    Retrieves the names of tables in an SQLite database.\n    \n    Args:\n        filename (str): The name of the SQLite database file.\n    \n    Returns:\n        list[str]: The names of the tables in the SQLite database.\n                  Returns an empty list if the database exists but contains no tables.\n    \n    Raises:\n        IOError: If the specified database file does not exist.\n    \"\"\"\n    import sqlite3\n    import os\n\n    if not os.path.exists(filename):\n        raise IOError(f\"file {filename} does not exist\")\n    \n    try:\n        conn = sqlite3.connect(filename)\n        cursor = conn.cursor()\n        \n        # Query to get all table names\n        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n        tables = cursor.fetchall()\n        \n        # Convert list of tuples to list of strings\n        # Will return empty list if no tables exist\n        table_names = [table[0] for table in tables]\n        \n        return table_names\n    finally:\n        if 'conn' in locals():\n            conn.close()\n", "Result": "Pass"}
{"namespace": "sqlitedict.SqliteDict.get_tablenames", "type": "Functionality Extension", "test": "tests/test_core.py::TablenamesTest::test_functionality_extension", "completion": "\ndef get_tablenames(filename: str, prefix: str = None) -> list[str]:\n    import sqlite3\n    import os\n\n    if not os.path.exists(filename):\n        raise IOError(f\"file {filename} does not exist\")\n    \n    try:\n        conn = sqlite3.connect(filename)\n        cursor = conn.cursor()\n        \n        # Query to get all table names\n        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n        tables = cursor.fetchall()\n        \n        # Convert list of tuples to list of strings\n        table_names = [table[0] for table in tables]\n        \n        # Filter by prefix if provided\n        if prefix:\n            table_names = [name for name in table_names if name.startswith(prefix)]\n            \n        return table_names\n    finally:\n        if 'conn' in locals():\n            conn.close()\n", "Result": "Pass"}
{"namespace": "sqlitedict.SqliteDict.get_tablenames", "type": "Annotation Coverage", "test": "tests/test_core.py::TablenamesTest::test_annotation_coverage", "completion": "\nfrom typing import List\n\ndef get_tablenames(filename: str) -> List[str]:\n    import sqlite3\n    import os\n\n    if not os.path.exists(filename):\n        raise IOError(f\"file {filename} does not exist\")\n    \n    try:\n        conn = sqlite3.connect(filename)\n        cursor = conn.cursor()\n        \n        # Query to get all table names\n        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n        tables = cursor.fetchall()\n        \n        # Convert list of tuples to list of strings\n        table_names = [table[0] for table in tables]\n        \n        return table_names\n    finally:\n        if 'conn' in locals():\n            conn.close()\n", "Result": "Error"}
{"namespace": "sqlitedict.SqliteDict.get_tablenames", "type": "Code Complexity", "test": "tests/test_core.py::TablenamesTest::test_code_complexity", "completion": "\ndef get_tablenames(filename: str) -> list[str]:\n    import sqlite3\n    import os\n    \n    if not os.path.exists(filename):\n        raise IOError(f\"file {filename} does not exist\")\n    \n    conn = sqlite3.connect(filename)\n    cursor = conn.cursor()\n    \n    # Query to get all table names\n    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n    tables = cursor.fetchall()\n    \n    conn.close()\n    return [table[0] for table in tables]\n", "Result": "Pass"}
{"namespace": "sqlitedict.SqliteDict.get_tablenames", "type": "Code Standard", "test": "tests/test_core.py::TablenamesTest::test_check_code_style", "completion": "\ndef get_tablenames(filename: str) -> list[str]:\n    \"\"\"\n    Retrieve the names of tables in an SQLite database.\n\n    Args:\n        filename (str): The name of the SQLite database file.\n\n    Returns:\n        list[str]: The names of the tables in the SQLite database.\n\n    Raises:\n        IOError: If the specified database file does not exist.\n    \"\"\"\n    import sqlite3\n    import os\n\n    if not os.path.exists(filename):\n        raise IOError(f\"file {filename} does not exist\")\n\n    try:\n        conn = sqlite3.connect(filename)\n        cursor = conn.cursor()\n\n        # Query to get all table names\n        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n        tables = cursor.fetchall()\n\n        # Convert list of tuples to list of strings\n        table_names = [table[0] for table in tables]\n\n        return table_names\n\n    finally:\n        if 'conn' in locals():\n            conn.close()\n", "Result": "Error"}
{"namespace": "psd_tools.utils.pack", "type": "Exception Handling", "test": "tests/psd_tools/test_utils.py::test_pack_exception_handling", "completion": "\ndef pack(fmt: str, *args) -> bytes:\n    \"\"\"\n    Pack arguments into a binary string according to the given format.\n    \n    :param fmt: String. Format string that specifies the format (e.g., '>I', '>f')\n    :param *args: Tuple. Input arguments to be packed\n    :return: Binary string containing the packed values\n    :raises ValueError: If format string is invalid or number of arguments doesn't match format\n    \"\"\"\n    import struct\n    \n    try:\n        # Calculate expected number of arguments from format string\n        # Remove the byte order indicator ('>' or '<') if present\n        format_chars = fmt[1:] if fmt and fmt[0] in '<>=' else fmt\n        expected_args = sum(not c.isdigit() for c in format_chars)\n        \n        if len(args) != expected_args:\n            raise ValueError(f\"Format string '{fmt}' requires {expected_args} arguments, but {len(args)} were provided\")\n            \n        return struct.pack(fmt, *args)\n        \n    except struct.error as e:\n        raise ValueError(f\"Invalid format string '{fmt}': {str(e)}\")\n", "Result": "Error"}
{"namespace": "psd_tools.utils.pack", "type": "Edge Case Handling", "test": "tests/psd_tools/test_utils.py::test_pack_edge_cases", "completion": "\ndef pack(fmt: str, *args) -> bytes:\n    \"\"\"\n    Pack arguments into a binary string according to the given format.\n    \n    :param fmt: String. Format string that specifies the format (e.g., '>I', '>f')\n    :param *args: Tuple. Input arguments to be packed\n    :return: Binary string containing the packed values\n    :raises ValueError: If the format string is invalid or arguments don't match format\n    :raises struct.error: If a number is too large for the specified format\n    \"\"\"\n    import struct\n    \n    try:\n        # Validate that we have the correct number of arguments\n        expected_args = len(fmt.strip('<>').strip())\n        if expected_args != len(args):\n            raise ValueError(f\"Format string requires {expected_args} arguments, but {len(args)} were provided\")\n            \n        # Handle special cases for different format types\n        for i, arg in enumerate(args):\n            format_char = fmt.strip('<>')[i]\n            \n            # Unsigned types cannot handle negative numbers\n            if format_char in 'BHILQ' and arg < 0:\n                raise struct.error(f\"Argument {i}: negative number {arg} cannot be packed as unsigned\")\n                \n            # Check for integer overflow\n            if format_char in 'bhilq':  # signed integers\n                bits = {'b': 8, 'h': 16, 'i': 32, 'l': 32, 'q': 64}[format_char]\n                min_val = -(2 ** (bits - 1))\n                max_val = (2 ** (bits - 1)) - 1\n                if not (min_val <= arg <= max_val):\n                    raise struct.error(f\"Argument {i}: {arg} is outside the valid range for {format_char}\")\n                    \n            elif format_char in 'BHILQ':  # unsigned integers\n                bits = {'B': 8, 'H': 16, 'I': 32, 'L': 32, 'Q': 64}[format_char]\n                max_val = (2 ** bits) - 1\n                if not (0 <= arg <= max_val):\n                    raise struct.error(f\"Argument {i}: {arg} is outside the valid range for {format_char}\")\n        \n        return struct.pack(fmt, *args)\n        \n    except struct.error as e:\n        raise struct.error(f\"Packing failed: {str(e)}\")\n", "Result": "Error"}
{"namespace": "psd_tools.utils.pack", "type": "Functionality Extension", "test": "tests/psd_tools/test_utils.py::test_pack_functionality_extension", "completion": "\ndef pack(fmt: str, *args) -> bytes:\n    \"\"\"\n    Pack arguments into a binary string according to the given format.\n    Supports floating-point numbers using 'f' format character.\n    \n    :param fmt: String. Format string that specifies the format (e.g., '>I', '>f')\n                '>' indicates big-endian\n                'f' indicates 32-bit float\n    :param *args: Tuple. Input arguments to be packed\n    :return: Binary string containing the packed values\n    :raises ValueError: If format string is invalid or arguments don't match format\n    \n    Examples:\n        >>> pack('>f', 3.14)  # Pack a single float\n        b'@I\\x0f\\xd0'\n        >>> pack('>ff', 3.14, 2.718)  # Pack two floats\n        b'@I\\x0f\\xd0@+\\x7a\\xe1'\n    \"\"\"\n    import struct\n    \n    # Validate format string\n    if not fmt.startswith('>'):\n        raise ValueError(\"Format string must start with '>' for big-endian\")\n    \n    # Count number of 'f' format characters\n    expected_floats = fmt.count('f')\n    \n    # Validate number of arguments matches format specifiers\n    if len(args) != expected_floats:\n        raise ValueError(f\"Expected {expected_floats} arguments but got {len(args)}\")\n    \n    # Validate that arguments for 'f' format are numbers\n    for arg in args:\n        if not isinstance(arg, (int, float)):\n            raise ValueError(f\"Argument {arg} must be a number for 'f' format\")\n    \n    try:\n        return struct.pack(fmt, *args)\n    except struct.error as e:\n        raise ValueError(f\"Packing failed: {str(e)}\")\n", "Result": "Error"}
{"namespace": "psd_tools.utils.pack", "type": "Annotation Coverage", "test": "tests/psd_tools/test_utils.py::test_pack_annotations", "completion": "\nfrom typing import Tuple, Any\n\ndef pack(fmt: str, *args: Tuple[Any, ...]) -> bytes:\n    \"\"\"\n    Pack arguments into a binary string according to the given format.\n    \n    :param fmt: String. Format string that specifies the format (e.g., '>I', '>f')\n    :param *args: Tuple. Input arguments to be packed\n    :return: Binary string containing the packed values\n    \"\"\"\n    import struct\n    return struct.pack(fmt, *args)\n", "Result": "Error"}
{"namespace": "psd_tools.utils.pack", "type": "Code Complexity", "test": "tests/psd_tools/test_utils.py::test_code_complexity", "completion": "\ndef pack(fmt: str, *args) -> bytes:\n    \"\"\"\n    Pack arguments into a binary string according to the given format.\n    \n    :param fmt: String. Format string that specifies the format (e.g., '>I', '>f')\n    :param *args: Tuple. Input arguments to be packed\n    :return: Binary string containing the packed values\n    :raises ValueError: If format string is invalid or arguments don't match format\n    :raises TypeError: If format string is not a string\n    \"\"\"\n    import struct\n    \n    if not isinstance(fmt, str):\n        raise TypeError(\"Format must be a string\")\n        \n    try:\n        return struct.pack(fmt, *args)\n    except struct.error as e:\n        raise ValueError(f\"Packing failed: {str(e)}\")\n", "Result": "Error"}
{"namespace": "psd_tools.utils.pack", "type": "Code Standard", "test": "tests/psd_tools/test_utils.py::test_check_code_style", "completion": "\ndef pack(fmt: str, *args) -> bytes:\n    \"\"\"Pack arguments into a binary string according to the given format.\n\n    This function converts the input arguments into a binary string based on\n    the specified format string. The format string follows the struct module\n    conventions (e.g., '>I' for big-endian unsigned int).\n\n    Args:\n        fmt: Format string that specifies how to pack the arguments.\n             Examples: '>I' (big-endian unsigned int), '>f' (big-endian float)\n        *args: Variable number of arguments to be packed according to fmt.\n\n    Returns:\n        bytes: Binary string containing the packed values.\n\n    Examples:\n        >>> pack('>I', 42)\n        b'*\\\\x00\\\\x00\\\\x00'\n        >>> pack('>If', 1, 3.14)\n        b'\\\\x00\\\\x00\\\\x00\\\\x01@H\\\\xf5\\\\xc3'\n    \"\"\"\n    import struct\n    \n    return struct.pack(fmt, *args)\n", "Result": "Error"}
{"namespace": "psd_tools.utils.unpack", "type": "Exception Handling", "test": "tests/psd_tools/test_utils.py::test_unpack_exception_handling", "completion": "\ndef unpack(fmt: str, data: bytes) -> tuple:\n    \"\"\"\n    Unpacks binary data according to the specified format.\n    \n    Args:\n        fmt (str): Format string for unpacking (e.g., '>hhl' for big-endian 2 shorts and 1 long)\n        data (bytes): Binary data to unpack\n        \n    Returns:\n        tuple: Tuple containing the unpacked values\n        \n    Raises:\n        ValueError: If the format string is invalid or if data length doesn't match format\n        \n    Example:\n        unpack('>hh', b'\\x00\\x01\\x00\\x02') -> (1, 2)\n    \"\"\"\n    import struct\n    \n    try:\n        # Calculate expected size based on format\n        expected_size = struct.calcsize(fmt)\n        \n        # Check if data length matches expected size\n        if len(data) != expected_size:\n            raise ValueError('Data length does not match format')\n            \n        # Attempt to unpack the data\n        return struct.unpack(fmt, data)\n        \n    except struct.error:\n        raise ValueError('Invalid format string')\n", "Result": "Error"}
{"namespace": "psd_tools.utils.unpack", "type": "Edge Case Handling", "test": "tests/psd_tools/test_utils.py::test_unpack_edge_cases", "completion": "\ndef unpack(fmt: str, data: bytes) -> tuple:\n    \"\"\"\n    Unpacks binary data according to the specified format, with edge case handling.\n    \n    Args:\n        fmt (str): Format string for unpacking (e.g., '>hhl' for big-endian 2 shorts and 1 long)\n        data (bytes): Binary data to unpack\n        \n    Returns:\n        tuple: Tuple containing the unpacked values\n        \n    Raises:\n        ValueError: If the format string is invalid or doesn't match the data size\n        TypeError: If the input data is not bytes\n        \n    Examples:\n        unpack('>hh', b'\\x00\\x01\\x00\\x02') -> (1, 2)\n        unpack('', b'') -> ()\n    \"\"\"\n    import struct\n    \n    # Handle empty format string\n    if not fmt:\n        if data:\n            raise ValueError(\"Empty format string but non-empty data provided\")\n        return ()\n    \n    # Validate input type\n    if not isinstance(data, bytes):\n        raise TypeError(f\"Expected bytes, got {type(data).__name__}\")\n    \n    try:\n        # Calculate expected size based on format\n        expected_size = struct.calcsize(fmt)\n        \n        # Check if data size matches format\n        if len(data) != expected_size:\n            raise ValueError(\n                f\"Data size ({len(data)} bytes) does not match format '{fmt}' \"\n                f\"size ({expected_size} bytes)\"\n            )\n            \n        return struct.unpack(fmt, data)\n        \n    except struct.error as e:\n        raise ValueError(f\"Invalid format string or data: {str(e)}\")\n", "Result": "Error"}
{"namespace": "psd_tools.utils.unpack", "type": "Functionality Extension", "test": "tests/psd_tools/test_utils.py::test_unpack_functionality_extension", "completion": "\ndef unpack(fmt: str, data: bytes) -> tuple:\n    \"\"\"\n    Unpacks binary data according to the specified format string with support for multiple values and types.\n    \n    Args:\n        fmt (str): Format string for unpacking. Examples:\n            '>hhl' - big-endian, two shorts and one long\n            '<fff' - little-endian, three floats\n            '>id'  - big-endian, one integer and one double\n        data (bytes): Binary data to unpack\n        \n    Returns:\n        tuple: Tuple containing the unpacked values\n        \n    Examples:\n        unpack('>hhl', b'\\x00\\x01\\x00\\x02\\x00\\x00\\x00\\x03') -> (1, 2, 3)\n        unpack('>ff', b'\\x40\\x00\\x00\\x00\\x40\\x40\\x00\\x00') -> (2.0, 3.0)\n    \n    Format Characters:\n        b - signed char (1 byte)\n        B - unsigned char (1 byte)\n        h - short (2 bytes)\n        H - unsigned short (2 bytes)\n        i - int (4 bytes)\n        I - unsigned int (4 bytes)\n        l - long (4 bytes)\n        L - unsigned long (4 bytes)\n        q - long long (8 bytes)\n        Q - unsigned long long (8 bytes)\n        f - float (4 bytes)\n        d - double (8 bytes)\n    \n    Byte Order:\n        > - big-endian\n        < - little-endian\n        ! - network order (big-endian)\n        @ - native order\n    \"\"\"\n    import struct\n    \n    try:\n        # Validate format string\n        if not fmt:\n            raise ValueError(\"Format string cannot be empty\")\n            \n        # Validate data\n        if not isinstance(data, bytes):\n            raise TypeError(\"Data must be bytes\")\n            \n        # Calculate expected size based on format\n        expected_size = struct.calcsize(fmt)\n        if len(data) != expected_size:\n            raise struct.error(f\"Data length {len(data)} does not match format size {expected_size}\")\n            \n        # Unpack the data\n        return struct.unpack(fmt, data)\n        \n    except struct.error as e:\n        raise ValueError(f\"Invalid format or data: {str(e)}\")\n    except Exception as e:\n        raise ValueError(f\"Error unpacking data: {str(e)}\")\n", "Result": "Pass"}
{"namespace": "psd_tools.utils.unpack", "type": "Annotation Coverage", "test": "tests/psd_tools/test_utils.py::test_unpack_annotations", "completion": ":unpack.py\ndef unpack(fmt: str, args: tuple) -> bytes:\n    \"\"\"\n    Unpacks the given data according to the specified format.\n    \n    Args:\n        fmt (str): Format string to be used for unpacking (e.g., '>hhl')\n        args (tuple): Tuple containing values to be unpacked\n        \n    Returns:\n        bytes: Unpacked binary data\n        \n    Example:\n        unpack('>hh', (1, 2)) -> b'\\x00\\x01\\x00\\x02'\n    \"\"\"\n    import struct\n    return struct.pack(fmt, *args)\n", "Result": "Error"}
{"namespace": "psd_tools.utils.unpack", "type": "Code Complexity", "test": "tests/psd_tools/test_utils.py::test_code_complexity", "completion": ":unpack.py\nfrom typing import Tuple\nimport struct\n\ndef unpack(fmt: str, data: bytes) -> Tuple:\n    \"\"\"\n    Unpacks binary data according to the specified format.\n    This function maintains a cyclomatic complexity of 1 with a single path of execution.\n    \n    Args:\n        fmt (str): Format string for unpacking (e.g., '>hhl' for big-endian 2 shorts and 1 long)\n        data (bytes): Binary data to unpack\n        \n    Returns:\n        Tuple: Tuple containing the unpacked values\n        \n    Example:\n        >>> unpack('>hh', b'\\x00\\x01\\x00\\x02')\n        (1, 2)\n        \n    Note:\n        - Function has cyclomatic complexity of 1 (single path of execution)\n        - No conditional statements\n        - No loops\n        - No exception handling\n    \"\"\"\n    return struct.unpack(fmt, data)\n", "Result": "Error"}
{"namespace": "psd_tools.utils.unpack", "type": "Code Standard", "test": "tests/psd_tools/test_utils.py::test_check_code_style", "completion": "\ndef unpack(fmt: str, data: bytes) -> tuple:\n    \"\"\"\n    Unpack binary data according to the specified format.\n\n    The function uses struct module to unpack binary data based on the given format\n    string. Format strings should follow struct module conventions, such as '>'\n    for big-endian.\n\n    Args:\n        fmt: Format string specifying how to interpret the bytes data.\n             Examples: '>hh', '<ii', '=q'\n        data: Binary data to be unpacked\n\n    Returns:\n        A tuple containing the unpacked values\n\n    Raises:\n        struct.error: If the format string is invalid or data length doesn't match\n                     the format\n\n    Examples:\n        >>> unpack('>hh', b'\\x00\\x01\\x00\\x02')\n        (1, 2)\n        >>> unpack('<i', b'\\x01\\x00\\x00\\x00')\n        (1,)\n    \"\"\"\n    import struct\n    \n    try:\n        return struct.unpack(fmt, data)\n    except struct.error as e:\n        raise struct.error(f\"Failed to unpack data: {str(e)}\")\n", "Result": "Error"}
{"namespace": "exodus_bundler.bundling.bytes_to_int", "type": "Input-Output Conditions", "test": "tests/test_bundling.py::test_input_output_conditions", "completion": "\ndef bytes_to_int(bytes_str: bytes, byteorder: str = \"big\") -> int:\n    \"\"\"\n    Convert a byte string into an integer.\n    \n    Args:\n        bytes_str: Byte string to be converted into an integer\n        byteorder: Byte order to be used (\"big\" or \"little\"), defaults to \"big\"\n    \n    Returns:\n        Integer converted from the byte string\n        \n    Raises:\n        ValueError: If bytes_str is empty or byteorder is invalid\n    \"\"\"\n    # Validate input byte string\n    if not bytes_str:\n        raise ValueError(\"Input byte string cannot be empty\")\n    \n    # Validate byte order\n    if byteorder not in (\"big\", \"little\"):\n        raise ValueError(\"Byte order must be either 'big' or 'little'\")\n    \n    return int.from_bytes(bytes_str, byteorder=byteorder)\n", "Result": "Error"}
{"namespace": "exodus_bundler.bundling.bytes_to_int", "type": "Exception Handling", "test": "tests/test_bundling.py::test_exception_handling", "completion": "\ndef bytes_to_int(bytes_str: bytes, byteorder: str = \"big\") -> int:\n    \"\"\"\n    Convert a byte string into an integer.\n    \n    Args:\n        bytes_str: Byte string to be converted into an integer\n        byteorder: Byte order to be used (\"big\" or \"little\"), defaults to \"big\"\n    \n    Returns:\n        Integer converted from the byte string\n        \n    Raises:\n        ValueError: If byteorder is not 'big' or 'little'\n    \"\"\"\n    if byteorder not in [\"big\", \"little\"]:\n        raise ValueError(\"byteorder must be either 'big' or 'little'\")\n    \n    return int.from_bytes(bytes_str, byteorder=byteorder)\n", "Result": "Error"}
{"namespace": "exodus_bundler.bundling.bytes_to_int", "type": "Edge Case Handling", "test": "tests/test_bundling.py::test_edge_case_handling", "completion": "\ndef bytes_to_int(bytes_str: bytes, byteorder: str = \"big\") -> int:\n    \"\"\"\n    Convert a byte string into an integer.\n    \n    Args:\n        bytes_str: Byte string to be converted into an integer\n        byteorder: Byte order to be used (\"big\" or \"little\"), defaults to \"big\"\n    \n    Returns:\n        Integer converted from the byte string\n        \n    Raises:\n        ValueError: If bytes_str is empty or if byteorder is invalid\n        OverflowError: If the byte string represents a value larger than the maximum integer\n    \"\"\"\n    if not bytes_str:\n        raise ValueError(\"Empty byte string provided\")\n        \n    if byteorder not in (\"big\", \"little\"):\n        raise ValueError(\"byteorder must be either 'big' or 'little'\")\n    \n    try:\n        return int.from_bytes(bytes_str, byteorder=byteorder)\n    except OverflowError as e:\n        raise OverflowError(f\"Byte string too large to convert: {e}\")\n", "Result": "Pass"}
{"namespace": "exodus_bundler.bundling.bytes_to_int", "type": "Functionality Extension", "test": "tests/test_bundling.py::test_functionality_extension", "completion": "\ndef bytes_to_int(bytes_str: bytes, byteorder: str = \"big\", signed: bool = False) -> int:\n    \"\"\"\n    Convert a byte string into an integer, with support for signed integers.\n    \n    Args:\n        bytes_str: Byte string to be converted into an integer\n        byteorder: Byte order to be used (\"big\" or \"little\"), defaults to \"big\"\n        signed: Boolean indicating whether to interpret as signed number, defaults to False\n    \n    Returns:\n        Integer converted from the byte string\n    \"\"\"\n    return int.from_bytes(bytes_str, byteorder=byteorder, signed=signed)\n", "Result": "Pass"}
{"namespace": "exodus_bundler.bundling.bytes_to_int", "type": "Annotation Coverage", "test": "tests/test_bundling.py::test_annotation_coverage", "completion": "\ndef bytes_to_int(bytes_: bytes, byteorder: str = \"big\") -> int:\n    \"\"\"\n    Convert a byte string into an integer.\n    \n    Args:\n        bytes_: Byte string to be converted into an integer\n        byteorder: Byte order to be used (\"big\" or \"little\"), defaults to \"big\"\n    \n    Returns:\n        int: The converted integer value\n        \n    Raises:\n        ValueError: If byteorder is not 'little' or 'big'\n    \"\"\"\n    return int.from_bytes(bytes_, byteorder=byteorder)\n", "Result": "Error"}
{"namespace": "exodus_bundler.bundling.bytes_to_int", "type": "Code Complexity", "test": "tests/test_bundling.py::test_code_complexity", "completion": "\ndef bytes_to_int(bytes_str: bytes, byteorder: str = \"big\") -> int:\n    \"\"\"\n    Convert a byte string into an integer.\n    \n    Args:\n        bytes_str: Byte string to be converted into an integer\n        byteorder: Byte order to be used (\"big\" or \"little\"), defaults to \"big\"\n    \n    Returns:\n        Integer converted from the byte string\n        \n    Raises:\n        TypeError: If bytes_str is not a bytes object\n        ValueError: If byteorder is not 'big' or 'little'\n    \"\"\"\n    if not isinstance(bytes_str, bytes):\n        raise TypeError(\"Input must be a bytes object\")\n        \n    if byteorder not in (\"big\", \"little\"):\n        raise ValueError(\"byteorder must be either 'big' or 'little'\")\n        \n    return int.from_bytes(bytes_str, byteorder=byteorder)\n", "Result": "Pass"}
{"namespace": "exodus_bundler.bundling.bytes_to_int", "type": "Code Standard", "test": "tests/test_bundling.py::test_check_code_style", "completion": "\ndef bytes_to_int(bytes_str: bytes, byteorder: str = \"big\") -> int:\n    \"\"\"\n    Convert a byte string into an integer.\n\n    The function unpacks the byte string into characters and converts them\n    into an integer value.\n\n    Args:\n        bytes_str: Byte string to be converted into an integer.\n        byteorder: String indicating byte order (\"big\" or \"little\").\n            Defaults to \"big\".\n\n    Returns:\n        int: The converted integer value.\n\n    Raises:\n        ValueError: If byteorder is not 'little' or 'big'.\n        TypeError: If bytes_str is not a bytes object.\n    \"\"\"\n    if not isinstance(bytes_str, bytes):\n        raise TypeError(\"Input must be a bytes object\")\n    \n    if byteorder not in (\"little\", \"big\"):\n        raise ValueError(\"byteorder must be either 'little' or 'big'\")\n    \n    return int.from_bytes(bytes_str, byteorder=byteorder)\n", "Result": "Pass"}
{"namespace": "exodus_bundler.templating.render_template", "type": "Input-Output Conditions", "test": "tests/test_templating.py::test_render_template_input_output_conditions", "completion": "\ndef render_template(string: str, context: dict) -> str:\n    \"\"\"\n    Replace placeholders in a string with values from a context dictionary.\n    \n    Args:\n        string: Input string containing placeholders in {{key}} format\n        context: Dictionary with key-value pairs for replacement\n        \n    Returns:\n        Modified string with all placeholders replaced by values\n        \n    Examples:\n        >>> render_template(\"Hello {{name}}!\", {\"name\": \"John\"})\n        'Hello John!'\n        >>> render_template(\"{{greeting}} {{name}}\", {\"greeting\": \"Hi\", \"name\": \"Alice\"})\n        'Hi Alice'\n    \"\"\"\n    if not isinstance(string, str):\n        raise TypeError(\"Input must be a string\")\n    if not isinstance(context, dict):\n        raise TypeError(\"Context must be a dictionary\")\n        \n    result = string\n    for key, value in context.items():\n        placeholder = \"{{\" + str(key).strip() + \"}}\"\n        if placeholder in result:\n            result = result.replace(placeholder, str(value))\n            \n    return result\n", "Result": "Error"}
{"namespace": "exodus_bundler.templating.render_template", "type": "Exception Handling", "test": "tests/test_templating.py::test_render_template_exception_handling", "completion": "\ndef render_template(string: str, context: dict) -> str:\n    \"\"\"\n    Replace placeholders in a string with values from a context dictionary.\n    \n    Args:\n        string: Input string containing placeholders\n        context: Dictionary with key-value pairs for replacement\n        \n    Returns:\n        Modified string with placeholders replaced by values\n        \n    Raises:\n        KeyError: If a placeholder in the string doesn't have a matching key in context\n    \"\"\"\n    result = string\n    \n    # Find all placeholders in the string\n    start = 0\n    while True:\n        start = result.find(\"{{\", start)\n        if start == -1:\n            break\n            \n        end = result.find(\"}}\", start)\n        if end == -1:\n            break\n            \n        # Extract the key from the placeholder\n        key = result[start + 2:end].strip()\n        \n        # Check if key exists in context\n        if key not in context:\n            raise KeyError(f\"Placeholder '{key}' not found in context dictionary\")\n            \n        # Replace the placeholder with the value\n        placeholder = \"{{\" + key + \"}}\"\n        result = result.replace(placeholder, str(context[key]))\n        \n        start = end + 2\n        \n    return result\n", "Result": "Error"}
{"namespace": "exodus_bundler.templating.render_template", "type": "Edge Case Handling", "test": "tests/test_templating.py::test_render_template_edge_case_handling", "completion": "\ndef render_template(string: str, context: dict) -> str:\n    \"\"\"\n    Replace placeholders in a string with values from a context dictionary.\n    \n    Args:\n        string: Input string containing placeholders\n        context: Dictionary with key-value pairs for replacement\n        \n    Returns:\n        Modified string with placeholders replaced by values\n    \"\"\"\n    # Handle empty string case\n    if not string:\n        return \"\"\n        \n    result = string\n    for key, value in context.items():\n        placeholder = \"{{\" + key + \"}}\"\n        result = result.replace(placeholder, str(value))\n    return result\n", "Result": "Error"}
{"namespace": "exodus_bundler.templating.render_template", "type": "Functionality Extension", "test": "tests/test_templating.py::test_render_template_functionality_extension", "completion": "\ndef render_template(string: str, context: dict) -> str:\n    \"\"\"\n    Replace placeholders in a string with values from a context dictionary.\n    Supports default values in the format {{key|default_value}}.\n    \n    Args:\n        string: Input string containing placeholders\n        context: Dictionary with key-value pairs for replacement\n        \n    Returns:\n        Modified string with placeholders replaced by values\n    \n    Examples:\n        >>> template = \"Hello {{name|guest}}, balance: {{balance|0}}\"\n        >>> context = {\"name\": \"John\"}\n        >>> render_template(template, context)\n        'Hello John, balance: 0'\n    \"\"\"\n    result = string\n    import re\n    \n    # Find all placeholders with or without default values\n    pattern = r'\\{\\{([^}]+)\\}\\}'\n    placeholders = re.finditer(pattern, string)\n    \n    for match in placeholders:\n        placeholder = match.group(1)\n        # Split into key and default value if default exists\n        parts = placeholder.split('|')\n        key = parts[0].strip()\n        default_value = parts[1].strip() if len(parts) > 1 else ''\n        \n        # Get value from context or use default\n        value = context.get(key, default_value)\n        \n        # Replace the entire placeholder with the value\n        full_placeholder = '{{' + placeholder + '}}'\n        result = result.replace(full_placeholder, str(value))\n    \n    return result\n", "Result": "Error"}
{"namespace": "exodus_bundler.templating.render_template", "type": "Annotation Coverage", "test": "tests/test_templating.py::test_render_template_annotation_coverage", "completion": "\ndef render_template(string: str, context: dict) -> str:\n    \"\"\"\n    Replace placeholders in a string with values from a context dictionary.\n    \n    Args:\n        string: Input string containing placeholders\n        context: Dictionary with key-value pairs for replacement\n        \n    Returns:\n        Modified string with placeholders replaced by values\n    \"\"\"\n    result = string\n    for key, value in context.items():\n        placeholder = \"{{\" + key + \"}}\"\n        result = result.replace(placeholder, str(value))\n    return result\n", "Result": "Error"}
{"namespace": "exodus_bundler.templating.render_template", "type": "Code Complexity", "test": "tests/test_templating.py::test_render_template", "completion": "\ndef render_template(string: str, context: dict) -> str:\n    \"\"\"\n    Replace placeholders in a string with values from a context dictionary.\n    \n    Args:\n        string: Input string containing placeholders\n        context: Dictionary with key-value pairs for replacement\n        \n    Returns:\n        Modified string with placeholders replaced by values\n        \n    Examples:\n        >>> render_template(\"Hello {{name}}\", {\"name\": \"John\"})\n        'Hello John'\n    \"\"\"\n    return reduce(\n        lambda s, kv: s.replace(\"{{\" + kv[0] + \"}}\", str(kv[1])),\n        context.items(),\n        string\n    )\n", "Result": "Error"}
{"namespace": "exodus_bundler.templating.render_template", "type": "Code Standard", "test": "tests/test_templating.py::test_check_code_style", "completion": "\ndef render_template(template_string: str, context: dict) -> str:\n    \"\"\"Replace placeholders in a string with values from a context dictionary.\n\n    This function takes a template string containing placeholders in the format\n    {{key}} and replaces them with corresponding values from the context\n    dictionary.\n\n    Args:\n        template_string: A string containing placeholders in {{key}} format.\n        context: A dictionary containing key-value pairs for replacement.\n\n    Returns:\n        A string with all placeholders replaced by their corresponding values.\n\n    Examples:\n        >>> template = \"Hello {{name}}!\"\n        >>> context = {\"name\": \"John\"}\n        >>> render_template(template, context)\n        'Hello John!'\n    \"\"\"\n    result = template_string\n    for key, value in context.items():\n        placeholder = \"{{\" + str(key) + \"}}\"\n        result = result.replace(placeholder, str(value))\n    \n    return result\n", "Result": "Error"}
{"namespace": "trailscraper.iam.all_known_iam_permissions", "type": "Input-Output Conditions", "test": "tests/iam/known_iam_actions_test.py::test_output_type_and_content", "completion": "\ndef all_known_iam_permissions():\n    \"\"\"\n    Returns a set of all known IAM actions by reading from 'known-iam-actions.txt'\n    Each line in the file should represent a valid IAM action (e.g., 's3:GetObject')\n    \n    :return: set - A set of strings, each representing a valid IAM action\n    :raises: FileNotFoundError if the actions file is not found\n    :raises: IOError if there are issues reading the file\n    \"\"\"\n    import os\n    \n    current_dir = os.path.dirname(os.path.abspath(__file__))\n    file_path = os.path.join(current_dir, 'known-iam-actions.txt')\n    \n    try:\n        with open(file_path, 'r') as f:\n            # Read lines, strip whitespace, and filter out empty lines\n            actions = set(line.strip() for line in f if line.strip())\n            \n            # Validate that each action follows the basic IAM format (service:action)\n            valid_actions = {\n                action for action in actions \n                if ':' in action and all(part.strip() for part in action.split(':'))\n            }\n            \n            return valid_actions\n            \n    except FileNotFoundError:\n        raise FileNotFoundError(f\"IAM actions file not found at: {file_path}\")\n    except IOError as e:\n        raise IOError(f\"Error reading IAM actions file: {str(e)}\")\n", "Result": "Pass"}
{"namespace": "trailscraper.iam.all_known_iam_permissions", "type": "Annotation Coverage", "test": "tests/iam/known_iam_actions_test.py::test_docstring_presence", "completion": "\ndef all_known_iam_permissions():\n    \"\"\"\n    Returns a set of all known IAM actions from 'known-iam-actions.txt'.\n    \n    The file is expected to be in the same directory as the current script.\n    Each line in the file represents one IAM action.\n    \n    :param: None\n    :return: set - A set of strings, where each string is an IAM action\n    \"\"\"\n    import os\n    \n    current_dir = os.path.dirname(os.path.abspath(__file__))\n    file_path = os.path.join(current_dir, 'known-iam-actions.txt')\n    \n    with open(file_path, 'r') as f:\n        return set(line.strip() for line in f)\n", "Result": "Error"}
{"namespace": "trailscraper.iam.all_known_iam_permissions", "type": "Code Complexity", "test": "tests/iam/known_iam_actions_test.py::test_cyclomatic_complexity", "completion": "\ndef all_known_iam_permissions():\n    \"\"\"\n    Returns a list of all known IAM actions by reading from 'known-iam-actions.txt'\n    Maintains cyclomatic complexity of 1 with linear flow.\n    \n    :return: set - A set of lines from the file\n    :raises: FileNotFoundError if the file doesn't exist\n    \"\"\"\n    import os\n    \n    current_dir = os.path.dirname(os.path.abspath(__file__))\n    file_path = os.path.join(current_dir, 'known-iam-actions.txt')\n    \n    with open(file_path, 'r') as f:\n        return {line.strip() for line in f}\n", "Result": "Pass"}
{"namespace": "trailscraper.iam.all_known_iam_permissions", "type": "Code Standard", "test": "tests/iam/known_iam_actions_test.py::test_check_code_style", "completion": "\ndef all_known_iam_permissions():\n    \"\"\"Returns a list of all known IAM actions.\n\n    This function reads IAM actions from 'known-iam-actions.txt' file located\n    in the same directory as the current script.\n\n    Returns:\n        set: A set of lines containing IAM actions.\n    \"\"\"\n    import os\n\n    current_dir = os.path.dirname(os.path.abspath(__file__))\n    file_path = os.path.join(current_dir, 'known-iam-actions.txt')\n\n    with open(file_path, 'r') as file:\n        return set(line.strip() for line in file)\n", "Result": "Pass"}
{"namespace": "trailscraper.cloudtrail.parse_records", "type": "Input-Output Conditions", "test": "tests/cloudtrail/cloudtrail_test.py::test_parse_records_with_empty_input", "completion": "\ndef parse_records(json_records):\n    \"\"\"\n    Parse a list of JSON records into Record objects.\n    \n    Args:\n        json_records (List): A list of JSON records to be parsed\n        \n    Returns:\n        List: A list of Record objects parsed from the JSON records.\n               Returns an empty list if input is empty.\n    \"\"\"\n    # Return empty list if input is empty\n    if not json_records:\n        return []\n        \n    # Map each JSON record through _parse_record and filter out None values\n    return [\n        record for record in map(_parse_record, json_records)\n        if record is not None\n    ]\n", "Result": "Pass"}
{"namespace": "trailscraper.cloudtrail.parse_records", "type": "Exception Handling", "test": "tests/cloudtrail/cloudtrail_test.py::test_parse_records_with_invalid_json_format", "completion": "\nimport json\n\ndef parse_records(json_records):\n    \"\"\"\n    Parse a list of JSON records into Record objects.\n    \n    Args:\n        json_records (List): A list of JSON records to be parsed\n        \n    Returns:\n        List: A list of Record objects parsed from the JSON records\n        \n    Raises:\n        ValueError: If any of the records are not in valid JSON format\n    \"\"\"\n    # Validate JSON format for each record\n    for record in json_records:\n        try:\n            if isinstance(record, str):\n                json.loads(record)\n            elif not isinstance(record, dict):\n                raise ValueError\n        except (json.JSONDecodeError, ValueError):\n            raise ValueError(\"Invalid JSON format\")\n    \n    # Map each JSON record through _parse_record and filter out None values\n    return [\n        record for record in map(_parse_record, json_records)\n        if record is not None\n    ]\n", "Result": "Pass"}
{"namespace": "trailscraper.cloudtrail.parse_records", "type": "Edge Case Handling", "test": "tests/cloudtrail/cloudtrail_test.py::test_parse_records_with_missing_fields", "completion": "\ndef parse_records(json_records):\n    \"\"\"\n    Parse a list of JSON records into Record objects, ignoring records with missing fields.\n    \n    Args:\n        json_records (List): A list of JSON records to be parsed\n        \n    Returns:\n        List: A list of Record objects parsed from the JSON records, excluding records\n              with missing fields\n    \"\"\"\n    parsed_records = []\n    \n    for json_record in json_records:\n        try:\n            parsed_record = _parse_record(json_record)\n            if parsed_record is not None:\n                parsed_records.append(parsed_record)\n        except (KeyError, ValueError, TypeError):\n            # Skip records with missing or invalid fields\n            continue\n            \n    return parsed_records\n", "Result": "Error"}
{"namespace": "trailscraper.cloudtrail.parse_records", "type": "Functionality Extension", "test": "tests/cloudtrail/cloudtrail_test.py::test_parse_records_with_filter_func", "completion": "\ndef parse_records(json_records, filter_func=None):\n    \"\"\"\n    Parse a list of JSON records into Record objects and optionally filter them.\n    \n    Args:\n        json_records (List): A list of JSON records to be parsed\n        filter_func (Callable, optional): A function that takes a Record object and returns\n            a boolean indicating whether to include the record. Defaults to None.\n        \n    Returns:\n        List: A list of Record objects parsed from the JSON records\n    \"\"\"\n    # First parse all records and filter out None values\n    parsed_records = [\n        record for record in map(_parse_record, json_records)\n        if record is not None\n    ]\n    \n    # If a filter function is provided, apply it to the parsed records\n    if filter_func is not None:\n        return [record for record in parsed_records if filter_func(record)]\n    \n    return parsed_records\n", "Result": "Error"}
{"namespace": "trailscraper.cloudtrail.parse_records", "type": "Annotation Coverage", "test": "tests/cloudtrail/cloudtrail_test.py::test_parse_records_annotations", "completion": "\nfrom typing import List, Optional\nfrom dataclasses import dataclass\n\ndef parse_records(json_records: List[dict]) -> List['Record']:\n    \"\"\"\n    Parse a list of JSON records into Record objects.\n    \n    Args:\n        json_records (List[dict]): A list of JSON records to be parsed\n        \n    Returns:\n        List[Record]: A list of Record objects parsed from the JSON records\n    \"\"\"\n    # Map each JSON record through _parse_record and filter out None values\n    return [\n        record for record in map(_parse_record, json_records)\n        if record is not None\n    ]\n", "Result": "Error"}
{"namespace": "trailscraper.cloudtrail.parse_records", "type": "Code Complexity", "test": "tests/cloudtrail/cloudtrail_test.py::test_code_complexity", "completion": "\ndef parse_records(json_records):\n    \"\"\"\n    Parse a list of JSON records into Record objects.\n    Maintains a cyclomatic complexity of 1 by using functional programming concepts.\n    \n    Args:\n        json_records (List): A list of JSON records to be parsed\n        \n    Returns:\n        List: A list of Record objects parsed from the JSON records\n    \"\"\"\n    # Using list comprehension with map and filter operations\n    # keeps cyclomatic complexity at 1 since there are no explicit\n    # control flow statements (if/else, for, while, etc.)\n    return [\n        record for record in map(_parse_record, json_records)\n        if record is not None\n    ]\n", "Result": "Pass"}
{"namespace": "trailscraper.cloudtrail.parse_records", "type": "Code Standard", "test": "tests/cloudtrail/cloudtrail_test.py::test_check_code_style", "completion": "\ndef parse_records(json_records: list) -> list:\n    \"\"\"\n    Parse a list of JSON records into Record objects.\n\n    This function takes a list of JSON records and converts them into Record objects.\n    It uses the _parse_record function to parse each JSON record and then filters\n    out any None values from the parsed records.\n\n    Args:\n        json_records: A list of JSON records to be parsed.\n\n    Returns:\n        A list of Record objects parsed from the JSON records.\n    \"\"\"\n    return [\n        record\n        for record in map(_parse_record, json_records)\n        if record is not None\n    ]\n", "Result": "Error"}
{"namespace": "discord.utils.get_slots", "type": "Input-Output Conditions", "test": "tests/test_utils.py::test_input_output_conditions", "completion": "\nfrom typing import Iterator\nfrom types import GenericAlias\n\ndef get_slots(cls: type) -> Iterator[str]:\n    \"\"\"\n    Returns an iterator that yields the names of slots in a class and its base classes.\n    \n    Args:\n        cls: The class for which the slots are to be retrieved\n        \n    Returns:\n        An iterator yielding slot names as strings\n        \n    Raises:\n        TypeError: If the input is not a class type\n        \n    Example:\n        for slot in get_slots(MyClass):\n            print(slot)\n    \"\"\"\n    # Validate input is a class type\n    if not isinstance(cls, type) and not isinstance(cls, GenericAlias):\n        raise TypeError(f\"Expected a class type, got {type(cls).__name__}\")\n\n    # Check each class in the method resolution order\n    for class_ in cls.__mro__:\n        # Get slots if they exist in the class\n        slots = getattr(class_, '__slots__', ())\n        if isinstance(slots, str):\n            yield slots\n        else:\n            for slot in slots:\n                yield slot\n", "Result": "Pass"}
{"namespace": "discord.utils.get_slots", "type": "Exception Handling", "test": "tests/test_utils.py::test_exception_handling", "completion": "\ndef get_slots(cls: type) -> Iterator[str]:\n    \"\"\"\n    Returns an iterator that yields the names of slots in a class and its base classes.\n    \n    Args:\n        cls: The class for which the slots are to be retrieved\n        \n    Returns:\n        An iterator yielding slot names as strings\n        \n    Raises:\n        TypeError: If the input is not a class type\n        \n    Example:\n        for slot in get_slots(MyClass):\n            print(slot)\n    \"\"\"\n    # Check if input is a class type\n    if not isinstance(cls, type):\n        raise TypeError('Input must be a class type.')\n        \n    # Check each class in the method resolution order\n    for class_ in cls.__mro__:\n        # Get slots if they exist in the class\n        slots = getattr(class_, '__slots__', ())\n        if isinstance(slots, str):\n            yield slots\n        else:\n            for slot in slots:\n                yield slot\n", "Result": "Error"}
{"namespace": "discord.utils.get_slots", "type": "Edge Case Handling", "test": "tests/test_utils.py::test_edge_case_handling", "completion": "\ndef get_slots(cls: type) -> Iterator[str]:\n    \"\"\"\n    Returns an iterator that yields the names of slots in a class and its base classes.\n    \n    Args:\n        cls: The class for which the slots are to be retrieved\n        \n    Returns:\n        An iterator yielding slot names as strings\n        \n    Example:\n        class A:\n            __slots__ = ('x', 'y')\n            \n        class B(A):\n            pass\n            \n        class C(B):\n            __slots__ = 'z'\n            \n        for slot in get_slots(C):\n            print(slot)  # Prints: z, x, y\n    \"\"\"\n    # Check each class in the method resolution order\n    for class_ in cls.__mro__:\n        # Skip if class doesn't have __slots__ attribute\n        if not hasattr(class_, '__slots__'):\n            continue\n            \n        slots = class_.__slots__\n        \n        # Skip if slots is None or empty\n        if not slots:\n            continue\n            \n        # Handle string slot definition\n        if isinstance(slots, str):\n            yield slots\n        # Handle iterable slot definition\n        else:\n            for slot in slots:\n                yield slot\n", "Result": "Pass"}
{"namespace": "discord.utils.get_slots", "type": "Functionality Extension", "test": "tests/test_utils.py::test_functionality_extension", "completion": ":get_slots.py\ndef get_slots(cls: type, depth: int = None) -> Iterator[str]:\n    \"\"\"\n    Returns an iterator that yields the names of slots in a class and its base classes.\n    \n    Args:\n        cls: The class for which the slots are to be retrieved\n        depth: Optional maximum depth in the inheritance hierarchy to search.\n               None means search all base classes.\n               0 means only search the class itself.\n               1 means search the class and its immediate parent classes, etc.\n        \n    Returns:\n        An iterator yielding slot names as strings\n        \n    Example:\n        # Get all slots\n        for slot in get_slots(MyClass):\n            print(slot)\n            \n        # Get slots only from MyClass and its immediate parent\n        for slot in get_slots(MyClass, depth=1):\n            print(slot)\n    \"\"\"\n    # Get the method resolution order\n    mro = cls.__mro__\n    \n    # If depth is specified, limit the classes to check\n    if depth is not None:\n        mro = mro[:depth + 1]  # +1 because we want to include the class at the specified depth\n    \n    # Check each class in the method resolution order\n    for class_ in mro:\n        # Get slots if they exist in the class\n        slots = getattr(class_, '__slots__', ())\n        if isinstance(slots, str):\n            yield slots\n        else:\n            for slot in slots:\n                yield slot\n", "Result": "Error"}
{"namespace": "discord.utils.get_slots", "type": "Annotation Coverage", "test": "tests/test_utils.py::test_annotation_coverage", "completion": "\nfrom typing import Type, Any, Iterator\n\ndef get_slots(cls: Type[Any]) -> Iterator[str]:\n    \"\"\"\n    Returns an iterator that yields the names of slots in a class and its base classes.\n    \n    Args:\n        cls: The class for which the slots are to be retrieved\n        \n    Returns:\n        An iterator yielding slot names as strings\n        \n    Example:\n        for slot in get_slots(MyClass):\n            print(slot)\n    \"\"\"\n    # Check each class in the method resolution order\n    for class_ in cls.__mro__:\n        # Get slots if they exist in the class\n        slots = getattr(class_, '__slots__', ())\n        if isinstance(slots, str):\n            yield slots\n        else:\n            for slot in slots:\n                yield slot\n", "Result": "Pass"}
{"namespace": "discord.utils.get_slots", "type": "Code Complexity", "test": "tests/test_utils.py::test_code_complexity", "completion": "\ndef get_slots(cls: type) -> Iterator[str]:\n    \"\"\"\n    Returns an iterator that yields the names of slots in a class and its base classes.\n    \n    Args:\n        cls: The class for which the slots are to be retrieved\n        \n    Returns:\n        An iterator yielding slot names as strings\n        \n    Example:\n        for slot in get_slots(MyClass):\n            print(slot)\n    \"\"\"\n    return (\n        slot\n        for class_ in cls.__mro__\n        for slot in (getattr(class_, '__slots__', ()) \n                    if isinstance(getattr(class_, '__slots__', ()), (list, tuple))\n                    else [getattr(class_, '__slots__', ())])\n        if slot\n    )\n", "Result": "Pass"}
{"namespace": "discord.utils.get_slots", "type": "Code Standard", "test": "tests/test_utils.py::test_check_code_style", "completion": ":get_slots.py\nfrom typing import Iterator\n\n\ndef get_slots(cls: type) -> Iterator[str]:\n    \"\"\"Return an iterator of slot names from a class and its base classes.\n\n    This function iterates through the class hierarchy and yields the names of\n    slots defined in the class and all its base classes. It handles both string\n    and iterable slot definitions.\n\n    Args:\n        cls: The class for which the slots are to be retrieved.\n\n    Returns:\n        An iterator yielding slot names as strings.\n\n    Example:\n        >>> class MyClass:\n        ...     __slots__ = ('name', 'age')\n        >>> list(get_slots(MyClass))\n        ['name', 'age']\n    \"\"\"\n    for class_ in cls.__mro__:\n        slots = getattr(class_, '__slots__', ())\n        if isinstance(slots, str):\n            yield slots\n        else:\n            yield from slots\n", "Result": "Error"}
{"namespace": "discord.utils.is_inside_class", "type": "Input-Output Conditions", "test": "tests/test_utils.py::test_input_output_conditions", "completion": "\ndef is_inside_class(func):\n    \"\"\"\n    Determine whether a given callable is defined within a class.\n    \n    Args:\n        func: Callable. The function to be checked.\n        \n    Returns:\n        bool: True if the function is defined inside a class, False otherwise.\n        \n    Raises:\n        TypeError: If the input is not a callable object.\n    \"\"\"\n    # Strictly check if input is callable\n    if not callable(func):\n        raise TypeError(f\"Expected a callable object, got {type(func).__name__}\")\n    \n    # Get the qualified name of the callable\n    qualname = getattr(func, '__qualname__', '')\n    \n    # If qualname is empty, it's definitely not in a class\n    if not qualname:\n        return False\n    \n    # Split the qualified name into parts\n    parts = qualname.split('.')\n    \n    # A function is inside a class if:\n    # 1. It has at least two parts (class.method)\n    # 2. The first part is not '<locals>' (which would indicate a nested function)\n    return len(parts) >= 2 and parts[0] != '<locals>'\n", "Result": "Error"}
{"namespace": "discord.utils.is_inside_class", "type": "Exception Handling", "test": "tests/test_utils.py::test_exception_handling", "completion": "\ndef is_inside_class(func):\n    \"\"\"\n    Determine whether a given callable is defined within a class.\n    \n    Args:\n        func: Callable. The function to be checked.\n    Returns:\n        bool: True if the function is defined inside a class, False otherwise.\n    Raises:\n        TypeError: If the input is not a callable.\n    \"\"\"\n    if not callable(func):\n        raise TypeError(\"Input must be a callable.\")\n        \n    # Get the qualified name of the callable\n    qualname = getattr(func, '__qualname__', '')\n    \n    # Split the qualified name into parts\n    parts = qualname.split('.')\n    \n    # Check if there are at least 2 parts (class.method)\n    # and the first part is not '<locals>' (nested function)\n    return len(parts) >= 2 and '<locals>' not in parts[:-1]\n", "Result": "Pass"}
{"namespace": "discord.utils.is_inside_class", "type": "Edge Case Handling", "test": "tests/test_utils.py::test_edge_case_handling", "completion": "\ndef is_inside_class(func):\n    \"\"\"\n    Determine whether a given callable is defined within a class.\n    Handles edge cases including nested classes and functions.\n    \n    Args:\n        func: Callable. The function to be checked.\n    Returns:\n        bool: True if the function is defined inside a class, False otherwise.\n        \n    Examples:\n        >>> class A:\n        ...     def method(self): pass\n        ...     class B:\n        ...         def nested_method(self): pass\n        ...     @staticmethod\n        ...     def static_method(): pass\n        >>> def standalone_function(): pass\n        >>> def outer():\n        ...     def inner(): pass\n        ...     return inner\n        >>> \n        >>> is_inside_class(A.method)  # True\n        >>> is_inside_class(A.B.nested_method)  # True\n        >>> is_inside_class(A.static_method)  # True\n        >>> is_inside_class(standalone_function)  # False\n        >>> is_inside_class(outer())  # False\n    \"\"\"\n    if not callable(func):\n        raise TypeError(\"Input must be a callable (function or method)\")\n    \n    # Get the qualified name of the callable\n    qualname = getattr(func, '__qualname__', '')\n    \n    # Split the qualified name into parts\n    parts = qualname.split('.')\n    \n    if len(parts) < 2:\n        return False\n        \n    # Check each part of the path\n    for i, part in enumerate(parts[:-1]):  # Exclude the last part (function name)\n        # Check if this part represents a class\n        if part.isidentifier() and not part.startswith('<'):\n            # Try to get the class from func's module\n            try:\n                current_obj = getattr(func.__module__, part, None)\n                if isinstance(current_obj, type):\n                    return True\n            except AttributeError:\n                pass\n            \n        # If we find '<locals>' and it's not followed by a class name,\n        # this indicates a nested function rather than a class method\n        if part == '<locals>' and i + 1 < len(parts) - 1:\n            next_part = parts[i + 1]\n            if not next_part.isidentifier() or next_part.startswith('<'):\n                return False\n                \n    return any(part.isidentifier() and not part.startswith('<') \n              for part in parts[:-1])\n", "Result": "Error"}
{"namespace": "discord.utils.is_inside_class", "type": "Functionality Extension", "test": "tests/test_utils.py::test_functionality_extension", "completion": "\ndef is_inside_class(func):\n    \"\"\"\n    Determine whether a given callable is defined within a class and identify its method type.\n    \n    Args:\n        func: Callable. The function to be checked.\n    Returns:\n        tuple: (is_in_class, method_type)\n            - is_in_class (bool): True if the function is defined inside a class\n            - method_type (str): One of 'static_method', 'class_method', 'instance_method', \n                                or None if not in a class\n    \"\"\"\n    if not callable(func):\n        raise TypeError(\"Input must be a callable (function or method)\")\n        \n    # Get the qualified name of the callable\n    qualname = getattr(func, '__qualname__', '')\n    \n    # Split the qualified name into parts\n    parts = qualname.split('.')\n    \n    # Check if there are at least 2 parts (class.method)\n    # and the first part is not '<locals>' (nested function)\n    is_in_class = len(parts) >= 2 and '<locals>' not in parts[:-1]\n    \n    if not is_in_class:\n        return (False, None)\n    \n    # Determine method type\n    method_type = None\n    \n    # Check if it's a static method\n    if isinstance(func, staticmethod):\n        method_type = 'static_method'\n    # Check if it's a class method\n    elif isinstance(func, classmethod):\n        method_type = 'class_method'\n    # If it's in a class but not static/class method, it's an instance method\n    else:\n        # Get the class from the method (if bound)\n        if hasattr(func, '__self__'):\n            method_type = 'class_method' if isinstance(func.__self__, type) else 'instance_method'\n        else:\n            # For unbound methods\n            method_type = 'instance_method'\n    \n    return (True, method_type)\n", "Result": "Error"}
{"namespace": "discord.utils.is_inside_class", "type": "Annotation Coverage", "test": "tests/test_utils.py::test_annotation_coverage", "completion": "\nfrom typing import Callable\n\ndef is_inside_class(func: Callable) -> bool:\n    \"\"\"\n    Determine whether a given callable is defined within a class.\n    \n    Args:\n        func: Callable. The function to be checked.\n    Returns:\n        bool: True if the function is defined inside a class, False otherwise.\n    \"\"\"\n    if not callable(func):\n        raise TypeError(\"Input must be a callable (function or method)\")\n        \n    # Get the qualified name of the callable\n    qualname = getattr(func, '__qualname__', '')\n    \n    # Split the qualified name into parts\n    parts = qualname.split('.')\n    \n    # Check if there are at least 2 parts (class.method)\n    # and the first part is not '<locals>' (nested function)\n    return len(parts) >= 2 and '<locals>' not in parts[:-1]\n", "Result": "Error"}
{"namespace": "discord.utils.is_inside_class", "type": "Code Complexity", "test": "tests/test_utils.py::test_code_complexity", "completion": "\ndef is_inside_class(func):\n    \"\"\"\n    Determine whether a given callable is defined within a class.\n    \n    Args:\n        func: Callable. The function to be checked.\n    Returns:\n        bool: True if the function is defined inside a class, False otherwise.\n    \"\"\"\n    qualname = getattr(func, '__qualname__', '')\n    parts = qualname.split('.')\n    return len(parts) >= 2\n", "Result": "Error"}
{"namespace": "discord.utils.is_inside_class", "type": "Code Standard", "test": "tests/test_utils.py::test_check_code_style", "completion": "\ndef is_inside_class(func):\n    \"\"\"\n    Determine whether a given callable is defined within a class.\n\n    This function examines the __qualname__ attribute of the callable to determine\n    if it is defined within a class scope. It handles nested functions and methods\n    appropriately.\n\n    Args:\n        func: A callable object (function or method) to be checked.\n\n    Returns:\n        bool: True if the callable is defined inside a class, False otherwise.\n\n    Raises:\n        TypeError: If the input is not a callable object.\n\n    Examples:\n        >>> class MyClass:\n        ...     def method(self):\n        ...         pass\n        >>> def standalone_function():\n        ...     pass\n        >>> is_inside_class(MyClass.method)\n        True\n        >>> is_inside_class(standalone_function)\n        False\n    \"\"\"\n    if not callable(func):\n        raise TypeError(\"Input must be a callable (function or method)\")\n\n    qualified_name = getattr(func, '__qualname__', '')\n    name_parts = qualified_name.split('.')\n\n    # Check if there are at least 2 parts (class.method)\n    # and ensure no '<locals>' in the path except possibly the last part\n    return len(name_parts) >= 2 and '<locals>' not in name_parts[:-1]\n", "Result": "Error"}
{"namespace": "wandb.util.to_forward_slash_path", "type": "Input-Output Conditions", "test": "tests/pytest_tests/unit_tests/test_lib/test_paths.py::test_input_output_conditions", "completion": "\ndef to_forward_slash_path(path: str) -> str:\n    \"\"\"\n    Convert backslash path to forward slash path if platform is Windows.\n    \n    :param path: String. The path to be converted.\n    :return: String. The converted path.\n    :raises TypeError: If the input path is not a string.\n    \"\"\"\n    import platform\n    \n    if not isinstance(path, str):\n        raise TypeError(f\"Expected string input, got {type(path).__name__}\")\n        \n    if platform.system() == 'Windows':\n        return path.replace('\\\\', '/')\n    return path\n", "Result": "Pass"}
{"namespace": "wandb.util.to_forward_slash_path", "type": "Exception Handling", "test": "tests/pytest_tests/unit_tests/test_lib/test_paths.py::test_exception_handling", "completion": "\ndef to_forward_slash_path(path: str) -> str:\n    \"\"\"\n    Convert backslash path to forward slash path if platform is Windows.\n    \n    :param path: String. The path to be converted.\n    :return: String. The converted path.\n    :raises ValueError: If the input path is None.\n    \"\"\"\n    if path is None:\n        raise ValueError('Input path cannot be None')\n        \n    import platform\n    \n    if platform.system() == 'Windows':\n        return path.replace('\\\\', '/')\n    return path\n", "Result": "Error"}
{"namespace": "wandb.util.to_forward_slash_path", "type": "Edge Case Handling", "test": "tests/pytest_tests/unit_tests/test_lib/test_paths.py::test_edge_case_handling", "completion": "\ndef to_forward_slash_path(path: str) -> str:\n    \"\"\"\n    Convert backslash path to forward slash path if platform is Windows.\n    \n    :param path: String. The path to be converted.\n    :return: String. The converted path.\n    \"\"\"\n    import platform\n    \n    if not path:  # Handle empty string\n        return \"\"\n        \n    if platform.system() == 'Windows':\n        return path.replace('\\\\', '/')\n    return path\n", "Result": "Pass"}
{"namespace": "wandb.util.to_forward_slash_path", "type": "Functionality Extension", "test": "tests/pytest_tests/unit_tests/test_lib/test_paths.py::test_functionality_extension", "completion": "\ndef to_forward_slash_path(path: str) -> str:\n    \"\"\"\n    Convert backslash path to forward slash path, handling mixed slashes.\n    \n    :param path: String. The path to be converted.\n    :return: String. The converted path with forward slashes.\n    \"\"\"\n    return path.replace('\\\\', '/')\n", "Result": "Pass"}
{"namespace": "wandb.util.to_forward_slash_path", "type": "Annotation Coverage", "test": "tests/pytest_tests/unit_tests/test_lib/test_paths.py::test_annotation_coverage", "completion": "\ndef to_forward_slash_path(path: str) -> str:\n    \"\"\"\n    Convert backslash path to forward slash path if platform is Windows.\n    \n    :param path: String. The path to be converted.\n    :return: String. The converted path.\n    \"\"\"\n    import platform\n    \n    if platform.system() == 'Windows':\n        return path.replace('\\\\', '/')\n    return path\n", "Result": "Pass"}
{"namespace": "wandb.util.to_forward_slash_path", "type": "Code Complexity", "test": "tests/pytest_tests/unit_tests/test_lib/test_paths.py::test_code_complexity", "completion": "\ndef to_forward_slash_path(path: str) -> str:\n    \"\"\"\n    Convert backslash path to forward slash path.\n    \n    :param path: String. The path to be converted.\n    :return: String. The converted path with forward slashes.\n    \"\"\"\n    return path.replace('\\\\', '/')\n", "Result": "Error"}
{"namespace": "wandb.util.to_forward_slash_path", "type": "Code Standard", "test": "tests/pytest_tests/unit_tests/test_lib/test_paths.py::test_check_code_style", "completion": "\ndef to_forward_slash_path(path: str) -> str:\n    \"\"\"\n    Convert backslash path to forward slash path if platform is Windows.\n\n    Args:\n        path: String containing the path to be converted.\n\n    Returns:\n        String containing the converted path with forward slashes if on Windows,\n        or the original path if on another platform.\n\n    Examples:\n        >>> to_forward_slash_path(r\"C:\\Users\\name\\file.txt\")\n        'C:/Users/name/file.txt'\n        >>> to_forward_slash_path(\"/home/user/file.txt\")  # on non-Windows\n        '/home/user/file.txt'\n    \"\"\"\n    import platform\n\n    if platform.system() == 'Windows':\n        return path.replace('\\\\', '/')\n    return path\n", "Result": "Error"}
{"namespace": "wandb.util.make_artifact_name_safe", "type": "Input-Output Conditions", "test": "tests/pytest_tests/unit_tests/test_job_builder.py::test_make_artifact_name_safe_input_output", "completion": "\nimport re\n\ndef make_artifact_name_safe(name: str) -> str:\n    # Replace invalid characters with underscore\n    safe_name = re.sub(r'[^a-zA-Z0-9\\-_.]', '_', name)\n    \n    # If name is longer than 128 characters, truncate with dots in middle\n    if len(safe_name) > 128:\n        half_length = (128 - 3) // 2\n        safe_name = f\"{safe_name[:half_length]}...{safe_name[-half_length:]}\"\n    \n    return safe_name\n\n# Test cases\ntest_cases = [\n    \"hello.world\",                  # Should remain unchanged\n    \"hello@world\",                  # @ should become _\n    \"hello world!123\",             # space and ! should become _\n    \"test#$%^&*()\",               # All special chars should become _\n    \"my-artifact_name.test\",       # Should remain unchanged\n    \"\u03b1\u03b2\u03b3\u03b4\u03b5\",                      # Non-ASCII chars should become _\n]\n\nfor test in test_cases:\n    print(f\"Original: {test}\")\n    print(f\"Safe: {make_artifact_name_safe(test)}\")\n    print(\"-\" * 40)\n", "Result": "Pass"}
{"namespace": "wandb.util.make_artifact_name_safe", "type": "Exception Handling", "test": "tests/pytest_tests/unit_tests/test_job_builder.py::test_make_artifact_name_safe_type_error", "completion": "\nimport re\n\ndef make_artifact_name_safe(name: str) -> str:\n    # Type checking\n    if not isinstance(name, str):\n        raise TypeError('Input must be a string')\n        \n    # Replace invalid characters with underscore\n    safe_name = re.sub(r'[^a-zA-Z0-9\\-_.]', '_', name)\n    \n    # If name is longer than 128 characters, truncate with dots in middle\n    if len(safe_name) > 128:\n        half_length = (128 - 3) // 2\n        safe_name = f\"{safe_name[:half_length]}...{safe_name[-half_length:]}\"\n    \n    return safe_name\n", "Result": "Error"}
{"namespace": "wandb.util.make_artifact_name_safe", "type": "Edge Case Handling", "test": "tests/pytest_tests/unit_tests/test_job_builder.py::test_make_artifact_name_safe_empty_string", "completion": "\nimport re\n\ndef make_artifact_name_safe(name: str) -> str:\n    # Handle empty string\n    if not name:\n        return \"\"\n        \n    # Replace invalid characters with underscore\n    safe_name = re.sub(r'[^a-zA-Z0-9\\-_.]', '_', name)\n    \n    # If name is longer than 128 characters, truncate with dots in middle\n    if len(safe_name) > 128:\n        half_length = (128 - 3) // 2\n        safe_name = f\"{safe_name[:half_length]}...{safe_name[-half_length:]}\"\n    \n    return safe_name\n", "Result": "Pass"}
{"namespace": "wandb.util.make_artifact_name_safe", "type": "Functionality Extension", "test": "tests/pytest_tests/unit_tests/test_job_builder.py::test_make_artifact_name_safe_trim_spaces", "completion": "\nimport re\n\ndef make_artifact_name_safe(name: str) -> str:\n    # Trim leading and trailing spaces\n    name = name.strip()\n    \n    # Replace invalid characters with underscore\n    safe_name = re.sub(r'[^a-zA-Z0-9\\-_.]', '_', name)\n    \n    # If name is longer than 128 characters, truncate with dots in middle\n    if len(safe_name) > 128:\n        half_length = (128 - 3) // 2\n        safe_name = f\"{safe_name[:half_length]}...{safe_name[-half_length:]}\"\n    \n    return safe_name\n", "Result": "Pass"}
{"namespace": "wandb.util.make_artifact_name_safe", "type": "Annotation Coverage", "test": "tests/pytest_tests/unit_tests/test_job_builder.py::test_make_artifact_name_safe_annotations", "completion": "\ndef make_artifact_name_safe(name: str) -> str:\n    # Replace invalid characters with underscore\n    safe_name = re.sub(r'[^a-zA-Z0-9\\-_.]', '_', name)\n    \n    # If name is longer than 128 characters, truncate with dots in middle\n    if len(safe_name) > 128:\n        half_length = (128 - 3) // 2\n        safe_name = f\"{safe_name[:half_length]}...{safe_name[-half_length:]}\"\n    \n    return safe_name\n", "Result": "Pass"}
{"namespace": "wandb.util.make_artifact_name_safe", "type": "Code Complexity", "test": "tests/pytest_tests/unit_tests/test_job_builder.py::test_code_complexity", "completion": "\nimport re\n\ndef make_artifact_name_safe(name: str) -> str:\n    \"\"\"\n    Makes an artifact name safe by replacing invalid characters and truncating if necessary.\n    \n    Args:\n        name: The original artifact name\n        \n    Returns:\n        A cleaned and safe artifact name with max length of 128 characters\n    \"\"\"\n    # Replace invalid characters with underscore using a single regex\n    safe_name = re.sub(r'[^a-zA-Z0-9\\-_.]', '_', name)\n    \n    # Early return if name is within length limit\n    if len(safe_name) <= 128:\n        return safe_name\n        \n    # Truncate with dots in middle\n    half_length = (128 - 3) // 2  # subtract 3 for the \"...\"\n    return f\"{safe_name[:half_length]}...{safe_name[-half_length:]}\"\n", "Result": "Pass"}
{"namespace": "wandb.util.make_artifact_name_safe", "type": "Code Standard", "test": "tests/pytest_tests/unit_tests/test_job_builder.py::test_check_code_style", "completion": "\nimport re\n\n\ndef make_artifact_name_safe(name: str) -> str:\n    \"\"\"\n    Make an artifact name safe for use by replacing invalid characters and truncating if needed.\n\n    This function replaces any characters that are not alphanumeric, dashes,\n    underscores, or dots with underscores. If the length of the cleaned name is\n    greater than 128, it truncates the name with dots in the middle.\n\n    Args:\n        name: The original artifact name.\n\n    Returns:\n        The cleaned and safe artifact name.\n\n    Examples:\n        >>> make_artifact_name_safe(\"my@artifact.name\")\n        'my_artifact.name'\n        >>> make_artifact_name_safe(\"a\" * 200)\n        'aaaaaa...aaaaaa'\n    \"\"\"\n    # Replace invalid characters with underscore\n    safe_name = re.sub(r'[^a-zA-Z0-9\\-_.]', '_', name)\n    \n    # If name is longer than 128 characters, truncate with dots in middle\n    if len(safe_name) > 128:\n        half_length = (128 - 3) // 2  # -3 accounts for the '...'\n        safe_name = f\"{safe_name[:half_length]}...{safe_name[-half_length:]}\"\n    \n    return safe_name\n", "Result": "Error"}
{"namespace": "jwt.utils.force_bytes", "type": "Input-Output Conditions", "test": "tests/test_utils.py::test_force_bytes_with_bytes_input", "completion": "\ndef force_bytes(value: Union[bytes, str]) -> bytes:\n    \"\"\"\n    Convert the input value to bytes.\n    \n    Args:\n        value: Input value that needs to be converted to bytes.\n        \n    Returns:\n        The input value converted to bytes.\n        \n    Raises:\n        TypeError: If input is neither bytes nor str.\n    \"\"\"\n    if isinstance(value, bytes):  # This line checks if input is already bytes\n        return value             # If it is bytes, returns it unchanged\n    elif isinstance(value, str):\n        return value.encode('utf-8')\n    else:\n        raise TypeError(f\"Expected bytes or str, got {type(value).__name__}\")\n", "Result": "Pass"}
{"namespace": "jwt.utils.force_bytes", "type": "Exception Handling", "test": "tests/test_utils.py::test_force_bytes_raises_error_with_message", "completion": "\nfrom typing import Union\n\ndef force_bytes(value: Union[bytes, str]) -> bytes:\n    \"\"\"\n    Convert the input value to bytes.\n    \n    Args:\n        value: Input value that needs to be converted to bytes.\n        \n    Returns:\n        The input value converted to bytes.\n        \n    Raises:\n        TypeError: If input is neither bytes nor str.\n        \n    Examples:\n        >>> force_bytes(\"\")\n        b''\n        >>> force_bytes(\"hello\")\n        b'hello'\n        >>> force_bytes(b\"hello\")\n        b'hello'\n    \"\"\"\n    if isinstance(value, bytes):\n        return value\n    elif isinstance(value, str):\n        return value.encode('utf-8')  # This will handle empty strings correctly, returning b''\n    else:\n        raise TypeError(f\"Expected bytes or str, got {type(value).__name__}\")\n", "Result": "Error"}
{"namespace": "jwt.utils.force_bytes", "type": "Edge Case Handling", "test": "tests/test_utils.py::test_force_bytes_with_empty_string", "completion": "\nfrom typing import Union\n\ndef force_bytes(value: Union[bytes, str]) -> bytes:\n    \"\"\"\n    Convert the input value to bytes.\n    \n    Args:\n        value: Input value that needs to be converted to bytes.\n        \n    Returns:\n        The input value converted to bytes.\n        \n    Raises:\n        TypeError: If input is neither bytes nor str.\n        \n    Examples:\n        >>> force_bytes(\"\")\n        b''\n        >>> force_bytes(\"hello\")\n        b'hello'\n        >>> force_bytes(b\"hello\")\n        b'hello'\n    \"\"\"\n    if isinstance(value, bytes):\n        return value\n    elif isinstance(value, str):\n        return value.encode('utf-8')  # This will handle empty strings correctly, returning b''\n    else:\n        raise TypeError(f\"Expected bytes or str, got {type(value).__name__}\")\n", "Result": "Pass"}
{"namespace": "jwt.utils.force_bytes", "type": "Functionality Extension", "test": "tests/test_utils.py::test_force_bytes_with_none_input", "completion": "\nfrom typing import Union, Optional\n\ndef force_bytes(value: Optional[Union[bytes, str]] -> bytes:\n    \"\"\"\n    Convert the input value to bytes.\n    \n    Args:\n        value: Input value that needs to be converted to bytes.\n               Can be bytes, str, or None.\n        \n    Returns:\n        The input value converted to bytes.\n        If input is None, returns empty bytes object.\n        \n    Raises:\n        TypeError: If input is neither bytes, str, nor None.\n    \"\"\"\n    if value is None:\n        return b''\n    elif isinstance(value, bytes):\n        return value\n    elif isinstance(value, str):\n        return value.encode('utf-8')\n    else:\n        raise TypeError(f\"Expected bytes, str, or None, got {type(value).__name__}\")\n", "Result": "Error"}
{"namespace": "jwt.utils.force_bytes", "type": "Annotation Coverage", "test": "tests/test_utils.py::test_force_bytes_annotations", "completion": "\nfrom typing import Union\n\ndef force_bytes(value: Union[bytes, str, None]) -> bytes:\n    \"\"\"\n    Convert the input value to bytes.\n    \n    Args:\n        value: Input value that needs to be converted to bytes.\n        Can be bytes, str, or None.\n        \n    Returns:\n        The input value converted to bytes.\n        \n    Raises:\n        TypeError: If input is neither bytes, str, nor None.\n    \"\"\"\n    if value is None:\n        return b''\n    elif isinstance(value, bytes):\n        return value\n    elif isinstance(value, str):\n        return value.encode('utf-8')\n    else:\n        raise TypeError(f\"Expected bytes, str, or None, got {type(value).__name__}\")\n", "Result": "Error"}
{"namespace": "jwt.utils.force_bytes", "type": "Code Complexity", "test": "tests/test_utils.py::test_code_complexity", "completion": "\ndef force_bytes(value: Union[bytes, str]) -> bytes:\n    \"\"\"\n    Convert the input value to bytes.\n    \n    Args:\n        value: Input value that needs to be converted to bytes.\n        \n    Returns:\n        The input value converted to bytes.\n        \n    Raises:\n        TypeError: If input is neither bytes nor str.\n    \"\"\"\n    if isinstance(value, bytes):\n        return value\n    if isinstance(value, str):\n        return value.encode('utf-8')\n    raise TypeError(f\"Expected bytes or str, got {type(value).__name__}\")\n", "Result": "Pass"}
{"namespace": "jwt.utils.force_bytes", "type": "Code Standard", "test": "tests/test_utils.py::test_check_code_style", "completion": "\nfrom typing import Union\n\n\ndef force_bytes(value: Union[bytes, str]) -> bytes:\n    \"\"\"Convert the input value to bytes.\n\n    Args:\n        value: Input value that needs to be converted to bytes.\n\n    Returns:\n        bytes: The input value converted to bytes.\n\n    Raises:\n        TypeError: If input is neither bytes nor str.\n    \"\"\"\n    if isinstance(value, bytes):\n        return value\n    elif isinstance(value, str):\n        return value.encode('utf-8')\n    else:\n        raise TypeError(f\"Expected bytes or str, got {type(value).__name__}\")\n", "Result": "Pass"}
{"namespace": "pytube.cli.display_progress_bar", "type": "Input-Output Conditions", "test": "tests/test_cli.py::test_display_progress_bar_input_types", "completion": "\ndef display_progress_bar(bytes_received: int, filesize: int, ch: str = \"\u2588\", scale: float = 0.55) -> None:\n    \"\"\"\n    Display a pretty progress bar in the terminal.\n    \n    Args:\n        bytes_received (int): The delta between total file size and bytes written\n        filesize (int): Total file size in bytes\n        ch (str): Character for progress segment (default: \"\u2588\")\n        scale (float): Scale multiplier for bar size (default: 0.55)\n        \n    Raises:\n        TypeError: If bytes_received or filesize are not integers, or if scale is not a float\n    \"\"\"\n    # Type checking\n    if not isinstance(bytes_received, int):\n        raise TypeError(\"bytes_received must be an integer\")\n    if not isinstance(filesize, int):\n        raise TypeError(\"filesize must be an integer\")\n    if not isinstance(scale, float):\n        raise TypeError(\"scale must be a float\")\n    \n    columns = min(int(80 * scale), 80)  # Get terminal width, cap at 80\n    max_width = columns - 7  # Leave space for percentages\n\n    filled = int(round(max_width * bytes_received / float(filesize)))\n    remaining = max_width - filled\n    progress = round(100.0 * bytes_received / float(filesize), 1)\n    bar = ch * filled + '-' * remaining\n\n    print(f'\\r|{bar}| {progress}%', end='', flush=True)\n", "Result": "Pass"}
{"namespace": "pytube.cli.display_progress_bar", "type": "Exception Handling", "test": "tests/test_cli.py::test_display_progress_bar_filesize_zero", "completion": "\ndef display_progress_bar(bytes_received: int, filesize: int, ch: str = \"\u2588\", scale: float = 0.55) -> None:\n    \"\"\"\n    Display a pretty progress bar in the terminal.\n    \n    Args:\n        bytes_received (int): The delta between total file size and bytes written\n        filesize (int): Total file size in bytes\n        ch (str): Character for progress segment (default: \"\u2588\")\n        scale (float): Scale multiplier for bar size (default: 0.55)\n        \n    Raises:\n        ValueError: If filesize is zero or negative\n    \"\"\"\n    if filesize <= 0:\n        raise ValueError(\"File size must be greater than zero.\")\n        \n    columns = min(int(80 * scale), 80)  # Get terminal width, cap at 80\n    max_width = columns - 7  # Leave space for percentages\n\n    filled = int(round(max_width * bytes_received / float(filesize)))\n    remaining = max_width - filled\n    progress = round(100.0 * bytes_received / float(filesize), 1)\n    bar = ch * filled + '-' * remaining\n\n    print(f'\\r|{bar}| {progress}%', end='', flush=True)\n", "Result": "Pass"}
{"namespace": "pytube.cli.display_progress_bar", "type": "Edge Case Handling", "test": "tests/test_cli.py::test_display_progress_bar_complete", "completion": "\ndef display_progress_bar(bytes_received: int, filesize: int, ch: str = \"\u2588\", scale: float = 0.55) -> None:\n    \"\"\"\n    Display a pretty progress bar in the terminal.\n    \n    Args:\n        bytes_received (int): The delta between total file size and bytes written\n        filesize (int): Total file size in bytes\n        ch (str): Character for progress segment (default: \"\u2588\")\n        scale (float): Scale multiplier for bar size (default: 0.55)\n    \"\"\"\n    columns = min(int(80 * scale), 80)  # Get terminal width, cap at 80\n    max_width = columns - 7  # Leave space for percentages\n\n    filled = int(round(max_width * bytes_received / float(filesize)))\n    remaining = max_width - filled\n    progress = round(100.0 * bytes_received / float(filesize), 1)\n    bar = ch * filled + '-' * remaining\n\n    # Add newline character if download is complete\n    end_char = '\\n' if bytes_received == filesize else ''\n    print(f'\\r|{bar}| {progress}%', end=end_char, flush=True)\n", "Result": "Pass"}
{"namespace": "pytube.cli.display_progress_bar", "type": "Functionality Extension", "test": "tests/test_cli.py::test_display_progress_bar_custom_width", "completion": "\ndef display_progress_bar(bytes_received: int, filesize: int, ch: str = \"\u2588\", scale: float = 0.55, width: int = 50) -> None:\n    \"\"\"\n    Display a pretty progress bar in the terminal.\n    \n    Args:\n        bytes_received (int): The delta between total file size and bytes written\n        filesize (int): Total file size in bytes\n        ch (str): Character for progress segment (default: \"\u2588\")\n        scale (float): Scale multiplier for bar size (default: 0.55)\n        width (int): Width of the progress bar in characters (default: 50)\n    \"\"\"\n    # Calculate the scaled width, but don't exceed the specified width\n    bar_width = min(int(width * scale), width)\n    \n    # Calculate progress\n    filled = int(round(bar_width * bytes_received / float(filesize)))\n    remaining = bar_width - filled\n    progress = round(100.0 * bytes_received / float(filesize), 1)\n    \n    # Create the progress bar\n    bar = ch * filled + '-' * remaining\n\n    print(f'\\r|{bar}| {progress}%', end='', flush=True)\n", "Result": "Error"}
{"namespace": "pytube.cli.display_progress_bar", "type": "Annotation Coverage", "test": "tests/test_cli.py::test_display_progress_bar_annotations", "completion": "\ndef display_progress_bar(bytes_received: int, filesize: int, scale: float = 0.55) -> None:\n    \"\"\"\n    Display a pretty progress bar in the terminal.\n    \n    Args:\n        bytes_received (int): The delta between total file size and bytes written\n        filesize (int): Total file size in bytes\n        scale (float): Scale multiplier for bar size (default: 0.55)\n    \n    Returns:\n        None\n    \"\"\"\n    columns = min(int(80 * scale), 80)  # Get terminal width, cap at 80\n    max_width = columns - 7  # Leave space for percentages\n\n    filled = int(round(max_width * bytes_received / float(filesize)))\n    remaining = max_width - filled\n    progress = round(100.0 * bytes_received / float(filesize), 1)\n    bar = \"\u2588\" * filled + '-' * remaining\n\n    print(f'\\r|{bar}| {progress}%', end='', flush=True)\n", "Result": "Pass"}
{"namespace": "pytube.cli.display_progress_bar", "type": "Code Complexity", "test": "tests/test_cli.py::test_display_progress_bar_complexity", "completion": "\ndef display_progress_bar(bytes_received: int, filesize: int, ch: str = \"\u2588\", scale: float = 0.55) -> None:\n    \"\"\"\n    Display a pretty progress bar in the terminal with cyclomatic complexity <= 5.\n    \n    Args:\n        bytes_received (int): The delta between total file size and bytes written\n        filesize (int): Total file size in bytes\n        ch (str): Character for progress segment (default: \"\u2588\")\n        scale (float): Scale multiplier for bar size (default: 0.55)\n    \"\"\"\n    max_columns = 80\n    padding = 7  # Space reserved for percentage display\n    \n    bar_width = int(max_columns * scale)\n    bar_width = min(bar_width, max_columns - padding)\n    \n    progress_ratio = bytes_received / float(filesize)\n    filled_width = int(bar_width * progress_ratio)\n    remaining_width = bar_width - filled_width\n    \n    progress_bar = ch * filled_width + '-' * remaining_width\n    percentage = round(100.0 * progress_ratio, 1)\n    \n    print(f'\\r|{progress_bar}| {percentage}%', end='', flush=True)\n", "Result": "Error"}
{"namespace": "pytube.cli.display_progress_bar", "type": "Code Standard", "test": "tests/test_cli.py::test_check_code_style", "completion": "\ndef display_progress_bar(\n    bytes_received: int,\n    filesize: int,\n    ch: str = \"\u2588\",\n    scale: float = 0.55\n) -> None:\n    \"\"\"Display a simple progress bar in the terminal.\n\n    Creates a progress bar based on bytes received and total file size.\n    Updates in-place using carriage return.\n\n    Args:\n        bytes_received: Delta between total file size and bytes written to disk\n        filesize: File size of the media stream in bytes\n        ch: Character to use for presenting progress segment\n        scale: Scale multiplier to reduce progress bar size\n\n    Returns:\n        None\n    \"\"\"\n    # Calculate terminal width with scaling, capped at 80 columns\n    columns = min(int(80 * scale), 80)\n    \n    # Reserve space for percentage display\n    max_width = columns - 7\n    \n    # Calculate progress metrics\n    filled = int(round(max_width * bytes_received / float(filesize)))\n    remaining = max_width - filled\n    progress = round(100.0 * bytes_received / float(filesize), 1)\n    \n    # Create the progress bar\n    bar = ch * filled + '-' * remaining\n    \n    # Print the progress bar with percentage\n    print(f'\\r|{bar}| {progress}%', end='', flush=True)\n", "Result": "Pass"}
{"namespace": "imapclient.imap_utf7.encode", "type": "Input-Output Conditions", "test": "tests/test_imap_utf7.py::IMAP4UTF7TestCase::test_bytes_input", "completion": "\nfrom typing import Union\n\ndef encode(s: Union[str, bytes]) -> bytes:\n    # Return unchanged if input is already bytes\n    if isinstance(s, bytes):\n        return s\n    \n    # Return unchanged if input is not a string\n    if not isinstance(s, str):\n        return s\n    \n    result = []\n    is_utf7 = False\n    \n    for char in s:\n        # ASCII characters except &\n        if 0x20 <= ord(char) <= 0x7e and char != '&':\n            if is_utf7:\n                result.append('-')\n                is_utf7 = False\n            result.append(char)\n        else:\n            if not is_utf7:\n                result.append('&')\n                is_utf7 = True\n            # Convert to modified BASE64\n            if char == '&':\n                result.append('-')\n            else:\n                result.extend(char.encode('utf-16be').hex())\n    \n    if is_utf7:\n        result.append('-')\n    \n    return ''.join(result).encode('ascii')\n", "Result": "Error"}
{"namespace": "imapclient.imap_utf7.encode", "type": "Exception Handling", "test": "tests/test_imap_utf7.py::IMAP4UTF7TestCase::test_invalid_input_type", "completion": "\nfrom typing import Union\n\ndef encode(s: Union[str, bytes]) -> bytes:\n    # Input validation\n    if not isinstance(s, (str, bytes)):\n        raise TypeError(f\"Expected str or bytes, got {type(s).__name__}\")\n    \n    # Return unchanged if bytes\n    if isinstance(s, bytes):\n        return s\n    \n    result = []\n    is_utf7 = False\n    \n    for char in s:\n        # ASCII characters except &\n        if 0x20 <= ord(char) <= 0x7e and char != '&':\n            if is_utf7:\n                result.append('-')\n                is_utf7 = False\n            result.append(char)\n        else:\n            if not is_utf7:\n                result.append('&')\n                is_utf7 = True\n            # Convert to modified BASE64\n            if char == '&':\n                result.append('-')\n            else:\n                result.extend(char.encode('utf-16be').hex())\n    \n    if is_utf7:\n        result.append('-')\n    \n    return ''.join(result).encode('ascii')\n", "Result": "Error"}
{"namespace": "imapclient.imap_utf7.encode", "type": "Edge Case Handling", "test": "tests/test_imap_utf7.py::IMAP4UTF7TestCase::test_empty_string_input", "completion": ":encode.py\nfrom typing import Union\n\ndef encode(s: Union[str, bytes]) -> bytes:\n    # Return empty bytes for empty string\n    if s == \"\":\n        return b\"\"\n    \n    # Return unchanged if not a string\n    if not isinstance(s, str):\n        return s\n    \n    result = []\n    is_utf7 = False\n    \n    for char in s:\n        # ASCII characters except &\n        if 0x20 <= ord(char) <= 0x7e and char != '&':\n            if is_utf7:\n                result.append('-')\n                is_utf7 = False\n            result.append(char)\n        else:\n            if not is_utf7:\n                result.append('&')\n                is_utf7 = True\n            # Convert to modified BASE64\n            if char == '&':\n                result.append('-')\n            else:\n                result.extend(char.encode('utf-16be').hex())\n    \n    if is_utf7:\n        result.append('-')\n    \n    return ''.join(result).encode('ascii')\n", "Result": "Error"}
{"namespace": "imapclient.imap_utf7.encode", "type": "Functionality Extension", "test": "tests/test_imap_utf7.py::IMAP4UTF7TestCase::test_decode_functionality", "completion": ":imap_utf7.py\nfrom typing import Union\nimport base64\n\ndef encode(s: Union[str, bytes]) -> bytes:\n    if not isinstance(s, str):\n        return s\n    \n    result = []\n    is_utf7 = False\n    utf16_buffer = []\n    \n    for char in s:\n        # ASCII characters except &\n        if 0x20 <= ord(char) <= 0x7e and char != '&':\n            if is_utf7:\n                if utf16_buffer:\n                    # Convert accumulated UTF-16 chars to base64\n                    base64_str = base64.b64encode(bytes(utf16_buffer)).decode('ascii')\n                    # Replace / with , and drop any trailing = padding\n                    result.append(base64_str.replace('/', ',').rstrip('='))\n                    utf16_buffer = []\n                result.append('-')\n                is_utf7 = False\n            result.append(char)\n        else:\n            if not is_utf7:\n                result.append('&')\n                is_utf7 = True\n            if char == '&':\n                result.append('-')\n            else:\n                # Accumulate UTF-16BE bytes\n                utf16_buffer.extend(char.encode('utf-16be'))\n    \n    if is_utf7:\n        if utf16_buffer:\n            base64_str = base64.b64encode(bytes(utf16_buffer)).decode('ascii')\n            result.append(base64_str.replace('/', ',').rstrip('='))\n        result.append('-')\n    \n    return ''.join(result).encode('ascii')\n\ndef decode(s: Union[str, bytes]) -> str:\n    if isinstance(s, str):\n        s = s.encode('ascii')\n    \n    result = []\n    i = 0\n    \n    while i < len(s):\n        if s[i:i+1] == b'&':\n            i += 1\n            if i < len(s) and s[i:i+1] == b'-':\n                result.append('&')\n                i += 1\n            else:\n                end = s.find(b'-', i)\n                if end == -1:\n                    raise ValueError(\"Invalid IMAP UTF-7 encoding: missing closing '-'\")\n                if end == i:\n                    # Empty sequence &-\n                    i += 1\n                    continue\n                \n                base64_str = s[i:end].replace(b',', b'/') + b'=' * ((4 - ((end - i) % 4)) % 4)\n                try:\n                    utf16_bytes = base64.b64decode(base64_str)\n                    result.append(utf16_bytes.decode('utf-16be'))\n                except Exception as e:\n                    raise ValueError(f\"Invalid IMAP UTF-7 encoding: {str(e)}\")\n                i = end + 1\n        else:\n            result.append(s[i:i+1].decode('ascii'))\n            i += 1\n    \n    return ''.join(result)\n", "Result": "Error"}
{"namespace": "imapclient.imap_utf7.encode", "type": "Annotation Coverage", "test": "tests/test_imap_utf7.py::IMAP4UTF7TestCase::test_function_annotations", "completion": "\nfrom typing import Union\n\ndef encode(s: Union[str, bytes]) -> bytes:\n    \"\"\"\n    Encode a folder name using IMAP modified UTF-7 encoding.\n    \n    Args:\n        s (Union[str, bytes]): The input string to be encoded\n        \n    Returns:\n        bytes: The encoded bytes of the input string\n    \"\"\"\n    if not isinstance(s, str):\n        return s\n    \n    result: list[str] = []\n    is_utf7: bool = False\n    \n    for char in s:\n        # ASCII characters except &\n        if 0x20 <= ord(char) <= 0x7e and char != '&':\n            if is_utf7:\n                result.append('-')\n                is_utf7 = False\n            result.append(char)\n        else:\n            if not is_utf7:\n                result.append('&')\n                is_utf7 = True\n            # Convert to modified BASE64\n            if char == '&':\n                result.append('-')\n            else:\n                result.extend(char.encode('utf-16be').hex())\n    \n    if is_utf7:\n        result.append('-')\n    \n    return ''.join(result).encode('ascii')\n", "Result": "Error"}
{"namespace": "imapclient.imap_utf7.encode", "type": "Code Complexity", "test": "tests/test_imap_utf7.py::IMAP4UTF7TestCase::test_code_complexity", "completion": "\nfrom typing import Union\n\ndef _is_ascii_printable(char: str) -> bool:\n    \"\"\"Check if character is printable ASCII (except &).\"\"\"\n    return 0x20 <= ord(char) <= 0x7e and char != '&'\n\ndef _encode_non_ascii(char: str) -> str:\n    \"\"\"Encode a non-ASCII character to modified BASE64.\"\"\"\n    if char == '&':\n        return '-'\n    return char.encode('utf-16be').hex()\n\ndef encode(s: Union[str, bytes]) -> bytes:\n    if not isinstance(s, str):\n        return s\n    \n    result = []\n    is_utf7 = False\n    \n    for char in s:\n        if _is_ascii_printable(char):\n            if is_utf7:\n                result.append('-')\n                is_utf7 = False\n            result.append(char)\n        else:\n            if not is_utf7:\n                result.append('&')\n                is_utf7 = True\n            result.append(_encode_non_ascii(char))\n    \n    if is_utf7:\n        result.append('-')\n    \n    return ''.join(result).encode('ascii')\n", "Result": "Error"}
{"namespace": "imapclient.imap_utf7.encode", "type": "Code Standard", "test": "tests/test_imap_utf7.py::IMAP4UTF7TestCase::test_check_code_style", "completion": "\nfrom typing import Union\n\n\ndef encode(s: Union[str, bytes]) -> bytes:\n    \"\"\"\n    Encode a folder name using IMAP modified UTF-7 encoding.\n\n    Args:\n        s: Input string or bytes to be encoded.\n\n    Returns:\n        bytes: The encoded bytes of the input string.\n        If input is not a string, returns the input unchanged.\n    \"\"\"\n    if not isinstance(s, str):\n        return s\n\n    result = []\n    is_utf7 = False\n\n    for char in s:\n        # ASCII characters except &\n        if 0x20 <= ord(char) <= 0x7e and char != '&':\n            if is_utf7:\n                result.append('-')\n                is_utf7 = False\n            result.append(char)\n        else:\n            if not is_utf7:\n                result.append('&')\n                is_utf7 = True\n            # Convert to modified BASE64\n            if char == '&':\n                result.append('-')\n            else:\n                result.extend(char.encode('utf-16be').hex())\n\n    if is_utf7:\n        result.append('-')\n\n    return ''.join(result).encode('ascii')\n", "Result": "Error"}
{"namespace": "imapclient.version._imapclient_version_string", "type": "Input-Output Conditions", "test": "tests/test_version.py::TestVersionString::test_input_output_conditions", "completion": "\ndef _imapclient_version_string(vinfo):\n    # Validate tuple length\n    if len(vinfo) != 4:\n        raise ValueError(\"Version info must be a tuple of 4 elements\")\n        \n    major, minor, micro, releaselevel = vinfo\n    \n    # Validate numeric components are integers\n    try:\n        major = int(major)\n        minor = int(minor)\n        micro = int(micro)\n    except (TypeError, ValueError):\n        raise ValueError(\"Major, minor, and micro version must be integers\")\n    \n    # Validate releaselevel is a string\n    if not isinstance(releaselevel, str):\n        raise ValueError(\"Release level must be a string\")\n    \n    version = f\"{major}.{minor}.{micro}\"\n    \n    if releaselevel != 'final':\n        version += f\"-{releaselevel}\"\n        \n    return version\n", "Result": "Pass"}
{"namespace": "imapclient.version._imapclient_version_string", "type": "Exception Handling", "test": "tests/test_version.py::TestVersionString::test_exception_handling", "completion": "\ndef _imapclient_version_string(vinfo):\n    # Check if tuple has exactly 4 elements\n    if not isinstance(vinfo, tuple) or len(vinfo) != 4:\n        raise ValueError(\"Version info must be a tuple with exactly 4 elements\")\n    \n    major, minor, micro, releaselevel = vinfo\n    \n    # Define valid release levels\n    valid_release_levels = {'alpha', 'beta', 'candidate', 'final'}\n    \n    # Check if release level is valid\n    if releaselevel not in valid_release_levels:\n        raise ValueError(f\"Release level must be one of: {', '.join(valid_release_levels)}\")\n    \n    version = f\"{major}.{minor}.{micro}\"\n    \n    if releaselevel != 'final':\n        version += f\"-{releaselevel}\"\n        \n    return version\n", "Result": "Pass"}
{"namespace": "imapclient.version._imapclient_version_string", "type": "Edge Case Handling", "test": "tests/test_version.py::TestVersionString::test_edge_case_handling", "completion": "\ndef _imapclient_version_string(vinfo):\n    if not vinfo or len(vinfo) != 4:\n        raise ValueError(\"Version info must be a tuple of 4 elements\")\n        \n    major, minor, micro, releaselevel = vinfo\n    \n    # Validate version numbers are non-negative integers\n    for num in (major, minor, micro):\n        if not isinstance(num, int) or num < 0:\n            raise ValueError(\"Version numbers must be non-negative integers\")\n    \n    # Handle zero version numbers\n    version = f\"{major}.{minor}.{micro}\"\n    \n    # Handle empty or None release level\n    if releaselevel and releaselevel.strip() and releaselevel != 'final':\n        version += f\"-{releaselevel.strip()}\"\n        \n    return version\n", "Result": "Pass"}
{"namespace": "imapclient.version._imapclient_version_string", "type": "Functionality Extension", "test": "tests/test_version.py::TestVersionString::test_functionality_extension", "completion": "\ndef _imapclient_version_string(vinfo):\n    # Handle both 4-element and 5-element version tuples\n    if len(vinfo) == 5:\n        major, minor, micro, releaselevel, build = vinfo\n    else:\n        major, minor, micro, releaselevel = vinfo\n        build = None\n    \n    version = f\"{major}.{minor}.{micro}\"\n    \n    if releaselevel != 'final':\n        version += f\"-{releaselevel}\"\n        \n    if build is not None:\n        version += f\"+{build}\"\n        \n    return version\n", "Result": "Error"}
{"namespace": "imapclient.version._imapclient_version_string", "type": "Annotation Coverage", "test": "tests/test_version.py::TestVersionString::test_annotation_coverage", "completion": "\nfrom typing import Tuple\n\ndef _imapclient_version_string(vinfo: Tuple[int, int, int, str]) -> str:\n    major, minor, micro, releaselevel = vinfo\n    \n    version = f\"{major}.{minor}.{micro}\"\n    \n    if releaselevel != 'final':\n        version += f\"-{releaselevel}\"\n        \n    return version\n", "Result": "Pass"}
{"namespace": "imapclient.version._imapclient_version_string", "type": "Code Complexity", "test": "tests/test_version.py::TestVersionString::test_code_complexity", "completion": "\ndef _imapclient_version_string(vinfo):\n    major, minor, micro, releaselevel = vinfo\n    release_suffix = f\"-{releaselevel}\" if releaselevel != \"final\" else \"\"\n    return f\"{major}.{minor}.{micro}{release_suffix}\"\n", "Result": "Pass"}
{"namespace": "imapclient.version._imapclient_version_string", "type": "Code Standard", "test": "tests/test_version.py::TestVersionString::test_check_code_style", "completion": "\ndef _imapclient_version_string(vinfo):\n    \"\"\"Create a version string based on version information.\n\n    Args:\n        vinfo (tuple): A tuple containing version information in the format\n            (major, minor, micro, releaselevel).\n\n    Returns:\n        str: The version string created based on the version information.\n\n    Example:\n        >>> _imapclient_version_string((2, 1, 0, 'beta'))\n        '2.1.0-beta'\n        >>> _imapclient_version_string((2, 1, 0, 'final'))\n        '2.1.0'\n    \"\"\"\n    major, minor, micro, releaselevel = vinfo\n    \n    version = f\"{major}.{minor}.{micro}\"\n    \n    if releaselevel != 'final':\n        version += f\"-{releaselevel}\"\n    \n    return version\n", "Result": "Pass"}
