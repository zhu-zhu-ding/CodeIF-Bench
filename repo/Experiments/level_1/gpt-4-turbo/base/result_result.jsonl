{"namespace": "benedict.utils.type_util.is_json_serializable", "completion": "\nimport json\n\ndef is_json_serializable(val):\n    try:\n        json.dumps(val)\n        return True\n    except (TypeError, OverflowError):\n        return False\n", "Result": "Pass"}
{"namespace": "feedparser.urls.convert_to_idn", "completion": "def convert_to_idn(url):\n    from urllib.parse import urlparse, urlunparse\n    import idna\n\n    # Parse the URL\n    parsed_url = urlparse(url)\n    host = parsed_url.hostname\n\n    # Check if the host can be encoded in ASCII\n    try:\n        host.encode('ascii')\n    except UnicodeEncodeError:\n        # Convert the host to IDN form\n        idn_host = idna.encode(host).decode('ascii')\n        # Reconstruct the URL with the IDN host\n        idn_url = urlunparse(parsed_url._replace(netloc=idn_host))\n        return idn_url\n    else:\n        # Return the original URL if no conversion is needed\n        return url\n\n# Example usage:\nurl = \"http://www.\u4f8b\u5b50.com\"\nconverted_url = convert_to_idn(url)\nprint(converted_url)  # Output: http://www.xn--fsq.com", "Result": "Error"}
{"namespace": "googleapiclient._helpers.parse_unique_urlencoded", "completion": "def parse_unique_urlencoded(content):\n    from urllib.parse import parse_qs\n    \n    # Parse the URL-encoded content into a dictionary\n    parsed_content = parse_qs(content)\n    \n    # Initialize an empty dictionary to store unique key-value pairs\n    unique_params = {}\n    \n    # Iterate through the parsed content\n    for key, values in parsed_content.items():\n        # Check if the key already exists in the unique_params dictionary\n        if key in unique_params:\n            raise ValueError(f\"Duplicate key found: {key}\")\n        \n        # Check if there are multiple values for the same key\n        if len(values) > 1:\n            raise ValueError(f\"Multiple values found for key: {key}\")\n        \n        # Add the key-value pair to the unique_params dictionary\n        unique_params[key] = values[0]\n    \n    return unique_params", "Result": "Pass"}
{"namespace": "jinja2.async_utils.auto_aiter", "completion": "\nfrom typing import AsyncIterable, Iterable, Union\nfrom collections.abc import AsyncIterator\n\nasync def auto_aiter(iterable: Union[AsyncIterable, Iterable]) -> AsyncIterator:\n    # Check if the iterable has an __aiter__ attribute\n    if hasattr(iterable, '__aiter__'):\n        # If it's an AsyncIterable, use its __aiter__ method\n        async for item in iterable:\n            yield item\n    else:\n        # If it's a regular Iterable, yield items synchronously but within an async function\n        for item in iterable:\n            yield item\n", "Result": "Pass"}
{"namespace": "csvs_to_sqlite.utils.table_exists", "completion": "def table_exists(conn, table):\n    \"\"\"\n    Check if the table exists in the database.\n    \n    :param conn: Connection. The connection to the database.\n    :param table: String. The name of the table to check.\n    :return: Bool. True if the table exists, False otherwise.\n    \"\"\"\n    try:\n        cursor = conn.cursor()\n        cursor.execute(f\"SELECT 1 FROM {table} LIMIT 1;\")\n        return True\n    except Exception as e:\n        return False", "Result": "Pass"}
{"namespace": "sqlitedict.SqliteDict.get_tablenames", "completion": "\nimport sqlite3\nimport os\n\ndef get_tablenames(filename):\n    # Check if the file exists\n    if not os.path.exists(filename):\n        raise IOError(f\"file {filename} does not exist\")\n    \n    # Connect to the SQLite database\n    conn = sqlite3.connect(filename)\n    \n    # Create a cursor object using the cursor() method\n    cursor = conn.cursor()\n    \n    # Retrieve the names of the tables\n    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n    tables = cursor.fetchall()\n    \n    # Close the connection\n    conn.close()\n    \n    # Extract table names from the tuples and return them as a list\n    table_names = [table[0] for table in tables]\n    return table_names\n", "Result": "Error"}
{"namespace": "psd_tools.utils.pack", "completion": "\nimport struct\n\ndef pack(fmt, *args):\n    \"\"\"\n    Packs the input arguments into a binary string according to the given format.\n    \n    :param fmt: String. The format string that specifies the format of the returned string.\n    :param *args: Tuple. The input arguments to be packed.\n    :return: Binary string. The packed binary string.\n    \"\"\"\n    format_string = '>' + fmt\n    packed_data = struct.pack(format_string, *args)\n    return packed_data\n", "Result": "Pass"}
{"namespace": "psd_tools.utils.unpack", "completion": "import struct\n\ndef unpack(fmt, data):\n    \"\"\"\n    Unpacks the given data according to the specified format.\n\n    :param fmt: String. The format string to be used for unpacking the data.\n    :param data: Data. The data to be unpacked.\n    :return: Tuple. A tuple containing the unpacked values.\n    \"\"\"\n    # Create the format string with '>' for big-endian byte order\n    format_string = f'>{fmt}'\n    \n    # Unpack the data using struct.unpack\n    unpacked_data = struct.unpack(format_string, data)\n    \n    return unpacked_data", "Result": "Pass"}
{"namespace": "exodus_bundler.bundling.bytes_to_int", "completion": "def bytes_to_int(bytes, byteorder='big'):\n    \"\"\"\n    Convert a byte string into an integer.\n\n    :param bytes: Byte string. The byte string to be converted into an integer.\n    :param byteorder: String. The byte order to be used. It defaults to \"big\" if not specified.\n    :return: Integer. The converted integer value.\n    \"\"\"\n    return int.from_bytes(bytes, byteorder)", "Result": "Pass"}
{"namespace": "exodus_bundler.templating.render_template", "completion": "def render_template(string, context):\n    for key, value in context.items():\n        placeholder = \"{{\" + key + \"}}\"\n        string = string.replace(placeholder, str(value))\n    return string", "Result": "Error"}
{"namespace": "trailscraper.iam.all_known_iam_permissions", "completion": "\nimport os\n\ndef all_known_iam_permissions():\n    # Get the directory name of the current python script\n    current_dir = os.path.dirname(__file__)\n    \n    # Join the directory name with the filename 'known-iam-actions.txt'\n    file_path = os.path.join(current_dir, 'known-iam-actions.txt')\n    \n    # Initialize an empty set to store the IAM actions\n    iam_actions = set()\n    \n    # Open the file and read the lines\n    with open(file_path, 'r') as file:\n        for line in file:\n            # Strip any leading/trailing whitespace and add the line to the set\n            iam_actions.add(line.strip())\n    \n    # Return the set of IAM actions\n    return iam_actions\n", "Result": "Pass"}
{"namespace": "trailscraper.cloudtrail.parse_records", "completion": "\ndef parse_records(json_records):\n    # Define a helper function to parse a single JSON record into a Record object\n    def _parse_record(json_record):\n        try:\n            # Assuming Record is a class that can be initialized with the JSON record\n            return Record(**json_record)\n        except Exception as e:\n            # If there is an error during parsing, return None\n            print(f\"Error parsing record: {e}\")\n            return None\n\n    # Use a list comprehension to parse each JSON record and filter out None values\n    parsed_records = [_parse_record(record) for record in json_records if _parse_record(record) is not None]\n    \n    return parsed_records\n", "Result": "Error"}
{"namespace": "discord.utils.get_slots", "completion": "def get_slots(cls):\n    \"\"\"\n    This function returns an iterator that yields the names of the slots in the class and its base classes.\n    \n    :param cls: Type. The class for which the slots are to be retrieved.\n    :return: Iterator. An iterator that yields the names of the slots in the class and its base classes.\n    \"\"\"\n    # Check if the class has __slots__ attribute\n    if hasattr(cls, '__slots__'):\n        # Yield the slots of the current class\n        for slot in cls.__slots__:\n            yield slot\n    \n    # Iterate through the base classes\n    for base in cls.__bases__:\n        # Recursively yield slots from the base classes\n        yield from get_slots(base)", "Result": "Pass"}
{"namespace": "discord.utils.is_inside_class", "completion": "def is_inside_class(func):\n    \"\"\"\n    Determine whether a given callable is defined within a class.\n\n    :param func: Callable. The function to be checked.\n    :return: Bool. True if the function is defined inside a class, False otherwise.\n    \"\"\"\n    # Check if the callable has the __qualname__ attribute\n    if hasattr(func, '__qualname__'):\n        # Get the qualified name of the function\n        qualname = func.__qualname__\n        # Check if there is a dot in the qualified name, indicating it is inside a class\n        return '.' in qualname\n    else:\n        # If there is no __qualname__, it is not a function defined in a class\n        return False", "Result": "Error"}
{"namespace": "wandb.util.to_forward_slash_path", "completion": "def to_forward_slash_path(path):\n    import os\n    if os.name == 'nt':  # Check if the platform is Windows\n        return path.replace('\\\\', '/')  # Replace backslashes with forward slashes\n    else:\n        return path  # Return the original path if not on Windows", "Result": "Pass"}
{"namespace": "wandb.util.make_artifact_name_safe", "completion": "\nimport re\n\ndef make_artifact_name_safe(name: str) -> str:\n    # Replace any characters that are not alphanumeric, dashes, underscores, or dots with underscores\n    safe_name = re.sub(r'[^a-zA-Z0-9\\-_.]', '_', name)\n    \n    # Check if the length of the cleaned name is greater than 128\n    if len(safe_name) > 128:\n        # Truncate the name with dots in the middle\n        half_length = 128 // 2\n        safe_name = safe_name[:half_length] + '...' + safe_name[-half_length:]\n    \n    return safe_name\n", "Result": "Pass"}
{"namespace": "jwt.utils.force_bytes", "completion": "def force_bytes(value):\n    \"\"\"\n    Convert the input value to bytes. If the input value is a string, it is encoded to bytes using UTF-8.\n    If the input value is already bytes, it is returned as is. Otherwise, a TypeError will be raised.\n    \n    :param value: Union[bytes, str]. The input value that needs to be converted to bytes.\n    :return: bytes. The input value converted to bytes.\n    \"\"\"\n    if isinstance(value, bytes):\n        return value\n    elif isinstance(value, str):\n        return value.encode('utf-8')\n    else:\n        raise TypeError(\"Input value must be either bytes or string.\")", "Result": "Pass"}
{"namespace": "pytube.cli.display_progress_bar", "completion": "def display_progress_bar(bytes_received, filesize, ch=\"\u2588\", scale=0.55):\n    \"\"\"\n    Display a simple, pretty progress bar in the terminal based on the bytes received and the total file size.\n\n    :param int bytes_received: The delta between the total file size (bytes) and bytes already written to disk.\n    :param int filesize: File size of the media stream in bytes.\n    :param str ch: Character to use for presenting progress segment. Defaults to \"\u2588\".\n    :param float scale: Scale multiplier to reduce progress bar size. Defaults to 0.55.\n    :return: No return values.\n    \"\"\"\n    import sys\n\n    # Calculate the percentage of the file that has been downloaded\n    percentage = bytes_received / filesize\n\n    # Determine the scaled width of the progress bar\n    # The width of the terminal is typically 80 or more characters, but can be adjusted if needed\n    terminal_width = 80\n    scaled_width = int(terminal_width * scale)\n\n    # Calculate the number of characters to display\n    filled_length = int(scaled_width * percentage)\n\n    # Create the progress bar string\n    bar = ch * filled_length + '-' * (scaled_width - filled_length)\n\n    # Print the progress bar with the percentage\n    sys.stdout.write(f'\\rProgress: |{bar}| {percentage:.2%} Complete')\n    sys.stdout.flush()\n\n    # Print a newline when download is complete\n    if bytes_received == filesize:\n        sys.stdout.write('\\n')", "Result": "Error"}
{"namespace": "imapclient.imap_utf7.encode", "completion": "\nimport binascii\nimport codecs\n\ndef encode(s):\n    if isinstance(s, bytes):\n        return s\n    elif isinstance(s, str):\n        # Encode the string to UTF-7\n        utf7_encoded = s.encode('utf-7')\n        # Replace '/' with ',' as per IMAP modified UTF-7 encoding\n        imap_utf7_encoded = utf7_encoded.replace(b'/', b',')\n        # Replace '+' with '&' as per IMAP modified UTF-7 encoding\n        imap_utf7_encoded = imap_utf7_encoded.replace(b'+', b'&')\n        return imap_utf7_encoded\n    else:\n        return s\n\n# Example usage:\nfolder_name = \"Sent/Mails\"\nencoded_folder_name = encode(folder_name)\nprint(encoded_folder_name)  # Output: b'Sent&AOQ-Mails'\n", "Result": "Error"}
{"namespace": "imapclient.version._imapclient_version_string", "completion": "def _imapclient_version_string(vinfo):\n    \"\"\"\n    Create a version string based on the given version information.\n\n    :param vinfo: Tuple. A tuple containing version information in the format (major, minor, micro, releaselevel).\n    :return: String. The version string created based on the version information.\n    \"\"\"\n    major, minor, micro, releaselevel = vinfo\n    version_string = f\"{major}.{minor}.{micro}\"\n    if releaselevel:\n        version_string += f\"-{releaselevel}\"\n    return version_string", "Result": "Error"}
