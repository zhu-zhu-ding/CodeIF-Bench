[
    {
        "namespace": "benedict.utils.type_util.is_json_serializable",
        "completion": "To create a function named `is_json_serializable` that checks whether an input value is JSON serializable, you can utilize Python's built-in `json` module. This module provides a `dumps` method which can be used to serialize simple data structures (like dictionaries, lists, strings, numbers, and booleans) into JSON format. If the `dumps` method raises a `TypeError`, it indicates that the given object cannot be serialized as JSON.\n\nHere is how you could implement this:\n\n```python\nimport json\n\ndef is_json_serializable(val):\n    \"\"\"\n    Check if the input value is JSON serializable.\n    \n    Parameters:\n    :param val: Any - The input value to be checked for JSON serializability.\n    \n    Returns:\n    :return: bool - True if the input value is JSON serializable, False otherwise.\n    \"\"\"\n    try:\n        json.dumps(val)\n        return True\n    except (TypeError, OverflowError):\n        # A TypeError occurs if the type is not serializable,\n        # and an OverflowError occurs with integers too large for JavaScript\n        return False\n\n# Example usage:\nprint(is_json_serializable({\"name\": \"Alice\", \"age\": 25}))  # True\nprint(is_json_serializable([1, 2, 3]))                     # True\nprint(is_json_serializable(\"Hello\"))                       # True\nprint(is_json_serializable(42))                            # True\nprint(is_json_serializable(None))                          # True\nprint(is_json_serializable(complex(1, 2)))                 # False\nprint(is_json_serializable(lambda x: x + 1))               # False\n```\n\nThis function tries to serialize the provided value using `json.dumps`. If successful, it returns `True`, indicating that the value is JSON serializable. If `json.dumps` fails due to a `TypeError` or `OverflowError`, it catches the exception and returns `False`.\n\nNote: This function assumes standard JSON serialization behavior. Custom classes or objects may require additional handling to make them JSON serializable, such as defining a `__json__()` method or providing a custom encoder to `json.dumps()`."
    },
    {
        "namespace": "feedparser.urls.convert_to_idn",
        "completion": "To accomplish the task of converting a URL's domain name to Internationalized Domain Name (IDN) notation if it cannot be encoded in ASCII, we can use Python's `idna` library, which provides functions for encoding and decoding domain names according to the IDNA 2008 standard.\n\nHere is how you can implement the `convert_to_idn` function:\n\n```python\nfrom urllib.parse import urlparse, urlunparse\nimport idna\n\ndef convert_to_idn(url):\n    \"\"\"\n    Converts a URL to IDN notation if the host cannot be encoded in ASCII.\n    \n    :param url: String. The URL to be converted to IDN notation.\n    :return: String. The URL in IDN notation.\n    \"\"\"\n    # Parse the URL to separate its components\n    parsed_url = urlparse(url)\n    \n    # Try to encode the host part of the URL using ASCII\n    try:\n        parsed_url.hostname.encode('ascii')\n    except UnicodeEncodeError:\n        # If encoding fails, then the hostname contains non-ASCII characters\n        # Convert the host to IDN form\n        idn_host = idna.encode(parsed_url.hostname).decode('ascii')\n        \n        # Reconstruct the URL with the new IDN-encoded host\n        new_url_parts = (\n            parsed_url.scheme,\n            idn_host,\n            parsed_url.path,\n            parsed_url.params,\n            parsed_url.query,\n            parsed_url.fragment\n        )\n        return urlunparse(new_url_parts)\n    \n    # If no exception occurred, the hostname was already ASCII and no conversion is needed\n    return url\n\n# Example usage\nurl = \"http://\u043f\u0440\u0438\u043c\u0435\u0440.\u0440\u0444/path\"\nidn_url = convert_to_idn(url)\nprint(idn_url)  # Output: http://xn--e1afmkfd.xn--p1ai/path\n```\n\nIn this script:\n1. We parse the URL into its component parts using `urlparse`.\n2. We attempt to encode the `hostname` part of the URL in ASCII.\n3. If an exception (`UnicodeEncodeError`) occurs, it means the hostname contains non-ASCII characters, so we proceed to convert it to IDN form using `idna.encode`.\n4. We reconstruct the URL using `urlunparse`, replacing only the hostname with its IDN-encoded version.\n5. If the original hostname could be encoded in ASCII without raising an error, we simply return the original URL as no conversion is necessary."
    },
    {
        "namespace": "googleapiclient._helpers.parse_unique_urlencoded",
        "completion": "Certainly! Below is a Python function named `parse_unique_urlencoded` that accomplishes the task described:\n\n```python\ndef parse_unique_urlencoded(content):\n    \"\"\"\n    Parses unique key-value parameters from URL-encoded content.\n    \n    :param content: string. URL-encoded key-value pairs.\n    :return: dict. The key-value pairs from the input content.\n    :raises ValueError: if one of the keys is repeated.\n    \"\"\"\n    # Importing necessary module\n    from urllib.parse import parse_qs, urlparse\n    \n    # Parse the query part of the URL into a dictionary with lists of values\n    parsed_content = parse_qs(content)\n    \n    # Prepare a dictionary to store the final key-value pairs\n    result_dict = {}\n    \n    # Iterate over each item in the parsed content\n    for key, values_list in parsed_content.items():\n        # Check if the key already exists in the result_dict\n        if key in result_dict:\n            raise ValueError(f\"Key '{key}' is repeated.\")\n        # Assign the first value to the key (assuming no duplicates allowed in keys)\n        result_dict[key] = values_list[0]\n    \n    return result_dict\n\n# Example usage\ntry:\n    url_encoded_data = \"key1=value1&key2=value2&key3=value3\"\n    print(parse_unique_urlencoded(url_encoded_data))\nexcept ValueError as e:\n    print(e)\n\ntry:\n    url_encoded_data_with_duplicates = \"key1=value1&key2=value2&key1=value3\"\n    print(parse_unique_urlencoded(url_encoded_data_with_duplicates))\nexcept ValueError as e:\n    print(e)\n```\n\nThis function takes a URL-encoded string as an argument, parses it, and returns a dictionary containing the unique key-value pairs. If a duplicate key is detected, it raises a `ValueError`. Note that this implementation assumes that the URL-encoded content does not contain multiple values for the same key unless those keys are duplicated (which is not allowed as per the requirements)."
    },
    {
        "namespace": "jinja2.async_utils.auto_aiter",
        "completion": "To create an asynchronous iterator from a given iterable in Python, you need to consider both asynchronous and synchronous iterables. If the iterable has an `__aiter__` method, it is treated as an asynchronous iterable and will be handled accordingly. Otherwise, it is treated as a synchronous iterable.\n\nHere's how you can implement the `auto_aiter` function:\n\n```python\nfrom typing import AsyncIterable, Iterable, Union\n\nasync def auto_aiter(iterable: Union[AsyncIterable, Iterable]):\n    \"\"\"\n    Creates an asynchronous iterator from the given iterable.\n    \n    Checks if the iterable has an __aiter__ attribute and if so,\n    it yields items asynchronously, otherwise yields items synchronously.\n    \n    :param iterable: Union[AsyncIterable, Iterable] - The input iterable.\n    :return: AsyncIterator - Asynchronous iterator.\n    \"\"\"\n    try:\n        async_iter = iterable.__aiter__()\n    except AttributeError:\n        # Fallback for synchronous iterables\n        async def sync_to_async_gen():\n            for item in iterable:\n                yield item\n        async_iter = sync_to_async_gen().__aiter__()\n    \n    while True:\n        try:\n            value = await async_iter.__anext__()\n            yield value\n        except StopAsyncIteration:\n            break\n\n# Example usage:\n# For a synchronous iterable\n# async for item in auto_aiter([1, 2, 3]):\n#     print(item)\n\n# For an asynchronous iterable\n# async for item in auto_aiter(asyncio.sleep(1) for _ in range(3)):\n#     print(item)\n```\n\nThis function first tries to get an asynchronous iterator using `iterable.__aiter__()`. If the iterable does not have this attribute (indicating that it is a synchronous iterable), it wraps the iterable into an asynchronous generator using `sync_to_async_gen()`, which yields each item in the iterable one by one. This allows the function to handle both types of iterables uniformly, providing an asynchronous iterator interface for the caller."
    },
    {
        "namespace": "csvs_to_sqlite.utils.table_exists",
        "completion": "To create a Python function named `table_exists` that checks if a table exists within a given database connection, you can use SQL queries depending on the type of database you are working with. The example provided here assumes you're using an SQLite database because it's a common choice for simple applications and it's built into Python's standard library. If you're using another type of database (like PostgreSQL, MySQL, etc.), the SQL query might need to be adjusted.\n\nHere is how you can implement this for an SQLite database:\n\n```python\nimport sqlite3\n\ndef table_exists(conn, table):\n    \"\"\"\n    Checks if the specified table exists in the database.\n\n    :param conn: A database connection object.\n    :param table: Name of the table to check.\n    :return: True if the table exists, False otherwise.\n    \"\"\"\n    try:\n        # Query the SQLite_master table which contains schema information for user tables\n        cursor = conn.cursor()\n        cursor.execute(f\"SELECT name FROM sqlite_master WHERE type='table' AND name=?\", (table,))\n        result = cursor.fetchone()\n        return result is not None\n    except sqlite3.Error as e:\n        print(f\"An error occurred: {e}\")\n        return False\n\n# Example usage\nif __name__ == \"__main__\":\n    # Establishing a connection to the SQLite database\n    conn = sqlite3.connect('example.db')\n    \n    # Check if a certain table exists\n    print(table_exists(conn, 'my_table'))  # Replace 'my_table' with your actual table name\n    \n    # Close the connection\n    conn.close()\n```\n\nThis script defines the `table_exists` function that takes a database connection (`conn`) and a table name (`table`) as parameters. It uses SQL to query the `sqlite_master` table, which stores metadata about the database, including tables. If the query returns a result, it means the table exists, and the function returns `True`. Otherwise, it returns `False`.\n\nRemember to replace `'example.db'` with your actual database file path if you're not using an in-memory SQLite database, and `'my_table'` with the name of the table you wish to check. Also, ensure you have the necessary permissions and the database is correctly set up."
    },
    {
        "namespace": "sqlitedict.SqliteDict.get_tablenames",
        "completion": "Sure! Below is a Python function `get_tablenames` that performs the task as described:\n\n```python\nimport sqlite3\nimport os\n\ndef get_tablenames(filename):\n    # Check if the file exists\n    if not os.path.exists(filename):\n        raise IOError(f'file {filename} does not exist')\n\n    # Connect to the SQLite database\n    conn = sqlite3.connect(filename)\n    cursor = conn.cursor()\n    \n    try:\n        # Query to retrieve table names\n        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n        tables = cursor.fetchall()\n        \n        # Extract table names from the result set\n        table_names = [table[0] for table in tables]\n        \n        return table_names\n    finally:\n        # Ensure the connection is closed properly\n        conn.close()\n\n# Example usage\n# Assuming you have an SQLite database file named 'example.db'\n# print(get_tablenames('example.db'))\n```\n\nThis function first checks if the provided SQLite database file exists using `os.path.exists`. If the file does not exist, it raises an `IOError` with a formatted message indicating the file's absence.\n\nIf the file does exist, the function connects to the SQLite database using `sqlite3.connect`, then creates a cursor object to execute SQL commands. It uses a query to fetch all the table names in the database and extracts these names into a list, which it returns.\n\nFinally, it ensures that the connection to the SQLite database is closed properly after executing the query, even if an error occurs during execution. This is achieved through the use of a `finally` block."
    },
    {
        "namespace": "psd_tools.utils.pack",
        "completion": "Certainly! Below is a Python function named `pack` that takes a format string and a variable number of arguments. It uses the `struct` module to pack the arguments into a binary string according to the specified format.\n\n```python\nimport struct\n\ndef pack(fmt, *args):\n    \"\"\"\n    Packs the input arguments into a binary string according to the given format.\n\n    Parameters:\n    :param fmt: String. The format string that specifies the format of the returned string.\n    :param *args: Tuple. The input arguments to be packed.\n    \n    Returns:\n    :return: Binary string. The packed binary string.\n    \"\"\"\n    # The '<' or '>' in fmt specifies the endianness (little/big). We assume it's correctly provided.\n    try:\n        packed_data = struct.pack(fmt, *args)\n        return packed_data\n    except struct.error as e:\n        print(f\"Error during packing: {e}\")\n        return None\n\n# Example usage:\nfmt = \">Iff\"  # Big-endian unsigned int followed by two floats\nvalues = (12345, 3.14, -273.15)\n\nbinary_string = pack(fmt, *values)\nprint(binary_string)  # Output will be a binary string\n```\n\n### Explanation:\n- **`fmt`**: This is a format string passed to `struct.pack`. The format string includes characters such as `<`, `>`, `I`, `f`, etc., which dictate how the arguments should be packed.\n- **`*args`**: This allows the function to accept a variable number of arguments.\n- **`struct.pack(fmt, *args)`**: This function call packs the arguments (`*args`) according to the format specified in `fmt`.\n- **Error Handling**: A simple error handling mechanism is included to catch any issues during packing.\n\n### Notes:\n- Make sure the format string `fmt` matches the types and order of the `args`.\n- The endianness (`<` for little-endian, `>` for big-endian) should be correctly specified in the format string."
    },
    {
        "namespace": "psd_tools.utils.unpack",
        "completion": "Certainly! Below is an implementation of the `unpack` function in Python that uses the `struct` module to unpack binary data according to a specified format string.\n\n```python\nimport struct\n\ndef unpack(fmt, data):\n    \"\"\"\n    Unpacks the given data according to the specified format string.\n    \n    Parameters:\n    :param fmt: str. The format string to be used for unpacking the data.\n    :param data: bytes. The data to be unpacked.\n    \n    Returns:\n    :return: tuple. A tuple containing the unpacked values.\n    \"\"\"\n    # Ensure the format string starts with '>'\n    if not fmt.startswith('>'):\n        raise ValueError(\"Format string must start with '>' for big-endian byte order.\")\n    \n    # Use struct.unpack to unpack the data according to the format string\n    try:\n        unpacked_data = struct.unpack(fmt, data)\n    except struct.error as e:\n        raise ValueError(f\"Error during unpacking: {e}\")\n    \n    return unpacked_data\n\n# Example usage:\nif __name__ == \"__main__\":\n    # Example data and format\n    data = b'\\x00\\x01\\x02\\x03'\n    fmt = '>HH'  # Two unsigned short integers (big-endian)\n    \n    # Unpack the data\n    result = unpack(fmt, data)\n    print(result)  # Output: (1, 515)\n```\n\n### Explanation:\n- **fmt**: A format string starting with `>` indicating big-endian byte order. Common format characters include `H` for unsigned short (2 bytes), `I` for unsigned int (4 bytes), etc.\n- **data**: The binary data to be unpacked. This should be provided as a `bytes` object.\n- The function checks if the format string starts with `>` and raises a `ValueError` if it does not.\n- It then attempts to unpack the data using `struct.unpack`, catching any errors and raising a `ValueError` with an appropriate message.\n- Finally, it returns the unpacked data as a tuple.\n\nThis function can be adapted based on the specific requirements and error handling needed for your application."
    },
    {
        "namespace": "exodus_bundler.bundling.bytes_to_int",
        "completion": "Certainly! To convert a byte string into an integer in Python, you can use the `int.from_bytes` method which is specifically designed for this purpose. Below is the implementation of the `bytes_to_int` function as per your requirements:\n\n```python\ndef bytes_to_int(bytes_str, byteorder=\"big\"):\n    \"\"\"\n    Converts a byte string into an integer.\n\n    Parameters:\n    :param bytes_str: Byte string. The byte string to be converted into an integer.\n    :param byteorder: String. The byte order to be used. Defaults to \"big\".\n\n    Returns:\n    :return: Integer. The converted integer value.\n    \"\"\"\n    return int.from_bytes(bytes_str, byteorder)\n\n# Example usage:\nbyte_string = b'\\x00\\x10'\ninteger_value = bytes_to_int(byte_string)  # Assuming big-endian byte order\nprint(integer_value)  # Output will depend on the byte order\n```\n\nIn this code:\n- `bytes_str` is the byte string that needs to be converted.\n- `byteorder` parameter specifies the byte order (\"big\" or \"little\"). If not provided, it defaults to \"big\".\n- `int.from_bytes(bytes_str, byteorder)` converts the byte string into an integer based on the specified byte order.\n\nThis function should cover the specific requirement you described."
    },
    {
        "namespace": "exodus_bundler.templating.render_template",
        "completion": "Certainly! Below is an implementation of the `render_template` function which takes a string and a dictionary (context) as inputs and replaces placeholders in the string with corresponding values from the dictionary.\n\n```python\ndef render_template(string: str, context: dict) -> str:\n    \"\"\"\n    Replaces placeholders in the input string with the corresponding values from the context dictionary.\n\n    Parameters:\n    :param string: String. The input string containing placeholders.\n    :param context: Dictionary. The key-value pairs to replace the placeholders in the input string.\n    \n    Returns:\n    :return: String. The modified string after replacing the placeholders.\n    \"\"\"\n    # Use .format() method for string formatting\n    return string.format(**context)\n\n# Example usage:\nif __name__ == \"__main__\":\n    template = \"Hello, {name}! Today is {day}.\"\n    context = {\"name\": \"Alice\", \"day\": \"Monday\"}\n    result = render_template(template, context)\n    print(result)  # Output: Hello, Alice! Today is Monday.\n```\n\n### Explanation:\n- **Placeholders**: In this function, placeholders in the string are expected to be in the form of `{key}`, where `key` corresponds to one of the keys in the `context` dictionary.\n- **String Formatting**: The `.format()` method is used to perform the replacement. By passing `**context`, all key-value pairs in the dictionary are unpacked and used as keyword arguments to the `.format()` method.\n- **Example**: The example provided shows how you can use this function with a simple greeting template and a context dictionary containing the name and day.\n\nThis function is quite flexible and can handle any number of placeholders as long as they match the keys in the provided dictionary."
    },
    {
        "namespace": "trailscraper.iam.all_known_iam_permissions",
        "completion": "To achieve this task, you can use the `os` module to handle file paths and the `set` data structure to ensure that each action is unique. Below is a Python function `all_known_iam_permissions` that reads from a file named `known-iam-actions.txt` located in the same directory as the script and returns a set containing each action listed on its own line.\n\nHere's the implementation:\n\n```python\nimport os\n\ndef all_known_iam_permissions():\n    # Get the directory name of the current script\n    dir_name = os.path.dirname(__file__)\n    \n    # Construct the path to the 'known-iam-actions.txt' file\n    actions_file_path = os.path.join(dir_name, 'known-iam-actions.txt')\n    \n    # Initialize an empty set to store IAM actions\n    iam_actions = set()\n    \n    try:\n        # Open the file and read all lines\n        with open(actions_file_path, 'r') as file:\n            # Add each line (action) stripped of leading/trailing whitespace to the set\n            for line in file:\n                action = line.strip()\n                if action:  # Ensure the line is not empty\n                    iam_actions.add(action)\n    except FileNotFoundError:\n        print(f\"The file {actions_file_path} was not found.\")\n    \n    return iam_actions\n\n# Example usage\nif __name__ == \"__main__\":\n    permissions = all_known_iam_permissions()\n    print(permissions)\n```\n\n### Explanation:\n1. **Directory Path Construction**: \n   - `os.path.dirname(__file__)` gets the directory of the current script.\n   - `os.path.join(dir_name, 'known-iam-actions.txt')` constructs the full path to the actions file.\n\n2. **Reading the File**:\n   - The file is opened in read mode (`'r'`).\n   - Each line is stripped of any leading or trailing whitespace using `strip()`.\n   - Only non-empty lines are added to the `iam_actions` set.\n   \n3. **Error Handling**:\n   - If the file does not exist, a `FileNotFoundError` is caught, and a message is printed.\n\n4. **Return Value**:\n   - The set of IAM actions is returned.\n\nThis function ensures that you get a clean, unique set of IAM actions from the specified file."
    },
    {
        "namespace": "trailscraper.cloudtrail.parse_records",
        "completion": "Certainly! Below is the Python code for the `parse_records` function, based on your specifications. Note that since you mentioned `_parse_record`, it's assumed that this helper function already exists or will be defined separately. If `_parse_record` is not already implemented, you might need to define it according to your specific parsing needs.\n\n```python\nfrom typing import List, Optional\n\n# Assuming Record is a predefined class\nclass Record:\n    def __init__(self, data):\n        self.data = data\n\ndef _parse_record(json_record) -> Optional[Record]:\n    \"\"\"\n    Parses a single JSON record and returns a Record object.\n    Returns None if the record cannot be parsed.\n    \n    This is a placeholder implementation. Replace with actual parsing logic.\n    \"\"\"\n    # Example placeholder implementation\n    try:\n        return Record(json_record)\n    except Exception as e:\n        print(f\"Failed to parse record: {json_record}. Error: {str(e)}\")\n        return None\n\ndef parse_records(json_records: List) -> List[Record]:\n    \"\"\"\n    Takes a list of JSON records and converts them into Record objects using the _parse_record function.\n    Filters out any None values from the parsed records.\n\n    :param json_records: List. A list of JSON records to be parsed.\n    :return: List. A list of Record objects parsed from the JSON records.\n    \"\"\"\n    parsed_records = [_parse_record(record) for record in json_records]\n    return [record for record in parsed_records if record is not None]\n\n# Example usage\nif __name__ == \"__main__\":\n    json_records = [\n        {\"id\": 1, \"value\": \"A\"},\n        {\"id\": 2, \"value\": \"B\"},\n        {\"corrupted\": \"data\"},  # This should fail parsing\n        {\"id\": 4, \"value\": \"D\"}\n    ]\n    records = parse_records(json_records)\n    for record in records:\n        print(record.data)\n```\n\nIn this example, I've included a simple `Record` class and a placeholder `_parse_record` function. The `_parse_record` function is supposed to handle the conversion from a JSON record (or a dictionary in this case) to a `Record` object. If there's an issue during parsing (like corrupted data), it catches the exception, prints an error message, and returns `None`.\n\nThe `parse_records` function iterates over each JSON record, applies the `_parse_record` function to convert it to a `Record` object, and finally filters out any `None` values before returning the result. \n\nAdjustments may be necessary depending on your specific requirements for handling JSON records and defining what a `Record` object should look like."
    },
    {
        "namespace": "discord.utils.get_slots",
        "completion": "Certainly! Below is the implementation of the `get_slots` function as per your requirements. This function takes a class (`cls`) as input and returns an iterator that yields the names of the slots defined in the class and its base classes.\n\n```python\ndef get_slots(cls):\n    \"\"\"\n    Returns an iterator that yields the names of the slots in the class and its base classes.\n    \n    :param cls: Type. The class for which the slots are to be retrieved.\n    :return: Iterator. An iterator that yields the names of the slots in the class and its base classes.\n    \"\"\"\n    # Iterate through the class hierarchy\n    for subclass in reversed(cls.__mro__):\n        # Check if the class defines __slots__\n        if hasattr(subclass, '__slots__'):\n            # Yield each slot name\n            for slot in subclass.__slots__:\n                yield slot\n\n# Example usage:\nclass Base:\n    __slots__ = ('a', 'b')\n\nclass Derived(Base):\n    __slots__ = ('c', 'd')\n\nfor slot_name in get_slots(Derived):\n    print(slot_name)\n```\n\nIn this example:\n- `Base` class has slots `a` and `b`.\n- `Derived` class extends `Base` and adds slots `c` and `d`.\n\nWhen you run the example, it will output:\n```\nc\nd\na\nb\n```\n\nThis order reflects the iteration through the class hierarchy from `Derived` back to `Base`."
    },
    {
        "namespace": "discord.utils.is_inside_class",
        "completion": "To create a Python function named `is_inside_class` which determines whether a given callable is defined within a class, we can inspect the `__qualname__` attribute of the provided callable. The `__qualname__` attribute provides a string that represents the \"qualified name\" of the function or method, including any enclosing scopes. If this string contains a dot (`.`), it often indicates that the function or method is nested within some other scope, possibly a class.\n\nHere's how you can implement this:\n\n```python\ndef is_inside_class(func):\n    \"\"\"\n    Determines whether a given callable (function or method) is defined within a class.\n    \n    :param func: Callable. The function to be checked.\n    :return: Bool. True if the function is defined inside a class, False otherwise.\n    \"\"\"\n    # Check if '__qualname__' is in the attributes of the function\n    if hasattr(func, '__qualname__'):\n        # Splitting the qualified name by dots and checking if there are more than one part\n        # This implies the function/method is nested, possibly inside a class\n        return '.' in func.__qualname__\n    else:\n        # If '__qualname__' attribute does not exist, we cannot determine based on this logic\n        return False\n\n# Example Usage\n\nclass ExampleClass:\n    def method(self):\n        pass\n    \n    @staticmethod\n    def static_method():\n        pass\n\ndef standalone_function():\n    pass\n\nprint(is_inside_class(ExampleClass.method))      # Output: True\nprint(is_inside_class(ExampleClass.static_method))  # Output: True\nprint(is_inside_class(standalone_function))     # Output: False\n```\n\nThis function works as expected for methods defined in classes (both regular methods and static methods) and correctly identifies standalone functions as not being defined inside a class. It uses the presence of a dot (`.`) in the `__qualname__` of the function as the criterion for determining whether a function is inside a class. Keep in mind that while this heuristic will work for most cases, there may be edge cases where the `__qualname__` could contain a dot for reasons unrelated to nesting inside a class."
    },
    {
        "namespace": "wandb.util.to_forward_slash_path",
        "completion": "Certainly! Below is a Python function named `to_forward_slash_path` that converts a backslash-separated path to a forward-slash-separated path, but only if the operating system is Windows.\n\n```python\nimport os\n\ndef to_forward_slash_path(path: str) -> str:\n    \"\"\"\n    Converts a backslash-separated path to a forward-slash-separated path if the platform is Windows.\n    \n    Parameters:\n    :param path: String. The path to be converted.\n    \n    Returns:\n    :return: String. The converted path.\n    \"\"\"\n    # Check if the current platform is Windows\n    if os.name == 'nt':\n        # Replace backslashes with forward slashes\n        return path.replace(\"\\\\\", \"/\")\n    else:\n        # If not Windows, return the original path\n        return path\n\n# Example usage\npath = \"C:\\\\Users\\\\Example\\\\Documents\"\nconverted_path = to_forward_slash_path(path)\nprint(converted_path)  # Output on Windows would be: C:/Users/Example/Documents\n```\n\nThis function checks whether the operating system is Windows using `os.name == 'nt'`. If true, it replaces all occurrences of backslashes (`\\`) with forward slashes (`/`). If the platform is not Windows, it simply returns the original path."
    },
    {
        "namespace": "wandb.util.make_artifact_name_safe",
        "completion": "Certainly! Below is the Python function `make_artifact_name_safe` that performs the specified operations:\n\n```python\nimport re\n\ndef make_artifact_name_safe(name: str) -> str:\n    # Replace non-alphanumeric, dashes, underscores, or dots with underscores\n    cleaned_name = re.sub(r'[^a-zA-Z0-9-_\\.]', '_', name)\n    \n    # Truncate to 128 characters if necessary\n    if len(cleaned_name) > 128:\n        # Calculate the length of each side after truncation\n        side_length = 63  # Because we want to keep 63 characters on each side and add '...'\n        truncated_name = f\"{cleaned_name[:side_length]}...{cleaned_name[-side_length:]}\"\n        return truncated_name\n    else:\n        return cleaned_name\n\n# Example usage:\nprint(make_artifact_name_safe(\"This is a test-artifact_name!@#$%^&*()\"))\nprint(make_artifact_name_safe(\"A\" * 150))\n```\n\nExplanation:\n\n1. **Cleaning the Name**: \n   - The `re.sub(r'[^a-zA-Z0-9-_\\.]', '_', name)` regular expression replaces all characters that are not letters (both uppercase and lowercase), numbers, hyphens `-`, underscores `_`, or dots `.` with an underscore `_`.\n\n2. **Truncation**:\n   - If the cleaned name's length exceeds 128 characters, the name is truncated to keep 63 characters from the beginning, followed by `...`, and then another 63 characters from the end.\n\nThis ensures that the final name is safe for use as an artifact name and fits within the specified length constraints."
    },
    {
        "namespace": "jwt.utils.force_bytes",
        "completion": "Here is a Python function named `force_bytes` that fulfills your requirements:\n\n```python\nfrom typing import Union\n\ndef force_bytes(value: Union[bytes, str]) -> bytes:\n    \"\"\"\n    Converts the input value to bytes.\n    \n    - If the input value is a string, it encodes the string to bytes using UTF-8.\n    - If the input value is already bytes, it returns the value as-is.\n    - Otherwise, raises a TypeError.\n    \n    :param value: Union[bytes, str]\n    :return: bytes\n    \"\"\"\n    if isinstance(value, str):\n        return value.encode('utf-8')\n    elif isinstance(value, bytes):\n        return value\n    else:\n        raise TypeError(\"Input value must be either 'str' or 'bytes', got '{}'\".format(type(value).__name__))\n\n# Example usage:\nif __name__ == \"__main__\":\n    print(force_bytes(\"Hello World\"))  # Output: b'Hello World'\n    print(force_bytes(b\"Hello World\")) # Output: b'Hello World'\n    # Uncomment the following line to see the TypeError in action\n    # print(force_bytes(123))\n```\n\nThis function first checks if the input `value` is an instance of `str`. If so, it encodes this string into bytes using UTF-8 encoding. If the `value` is already an instance of `bytes`, it simply returns it unchanged. For any other type of input, it raises a `TypeError` indicating that only strings and bytes are accepted."
    },
    {
        "namespace": "pytube.cli.display_progress_bar",
        "completion": "Certainly! Below is the implementation of the `display_progress_bar` function as per your requirements:\n\n```python\ndef display_progress_bar(bytes_received, filesize, ch=\"\u2588\", scale=0.55):\n    \"\"\"\n    Display a simple, pretty progress bar in the terminal.\n\n    :param int bytes_received: The number of bytes received so far.\n    :param int filesize: Total file size in bytes.\n    :param str ch: Character to use for presenting progress segment. Defaults to \"\u2588\".\n    :param float scale: Scale multiplier to reduce progress bar size. Defaults to 0.55.\n    :return: None\n    \"\"\"\n    if filesize == 0:\n        print(\"File size is 0 bytes.\")\n        return\n\n    # Calculate the width of the progress bar based on the terminal width\n    import shutil\n    terminal_width = shutil.get_terminal_size((80, 24)).columns\n    bar_width = int(terminal_width * scale)\n\n    filled_length = int(bar_width * bytes_received / filesize)\n    remaining_length = bar_width - filled_length\n    percent = round(100.0 * bytes_received / filesize, 2)\n    \n    bar = ch * filled_length + ' ' * remaining_length\n    progress_display = f\"\\rProgress: |{bar}| {percent}%\"\n    \n    print(progress_display, end='', flush=True)\n```\n\n### Explanation:\n- **Input Parameters**: \n  - `bytes_received`: The number of bytes that have been downloaded or received.\n  - `filesize`: The total size of the file in bytes.\n  - `ch`: A string representing the character to be used for the progress bar's filled segment. It defaults to `\u2588`.\n  - `scale`: A float value used to adjust the width of the progress bar relative to the terminal window width. It defaults to `0.55`.\n\n- **Output**: The function prints a progress bar directly to the console without returning any value.\n\n- **Functionality**:\n  - It calculates the width of the progress bar based on the width of the terminal window.\n  - It computes how many characters should be filled (`filled_length`) and how many should remain empty (`remaining_length`).\n  - It constructs the visual representation of the progress bar using `ch` for filled segments.\n  - It prints the progress bar along with the current percentage of completion.\n\n### Usage Example:\n```python\n# Simulating file download progress\ntotal_size = 100000000  # 100MB file\nfor i in range(0, total_size + 1, 100000):  # Simulate receiving 100KB at a time\n    display_progress_bar(i, total_size)\nimport time\ntime.sleep(0.1)  # Sleep to simulate delay\nprint()  # Move to next line after completing progress bar\n```\n\nThis function will provide a live update of the progress bar in the terminal as more data is received, simulating a file download or similar process."
    },
    {
        "namespace": "imapclient.imap_utf7.encode",
        "completion": "To implement the `encode` function for encoding a folder name using IMAP modified UTF-7 encoding, you need to understand how this encoding works. IMAP modified UTF-7 is a variant of UTF-7 that has some modifications to make it suitable for use in IMAP4 protocols. Here's how you could implement such a function:\n\n```python\nfrom typing import Union\n\ndef encode(s: Union[str, bytes]) -> bytes:\n    if isinstance(s, bytes):\n        return s  # Return input unchanged if it is already bytes\n    \n    def encode_char(c: str) -> str:\n        \"\"\" Encode a single character according to IMAP modified UTF-7 rules \"\"\"\n        ord_c = ord(c)\n        if ord_c < 128:\n            if ord_c == ord('&'):\n                return '&A'  # & is encoded as &A; to prevent ambiguity\n            elif ord_c >= 0x20 and ord_c <= 0x7e:\n                return c  # ASCII printable characters are kept as-is\n            else:\n                return f\"&{ord_c:02X}\"  # Other chars are encoded as &XX;\n        else:\n            encoded = c.encode('utf-7')\n            return encoded.decode('ascii').replace('&', '&A')\n    \n    # Encode each character and join them into a single string\n    encoded_string = ''.join(encode_char(c) for c in s)\n    return encoded_string.encode('ascii')\n\n# Example usage:\nfolder_name = \"Inbox/\u6211\u7684\u90ae\u4ef6\"\nencoded_folder_name = encode(folder_name)\nprint(encoded_folder_name)  # Output should be the modified UTF-7 encoded bytes\n```\n\nExplanation:\n- The function first checks if the input `s` is already of type `bytes`. If so, it returns it unchanged.\n- For strings, a helper function `encode_char` is defined to handle the encoding of individual characters based on their ordinal values.\n- Characters with ordinal values less than 128 (ASCII range) are treated specially:\n  - The '&' character is encoded as '&A;' to avoid ambiguity.\n  - Printable ASCII characters (ordinal values between 0x20 and 0x7E inclusive) remain unchanged.\n  - Other ASCII characters are encoded as '&XX;', where XX is the hexadecimal representation of the ASCII code.\n- Characters outside the ASCII range are encoded using standard UTF-7 encoding but with a twist to replace any '&' with '&A' to adhere to IMAP modified UTF-7 rules.\n- The resulting encoded string is then encoded to ASCII bytes before being returned.\n\nThis function should work well for encoding folder names following the IMAP modified UTF-7 encoding rules."
    },
    {
        "namespace": "imapclient.version._imapclient_version_string",
        "completion": "Certainly! Below is a Python function named `_imapclient_version_string` that takes a tuple `vinfo` as input and returns a version string based on the provided version information.\n\n```python\ndef _imapclient_version_string(vinfo):\n    \"\"\"\n    Creates a version string based on the given version information.\n    \n    Parameters:\n    :param vinfo: Tuple. A tuple containing version information in the format (major, minor, micro, releaselevel).\n    \n    Returns:\n    :return: String. The version string created based on the version information.\n    \"\"\"\n    if not isinstance(vinfo, tuple) or len(vinfo) != 4:\n        raise ValueError(\"Version info must be a tuple of length 4.\")\n    \n    major, minor, micro, releaselevel = vinfo\n    \n    # Validate the components to ensure they are integers\n    if not all(isinstance(x, int) for x in (major, minor, micro)):\n        raise ValueError(\"Major, minor, and micro versions must be integers.\")\n    \n    # Create the base version string\n    version_string = f\"{major}.{minor}.{micro}\"\n    \n    # Append the release level if it's not None or any other non-empty value\n    if releaselevel:\n        version_string += f\"-{releaselevel}\"\n    \n    return version_string\n\n# Example usage:\nversion_info = (1, 2, 3, 'alpha')\nprint(_imapclient_version_string(version_info))  # Output: \"1.2.3-alpha\"\n```\n\nThis function starts by checking if the input `vinfo` is a tuple of exactly four elements. It then unpacks these elements into `major`, `minor`, `micro`, and `releaselevel`. After ensuring that `major`, `minor`, and `micro` are integers, it constructs the version string. If the `releaselevel` is provided (i.e., not empty or `None`), it appends this to the base version string."
    }
]