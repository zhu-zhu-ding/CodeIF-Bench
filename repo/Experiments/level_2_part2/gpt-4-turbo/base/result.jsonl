[
    {
        "namespace": "prometheus_client.mmap_dict.MmapedDict.read_value",
        "completion": "def read_value(self, key):\n    \"\"\"\n    Read the value corresponding to the given key from the MmapedDict instance.\n    If the key is not found in the instance, it initializes the value and then returns it.\n\n    :param self: MmapedDict. An instance of the MmapedDict class.\n    :param key: The key to read the value from the instance.\n    :return: The value corresponding to the key.\n    \"\"\"\n    if key not in self._positions:\n        self._init_value(key)\n        return 0.0  # Assuming default initialized value is 0.0\n\n    pos = self._positions[key]\n    value, timestamp = _unpack_two_doubles(self._m, pos)\n    return value"
    },
    {
        "namespace": "boto.ec2.securitygroup.SecurityGroup.add_rule",
        "completion": "```python\ndef add_rule(self, ip_protocol, from_port, to_port, src_group_name, src_group_owner_id, cidr_ip, src_group_group_id, dry_run=False):\n    \"\"\"\n    Add a rule to the SecurityGroup object. Note that this method\n    only changes the local version of the object. No information\n    is sent to EC2.\n    \"\"\"\n    if dry_run:\n        print(\"Dry run enabled. No changes will be made.\")\n        return\n\n    # Create a new IPPermissions object\n    new_permission = IPPermissions()\n    new_permission.ip_protocol = ip_protocol\n    new_permission.from_port = from_port\n    new_permission.to_port = to_port\n\n    # Create a new GroupOrCIDR object for the grant\n    new_grant = GroupOrCIDR()\n    new_grant.name = src_group_name\n    new_grant.owner_id = src_group_owner_id\n    new_grant.cidr_ip = cidr_ip\n    new_grant.group_id = src_group_group_id\n\n    # Add the grant to the permissions\n    new_permission.grants.append(new_grant)\n\n    # Add the new permission to the rules list\n    self.rules.append(new_permission)\n    print(f\"Rule added: {new_permission}\")\n```"
    },
    {
        "namespace": "bentoml._internal.runner.container.DefaultContainer.from_batch_payloads",
        "completion": "Here is the implementation of the `from_batch_payloads` function for the `DefaultContainer` class:\n\n```python\nclass DefaultContainer(DataContainer[t.Any, t.List[t.Any]]):\n    @classmethod\n    def from_batch_payloads(\n        cls, payloads: t.Sequence[Payload], batch_dim: int = 0\n    ) -> tuple[list[t.Any], list[int]]:\n        # Convert each payload back to its original data form\n        batches = [cls.from_payload(payload) for payload in payloads]\n        \n        # Combine all batches into a single batch\n        combined_batch, indices = cls.batches_to_batch(batches, batch_dim)\n        \n        return combined_batch, indices\n```\n\nThis function takes a sequence of `Payload` objects and converts each payload back to its original data form using the `from_payload` method. It then combines all these batches into a single batch using the `batches_to_batch` method, and returns the combined batch along with a list of indices that represent the batch sizes."
    },
    {
        "namespace": "sqlitedict.SqliteDict.commit",
        "completion": "```python\ndef commit(self, blocking=True):\n    \"\"\"\n    Commit all data in the SqliteDict instance to disk. This commits the changes made to the database.\n    If `blocking` is set to False, the commit command is queued but the data is not guaranteed to be persisted immediately.\n\n    :param blocking: Whether to block until the commit is complete. Defaults to True.\n    \"\"\"\n    self.conn.commit(blocking=blocking)\n```"
    },
    {
        "namespace": "alembic.operations.ops.DropColumnOp.from_column_and_tablename",
        "completion": "Here is the function `from_column_and_tablename` that you requested:\n\n```python\n@classmethod\ndef from_column_and_tablename(cls, schema, tname, col):\n    return cls(tname, col, schema=schema)\n```\n\nThis function is a class method that creates an instance of the class it belongs to, using the provided table name, column, and optional schema. The parameters are used to initialize the instance with the appropriate attributes."
    },
    {
        "namespace": "pyramid.i18n.Translations.add",
        "completion": "def add(self, translations, merge=True):\n    \"\"\"\n    Add the given translations to the catalog. If the domain of the translations\n    is different from the current catalog, they are added as a separate catalog.\n    It also provides the option to merge translations for message domains that\n    have already been added.\n\n    :param self: Translations. An instance of the Translations class.\n    :param translations: Translations. The Translations instance with the messages to add.\n    :param merge: Bool. Whether translations for message domains that have already been added\n                  should be merged with the existing translations. Defaults to True.\n    :return: Translations. The Translations instance (self) so that merge calls can be easily chained.\n    \"\"\"\n    if translations.domain not in self._domains:\n        # If the domain is not already in the catalog, add it as a new domain\n        self._domains[translations.domain] = translations\n    elif merge:\n        # If the domain exists and merging is allowed, merge the translations\n        existing_translations = self._domains[translations.domain]\n        existing_translations.merge(translations)\n    return self"
    },
    {
        "namespace": "pythonforandroid.prerequisites.OpenSSLPrerequisite.darwin_checker",
        "completion": "```python\ndef darwin_checker(self):\n    \"\"\"\n    Check if the OpenSSL prerequisite is met on a Darwin (MacOS) system.\n    It checks if the Homebrew formula for OpenSSL is installed.\n    \n    :param self: OpenSSLPrerequisite. An instance of the OpenSSLPrerequisite class.\n    :return: bool. True if the OpenSSL prerequisite is met, False otherwise.\n    \"\"\"\n    # Check if the Homebrew formula for OpenSSL is installed\n    formula_prefix = self._darwin_get_brew_formula_location_prefix(self.homebrew_formula_name, installed=True)\n    if formula_prefix is not None:\n        info(f\"OpenSSL is installed at {formula_prefix}\")\n        return True\n    else:\n        error(\"OpenSSL is not installed.\")\n        return False\n```"
    },
    {
        "namespace": "boltons.cacheutils.LRI.pop",
        "completion": "def pop(self, key, default=_UNSET):\n    try:\n        value = self[key]\n        del self[key]\n        return value\n    except KeyError:\n        if default is _UNSET:\n            raise\n        return default"
    },
    {
        "namespace": "imapclient.imapclient.IMAPClient.expunge",
        "completion": "Here is the implementation of the `expunge` function based on the provided context:\n\n```python\ndef expunge(self, messages=None):\n    \"\"\"\n    Expunge messages from the selected folder in an IMAP client.\n    If no messages are specified, it removes all messages with the \"\\Deleted\" flag set.\n    If messages are specified, it removes the specified messages with the \"\\Deleted\" flag set.\n    The function returns the server response message followed by a list of expunge responses.\n    The implementation takes into account whether the client is using UIDs or not.\n\n    :param self: IMAPClient. An instance of the IMAPClient class.\n    :param messages: List of int or str. The messages to be expunged. Defaults to None.\n    :return: Tuple. The server response message followed by a list of expunge responses if no messages are specified. None if messages are specified.\n    \"\"\"\n    if messages:\n        if self.use_uid:\n            return self.uid_expunge(messages)\n        else:\n            # Convert message IDs to sequence set\n            sequence_set = ','.join(str(msg) for msg in messages)\n            return self._command_and_check('EXPUNGE', sequence_set, uid=False)\n    else:\n        # No specific messages, expunge all deleted messages\n        typ, data = self._imap.expunge()\n        self._checkok('expunge', typ, data)\n        return data\n```\n\nThis function is designed to be a method of the `IMAPClient` class. It uses the `uid_expunge` method if the client is using UIDs and the messages are specified. If no messages are specified, it calls the `expunge` method on the `imaplib.IMAP4` object to remove all messages with the `\\Deleted` flag set. The function checks the server response to ensure the command was successful and returns the appropriate data based on whether specific messages were provided."
    },
    {
        "namespace": "mopidy.ext.load_extensions",
        "completion": "def load_extensions() -> List[ExtensionData]:\n    installed_extensions = []\n\n    for entry_point in pkg_resources.iter_entry_points(\"mopidy.ext\"):\n        try:\n            extension_class = entry_point.load()\n            if not issubclass(extension_class, Extension):\n                logger.warning(\n                    \"Entry point %s does not point to a valid Mopidy Extension class.\",\n                    entry_point.name,\n                )\n                continue\n        except Exception:\n            logger.exception(\n                \"Failed to load extension from entry point %s.\", entry_point.name\n            )\n            continue\n\n        extension_instance = extension_class()\n        config_schema = extension_instance.get_config_schema()\n        config_defaults = config_lib.parse(extension_instance.get_default_config())\n        command = extension_instance.get_command()\n\n        extension_data = ExtensionData(\n            extension=extension_instance,\n            entry_point=entry_point,\n            config_schema=config_schema,\n            config_defaults=config_defaults,\n            command=command,\n        )\n\n        if validate_extension_data(extension_data):\n            installed_extensions.append(extension_data)\n        else:\n            logger.info(\n                \"Extension %s did not pass validation and will not be loaded.\",\n                extension_instance.ext_name,\n            )\n\n    return installed_extensions"
    },
    {
        "namespace": "wikipediaapi.WikipediaPage.section_by_title",
        "completion": "Here is the `section_by_title` function that you requested:\n\n```python\ndef section_by_title(self, title: str) -> Optional[WikipediaPageSection]:\n    \"\"\"\n    Returns the last section of the current Wikipedia page with the given title.\n    \n    :param title: The title of the section to retrieve.\n    :return: The last section of the current page with the given title, or None if no such section exists.\n    \"\"\"\n    if not self._called[\"extracts\"]:\n        self._fetch(\"extracts\")\n    \n    sections = self._section_mapping.get(title)\n    if sections:\n        return sections[-1]\n    return None\n```\n\nThis function should be added as a method to the `WikipediaPage` class. It checks if the extracts data has been fetched, fetches it if necessary, and then retrieves the sections with the given title from the section mapping. If there are sections with the given title, it returns the last section; otherwise, it returns `None`."
    },
    {
        "namespace": "csvkit.cli.CSVKitUtility.run",
        "completion": "def run(self):\n    \"\"\"\n    Wrapper around the main loop of a utility that handles opening and closing files.\n    \"\"\"\n    input_file = None\n\n    # Check if 'f' flag is not present in the override flags\n    if 'f' not in self.override_flags:\n        # Open the input file if the 'f' flag is not present\n        input_file = self._open_input_file(self.args.input_path)\n        self.input_file = input_file\n\n    # Execute the main loop of the utility\n    try:\n        if self.args.no_header_row:\n            # Ignore warnings related to column names if no_header_row option is present\n            with warnings.catch_warnings():\n                warnings.simplefilter(\"ignore\")\n                self.main()\n        else:\n            self.main()\n    finally:\n        # Close the input file if it was opened and 'f' flag is not present\n        if input_file and 'f' not in self.override_flags:\n            input_file.close()"
    },
    {
        "namespace": "prometheus_client.mmap_dict.MmapedDict.write_value",
        "completion": "def write_value(self, key: str, value: float, timestamp: float):\n    if key not in self._positions:\n        self._init_value(key)\n    pos = self._positions[key]\n    _pack_two_doubles(self._m, pos, value, timestamp)"
    },
    {
        "namespace": "mopidy.config.types.LogLevel.serialize",
        "completion": "```python\ndef serialize(self, value, display=False):\n    \"\"\"\n    Serialize a value based on the LogLevel instance.\n    It looks up the value in the levels dictionary and returns the corresponding key.\n    If the value is not found, it returns an empty string.\n\n    :param self: LogLevel. An instance of the LogLevel class.\n    :param value: The value to be serialized.\n    :param display: Bool. Whether to display the serialized value. Defaults to False.\n    :return: String. The serialized value or an empty string if the value is not found.\n    \"\"\"\n    for key, val in self.levels.items():\n        if val == value:\n            return key if not display else f\"Serialized LogLevel: {key}\"\n    return \"\"\n```"
    },
    {
        "namespace": "playhouse.kv.KeyValue.pop",
        "completion": "def pop(self, key, default=Sentinel):\n    with self._database.atomic():\n        try:\n            value = self[key]\n            del self[key]\n            return value\n        except KeyError:\n            if default is Sentinel:\n                raise\n            return default"
    },
    {
        "namespace": "asyncssh.public_key.SSHKey.convert_to_public",
        "completion": "The function `convert_to_public` is designed to convert an SSHKey object containing a private key into an object containing only the corresponding public key. This function is a method of the SSHKey class, and it operates by extracting the public key data from the private key object, ensuring that only the public key information is retained. The function then returns the new SSHKey object containing only the public key.\n\nHere's the implementation of the `convert_to_public` function:\n\n```python\ndef convert_to_public(self):\n    \"\"\"Convert an SSHKey object with a private key to one with only the public key.\"\"\"\n    if self._key is None:\n        raise ValueError(\"No private key available to convert to public key.\")\n    \n    # Extract public key data from the private key\n    public_key_data = self.public_data\n    \n    # Create a new SSHKey object with the public key data\n    public_key = SSHKey()\n    public_key.algorithm = self.algorithm\n    public_key._key = None  # Ensure no private key is included\n    public_key._comment = self._comment\n    public_key._filename = self._filename\n    \n    # Assign public key data\n    public_key.public_data = public_key_data\n    \n    return public_key\n```\n\nThis method should be added to the SSHKey class. It checks if the private key is available, extracts the public key data, and constructs a new SSHKey object that contains only the public key data. The new object retains the same algorithm, comment, and filename as the original but ensures that the private key data is not included."
    },
    {
        "namespace": "rows.fields.DateField.deserialize",
        "completion": "def deserialize(cls, value, *args, **kwargs):\n    # First, call the parent class's deserialize method\n    value = super(DateField, cls).deserialize(value, *args, **kwargs)\n    \n    # Check if the value is already None or an instance of allowed type\n    if value is None or isinstance(value, cls.TYPE):\n        return value\n    \n    # Convert the value into a string and parse it into a datetime object\n    value_str = str(value)\n    try:\n        datetime_obj = datetime.datetime.strptime(value_str, cls.INPUT_FORMAT)\n    except ValueError:\n        raise ValueError(f\"Value '{value_str}' does not match format '{cls.INPUT_FORMAT}'\")\n    \n    # Create a new date object using the year, month, and day attributes\n    return datetime.date(datetime_obj.year, datetime_obj.month, datetime_obj.day)"
    },
    {
        "namespace": "rows.fields.EmailField.deserialize",
        "completion": "def deserialize(cls, value, *args, **kwargs):\n        value = super(EmailField, cls).deserialize(value, *args, **kwargs)\n        if value is None or value == \"\":\n            return None\n\n        match = cls.EMAIL_REGEXP.match(value)\n        if match:\n            return match.group(0)\n        else:\n            raise ValueError(\"Invalid email format\")"
    },
    {
        "namespace": "playhouse.dataset.DataSet.freeze",
        "completion": "def freeze(self, query, format='csv', filename=None, file_obj=None, encoding='utf8', **kwargs):\n    self._check_arguments(filename, file_obj, format, self._export_formats)\n    \n    if filename:\n        file_obj = open_file(filename, 'w', encoding)\n    \n    exporter = self._export_formats[format](query)\n    exporter.export(file_obj, **kwargs)\n    \n    if filename:\n        file_obj.close()"
    },
    {
        "namespace": "pycoin.message.PeerAddress.PeerAddress.host",
        "completion": "```python\ndef host(self):\n    if self.ip_bin.startswith(IP4_HEADER):\n        return ip_bin_to_ip4_addr(self.ip_bin)\n    else:\n        return ip_bin_to_ip6_addr(self.ip_bin)\n```"
    }
]